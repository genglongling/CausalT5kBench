[
  {
    "id": "T3-BucketD-0001",
    "case_id": "0001",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Baseball Analytics",
    "scenario": "A baseball shortstop is famous for his spectacular diving catches and jump-throws, leading fans to label him an 'Elite Defender'. However, advanced metrics rank him in the bottom 10% of the league, revealing that he reaches far fewer balls than the average player.",
    "claim": "The frequent diving catches prove that the player has elite defensive range and skill.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Spectacular Diving Catches",
        "role": "exposure"
      },
      "Y": {
        "name": "Perception of Elite Defense",
        "role": "outcome"
      },
      "Z": [
        "Range Factor / Balls reached (Full Data)"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Availability Bias",
      "subtype": "Salience / Visibility Bias",
      "subtype_name": "Salience / Visibility Bias"
    },
    "difficulty": "Medium",
    "causal_structure": "Slow_Speed -> Necessity_to_Dive(X); X -> Y (Inference); Z (Full_Data) -> Poor_Defense.",
    "key_insight": "Spectacular effort (X) is often a symptom of poor positioning or speed, not elite skill; invisible errors (balls not reached) are ignored.",
    "hidden_timestamp": "Fans form the belief (Y) based on a highlight reel of X accumulated over time, ignoring the non-events (balls not reached) in Z.",
    "conditional_answers": {
      "answer_if_condition_1": "If we only observe the selected/surviving sample, the pattern appears valid.",
      "answer_if_condition_2": "If we account for the missing data, the causal claim is not justified."
    },
    "wise_refusal": "This inference commits the Availability Bias. Diving catches (X) are visually spectacular and memorable, leading observers to overestimate the player's skill (Y). However, the full data (Z) reveals that he dives because he lacks the speed to reach balls while standing up. He is actually a poor defender who turns routine plays into difficult highlights, while missing many other balls entirely.",
    "gold_rationale": "This inference commits the Availability Bias. Diving catches (X) are visually spectacular and memorable, leading observers to overestimate the player's skill (Y). However, the full data (Z) reveals that he dives because he lacks the speed to reach balls while standing up. He is actually a poor defender who turns routine plays into difficult highlights, while missing many other balls entirely.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketD-0002",
    "case_id": "0002",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Sports Media / Superstition",
    "scenario": "A prestigious sports magazine features five 'Breakout Stars' on its cover after they averaged 35 points per game in the first month of the season. By the end of the season, all five players saw their averages drop significantly to 24 points. Fans and media claim the 'Cover Curse' jinxed their performance.",
    "claim": "Appearing on the magazine cover caused the players' performance to decline.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Magazine Cover Selection",
        "role": "exposure"
      },
      "Y": {
        "name": "End of Season Average",
        "role": "outcome"
      },
      "Z": [
        "\"Cover Curse\" (Spurious Attribution)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Peak Selection Regression",
      "subtype_name": "Peak Selection Regression"
    },
    "difficulty": "Easy",
    "causal_structure": "True_Skill -> X; Hot_Streak_Variance -> X; True_Skill -> Y; Variance_Normalizes -> Y; No causal link Cover(X) -> Performance_Drop(Y).",
    "key_insight": "Magazine covers select players at their statistical peak; regression to the mean makes a decline in performance the most probable future outcome.",
    "hidden_timestamp": "The selection for the cover (X) happens during a period of extreme positive variance. The subsequent performance (Y) is observed over a longer timeline where variance normalizes.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The 'Cover Curse' is a classic example of Regression to the Mean. Players are selected for the cover (X) specifically because they are performing at an unsustainable peak (an outlier event driven by skill plus a 'hot streak'). It is statistically inevitable that their performance will regress toward their career average (Y) in the following months. The magazine didn't cause the decline; it simply captured the peak before the natural fall.",
    "gold_rationale": "The 'Cover Curse' is a classic example of Regression to the Mean. Players are selected for the cover (X) specifically because they are performing at an unsustainable peak (an outlier event driven by skill plus a 'hot streak'). It is statistically inevitable that their performance will regress toward their career average (Y) in the following months. The magazine didn't cause the decline; it simply captured the peak before the natural fall.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0003",
    "case_id": "0003",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Tennis Analytics",
    "scenario": "In a Grand Slam final, a tennis player wins 15 consecutive points on their serve without making a single unforced error. Commentators declare the player has entered 'God Mode' and is visibly invincible. In the very next service game, the player double-faults twice and loses the game to love.",
    "claim": "The streak of 15 points indicates a shift in causal state ('God Mode') that guarantees continued dominance in the next game.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "15 Consecutive Points Won",
        "role": "exposure"
      },
      "Y": {
        "name": "Subsequent Service Game Loss",
        "role": "outcome"
      },
      "Z": [
        "\"God Mode\" / Psychological Flow (Hypothesized State)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Outcome Bias",
      "subtype": "Hot Hand Fallacy / Clustering Illusion",
      "subtype_name": "Hot Hand Fallacy / Clustering Illusion"
    },
    "difficulty": "Hard",
    "causal_structure": "Base_Skill -> Point_t(X); Base_Skill -> Point_t+1(Y); Points are largely independent; No causal link X -> Y.",
    "key_insight": "In probabilistic domains, clusters of success (X) appear naturally and do not imply a persistent state shift (Z) that overrides variance.",
    "hidden_timestamp": "The inference is made at the peak of the streak (X), assuming the state Z persists to time t+1 (Y).",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The belief in 'God Mode' (Z) commits the Hot Hand Fallacy. While tennis involves psychological momentum, individual points are statistically independent events governed by the player's base skill level. A streak of 15 points (X) is a rare but expected cluster in a long match. It does not causally alter the physics or probability of the next serve. The subsequent loss (Y) demonstrates that the 'invincible state' was likely an illusion of variance.",
    "gold_rationale": "The belief in 'God Mode' (Z) commits the Hot Hand Fallacy. While tennis involves psychological momentum, individual points are statistically independent events governed by the player's base skill level. A streak of 15 points (X) is a rare but expected cluster in a long match. It does not causally alter the physics or probability of the next serve. The subsequent loss (Y) demonstrates that the 'invincible state' was likely an illusion of variance.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0004",
    "case_id": "0004",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Sports Betting",
    "scenario": "In the Super Bowl, the NFC representative has won the pre-game coin toss for 5 consecutive years. A bettor places a large wager on the NFC team to win the coin toss again, arguing that 'the NFC has the momentum' in coin flips.",
    "claim": "The 5-year winning streak increases the probability that the NFC will win the next coin toss.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "5-Year Coin Toss Winning Streak",
        "role": "exposure"
      },
      "Y": {
        "name": "Next Coin Toss Outcome",
        "role": "outcome"
      },
      "Z": [
        "Physical Independence / Fair Coin (Mechanism)"
      ]
    },
    "trap": {
      "type": "W5",
      "type_name": "Fallacy",
      "subtype": "Gambler's Fallacy / Hot Hand",
      "subtype_name": "Gambler's Fallacy / Hot Hand"
    },
    "difficulty": "Easy",
    "causal_structure": "Coin_Flip_Year_t(X) _||_ Coin_Flip_Year_t+1(Y); Events are independent; No causal path X -> Y.",
    "key_insight": "Past streaks in random processes do not influence future trials; the coin has no memory.",
    "hidden_timestamp": "The streak (X) is observed over the past 5 years. The prediction (Y) is for the immediate future. There is no physical connection between the coins used in different years.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "The historical streak (X) has no causal influence on the physics of the next coin toss (Y). Assuming the coin is fair, the events are independent (Z). Believing that a streak changes the underlying probability of a random binary event is a fallacy. The odds remain 50/50 regardless of the past outcomes.",
    "gold_rationale": "The historical streak (X) has no causal influence on the physics of the next coin toss (Y). Assuming the coin is fair, the events are independent (Z). Believing that a streak changes the underlying probability of a random binary event is a fallacy. The odds remain 50/50 regardless of the past outcomes.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0005",
    "case_id": "0005",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Basketball Analytics",
    "scenario": "A basketball analyst looks at a season's worth of shot chart data for a player and identifies three specific spots on the floor where made shots are tightly clustered. The analyst concludes these are the player's 'Sweet Spots' and advises the coach to design plays specifically for these locations. However, a spatial randomness test reveals the distribution of shots is statistically indistinguishable from a random scatter.",
    "claim": "The clusters of made shots on the chart indicate specialized skill or 'Sweet Spots' at those specific locations.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Spatial Clusters of Made Shots",
        "role": "exposure"
      },
      "Y": {
        "name": "Inference of \"Sweet Spots\"",
        "role": "outcome"
      },
      "Z": [
        "Random Spatial Distribution (Null Hypothesis)"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Clustering Illusion",
      "subtype": "Spatial Pattern Perception",
      "subtype_name": "Spatial Pattern Perception"
    },
    "difficulty": "Medium",
    "causal_structure": "Random_Spatial_Process(Z) -> Spatial_Clusters(X); X -> Inference_of_Skill(Y); No causal link Special_Skill -> X.",
    "key_insight": "Humans perceive clusters in random spatial data as meaningful signals; true skill requires deviation from random scatter.",
    "hidden_timestamp": "The clusters (X) are observed retrospectively. The inference (Y) assumes these clusters predict future success at those spots better than the player's general average, which is false under Z.",
    "conditional_answers": {
      "answer_if_condition_1": "If we only observe the selected/surviving sample, the pattern appears valid.",
      "answer_if_condition_2": "If we account for the missing data, the causal claim is not justified."
    },
    "wise_refusal": "The identification of 'Sweet Spots' here is likely a Clustering Illusion. Random spatial data naturally forms clumps or clusters (X) that the human eye interprets as meaningful patterns. Since the data is indistinguishable from random scatter (Z), these clusters do not represent a stable skill advantage (Y). Attributing special significance to these random coordinates ignores the nature of stochastic processes.",
    "gold_rationale": "The identification of 'Sweet Spots' here is likely a Clustering Illusion. Random spatial data naturally forms clumps or clusters (X) that the human eye interprets as meaningful patterns. Since the data is indistinguishable from random scatter (Z), these clusters do not represent a stable skill advantage (Y). Attributing special significance to these random coordinates ignores the nature of stochastic processes.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketD-0006",
    "case_id": "0006",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Business",
    "subdomain": "Gaming Industry",
    "scenario": "An indie game studio's debut release went viral and sold 10 million copies, winning 'Game of the Year'. Three years later, their highly anticipated sequel sold only 500,000 copies and received average reviews. Gaming forums are flooded with comments claiming the developers 'sold out' and 'lost their passion' after getting rich.",
    "claim": "The developers 'lost their passion' or 'sold out' (Z), causing the decline in the sequel's performance.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Viral Debut Hit",
        "role": "exposure"
      },
      "Y": {
        "name": "Average Sequel Performance",
        "role": "outcome"
      },
      "Z": [
        "\"Lost Passion\" / \"Sold Out\" (Attribution)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Viral Success Regression",
      "subtype_name": "Viral Success Regression"
    },
    "difficulty": "Easy",
    "causal_structure": "Dev_Skill -> X; Viral_Market_Timing -> X; Dev_Skill -> Y; Normal_Market_Timing -> Y; Z (Behavioral_Change) -> Y is spurious; No causal link X -> Y.",
    "key_insight": "A viral hit is a statistical outlier combining quality with perfect timing; regression to the mean is the expected outcome for the next project.",
    "hidden_timestamp": "The viral hit (X) creates a high baseline expectation at t=1. The sequel (Y) at t=2 faces independent market variance.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The decline in sales is a classic case of Regression to the Mean. The debut's massive success (X) was an outlier driven by skill combined with exceptional, non-repeatable viral luck (timing, streamer attention). The sequel's performance (Y) represents a return to the studio's realistic baseline. Claiming they 'lost passion' (Z) falsely attributes a statistical inevitability to a behavioral change.",
    "gold_rationale": "The decline in sales is a classic case of Regression to the Mean. The debut's massive success (X) was an outlier driven by skill combined with exceptional, non-repeatable viral luck (timing, streamer attention). The sequel's performance (Y) represents a return to the studio's realistic baseline. Claiming they 'lost passion' (Z) falsely attributes a statistical inevitability to a behavioral change.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0007",
    "case_id": "0007",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Finance",
    "subdomain": "Investment Management",
    "scenario": "A hedge fund manager achieved a 200% return in 2024, outperforming the market by a massive margin. Financial news outlets labeled him the next 'Oracle of Investing'. In 2025, using the same strategy, the fund lost 40% of its value.",
    "claim": "The manager is an 'Oracle' (Z), so the 2025 loss must be due to external manipulation or a sudden loss of skill.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "200% Return in Year 1",
        "role": "exposure"
      },
      "Y": {
        "name": "40% Loss in Year 2",
        "role": "outcome"
      },
      "Z": [
        "\"Oracle\" Status (Attributed Trait)"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "Survivorship",
      "subtype": "Single Data Point Bias",
      "subtype_name": "Single Data Point Bias"
    },
    "difficulty": "Medium",
    "causal_structure": "High_Risk_Taking -> X; Market_Tailwind -> X; High_Risk_Taking -> Y; Market_Headwind -> Y; Z (Skill) is over-inferred from X; No causal link X -> Y.",
    "key_insight": "Extreme returns in a single year often reflect high risk exposure rather than skill; N=1 is not a valid sample size for evaluating an investor.",
    "hidden_timestamp": "The label 'Oracle' (Z) is applied at t=1 based on X. The loss (Y) occurs at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "Labeling the manager an 'Oracle' (Z) based on a single year of performance (X) is a Single Data Point fallacy. A 200% return is statistically likely to be the result of aggressive risk-taking combined with lucky market conditions. The subsequent crash (Y) is not a loss of skill, but the downside of that same risk profile manifesting when luck normalizes. One data point cannot distinguish genius from a gambler.",
    "gold_rationale": "Labeling the manager an 'Oracle' (Z) based on a single year of performance (X) is a Single Data Point fallacy. A 200% return is statistically likely to be the result of aggressive risk-taking combined with lucky market conditions. The subsequent crash (Y) is not a loss of skill, but the downside of that same risk profile manifesting when luck normalizes. One data point cannot distinguish genius from a gambler.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0008",
    "case_id": "0008",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Business",
    "subdomain": "Human Resources",
    "scenario": "A large corporation identified the bottom 10% of its sales force based on last year's revenue and mandated they attend a 'High Performance Bootcamp'. In the following year, this group's average revenue increased by 20%. The HR director concludes the bootcamp was a massive success.",
    "claim": "The 'High Performance Bootcamp' caused the 20% increase in revenue for the low-performing salespeople.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Bottom 10% Sales Performance",
        "role": "exposure"
      },
      "Y": {
        "name": "Revenue Increase",
        "role": "outcome"
      },
      "Z": [
        "Bootcamp Intervention (Ambiguous Cause)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Bottom Selection / Trough Regression",
      "subtype_name": "Bottom Selection / Trough Regression"
    },
    "difficulty": "Medium",
    "causal_structure": "Sales_Skill -> X; Bad_Market_Luck -> X; Sales_Skill -> Y; Normal_Market_Luck -> Y; Bootcamp(Z) -> Y is confounded by selection on Low(X); E[Y|X=Low] > X.",
    "key_insight": "Interventions targeting the bottom of a distribution will appear successful due to natural regression, even if the intervention is useless.",
    "hidden_timestamp": "Selection X occurs at t=1 (nadir). Outcome Y is measured at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The conclusion is flawed due to Regression to the Mean. By selecting the bottom 10% (X), the company isolated a group suffering from negative variance (bad territories, bad luck). Statistically, this group's performance would naturally improve (Y) in the next period as variance normalizes. Without a control group of similarly poor performers who *didn't* take the bootcamp, we cannot attribute the recovery to the training (Z).",
    "gold_rationale": "The conclusion is flawed due to Regression to the Mean. By selecting the bottom 10% (X), the company isolated a group suffering from negative variance (bad territories, bad luck). Statistically, this group's performance would naturally improve (Y) in the next period as variance normalizes. Without a control group of similarly poor performers who *didn't* take the bootcamp, we cannot attribute the recovery to the training (Z).",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0009",
    "case_id": "0009",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Sports Management",
    "scenario": "A professional soccer team suffered a humiliating 10-game losing streak, dropping to the bottom of the league table. The board fired the manager and hired a 'turnaround specialist'. In the very next match, the team won 2-0. Fans credit the new manager's 'tactical genius' for the immediate victory.",
    "claim": "The new manager's tactics caused the immediate victory in the next game.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Hiring New Manager",
        "role": "exposure"
      },
      "Y": {
        "name": "Winning Next Game",
        "role": "outcome"
      },
      "Z": [
        "10-Game Losing Streak (Performance Nadir)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Consultant's Fallacy / New Coach Bounce",
      "subtype_name": "Consultant's Fallacy / New Coach Bounce"
    },
    "difficulty": "Medium",
    "causal_structure": "Losing_Streak(Z) -> Fire_Hire_New(X); Losing_Streak(Z) -> Probability_of_Win_Regresses(Y); No strong causal link X -> Y in short term.",
    "key_insight": "Interventions triggered by extreme failure (Z) often coincide with the natural end of a negative variance streak.",
    "hidden_timestamp": "The intervention (X) occurs at t=1, immediately following the extreme outlier event (Z). The outcome (Y) is observed at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "Attributing the win solely to the new manager (X) ignores Regression to the Mean. A 10-game losing streak (Z) is a statistical anomaly involving bad luck and negative variance. It is highly probable that the streak would end (Y) in the next game simply due to probability normalizing, regardless of who was sitting on the bench. The 'New Coach Bounce' is often just the natural regression of results.",
    "gold_rationale": "Attributing the win solely to the new manager (X) ignores Regression to the Mean. A 10-game losing streak (Z) is a statistical anomaly involving bad luck and negative variance. It is highly probable that the streak would end (Y) in the next game simply due to probability normalizing, regardless of who was sitting on the bench. The 'New Coach Bounce' is often just the natural regression of results.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0010",
    "case_id": "0010",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Finance",
    "subdomain": "Algorithmic Trading",
    "scenario": "A quantitative trading firm ran simulations for 10,000 different trading algorithms using historical market data. They identified the single algorithm with the highest return on investment over the past year and deployed it with live capital. Six months later, the algorithm performed no better than the market average. The developers claim a sudden 'market regime shift' ruined the strategy.",
    "claim": "A 'market regime shift' (Z) caused the algorithm's performance to drop significantly after deployment.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Top Performing Algorithm in Simulation",
        "role": "exposure"
      },
      "Y": {
        "name": "Average Live Performance",
        "role": "outcome"
      },
      "Z": [
        "Market Regime Shift (Spurious Attribution)"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection",
      "subtype": "Winner's Curse / Overfitting",
      "subtype_name": "Winner's Curse / Overfitting"
    },
    "difficulty": "Hard",
    "causal_structure": "True_Alpha -> X; Overfitting_Noise -> X; True_Alpha -> Y; Zero_Mean_Noise -> Y; Intervention(Select_Max_X) -> Maximizes Overfitting_Noise; No causal link X -> Y.",
    "key_insight": "When selecting the 'best' from a large set of noisy candidates, the winner is usually the one with the most positive luck (overfitting), not the most skill.",
    "hidden_timestamp": "The selection (X) is based on historical data (t=1). The live performance (Y) is observed in real-time (t=2).",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "This is the Winner's Curse (or Overfitting) in data mining. By selecting the single best algorithm out of 10,000 (X), the firm selected the one with the most extreme positive variance (luck/noise) in the historical data. In live trading, noise does not repeat, so performance regresses to the algorithm's true, likely average, ability (Y). No 'market shift' (Z) is needed to explain why an outlier in training fails in testing.",
    "gold_rationale": "This is the Winner's Curse (or Overfitting) in data mining. By selecting the single best algorithm out of 10,000 (X), the firm selected the one with the most extreme positive variance (luck/noise) in the historical data. In live trading, noise does not repeat, so performance regresses to the algorithm's true, likely average, ability (Y). No 'market shift' (Z) is needed to explain why an outlier in training fails in testing.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0011",
    "case_id": "0011",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Education",
    "subdomain": "Academic Performance",
    "scenario": "A university awarded 'Merit Scholarships' to all students who achieved a perfect 4.0 GPA in the fall semester. In the spring semester, the average GPA of these scholarship recipients dropped to 3.7. The Dean worries that the free money made the students 'lazy' or 'complacent'.",
    "claim": "The scholarship money caused the students to become lazy (Z), resulting in lower grades.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Perfect 4.0 GPA",
        "role": "exposure"
      },
      "Y": {
        "name": "GPA Drop to 3.7",
        "role": "outcome"
      },
      "Z": [
        "Laziness / Complacency (Attribution)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Performance Rating Regression",
      "subtype_name": "Performance Rating Regression"
    },
    "difficulty": "Easy",
    "causal_structure": "Academic_Ability -> X; Perfect_Conditions(Luck) -> X; Academic_Ability -> Y; Normal_Conditions -> Y; Scholarship(Intervention) -> Y is confounded by selection on Max(X); No causal link Z -> Y.",
    "key_insight": "A perfect score (4.0) is a statistical ceiling; the only direction for variance to move is down, regardless of financial incentives.",
    "hidden_timestamp": "The scholarship is awarded based on t=1 performance (X). The regression is observed at t=2 (Y).",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The drop in GPA is a classic example of Regression to the Mean. Achieving a perfect 4.0 (X) requires both ability and everything going right (no illness, favorable exams). In the next semester, conditions are likely to be normal rather than perfect, leading to a natural regression in scores (Y). Attributing this decline to 'laziness' caused by the scholarship (Z) is a fallacy; the decline would have likely occurred even without the money.",
    "gold_rationale": "The drop in GPA is a classic example of Regression to the Mean. Achieving a perfect 4.0 (X) requires both ability and everything going right (no illness, favorable exams). In the next semester, conditions are likely to be normal rather than perfect, leading to a natural regression in scores (Y). Attributing this decline to 'laziness' caused by the scholarship (Z) is a fallacy; the decline would have likely occurred even without the money.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0012",
    "case_id": "0012",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Coaching Strategy",
    "scenario": "A star basketball player missed 20 consecutive shots over a span of three games, marking the worst slump of his career. The coach decided to 'bench' him for the next game to provide a 'mental reset'. Upon returning to the starting lineup in the following game, the player shot 50% from the field. The coach claims the benching was the cause of the performance recovery.",
    "claim": "The disciplinary benching (Intervention) caused the player's shooting percentage to recover.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Performance Slump / Benching",
        "role": "exposure"
      },
      "Y": {
        "name": "Shooting Recovery",
        "role": "outcome"
      },
      "Z": [
        "\"Mental Reset\" (Attributed Cause)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Trough Selection / Intervention at Nadir",
      "subtype_name": "Trough Selection / Intervention at Nadir"
    },
    "difficulty": "Medium",
    "causal_structure": "Shooting_Slump(Nadir) -> Bench_Player(X); Shooting_Slump(Nadir) -> Probability_Regresses_to_Mean(Y); No causal link X -> Y.",
    "key_insight": "Interventions applied during a performance trough often get credit for the natural normalization of variance that would have happened anyway.",
    "hidden_timestamp": "The intervention (X) is applied exactly when the performance metric hits its minimum (t=1). The outcome (Y) captures the regression at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The coach's claim ignores Regression to the Mean. The player was benched specifically because he was at a statistical nadir (X). In a random process like shooting, an extreme slump is almost always followed by improvement (Y) as variance normalizes. The recovery likely would have occurred even if he had played through the slump, making the 'mental reset' (Z) a superfluous explanation.",
    "gold_rationale": "The coach's claim ignores Regression to the Mean. The player was benched specifically because he was at a statistical nadir (X). In a random process like shooting, an extreme slump is almost always followed by improvement (Y) as variance normalizes. The recovery likely would have occurred even if he had played through the slump, making the 'mental reset' (Z) a superfluous explanation.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0013",
    "case_id": "0013",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Arts",
    "subdomain": "Music Industry",
    "scenario": "Historical data shows that 80% of musicians who win the 'Best New Artist' award see a significant drop in sales for their subsequent album. A rising star's manager advises them to decline the nomination to avoid this 'curse'.",
    "claim": "Accepting the 'Best New Artist' award causes the subsequent decline in career success.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Winning Best New Artist",
        "role": "exposure"
      },
      "Y": {
        "name": "Second Album Flop",
        "role": "outcome"
      },
      "Z": [
        "Viral Debut Success (Selection Criteria)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Peak Selection Regression",
      "subtype_name": "Peak Selection Regression"
    },
    "difficulty": "Medium",
    "causal_structure": "Talent -> Z; Viral_Luck -> Z; Z -> Win_Award(X); Talent -> Y; Normal_Luck -> Y; No causal link X -> Y.",
    "key_insight": "Winning 'Best New Artist' implies the debut was a statistical outlier; the second album faces regression to the artist's true baseline.",
    "hidden_timestamp": "The award (X) is given based on the debut performance Z (t=1). The second album (Y) is released at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The 'Best New Artist Curse' is a statistical artifact of Regression to the Mean. Artists win the award (X) because their debut (Z) was an extreme outlier, combining talent with perfect timing and viral luck. It is statistically probable that their next work (Y) will regress to a more normal level of success. Declining the award (Intervention) will not change the probability of this regression.",
    "gold_rationale": "The 'Best New Artist Curse' is a statistical artifact of Regression to the Mean. Artists win the award (X) because their debut (Z) was an extreme outlier, combining talent with perfect timing and viral luck. It is statistically probable that their next work (Y) will regress to a more normal level of success. Declining the award (Intervention) will not change the probability of this regression.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0014",
    "case_id": "0014",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Finance",
    "subdomain": "Cryptocurrency / Social Media",
    "scenario": "A crypto influencer on social media correctly predicted the price direction of Bitcoin for 10 consecutive weeks. Impressed by this perfect track record, a follower decides to subscribe to their premium signals and trades their entire portfolio based on the next prediction. The next prediction turns out to be wrong, and the follower loses significant capital.",
    "claim": "The influencer's 10-week streak proves they have a predictive algorithm, ensuring the next trade will be profitable.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "10-Week Correct Prediction Streak",
        "role": "exposure"
      },
      "Y": {
        "name": "Loss on Next Trade",
        "role": "outcome"
      },
      "Z": [
        "Random Chance / Survivor Selection (Mechanism)"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection",
      "subtype": "Survivorship Bias",
      "subtype_name": "Survivorship Bias"
    },
    "difficulty": "Medium",
    "causal_structure": "Random_Guessing -> X; Random_Market_Moves -> Y; Intervention(Trade) -> Selects Survivor(X); No causal link X -> Y.",
    "key_insight": "Given thousands of influencers guessing randomly, one will inevitably have a 10-week streak by pure chance; investing in the 'survivor' creates a false expectation of skill.",
    "hidden_timestamp": "The streak (X) is observed retrospectively over t=1 to t=10. The intervention occurs at t=11.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "This is a classic case of Survivorship Bias. With thousands of accounts making binary predictions (up/down), it is statistically certain that someone will guess correctly 10 times in a row (X) purely by luck (Z). By intervening and following this 'survivor', you are betting on a streak that has no causal grounding. The probability of the next prediction being correct (Y) remains 50/50, unrelated to the past streak.",
    "gold_rationale": "This is a classic case of Survivorship Bias. With thousands of accounts making binary predictions (up/down), it is statistically certain that someone will guess correctly 10 times in a row (X) purely by luck (Z). By intervening and following this 'survivor', you are betting on a streak that has no causal grounding. The probability of the next prediction being correct (Y) remains 50/50, unrelated to the past streak.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0015",
    "case_id": "0015",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Finance",
    "subdomain": "Corporate Governance",
    "scenario": "A tech company's stock price plummeted for six consecutive months, losing 40% of its value. Under pressure from the board, the CEO resigned. In the month following the resignation, the stock price rebounded by 15%. The board chairman claims the CEO's departure restored investor confidence and caused the rally.",
    "claim": "The resignation of the CEO (Z) caused the stock price to rebound (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "6-Month Stock Crash",
        "role": "exposure"
      },
      "Y": {
        "name": "Price Rebound",
        "role": "outcome"
      },
      "Z": [
        "CEO Resignation (Intervention)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Nadir Effect / Scapegoating",
      "subtype_name": "Nadir Effect / Scapegoating"
    },
    "difficulty": "Hard",
    "causal_structure": "Negative_Sentiment_Peak -> X; X -> Intervention(Z); Market_Correction -> Y; No strong causal link Z -> Y.",
    "key_insight": "Interventions (resignations) are often timed at the bottom of a crash; a technical rebound (dead cat bounce) is statistically probable regardless of leadership change.",
    "hidden_timestamp": "The resignation (Z) coincides with the price trough (X) at t=1. The rebound (Y) occurs at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The CEO resigned (Z) exactly when the stock was at its statistical nadir (X). After such a steep decline (40%), markets typically experience a technical rebound or 'correction' (Y) as sellers are exhausted and variance normalizes. Attributing the price rise solely to the resignation ignores the natural tendency of volatile markets to revert to the mean after extreme moves.",
    "gold_rationale": "The CEO resigned (Z) exactly when the stock was at its statistical nadir (X). After such a steep decline (40%), markets typically experience a technical rebound or 'correction' (Y) as sellers are exhausted and variance normalizes. Attributing the price rise solely to the resignation ignores the natural tendency of volatile markets to revert to the mean after extreme moves.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0016",
    "case_id": "0016",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Business",
    "subdomain": "Hospitality / Culinary Arts",
    "scenario": "A young chef was awarded the prestigious 'Chef of the Year' title after a year of flawless reviews and zero mistakes. In the following year, while still excellent, the restaurant's average rating dropped from 5.0 to 4.7. Food critics claim the fame made the chef 'complacent' or 'arrogant'.",
    "claim": "The chef's complacency (Z) caused the decline in ratings (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Winning 'Chef of the Year'",
        "role": "exposure"
      },
      "Y": {
        "name": "Rating Drop to 4.7",
        "role": "outcome"
      },
      "Z": [
        "Complacency (Attributed Cause)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Peak Selection Regression",
      "subtype_name": "Peak Selection Regression"
    },
    "difficulty": "Easy",
    "causal_structure": "Culinary_Skill -> X; Perfect_Luck -> X; Culinary_Skill -> Y; Normal_Luck -> Y; Z(Complacency) -> Y is spurious; High(X) implies E[Y] < X.",
    "key_insight": "A flawless year (X) is an outlier event; maintaining perfection is statistically unlikely, regardless of the chef's attitude.",
    "hidden_timestamp": "The award (X) is based on performance at t=1. The ratings drop (Y) is observed at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The decline in ratings is an example of Regression to the Mean. Winning 'Chef of the Year' (X) implies the chef had a year of maximum positive variance (everything went perfectly). In the subsequent year, variance normalizes, making a slight drop in ratings (Y) statistically inevitable. Attributing this natural fluctuation to 'complacency' (Z) is a narrative fallacy; perfection is simply hard to replicate continuously.",
    "gold_rationale": "The decline in ratings is an example of Regression to the Mean. Winning 'Chef of the Year' (X) implies the chef had a year of maximum positive variance (everything went perfectly). In the subsequent year, variance normalizes, making a slight drop in ratings (Y) statistically inevitable. Attributing this natural fluctuation to 'complacency' (Z) is a narrative fallacy; perfection is simply hard to replicate continuously.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0017",
    "case_id": "0017",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Business",
    "subdomain": "Tech Startups",
    "scenario": "A small startup launched a mobile game that went viral overnight, reaching 50 million downloads in a month. Their next three game releases failed to crack the top 100 charts. Tech bloggers claim the early success made the team 'lazy' and 'unfocused'.",
    "claim": "The early viral success (X) caused the team to become lazy (Z), leading to the failure of subsequent games (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Viral Mobile Game",
        "role": "exposure"
      },
      "Y": {
        "name": "Subsequent Games Flop",
        "role": "outcome"
      },
      "Z": [
        "Laziness / Lack of Focus (Attributed Cause)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Lightning Strikes Twice",
      "subtype_name": "Lightning Strikes Twice"
    },
    "difficulty": "Easy",
    "causal_structure": "Dev_Skill -> X; Viral_Luck -> X; Dev_Skill -> Y; Normal_Luck -> Y; Z(Laziness) -> Y is spurious; X does not cause Y.",
    "key_insight": "A viral hit is a rare combination of skill and luck (a 'black swan'); subsequent attempts regress to the team's average output.",
    "hidden_timestamp": "The viral success (X) occurs at t=1. The subsequent releases (Y) occur at t=2, t=3.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The startup's trajectory is a clear case of Regression to the Mean. The first game (X) was a statistical outlier, likely driven by a 'lightning in a bottle' moment of viral luck. Subsequent games (Y) represent the team's baseline performance in a competitive market. Attributing the drop to 'laziness' (Z) falsely implies that extreme viral success is the sustainable norm for a small team.",
    "gold_rationale": "The startup's trajectory is a clear case of Regression to the Mean. The first game (X) was a statistical outlier, likely driven by a 'lightning in a bottle' moment of viral luck. Subsequent games (Y) represent the team's baseline performance in a competitive market. Attributing the drop to 'laziness' (Z) falsely implies that extreme viral success is the sustainable norm for a small team.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0018",
    "case_id": "0018",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Science",
    "subdomain": "Genetics / Intelligence",
    "scenario": "Two Nobel Prize-winning physicists married and had a son. While the son is intelligent and holds a PhD, he works as a mid-level researcher with no major breakthroughs. The parents believe that the 'unstructured' education system failed him.",
    "claim": "The unstructured education system (Z) caused the son's failure to match his parents' achievements.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Nobel Prize Parents",
        "role": "exposure"
      },
      "Y": {
        "name": "Average Researcher Son",
        "role": "outcome"
      },
      "Z": [
        "Education System (Attributed Cause)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Galton's Regression",
      "subtype_name": "Galton's Regression"
    },
    "difficulty": "Hard",
    "causal_structure": "Genetics -> X; Perfect_Environment_Luck -> X; Genetics -> Y; Normal_Environment_Luck -> Y; Z(Education) -> Y is spurious; High(X) implies E[Y] < X.",
    "key_insight": "Intelligence and achievement have a hereditary component but are subject to strong regression; two outliers mating usually produce less extreme offspring.",
    "hidden_timestamp": "Parents' achievement (X) is at t=1. Son's achievement (Y) is at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The son's career trajectory is an example of Galton's Regression to the Mean. Winning a Nobel Prize (X) requires not just high IQ (genetics) but also exceptional luck and timing (variance). While the son inherits the genetics, he likely did not inherit the extreme positive variance. It is statistically expected for the children of outliers to regress toward the population mean (Y), regardless of the education system (Z).",
    "gold_rationale": "The son's career trajectory is an example of Galton's Regression to the Mean. Winning a Nobel Prize (X) requires not just high IQ (genetics) but also exceptional luck and timing (variance). While the son inherits the genetics, he likely did not inherit the extreme positive variance. It is statistically expected for the children of outliers to regress toward the population mean (Y), regardless of the education system (Z).",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0019",
    "case_id": "0019",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Health",
    "subdomain": "Fitness / Biology",
    "scenario": "A person starts a new diet and loses 8 pounds in the first week, a record start. In the second week, sticking to the same diet, they lose only 1 pound. They conclude that they must have 'subconsciously cheated' on the diet or that the diet stopped working.",
    "claim": "Cheating on the diet or efficacy loss (Z) caused the drastic drop in weight loss rate (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "8 lbs Loss Week 1",
        "role": "exposure"
      },
      "Y": {
        "name": "1 lb Loss Week 2",
        "role": "outcome"
      },
      "Z": [
        "Cheating / Diet Failure (Attributed Cause)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Peak Selection Regression",
      "subtype_name": "Peak Selection Regression"
    },
    "difficulty": "Easy",
    "causal_structure": "Caloric_Deficit -> X; Water_Weight_Loss(Transient) -> X; Caloric_Deficit -> Y; Water_Weight_Stabilizes -> Y; Z(Cheating) -> Y is spurious; X does not cause Y.",
    "key_insight": "Initial weight loss is often an outlier due to water depletion; the rate naturally regresses to the rate of fat loss.",
    "hidden_timestamp": "Week 1 loss (X) is observed at t=1. Week 2 loss (Y) is observed at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The drop in the rate of weight loss is a classic example of Regression to the Mean (specifically, physiological normalization). The first week's loss (X) is an outlier driven by water weight and glycogen depletion. The second week (Y) represents the true, sustainable rate of fat loss. Attributing the slowdown to 'cheating' (Z) is unnecessary; the extreme initial result simply could not be sustained.",
    "gold_rationale": "The drop in the rate of weight loss is a classic example of Regression to the Mean (specifically, physiological normalization). The first week's loss (X) is an outlier driven by water weight and glycogen depletion. The second week (Y) represents the true, sustainable rate of fat loss. Attributing the slowdown to 'cheating' (Z) is unnecessary; the extreme initial result simply could not be sustained.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0020",
    "case_id": "0020",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Public Policy",
    "subdomain": "Urban Planning / Traffic Safety",
    "scenario": "A city government identified the five intersections with the highest number of traffic accidents recorded last year. In response, they installed expensive 'Smart Traffic Monitoring Systems' at these specific locations. The following year, accidents at these intersections dropped by 40%. The mayor announced that the smart systems were highly effective.",
    "claim": "The 'Smart Traffic Monitoring Systems' (Z) caused the 40% reduction in accidents.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Top 5 High-Accident Intersections",
        "role": "exposure"
      },
      "Y": {
        "name": "Reduced Accident Count",
        "role": "outcome"
      },
      "Z": [
        "Smart Monitoring System (Intervention)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Selection on Baseline",
      "subtype_name": "Selection on Baseline"
    },
    "difficulty": "Hard",
    "causal_structure": "Inherent_Risk -> X; Negative_Variance(Bad_Luck) -> X; Inherent_Risk -> Y; Normal_Variance -> Y; Intervention(Z) -> Y is confounded by Selection on Max(X); No causal link Z -> Y confirmed.",
    "key_insight": "Interventions targeted at sites with record-high accident rates often claim credit for the natural decrease in accidents (regression) that follows a spike.",
    "hidden_timestamp": "Selection (X) is based on data from year t=1. Outcome (Y) is observed in year t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The observed safety improvement is likely due to Regression to the Mean. By selecting intersections with the absolute highest accident counts (X), the city targeted sites that likely experienced an abnormal spike in 'bad luck' (negative variance) that year. Statistically, accident rates at these outlier sites would be expected to fall (Y) in the next year even without any intervention. Attributing the full drop to the smart systems (Z) is fallacious without a control group.",
    "gold_rationale": "The observed safety improvement is likely due to Regression to the Mean. By selecting intersections with the absolute highest accident counts (X), the city targeted sites that likely experienced an abnormal spike in 'bad luck' (negative variance) that year. Statistically, accident rates at these outlier sites would be expected to fall (Y) in the next year even without any intervention. Attributing the full drop to the smart systems (Z) is fallacious without a control group.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0021",
    "case_id": "0021",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Public Policy",
    "subdomain": "Law Enforcement",
    "scenario": "A quiet neighborhood experienced a record-breaking spike of 20 burglaries in a single month. In response, the Police Chief deployed a special tactical unit to patrol the area 24/7. The following month, burglaries dropped to 5. The Chief announced that the tactical unit successfully eradicated the crime wave.",
    "claim": "The deployment of the tactical unit (Z) caused the significant drop in burglaries (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Record Burglary Spike",
        "role": "exposure"
      },
      "Y": {
        "name": "Drop in Crime",
        "role": "outcome"
      },
      "Z": [
        "Special Tactical Unit (Intervention)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Crime Variance / Selection on Baseline",
      "subtype_name": "Crime Variance / Selection on Baseline"
    },
    "difficulty": "Medium",
    "causal_structure": "Base_Crime_Rate -> X; Temporal_Clustering(Bad_Luck) -> X; X -> Deploy_Unit(Z); Base_Crime_Rate -> Y; Normal_Variance -> Y; No proof Z -> Y > Natural_Regression.",
    "key_insight": "Crime waves often represent temporary clusters (Poisson bursts); interventions deployed at the peak get credit for the natural return to baseline.",
    "hidden_timestamp": "The spike (X) occurs at month t=1. The drop (Y) is observed at month t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The drop in crime is a likely candidate for Regression to the Mean. The tactical unit (Z) was deployed specifically because of a statistical outlier event (X). Crime data often exhibits random clustering; a record spike is typically followed by a return to the average (Y) as the temporary factors causing the spike dissipate. Attributing the entire decline to the police presence ignores this natural statistical normalization.",
    "gold_rationale": "The drop in crime is a likely candidate for Regression to the Mean. The tactical unit (Z) was deployed specifically because of a statistical outlier event (X). Crime data often exhibits random clustering; a record spike is typically followed by a return to the average (Y) as the temporary factors causing the spike dissipate. Attributing the entire decline to the police presence ignores this natural statistical normalization.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0022",
    "case_id": "0022",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Computer Science",
    "subdomain": "DevOps / Systems Engineering",
    "scenario": "A cloud server's CPU usage spiked to 99%, triggering a critical alert. The system administrator immediately ran a script to 'clear temporary log files'. Five minutes later, the CPU usage dropped back to a normal 40%. The administrator claims the log clearing script fixed the CPU overload.",
    "claim": "The log clearing script (Z) caused the CPU usage to drop (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "CPU Usage Spike",
        "role": "exposure"
      },
      "Y": {
        "name": "Normal CPU Usage",
        "role": "outcome"
      },
      "Z": [
        "Log Clearing Script (Intervention)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "System Variance / Peak Selection",
      "subtype_name": "System Variance / Peak Selection"
    },
    "difficulty": "Medium",
    "causal_structure": "Traffic_Burst -> X; X -> Run_Script(Z); Traffic_Burst_Ends -> Y; Z -> Y is weak/spurious; High(X) implies E[Y] < X due to transient nature of bursts.",
    "key_insight": "System resource spikes are often transient (bursty); interventions applied at the peak often get credit for the natural end of the burst.",
    "hidden_timestamp": "The intervention (Z) is applied at the moment of peak load (X, t=1). The recovery (Y) is observed at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The drop in CPU usage is likely Regression to the Mean. The administrator intervened exactly when the load was at a peak (X). Server loads often exhibit 'bursty' behavior where spikes are transient. It is statistically probable that the load would have dropped (Y) as the traffic burst ended, regardless of the log clearing script (Z). Without evidence that logs were actually consuming CPU, the correlation is likely spurious.",
    "gold_rationale": "The drop in CPU usage is likely Regression to the Mean. The administrator intervened exactly when the load was at a peak (X). Server loads often exhibit 'bursty' behavior where spikes are transient. It is statistically probable that the load would have dropped (Y) as the traffic burst ended, regardless of the log clearing script (Z). Without evidence that logs were actually consuming CPU, the correlation is likely spurious.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0023",
    "case_id": "0023",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Sales Psychology",
    "scenario": "A top-performing salesperson insists on using a specific, cheap blue ballpoint pen to sign every contract. She claims that this pen is 'charmed' because every time she uses it, the deal closes successfully. She refuses to go to client meetings without it.",
    "claim": "Using the specific blue pen (X) causes the deals to close successfully (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Using 'Lucky' Pen",
        "role": "exposure"
      },
      "Y": {
        "name": "Closing the Deal",
        "role": "outcome"
      },
      "Z": [
        "Sales Skill / Product Fit (True Causes)"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Spurious",
      "subtype": "Superstition / Magical Thinking",
      "subtype_name": "Superstition / Magical Thinking"
    },
    "difficulty": "Easy",
    "causal_structure": "Pen_Choice(X) _||_ Client_Decision(Y); Sales_Skill(Z) -> Y; No causal path X -> Y.",
    "key_insight": "Attributing success to an incidental object is a classic superstition; the object has no mechanistic power over the outcome.",
    "hidden_timestamp": "The ritual usage (X) happens at the moment of signing (t=1). The deal confirmation (Y) happens at t=1 or t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "This is a case of Superstition or Magical Thinking. The choice of pen (X) is physically and logically independent of the client's decision to buy (Y), which is driven by product fit and negotiation skill (Z). While the ritual might boost the salesperson's confidence (placebo), the pen itself exerts no causal force on the deal's outcome.",
    "gold_rationale": "This is a case of Superstition or Magical Thinking. The choice of pen (X) is physically and logically independent of the client's decision to buy (Y), which is driven by product fit and negotiation skill (Z). While the ritual might boost the salesperson's confidence (placebo), the pen itself exerts no causal force on the deal's outcome.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0024",
    "case_id": "0024",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Career Advice",
    "scenario": "A student observes that several of the world's richest tech moguls dropped out of college and achieved massive success. Convinced that formal education holds people back, the student decides to drop out of university to maximize their chances of becoming a billionaire.",
    "claim": "Dropping out of college (X) causes one to become a tech billionaire (Y) and is a recommended strategy.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Dropping Out of College",
        "role": "exposure"
      },
      "Y": {
        "name": "Billionaire Status",
        "role": "outcome"
      },
      "Z": [
        "Career Failure / Low Income (Unobserved Outcome)"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection",
      "subtype": "Survivorship Bias",
      "subtype_name": "Survivorship Bias"
    },
    "difficulty": "Medium",
    "causal_structure": "Drop_Out(X) -> High_Career_Variance; High_Career_Variance -> Billionaire(Y); High_Career_Variance -> Failure(Z); Media selects Y; Intervention(Do X) ignores P(Z|X).",
    "key_insight": "Visible successful dropouts are the rare survivors of a high-risk strategy; the vast majority of dropouts do not become billionaires.",
    "hidden_timestamp": "The observation focuses on historical survivors (Y). The intervention (X) is applied to a new student who faces the full probability distribution (Y + Z).",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "This decision relies on Survivorship Bias. While it is true that some billionaires dropped out (X), you are only looking at the numerator of success (Y) and ignoring the vast denominator of dropouts who failed or struggled (Z). Dropping out increases the variance of outcomes, often removing the safety net of a degree. The probability of becoming a billionaire given you drop out is statistically lower than the probability of failure.",
    "gold_rationale": "This decision relies on Survivorship Bias. While it is true that some billionaires dropped out (X), you are only looking at the numerator of success (Y) and ignoring the vast denominator of dropouts who failed or struggled (Z). Dropping out increases the variance of outcomes, often removing the safety net of a degree. The probability of becoming a billionaire given you drop out is statistically lower than the probability of failure.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0025",
    "case_id": "0025",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Product Management",
    "scenario": "A subscription software company surveys its long-term active users to decide what features to build next. The most common request from these users is 'Dark Mode'. The CEO decides to prioritize Dark Mode to reduce the high cancellation rate of new users.",
    "claim": "Building Dark Mode (X) will reduce the cancellation rate of new users.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Request for 'Dark Mode'",
        "role": "exposure"
      },
      "Y": {
        "name": "Active Long-Term Users",
        "role": "outcome"
      },
      "Z": [
        "Missing Core Feature / Fatal Flaws (Unobserved)"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection",
      "subtype": "Wald's Survivorship Bias",
      "subtype_name": "Wald's Survivorship Bias"
    },
    "difficulty": "Hard",
    "causal_structure": "Fatal_Flaw(Z) -> Churn(Non-Y); Minor_Annoyance(X) -> Retention(Y); Dataset includes only Y; Feedback(X)|Y ignores Z.",
    "key_insight": "Feedback from happy survivors (active users) often focuses on optimization (polish), while the fatal flaws that cause churn (Z) are unobserved because those users have already left.",
    "hidden_timestamp": "The survey (X) is taken by survivors (Y) at t=1. The intervention targets churners (who are not Y) at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "This decision relies on Survivorship Bias. The active users (Y) are the ones who successfully navigated the product's core value proposition; they are complaining about minor preferences like Dark Mode (X). The users who cancelled (Z) likely left because of fundamental missing features or pricing issues that the survivors don't care about. Fixing X will please survivors but fail to save the non-survivors.",
    "gold_rationale": "This decision relies on Survivorship Bias. The active users (Y) are the ones who successfully navigated the product's core value proposition; they are complaining about minor preferences like Dark Mode (X). The users who cancelled (Z) likely left because of fundamental missing features or pricing issues that the survivors don't care about. Fixing X will please survivors but fail to save the non-survivors.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0026",
    "case_id": "0026",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Health",
    "subdomain": "Lifestyle / Epidemiology",
    "scenario": "A local newspaper interviews a 105-year-old woman. When asked for her secret to longevity, she credits her daily habit of drinking whiskey and smoking a cigar. A health-conscious reader decides to adopt this habit to live longer.",
    "claim": "Drinking whiskey and smoking cigars (X) causes longevity (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Whiskey and Cigars",
        "role": "exposure"
      },
      "Y": {
        "name": "Living to 105",
        "role": "outcome"
      },
      "Z": [
        "Premature Deaths (Unobserved)"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection",
      "subtype": "Survivorship Bias",
      "subtype_name": "Survivorship Bias"
    },
    "difficulty": "Medium",
    "causal_structure": "Genetics -> Y; Genetics -> Tolerance_of_X; X -> Mortality_Risk(Z); Dataset selects Y; Observing X|Y implies X is safe, but ignores Z.",
    "key_insight": "Survivors of risky behaviors often possess protective factors (genetics) that allow them to survive 'despite' the behavior, not 'because' of it.",
    "hidden_timestamp": "The interview observes a survivor (Y) at t=1. The intervention (X) is applied to a general population member at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "Adopting this habit is dangerous due to Survivorship Bias. The 105-year-old (Y) likely survived *despite* the smoking and drinking (X), thanks to exceptional genetics. Countless others who smoked and drank (Z) died prematurely and are not around to give interviews. Mistaking a survivor's resilience for a causal recipe is a fatal error.",
    "gold_rationale": "Adopting this habit is dangerous due to Survivorship Bias. The 105-year-old (Y) likely survived *despite* the smoking and drinking (X), thanks to exceptional genetics. Countless others who smoked and drank (Z) died prematurely and are not around to give interviews. Mistaking a survivor's resilience for a causal recipe is a fatal error.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0027",
    "case_id": "0027",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Human Resources / Sales",
    "scenario": "A software company hires a 'Rockstar' salesperson who was the top performer at a competitor for three consecutive years, paying them a massive signing bonus. In the first year at the new company, the salesperson's revenue is average, failing to meet the high quota. The sales director is confused why the 'proven skill' didn't transfer.",
    "claim": "Hiring the top performer (X) caused by past success (Z) ensures high revenue in the new role.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Hiring 'Rockstar' Salesperson",
        "role": "exposure"
      },
      "Y": {
        "name": "Average Performance",
        "role": "outcome"
      },
      "Z": [
        "Top Performer at Previous Job (Selection Criteria)"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "Survivorship",
      "subtype": "Contextual Selection Bias",
      "subtype_name": "Contextual Selection Bias"
    },
    "difficulty": "Medium",
    "causal_structure": "Territory_Quality + Luck -> Z; Z -> Hire(X); New_Territory + Normal_Luck -> Y; No causal link Z -> Y.",
    "key_insight": "Top performance is often context-dependent (e.g., easy territory); selecting based on peak outcome (Z) ignores the environmental factors that enabled it.",
    "hidden_timestamp": "The hiring (X) is based on performance at the previous company (Z, t=1). The new performance (Y) is observed at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "This is a case of Attribution Error mixed with Regression to the Mean. The salesperson's past success (Z) was likely heavily influenced by situational factors (e.g., a ripe territory, a specific product-market fit) and luck. By selecting the 'top' performer, the company selected for these favorable contexts. In a new environment without those specific advantages, performance naturally regresses to the individual's true ability level (Y).",
    "gold_rationale": "This is a case of Attribution Error mixed with Regression to the Mean. The salesperson's past success (Z) was likely heavily influenced by situational factors (e.g., a ripe territory, a specific product-market fit) and luck. By selecting the 'top' performer, the company selected for these favorable contexts. In a new environment without those specific advantages, performance naturally regresses to the individual's true ability level (Y).",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0028",
    "case_id": "0028",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Business",
    "subdomain": "Retail Management",
    "scenario": "A retail chain identified the 10 store locations with the lowest customer satisfaction scores in the previous quarter. Corporate management mandated a strict 'Smile & Greet' training program for all employees at these locations. In the following quarter, customer satisfaction scores at these stores improved by 15%. The Regional Director concludes the training was a success.",
    "claim": "The 'Smile & Greet' training (X) caused the 15% improvement in satisfaction scores (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Smile & Greet Training",
        "role": "exposure"
      },
      "Y": {
        "name": "Score Improvement",
        "role": "outcome"
      },
      "Z": [
        "Lowest Satisfaction Scores (Selection Criterion)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Bottom Selection / Nadir Effect",
      "subtype_name": "Bottom Selection / Nadir Effect"
    },
    "difficulty": "Hard",
    "causal_structure": "Bad_Luck_Variance -> Low_Score(Z); Low_Score(Z) -> Mandate_Training(X); Luck_Normalizes -> Score_Improves(Y); No confirmed link X -> Y.",
    "key_insight": "Stores at the bottom of the ranking (Z) are statistically the most likely to improve (Y) in the next period due to variance normalization, regardless of intervention.",
    "hidden_timestamp": "Selection (X) occurs at the performance nadir (Z, t=1). Recovery (Y) is observed at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The improvement is likely due to Regression to the Mean. By selecting the absolute worst-performing stores (Z), management targeted locations that likely suffered from temporary negative variance (e.g., staffing shortages, local construction, bad luck). Statistical theory predicts these stores would bounce back (Y) towards the average in the next quarter naturally. Attributing the entire gain to the 'Smile & Greet' training (X) without a control group is flawed.",
    "gold_rationale": "The improvement is likely due to Regression to the Mean. By selecting the absolute worst-performing stores (Z), management targeted locations that likely suffered from temporary negative variance (e.g., staffing shortages, local construction, bad luck). Statistical theory predicts these stores would bounce back (Y) towards the average in the next quarter naturally. Attributing the entire gain to the 'Smile & Greet' training (X) without a control group is flawed.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0029",
    "case_id": "0029",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Marketing / HR",
    "scenario": "A summer intern managed the company's social media account for one week and posted three memes that went viral, gaining millions of views. Impressed by this 'perfect streak,' the CEO fired the external marketing agency and promoted the intern to Chief Marketing Officer. Over the next six months, the intern's marketing campaigns failed to generate any significant engagement.",
    "claim": "Promoting the intern (X) based on the viral streak (Z) ensures continued marketing success.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Promotion to CMO",
        "role": "exposure"
      },
      "Y": {
        "name": "Campaign Failure / Regression",
        "role": "outcome"
      },
      "Z": [
        "3 Viral Posts (Selection Criteria)"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "Survivorship",
      "subtype": "Small Sample Selection / Hot Hand",
      "subtype_name": "Small Sample Selection / Hot Hand"
    },
    "difficulty": "Easy",
    "causal_structure": "High_Variance_Content -> Lucky_Streak(Z); Z -> Promotion(X); Normal_Variance -> Y; No causal link Z(Luck) -> Y(Skill).",
    "key_insight": "A short streak of high-variance success (viral hits) is often due to luck; extrapolating this to long-term strategic skill is a selection error.",
    "hidden_timestamp": "The promotion (X) is based on the short-term streak (Z) at t=1. The long-term performance (Y) is observed at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "The CEO's decision fell victim to the Small Sample fallacy (or Hot Hand fallacy). Viral success on social media is highly stochastic (random). Hitting a streak of 3 viral posts (Z) in one week is likely a statistical anomaly or 'beginners luck' rather than proof of executive-level strategic competence. Promoting the intern to CMO (X) assumed a causal skill that likely didn't exist, leading to regression (Y).",
    "gold_rationale": "The CEO's decision fell victim to the Small Sample fallacy (or Hot Hand fallacy). Viral success on social media is highly stochastic (random). Hitting a streak of 3 viral posts (Z) in one week is likely a statistical anomaly or 'beginners luck' rather than proof of executive-level strategic competence. Promoting the intern to CMO (X) assumed a causal skill that likely didn't exist, leading to regression (Y).",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 7.5,
    "validator_2": "Longling Geng",
    "final_score_2": 8.25
  },
  {
    "id": "T3-BucketD-0030",
    "case_id": "0030",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Finance",
    "subdomain": "Venture Capital",
    "scenario": "A venture capitalist invested $5 million in a tech startup after due diligence showed strong fundamentals and an 80% probability of success. Six months later, an unforeseen geopolitical crisis destroyed the startup's supply chain, leading to bankruptcy. The fund's investors label the decision 'amateurish' and 'blind'.",
    "claim": "The investment decision (X) was 'amateurish' (Z) because the startup went bankrupt (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Investment Decision",
        "role": "exposure"
      },
      "Y": {
        "name": "Bankruptcy",
        "role": "outcome"
      },
      "Z": [
        "\"Amateurish\" Label (Evaluation)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Outcome Bias",
      "subtype": "Resulting / Process vs. Outcome",
      "subtype_name": "Resulting / Process vs. Outcome"
    },
    "difficulty": "Medium",
    "causal_structure": "Decision(X) -> High_Prob_Success; Black_Swan_Event -> Y; Y -> Criticism(Z); Z ignores P(Success|X) at t=1.",
    "key_insight": "In probabilistic fields like investing, a high-quality decision can still lead to a loss due to variance; judging the decision solely by the loss is fallacious.",
    "hidden_timestamp": "The investment (X) occurs at t=1. The crisis and failure (Y) occur at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The investors are committing Outcome Bias (also known as 'Resulting' in poker). The quality of the investment decision (X) depends on the information available at the time, which showed an 80% chance of success. The bankruptcy (Y) was caused by an unforeseeable external event (low probability variance). Evaluating a probabilistic decision solely by its negative outcome ignores the sound logic that justified it.",
    "gold_rationale": "The investors are committing Outcome Bias (also known as 'Resulting' in poker). The quality of the investment decision (X) depends on the information available at the time, which showed an 80% chance of success. The bankruptcy (Y) was caused by an unforeseeable external event (low probability variance). Evaluating a probabilistic decision solely by its negative outcome ignores the sound logic that justified it.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0031",
    "case_id": "0031",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Public Policy",
    "subdomain": "Urban Planning / Traffic",
    "scenario": "A commuter ignores the GPS recommendation to take the highway and instead takes a narrow backroad, saving 30 minutes by avoiding a traffic jam. The commuter wonders: 'If the GPS updated to route everyone through this backroad, would all drivers save 30 minutes?'",
    "claim": "Routing everyone through the backroad (X') would result in time savings for all drivers.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Taking Highway",
      "Y": "Commute Time",
      "Z": [
        "Traffic Volume / Road Capacity (Constraint)"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Fallacy of Composition / SUTVA Violation",
      "subtype_name": "Fallacy of Composition / SUTVA Violation"
    },
    "difficulty": "Hard",
    "causal_structure": "Congestion(Z) -> GPS_Route(X); Individual_Do(X') -> Avoids_Z -> Low_Y; Universal_Do(X') -> Moves_Z_to_Backroad -> High_Y.",
    "key_insight": "A strategy that exploits system inefficiency (an empty road) works for an individual but fails if universalized due to capacity constraints.",
    "hidden_timestamp": "The observation of savings (Y) is based on the current state where most people do X. The counterfactual assumes X' for everyone.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "This counterfactual works only for an individual, not for the population. The backroad is faster specifically because it is underutilized. If the GPS routed everyone there (Universal X'), the traffic volume (Z) would shift, overwhelming the narrow road and likely increasing travel time for everyone. What is true for the part is not true for the whole (Fallacy of Composition).",
    "gold_rationale": "This counterfactual works only for an individual, not for the population. The backroad is faster specifically because it is underutilized. If the GPS routed everyone there (Universal X'), the traffic volume (Z) would shift, overwhelming the narrow road and likely increasing travel time for everyone. What is true for the part is not true for the whole (Fallacy of Composition).",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0032",
    "case_id": "0032",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Business",
    "subdomain": "Management / Sales",
    "scenario": "A regional store manager led his branch to break all-time revenue records in 2025. Following this success, he was promoted to a corporate role in 2026. The branch's revenue dropped significantly in 2026. Employees claim: 'If the manager had stayed, the branch would have matched the 2025 record again.'",
    "claim": "If the manager had stayed at the branch (X'), the revenue would have remained at the record peak (Y' = Z).",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Manager Promotion/Transfer",
      "Y": "2026 Revenue Drop",
      "Z": [
        "Record-Breaking 2025 Revenue (Peak Selection)"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Unobservable Counterfactual / Regression",
      "subtype_name": "Unobservable Counterfactual / Regression"
    },
    "difficulty": "Medium",
    "causal_structure": "Record_Revenue(Z) = Manager_Skill + Market_Boom(Luck); Promotion(X) changes Leader; Counterfactual(Stay) keeps Leader; Market_Boom ends; Y' < Z due to Regression.",
    "key_insight": "Attributing the entire drop to the manager's departure ignores that the record year was an outlier; maintaining an outlier year is probabilistically unlikely even for the same manager.",
    "hidden_timestamp": "The counterfactual compares the actual outcome at t=2 (Y) with a hypothetical t=2 (Y') that falsely assumes t=1's variance (Z) can be extended.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "The claim is invalid because it ignores Regression to the Mean. The record-breaking year (Z) was likely an outlier driven by a combination of good management and exceptional market luck. In the counterfactual scenario where the manager stayed, the 'luck' component would naturally fade. Therefore, the revenue would likely have declined anyway (Y' < Z), making the promotion a convenient but incorrect scapegoat for the drop.",
    "gold_rationale": "The claim is invalid because it ignores Regression to the Mean. The record-breaking year (Z) was likely an outlier driven by a combination of good management and exceptional market luck. In the counterfactual scenario where the manager stayed, the 'luck' component would naturally fade. Therefore, the revenue would likely have declined anyway (Y' < Z), making the promotion a convenient but incorrect scapegoat for the drop.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0033",
    "case_id": "0033",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Technology",
    "subdomain": "Product Management",
    "scenario": "An app store gives the 'Editor's Choice' award exclusively to apps with a perfect 5.0 rating. After receiving the award and gaining mass users, these apps almost always drop to a 4.7 rating. The editors wonder: 'If we had given the award to 4.5-rated apps instead, would they have maintained their rating better?'",
    "claim": "Apps with a 4.5 rating (X') would maintain their score better than the perfect 5.0 apps (X).",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Award to 5.0 Apps",
      "Y": "Post-Award Rating",
      "Z": [
        "App Quality + Variance"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Ceiling Counterfactual / Regression Asymmetry",
      "subtype_name": "Ceiling Counterfactual / Regression Asymmetry"
    },
    "difficulty": "Hard",
    "causal_structure": "Rating_5.0(X) = High_Quality + No_Negative_Variance (Capped); Rating_4.5(X') = High_Quality + Some_Negative_Variance; X can only regress Y < X; X' can regress Y > X' or Y < X'.",
    "key_insight": "A perfect score implies the absence of negative variance; once sample size increases (award), negative variance inevitably appears, forcing the score down. A non-perfect score has room to improve.",
    "hidden_timestamp": "The counterfactual question compares a ceiling state (X) with a flexible state (X') assuming symmetric stability.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "This counterfactual comparison is flawed due to Regression Asymmetry caused by the ceiling effect. Apps with a 5.0 rating (X) are at the mathematical limit; as user volume grows, statistical variance guarantees they can only move downwards (Y < 5.0). Apps with a 4.5 rating (X') have room to improve (move up to 5.0) or decline. You cannot conclude the 4.5 apps are 'more stable'; you are simply comparing a group that faces a mathematical gravity to one that does not.",
    "gold_rationale": "This counterfactual comparison is flawed due to Regression Asymmetry caused by the ceiling effect. Apps with a 5.0 rating (X) are at the mathematical limit; as user volume grows, statistical variance guarantees they can only move downwards (Y < 5.0). Apps with a 4.5 rating (X') have room to improve (move up to 5.0) or decline. You cannot conclude the 4.5 apps are 'more stable'; you are simply comparing a group that faces a mathematical gravity to one that does not.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0034",
    "case_id": "0034",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Finance",
    "subdomain": "Scams / Probability",
    "scenario": "An investor receives a free email newsletter from 'The Market Oracle' that correctly predicts the stock market's direction for 10 consecutive weeks. Convinced that the sender possesses insider information or a superior algorithm, the investor prepares to invest their life savings. A skeptic asks: 'What if the sender started with a list of 1,000 people and split the predictions 50/50 each week?'",
    "claim": "The 10-week perfect prediction record (X) proves the sender has predictive skill (Y).",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "10-Week Correct Streak",
      "Y": "Predictive Skill",
      "Z": [
        "Hidden Mailing List Size (Context)"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Pre-Registration / Survivorship Scam",
      "subtype_name": "Pre-Registration / Survivorship Scam"
    },
    "difficulty": "Hard",
    "causal_structure": "Split_Mailing_List(Z) -> Survivor(X); True_Skill -> X; Observing X (Survivor) creates spurious link to Skill; Counterfactual W (N=1) confirms Skill.",
    "key_insight": "A perfect streak is meaningless if generated by a 'divide and conquer' survivorship algorithm; evidential value depends on the unobserved denominator.",
    "hidden_timestamp": "The inference depends on the counterfactual knowledge of the sender's process (Z) which is unobserved by the receiver.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "The credibility of the predictions (X) is conditional on the existence of a hidden population (Z). In a counterfactual world where you are the *only* recipient (World B), the streak implies skill. However, in a world where the sender uses a survivorship algorithm on a large list (World A), your 'perfect record' is a statistical inevitability of the scam, not evidence of the sender's ability. Without knowing the denominator, you cannot infer the numerator's quality.",
    "gold_rationale": "The credibility of the predictions (X) is conditional on the existence of a hidden population (Z). In a counterfactual world where you are the *only* recipient (World B), the streak implies skill. However, in a world where the sender uses a survivorship algorithm on a large list (World A), your 'perfect record' is a statistical inevitability of the scam, not evidence of the sender's ability. Without knowing the denominator, you cannot infer the numerator's quality.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0035",
    "case_id": "0035",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Technology",
    "subdomain": "Innovation Studies",
    "scenario": "A tech documentary claims: 'If Steve Jobs had not returned to Apple in 1997, the modern touchscreen smartphone revolution would never have happened.' A tech historian argues that capacitive touchscreens, mobile internet, and battery technology were already maturing, making the form factor inevitable.",
    "claim": "Steve Jobs' return (X) was a necessary condition for the invention of the modern smartphone (Y).",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Steve Jobs' Return",
      "Y": "Smartphone Revolution",
      "Z": [
        "Technological Maturity (Zeitgeist)"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Great Man vs. Inevitability",
      "subtype_name": "Great Man vs. Inevitability"
    },
    "difficulty": "Hard",
    "causal_structure": "Visionary_Leader(X) -> Y; Tech_Convergence(Z) -> Y; Question: Is Y dependent solely on X, or is Z sufficient to cause Y via another agent?",
    "key_insight": "Was the iPhone a 'black swan' unique to Jobs, or a 'multiple discovery' waiting to happen due to component availability?",
    "hidden_timestamp": "The counterfactual removes the key innovator (X) while keeping the technological substrate (Z) constant.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "This counterfactual depends on whether you view innovation as driven by unique visionaries or technological convergence. Under the 'Visionary' model, Jobs was a necessary cause for the specific timing and form of the smartphone revolution. However, under 'Technological Determinism,' the convergence of 3G, touch panels, and processors (Z) made a smartphone-like device inevitable, meaning the revolution would have occurred eventually without him, though perhaps with a different design philosophy.",
    "gold_rationale": "This counterfactual depends on whether you view innovation as driven by unique visionaries or technological convergence. Under the 'Visionary' model, Jobs was a necessary cause for the specific timing and form of the smartphone revolution. However, under 'Technological Determinism,' the convergence of 3G, touch panels, and processors (Z) made a smartphone-like device inevitable, meaning the revolution would have occurred eventually without him, though perhaps with a different design philosophy.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0036",
    "case_id": "0036",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Finance",
    "subdomain": "Macroeconomics",
    "scenario": "The Global Financial Crisis began shortly after the collapse of Lehman Brothers. A politician argues: 'If the regulators had bailed out Lehman Brothers, the crisis would have been avoided.' An economist counters that the subprime mortgage bubble and systemic leverage were so massive that a crash was mathematically inevitable.",
    "claim": "Bailing out Lehman Brothers (X') would have prevented the Financial Crisis (Y).",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Lehman Brothers Collapse",
      "Y": "Financial Crisis",
      "Z": [
        "Systemic Leverage / Housing Bubble (Structural Cause)"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Trigger vs. Structural Cause",
      "subtype_name": "Trigger vs. Structural Cause"
    },
    "difficulty": "Hard",
    "causal_structure": "Housing_Bubble(Z) -> Crash_Probability(Y); Lehman_Collapse(X) -> Y (Specific Timing); Z implies P(Y) -> 1; Counterfactual X' delays Y but Z finds another trigger.",
    "key_insight": "Preventing a specific trigger in a fragile system usually results in the system breaking at the next weakest link (replaceable triggers).",
    "hidden_timestamp": "The counterfactual alters the specific spark (X) while ignoring the explosive material (Z) covering the floor.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "The claim confuses a trigger with a root cause. While letting Lehman fail (X) sparked the panic, the crisis was structurally caused by the unsustainable subprime bubble and excessive leverage (Z). Bailing out Lehman (X') might have bought time, but the systemic fragility meant that a correction (Y) was inevitable. The crisis would likely have been triggered by the failure of a different bank shortly thereafter.",
    "gold_rationale": "The claim confuses a trigger with a root cause. While letting Lehman fail (X) sparked the panic, the crisis was structurally caused by the unsustainable subprime bubble and excessive leverage (Z). Bailing out Lehman (X') might have bought time, but the systemic fragility meant that a correction (Y) was inevitable. The crisis would likely have been triggered by the failure of a different bank shortly thereafter.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0037",
    "case_id": "0037",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Computer Science",
    "subdomain": "Systems Engineering",
    "scenario": "An e-commerce website crashed during a Black Friday sale. An investigation reveals three factors: 1. The database architecture chosen a year ago was not scalable. 2. The auto-scaling feature was disabled by a senior dev last week. 3. An intern uploaded a large promotional image one minute before the crash. The CEO blames the intern for the crash.",
    "claim": "The intern's file upload (X) was the cause of the system crash (Y).",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Intern Uploading Image",
      "Y": "System Crash",
      "Z": [
        "Non-scalable Architecture (Root Cause 1)"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Actual Cause Selection / Root Cause Analysis",
      "subtype_name": "Actual Cause Selection / Root Cause Analysis"
    },
    "difficulty": "Medium",
    "causal_structure": "Z & W & X -> Y; Counterfactual(X') -> No_Crash; Counterfactual(Z') -> No_Crash; Counterfactual(W') -> No_Crash; X is selected due to proximity.",
    "key_insight": "In complex systems, failures are often conjunctive (AND logic); blaming the final trigger ignores the systemic fragility that made the trigger fatal.",
    "hidden_timestamp": "The blame is assigned at t=3 based on the event at t=2 (X), ignoring t=0 (Z) and t=1 (W).",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "Blaming the intern (X) is a classic example of confusing a 'trigger' with a 'root cause' due to Recency Bias. While the upload was the final event, the crash was structurally caused by the non-scalable architecture (Z) and the disabled auto-scaling (W). All three were necessary conditions (NESS causes) for the specific failure, but the architectural decisions were far more significant. Focusing on the intern ignores the systemic fragility that made a simple file upload fatal.",
    "gold_rationale": "Blaming the intern (X) is a classic example of confusing a 'trigger' with a 'root cause' due to Recency Bias. While the upload was the final event, the crash was structurally caused by the non-scalable architecture (Z) and the disabled auto-scaling (W). All three were necessary conditions (NESS causes) for the specific failure, but the architectural decisions were far more significant. Focusing on the intern ignores the systemic fragility that made a simple file upload fatal.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0038",
    "case_id": "0038",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Business",
    "subdomain": "Auctions / Strategy",
    "scenario": "A construction firm submitted a sealed bid of $1.2 million for a government contract. They lost to a competitor who bid $1.1 million. The CEO claims: 'If we had bid $1.05 million, we would have won the contract.'",
    "claim": "Bidding $1.05 million (X') would have resulted in winning the contract.",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Bid $1.2M",
      "Y": "Lost Contract",
      "Z": [
        "Competitor Bid $1.1M (State of Nature)"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Game Theory / Sealed vs. Open",
      "subtype_name": "Game Theory / Sealed vs. Open"
    },
    "difficulty": "Medium",
    "causal_structure": "Competitor_Bid(Z) is independent of X (Sealed); Outcome Y = (X < Z); Counterfactual X' < Z implies Win; Z is invariant to X'.",
    "key_insight": "In a sealed-bid auction, the opponent's move is fixed and hidden; counterfactual changes to one's own bid do not retroactively alter the opponent's bid.",
    "hidden_timestamp": "The validity depends on whether Z is determined independently of X (Sealed) or reactively to X (Open).",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "The counterfactual claim is VALID because this was a sealed-bid auction. The competitor's bid (Z) was determined independently of your decision and is invariant in the counterfactual scenario. Since their bid is 'frozen' at $1.1 million, a counterfactual bid of $1.05 million (X') would objectively lower your price below theirs, guaranteeing the win.",
    "gold_rationale": "The counterfactual claim is VALID because this was a sealed-bid auction. The competitor's bid (Z) was determined independently of your decision and is invariant in the counterfactual scenario. Since their bid is 'frozen' at $1.1 million, a counterfactual bid of $1.05 million (X') would objectively lower your price below theirs, guaranteeing the win.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0039",
    "case_id": "0039",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Education",
    "subdomain": "Testing",
    "scenario": "A student initially marked option 'A' on a multiple-choice test but erased it and marked 'B' just before handing it in. The grading key reveals the correct answer was 'A'. The student claims: 'If I had stuck with my original choice, I would have gotten the question right.'",
    "claim": "If I had kept my original answer (X'), I would have answered correctly (Y).",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Changed Answer to B",
      "Y": "Correct Score",
      "Z": [
        "Official Answer Key (State of Nature)"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Deterministic Sequence / Independent State",
      "subtype_name": "Deterministic Sequence / Independent State"
    },
    "difficulty": "Easy",
    "causal_structure": "Answer_Key(Z) is fixed pre-exam; Z is independent of Student_Choice(X); Y = (Student_Choice == Z); Counterfactual X' matches Z.",
    "key_insight": "The answer key is an invariant fact established before the student's action; changing the student's action in a counterfactual world does not retroactively change the answer key.",
    "hidden_timestamp": "The answer key (Z) is fixed at t=0. The student's change (X) occurs at t=1. Z is invariant to X.",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "The counterfactual claim is VALID. The correct answer (Z) is an objective fact determined by the answer key created before the test. The student's decision to change their answer (X) did not causally affect which answer was correct. Therefore, had they kept their original choice (X'), it would have matched the invariant key (Z).",
    "gold_rationale": "The counterfactual claim is VALID. The correct answer (Z) is an objective fact determined by the answer key created before the test. The student's decision to change their answer (X) did not causally affect which answer was correct. Therefore, had they kept their original choice (X'), it would have matched the invariant key (Z).",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.0,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketD-0040",
    "case_id": "0040",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Finance",
    "subdomain": "Risk Management",
    "scenario": "A bank has a strict policy of only approving loans for applicants with a Credit Score above 750. An internal study of the approved loans shows zero correlation between Credit Score and Default Rate. Based on this, the CEO proposes: 'If we lowered the requirement and lent to people with scores of 500, they would likely repay at the same rate.'",
    "claim": "Lending to applicants with low credit scores (counterfactual) would result in similar default rates to high-score applicants.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Credit Score",
      "Y": "Default Rate",
      "Z": [
        "Loan Approval (Selection Filter)"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Counterfactual",
      "subtype": "Unobserved Counterfactual / Range Restriction",
      "subtype_name": "Unobserved Counterfactual / Range Restriction"
    },
    "difficulty": "Medium",
    "causal_structure": "Credit_Score(X) -> Repayment(Y); Credit_Score(X) > 750 -> Approved(Z); Dataset = Z=1; Correlation(X,Y)|Z=1 approx 0 due to ceiling effect.",
    "key_insight": "The lack of correlation among the 'cream of the crop' does not imply a lack of correlation in the general population. The filter removed the bad risks.",
    "hidden_timestamp": "The inference attempts to generalize statistics from a filtered survivor group (t=1) to the excluded population (t=0).",
    "conditional_answers": {
      "answer_if_condition_1": "Under one interpretation of the evidence, the claim might hold.",
      "answer_if_condition_2": "Under a more careful analysis accounting for biases, the claim fails."
    },
    "wise_refusal": "The CEO's proposal relies on a flaw known as Range Restriction. By observing only borrowers with scores above 750, the bank has looked at a sample with artificially low variancethey are all 'good' borrowers, so the score doesn't differentiate them further. The counterfactuallending to 500-score applicantsinvolves a completely different segment of the risk curve. Without observing their performance, assuming they behave like the 750+ group is a dangerous gamble.",
    "gold_rationale": "The CEO's proposal relies on a flaw known as Range Restriction. By observing only borrowers with scores above 750, the bank has looked at a sample with artificially low variancethey are all 'good' borrowers, so the score doesn't differentiate them further. The counterfactuallending to 500-score applicantsinvolves a completely different segment of the risk curve. Without observing their performance, assuming they behave like the 750+ group is a dangerous gamble.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.2,
    "invariants": [
      "Causal structure as stated in scenario",
      "Background conditions held constant"
    ],
    "validator_2": "Longling Geng",
    "final_score_2": 8.95
  },
  {
    "id": "T3-BucketD-0041",
    "case_id": "0041",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Venture Capital",
    "scenario": "A prestigious venture capital firm publishes a 10-year retrospective highlighting their portfolio companies. The report analyzes 25 'success stories' that achieved valuations over $100 million, showing these companies shared common traits: aggressive growth strategies, charismatic founders, and willingness to operate at losses for market share. The VC firm recommends these traits to new portfolio companies. However, the analysis excludes 150 portfolio companies that failed using identical strategies. The failed companies were quietly written off, sold for pennies, or shut down without public announcements. Of the 175 total companies funded, only 25 survived using these aggressive tactics - an 86% failure rate that the retrospective renders invisible.",
    "claim": "Aggressive growth strategies, charismatic founders, and sustained losses cause startup success.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Aggressive growth tactics",
        "role": "exposure"
      },
      "Y": {
        "name": "Startup valuation over $100M",
        "role": "outcome"
      },
      "Z": [
        "Failed companies excluded (86%)",
        "Selection on survival",
        "Missing failure data"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "SURVIVORSHIP",
      "subtype": "Business survival",
      "subtype_name": "Portfolio Company Survivorship Bias"
    },
    "difficulty": "Hard",
    "causal_structure": "Only survivors are analyzed (conditioning on Survival=1), making failed companies invisible. True structure shows aggressive tactics create both rare successes and frequent failures.",
    "key_insight": "Analyzing only survivors makes risky strategies appear effective by hiding the 86% failure rate.",
    "hidden_timestamp": "What happened to the 150 companies that pursued identical strategies but failed?",
    "conditional_answers": {
      "answer_if_condition_1": "If we could observe all 175 companies (including failures), we would see aggressive tactics have only 14% success rate, not the implied high rate.",
      "answer_if_condition_2": "If we condition only on survivors, the strategies appear highly effective because we systematically exclude failures."
    },
    "wise_refusal": "This inference commits survivorship bias by analyzing only the 25 successful companies (14% survival rate) while excluding the 150 failures that used identical strategies. The VC firm selected cases where Y=success occurred, creating systematic distortion. The excluded failures are not missing at randomthey're missing precisely because they pursued these aggressive strategies and failed. Without observing failures, we cannot distinguish whether these traits cause success or are merely necessary-but-not-sufficient conditions. The data actually shows aggressive tactics have an 86% failure rate, contradicting the implied recommendation. We need intention-to-treat analysis of all 175 companies to assess causal effectiveness.",
    "gold_rationale": "Survivorship bias occurs when analysis conditions on survival (Y=1), rendering failures invisible. The causal claim XY cannot be evaluated from survivors alone because we're comparing P(X|Y=success) rather than P(Y=success|X). The proper comparison requires all 175 companies. From a causal DAG perspective: XYSurvival, and we're conditioning on the collider Survival, which induces spurious associations. The 14% success rate (25/175) indicates these tactics usually fail, not succeed. Statistical principle: P(X|Y)  P(Y|X)having trait X given success doesn't mean X causes success.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketD-0042",
    "case_id": "0042",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Venture Capital",
    "scenario": "A prestigious venture capital firm publishes a 10-year retrospective highlighting their portfolio companies. The report analyzes 25 'success stories' that achieved valuations over $100 million, showing these companies shared common traits: aggressive growth strategies, charismatic founders, and willingness to operate at losses for market share. The VC firm recommends these traits to new portfolio companies. However, the analysis excludes 150 portfolio companies that failed using identical strategies. The failed companies were quietly written off, sold for pennies, or shut down without public announcements. Of the 175 total companies funded, only 25 survived using these aggressive tactics - an 86% failure rate that the retrospective renders invisible.",
    "claim": "Aggressive growth strategies, charismatic founders, and sustained losses cause startup success.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Aggressive growth tactics",
        "role": "exposure"
      },
      "Y": {
        "name": "Startup valuation over $100M",
        "role": "outcome"
      },
      "Z": [
        "Failed companies excluded (86%)",
        "Selection on survival",
        "Missing failure data"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "SURVIVORSHIP",
      "subtype": "Business survival",
      "subtype_name": "Portfolio Company Survivorship Bias"
    },
    "difficulty": "Hard",
    "causal_structure": "Only survivors are analyzed (conditioning on Survival=1), making failed companies invisible. True structure shows aggressive tactics create both rare successes and frequent failures.",
    "key_insight": "Analyzing only survivors makes risky strategies appear effective by hiding the 86% failure rate.",
    "hidden_timestamp": "What happened to the 150 companies that pursued identical strategies but failed?",
    "conditional_answers": {
      "answer_if_condition_1": "If we could observe all 175 companies (including failures), we would see aggressive tactics have only 14% success rate, not the implied high rate.",
      "answer_if_condition_2": "If we condition only on survivors, the strategies appear highly effective because we systematically exclude failures."
    },
    "wise_refusal": "This inference commits survivorship bias by analyzing only the 25 successful companies (14% survival rate) while excluding the 150 failures that used identical strategies. The VC firm selected cases where Y=success occurred, creating systematic distortion. The excluded failures are not missing at randomthey're missing precisely because they pursued these aggressive strategies and failed. Without observing failures, we cannot distinguish whether these traits cause success or are merely necessary-but-not-sufficient conditions. The data actually shows aggressive tactics have an 86% failure rate, contradicting the implied recommendation. We need intention-to-treat analysis of all 175 companies to assess causal effectiveness.",
    "gold_rationale": "Survivorship bias occurs when analysis conditions on survival (Y=1), rendering failures invisible. The causal claim XY cannot be evaluated from survivors alone because we're comparing P(X|Y=success) rather than P(Y=success|X). The proper comparison requires all 175 companies. From a causal DAG perspective: XYSurvival, and we're conditioning on the collider Survival, which induces spurious associations. The 14% success rate (25/175) indicates these tactics usually fail, not succeed. Statistical principle: P(X|Y)  P(Y|X)having trait X given success doesn't mean X causes success.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketD-0043",
    "case_id": "0043",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Venture Capital",
    "scenario": "A prestigious venture capital firm publishes a 10-year retrospective highlighting their portfolio companies. The report analyzes 25 'success stories' that achieved valuations over $100 million, showing these companies shared common traits: aggressive growth strategies, charismatic founders, and willingness to operate at losses for market share. The VC firm recommends these traits to new portfolio companies. However, the analysis excludes 150 portfolio companies that failed using identical strategies. The failed companies were quietly written off, sold for pennies, or shut down without public announcements. Of the 175 total companies funded, only 25 survived using these aggressive tactics - an 86% failure rate that the retrospective renders invisible.",
    "claim": "Aggressive growth strategies, charismatic founders, and sustained losses cause startup success.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Aggressive growth tactics",
        "role": "exposure"
      },
      "Y": {
        "name": "Startup valuation over $100M",
        "role": "outcome"
      },
      "Z": [
        "Failed companies excluded (86%)",
        "Selection on survival",
        "Missing failure data"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "SURVIVORSHIP",
      "subtype": "Business survival",
      "subtype_name": "Portfolio Company Survivorship Bias"
    },
    "difficulty": "Hard",
    "causal_structure": "Only survivors are analyzed (conditioning on Survival=1), making failed companies invisible. True structure shows aggressive tactics create both rare successes and frequent failures.",
    "key_insight": "Analyzing only survivors makes risky strategies appear effective by hiding the 86% failure rate.",
    "hidden_timestamp": "What happened to the 150 companies that pursued identical strategies but failed?",
    "conditional_answers": {
      "answer_if_condition_1": "If we could observe all 175 companies (including failures), we would see aggressive tactics have only 14% success rate, not the implied high rate.",
      "answer_if_condition_2": "If we condition only on survivors, the strategies appear highly effective because we systematically exclude failures."
    },
    "wise_refusal": "This inference commits survivorship bias by analyzing only the 25 successful companies (14% survival rate) while excluding the 150 failures that used identical strategies. The VC firm selected cases where Y=success occurred, creating systematic distortion. The excluded failures are not missing at randomthey're missing precisely because they pursued these aggressive strategies and failed. Without observing failures, we cannot distinguish whether these traits cause success or are merely necessary-but-not-sufficient conditions. The data actually shows aggressive tactics have an 86% failure rate, contradicting the implied recommendation. We need intention-to-treat analysis of all 175 companies to assess causal effectiveness.",
    "gold_rationale": "Survivorship bias occurs when analysis conditions on survival (Y=1), rendering failures invisible. The causal claim XY cannot be evaluated from survivors alone because we're comparing P(X|Y=success) rather than P(Y=success|X). The proper comparison requires all 175 companies. From a causal DAG perspective: XYSurvival, and we're conditioning on the collider Survival, which induces spurious associations. The 14% success rate (25/175) indicates these tactics usually fail, not succeed. Statistical principle: P(X|Y)  P(Y|X)having trait X given success doesn't mean X causes success.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketD-0044",
    "case_id": "0044",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "University Admissions",
    "scenario": "A university's aggregate admission data shows men are admitted at a 45% rate while women are admitted at a 35% rate, suggesting gender bias favoring men. However, when examining individual departments, every single department actually admits women at equal or higher rates than men. Department A: Men 5% admission, Women 8% admission, but 80% of male applicants apply here. Department B: Men 60% admission, Women 65% admission, but 80% of female applicants apply here. The aggregate pattern reverses because men disproportionately apply to the high-admission department while women disproportionately apply to the competitive department.",
    "claim": "The university discriminates against women in admissions.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Applicant gender",
        "role": "exposure"
      },
      "Y": {
        "name": "Admission decision",
        "role": "outcome"
      },
      "Z": [
        "Department applied to",
        "Department selectivity",
        "Application distribution"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "SIMPSON'S PARADOX",
      "subtype": "Confounded pooling",
      "subtype_name": "Department Selectivity Confounder"
    },
    "difficulty": "Medium",
    "causal_structure": "Department (Z) is a confounder that affects both application patterns (X) and admission rates (Y). Z causes differential selection into departments and determines admission difficulty.",
    "key_insight": "Aggregate trend favors men (45% vs 35%), but within every department, women have equal or higher admission rates.",
    "hidden_timestamp": "What happens when we stratify admission rates by department (the confounder Z)?",
    "conditional_answers": {
      "answer_if_condition_1": "If we examine only aggregate data without stratifying by department, men appear to have a 10 percentage point advantage.",
      "answer_if_condition_2": "If we stratify by department (controlling for Z), women have equal or higher admission rates in every single department."
    },
    "wise_refusal": "This is Simpson's Paradoxthe aggregate association reverses when we stratify by the confounder (department). The university does not discriminate against women; rather, women disproportionately apply to more selective departments. Department choice (Z) is a common cause of both observed gender differences (X) and admission outcomes (Y). Z confounds the relationship: it determines both who applies where and how hard it is to get admitted. The 45% vs 35% aggregate difference arises purely from different application distributions across departments with different base rates. Within each stratum (department), women perform equally or better. The causal graph is: ZX and ZY, creating spurious X-Y correlation. Controlling for Z reveals no discrimination. This is the classic Berkeley admissions case (Bickel et al., 1975) demonstrating that aggregate statistics can mislead when confounders create unequal base rates across groups.",
    "gold_rationale": "Simpson's Paradox occurs when a confounder Z creates different distributions across groups, causing aggregate and stratified analyses to conflict. Here Z (department) affects both gender application patterns and admission difficulty. Mathematically, the weighted average of within-stratum effects differs from the marginal effect due to different weighting. Women's 35% aggregate rate results from applying heavily to Department A (8% admit rate) while men's 45% aggregate rate results from applying heavily to Department B (60% admit rate). The paradox resolves by recognizing Z as a confounder: GenderDepartment selection and DepartmentAdmission difficulty. Proper causal inference requires conditioning on Z, which eliminates the spurious aggregate association. The do-calculus formulation: P(Y|do(X=female)) would require equalizing department distributions, not comparing marginal rates. This demonstrates why causal claims require identifying and controlling for confounders, not just comparing marginal associations.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0045",
    "case_id": "0045",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "University Admissions",
    "scenario": "A university's aggregate admission data shows men are admitted at a 45% rate while women are admitted at a 35% rate, suggesting gender bias favoring men. However, when examining individual departments, every single department actually admits women at equal or higher rates than men. Department A: Men 5% admission, Women 8% admission, but 80% of male applicants apply here. Department B: Men 60% admission, Women 65% admission, but 80% of female applicants apply here. The aggregate pattern reverses because men disproportionately apply to the high-admission department while women disproportionately apply to the competitive department.",
    "claim": "The university discriminates against women in admissions.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Applicant gender",
        "role": "exposure"
      },
      "Y": {
        "name": "Admission decision",
        "role": "outcome"
      },
      "Z": [
        "Department applied to",
        "Department selectivity",
        "Application distribution"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "SIMPSON'S PARADOX",
      "subtype": "Confounded pooling",
      "subtype_name": "Department Selectivity Confounder"
    },
    "difficulty": "Medium",
    "causal_structure": "Department (Z) is a confounder that affects both application patterns (X) and admission rates (Y). Z causes differential selection into departments and determines admission difficulty.",
    "key_insight": "Aggregate trend favors men (45% vs 35%), but within every department, women have equal or higher admission rates.",
    "hidden_timestamp": "What happens when we stratify admission rates by department (the confounder Z)?",
    "conditional_answers": {
      "answer_if_condition_1": "If we examine only aggregate data without stratifying by department, men appear to have a 10 percentage point advantage.",
      "answer_if_condition_2": "If we stratify by department (controlling for Z), women have equal or higher admission rates in every single department."
    },
    "wise_refusal": "This is Simpson's Paradoxthe aggregate association reverses when we stratify by the confounder (department). The university does not discriminate against women; rather, women disproportionately apply to more selective departments. Department choice (Z) is a common cause of both observed gender differences (X) and admission outcomes (Y). Z confounds the relationship: it determines both who applies where and how hard it is to get admitted. The 45% vs 35% aggregate difference arises purely from different application distributions across departments with different base rates. Within each stratum (department), women perform equally or better. The causal graph is: ZX and ZY, creating spurious X-Y correlation. Controlling for Z reveals no discrimination. This is the classic Berkeley admissions case (Bickel et al., 1975) demonstrating that aggregate statistics can mislead when confounders create unequal base rates across groups.",
    "gold_rationale": "Simpson's Paradox occurs when a confounder Z creates different distributions across groups, causing aggregate and stratified analyses to conflict. Here Z (department) affects both gender application patterns and admission difficulty. Mathematically, the weighted average of within-stratum effects differs from the marginal effect due to different weighting. Women's 35% aggregate rate results from applying heavily to Department A (8% admit rate) while men's 45% aggregate rate results from applying heavily to Department B (60% admit rate). The paradox resolves by recognizing Z as a confounder: GenderDepartment selection and DepartmentAdmission difficulty. Proper causal inference requires conditioning on Z, which eliminates the spurious aggregate association. The do-calculus formulation: P(Y|do(X=female)) would require equalizing department distributions, not comparing marginal rates. This demonstrates why causal claims require identifying and controlling for confounders, not just comparing marginal associations.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0046",
    "case_id": "0046",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "University Admissions",
    "scenario": "A university's aggregate admission data shows men are admitted at a 45% rate while women are admitted at a 35% rate, suggesting gender bias favoring men. However, when examining individual departments, every single department actually admits women at equal or higher rates than men. Department A: Men 5% admission, Women 8% admission, but 80% of male applicants apply here. Department B: Men 60% admission, Women 65% admission, but 80% of female applicants apply here. The aggregate pattern reverses because men disproportionately apply to the high-admission department while women disproportionately apply to the competitive department.",
    "claim": "The university discriminates against women in admissions.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Applicant gender",
        "role": "exposure"
      },
      "Y": {
        "name": "Admission decision",
        "role": "outcome"
      },
      "Z": [
        "Department applied to",
        "Department selectivity",
        "Application distribution"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "SIMPSON'S PARADOX",
      "subtype": "Confounded pooling",
      "subtype_name": "Department Selectivity Confounder"
    },
    "difficulty": "Medium",
    "causal_structure": "Department (Z) is a confounder that affects both application patterns (X) and admission rates (Y). Z causes differential selection into departments and determines admission difficulty.",
    "key_insight": "Aggregate trend favors men (45% vs 35%), but within every department, women have equal or higher admission rates.",
    "hidden_timestamp": "What happens when we stratify admission rates by department (the confounder Z)?",
    "conditional_answers": {
      "answer_if_condition_1": "If we examine only aggregate data without stratifying by department, men appear to have a 10 percentage point advantage.",
      "answer_if_condition_2": "If we stratify by department (controlling for Z), women have equal or higher admission rates in every single department."
    },
    "wise_refusal": "This is Simpson's Paradoxthe aggregate association reverses when we stratify by the confounder (department). The university does not discriminate against women; rather, women disproportionately apply to more selective departments. Department choice (Z) is a common cause of both observed gender differences (X) and admission outcomes (Y). Z confounds the relationship: it determines both who applies where and how hard it is to get admitted. The 45% vs 35% aggregate difference arises purely from different application distributions across departments with different base rates. Within each stratum (department), women perform equally or better. The causal graph is: ZX and ZY, creating spurious X-Y correlation. Controlling for Z reveals no discrimination. This is the classic Berkeley admissions case (Bickel et al., 1975) demonstrating that aggregate statistics can mislead when confounders create unequal base rates across groups.",
    "gold_rationale": "Simpson's Paradox occurs when a confounder Z creates different distributions across groups, causing aggregate and stratified analyses to conflict. Here Z (department) affects both gender application patterns and admission difficulty. Mathematically, the weighted average of within-stratum effects differs from the marginal effect due to different weighting. Women's 35% aggregate rate results from applying heavily to Department A (8% admit rate) while men's 45% aggregate rate results from applying heavily to Department B (60% admit rate). The paradox resolves by recognizing Z as a confounder: GenderDepartment selection and DepartmentAdmission difficulty. Proper causal inference requires conditioning on Z, which eliminates the spurious aggregate association. The do-calculus formulation: P(Y|do(X=female)) would require equalizing department distributions, not comparing marginal rates. This demonstrates why causal claims require identifying and controlling for confounders, not just comparing marginal associations.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0047",
    "case_id": "0047",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Epidemiology",
    "scenario": "A cross-national study finds that countries with higher per capita chocolate consumption have significantly more Nobel Prize laureates per capita. The correlation persists even after controlling for GDP, education spending, and R&D investment. A researcher concludes that chocolate consumption improves cognitive function at the population level, leading to more scientific achievement. However, this commits the ecological fallacy by inferring individual-level causation from country-level correlations. Both chocolate consumption and Nobel prizes are driven by wealth, cultural factors, and historical scientific infrastructurevariables that operate at the national level but don't translate to individual cause-effect relationships.",
    "claim": "Chocolate consumption causes increased scientific achievement (Nobel laureates).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "National chocolate consumption per capita",
        "role": "exposure"
      },
      "Y": {
        "name": "Nobel laureates per capita",
        "role": "outcome"
      },
      "Z": [
        "National wealth and development",
        "Historical scientific infrastructure",
        "Cultural factors",
        "Aggregation level"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "ECOLOGICAL FALLACY",
      "subtype": "Cross-level inference",
      "subtype_name": "Country-to-Individual Inference"
    },
    "difficulty": "Medium",
    "causal_structure": "National-level wealth and development (Z) causes both higher chocolate consumption (X) and scientific infrastructure that produces laureates (Y). The correlation exists at the country level but doesn't imply individual causation.",
    "key_insight": "Country-level correlation doesn't imply individual-level causationecological fallacy.",
    "hidden_timestamp": "Does the pattern hold within each country when examining individual consumption and achievement?",
    "conditional_answers": {
      "answer_if_condition_1": "If we examine only country-level aggregate data, chocolate consumption strongly correlates with Nobel prizes (r=0.79).",
      "answer_if_condition_2": "If we examine individual-level data within countries, there's no evidence that people who eat more chocolate are more likely to win Nobel prizes."
    },
    "wise_refusal": "This commits the ecological fallacy by inferring individual-level causation from group-level correlation. The r=0.79 correlation exists at the country level, but this doesn't mean individuals who eat more chocolate are more likely to win Nobel prizes. Both variables are driven by national wealth, historical scientific tradition, and development level (Z). Wealthy developed nations have both higher chocolate consumption and long-established scientific institutions. The correlation is compositionalit reflects between-country differences in development, not within-individual causal effects. Switzerland has high chocolate consumption and many laureates, but this doesn't mean eating Swiss chocolate makes you a Nobel laureate. The causal structure is ZX and ZY at the national level. Robinson (1950) demonstrated that ecological correlations can be radically different from individual correlations, sometimes even opposite in sign. Without individual-level data showing that chocolate consumers within countries achieve more, the causal inference is unfounded.",
    "gold_rationale": "The ecological fallacy (Robinson, 1950) occurs when group-level associations are used to infer individual-level causation. Mathematically, the between-group correlation _between can differ substantially from the within-group correlation _within. Here, _between=0.79 for countries, but _within is likely near zero for individuals. The correlation exists because national development (Z) affects both aggregate consumption patterns and scientific infrastructure. This creates a compositional effect: variation between countries in Z drives correlation between X and Y, but variation within countries shows no such relationship. The causal graph at the ecological level is: National Development (Z)  Chocolate Consumption (X_country) and National Development (Z)  Nobel Prizes (_country). This doesn't translate to individual causation: Chocolate_individual  Nobel_individual. Cross-level inference fails because confounding operates differently at different levels of aggregation. The study would need individual-level data controlling for personal wealth, education, and career to test the causal claim.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0048",
    "case_id": "0048",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Epidemiology",
    "scenario": "A cross-national study finds that countries with higher per capita chocolate consumption have significantly more Nobel Prize laureates per capita. The correlation persists even after controlling for GDP, education spending, and R&D investment. A researcher concludes that chocolate consumption improves cognitive function at the population level, leading to more scientific achievement. However, this commits the ecological fallacy by inferring individual-level causation from country-level correlations. Both chocolate consumption and Nobel prizes are driven by wealth, cultural factors, and historical scientific infrastructurevariables that operate at the national level but don't translate to individual cause-effect relationships.",
    "claim": "Chocolate consumption causes increased scientific achievement (Nobel laureates).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "National chocolate consumption per capita",
        "role": "exposure"
      },
      "Y": {
        "name": "Nobel laureates per capita",
        "role": "outcome"
      },
      "Z": [
        "National wealth and development",
        "Historical scientific infrastructure",
        "Cultural factors",
        "Aggregation level"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "ECOLOGICAL FALLACY",
      "subtype": "Cross-level inference",
      "subtype_name": "Country-to-Individual Inference"
    },
    "difficulty": "Medium",
    "causal_structure": "National-level wealth and development (Z) causes both higher chocolate consumption (X) and scientific infrastructure that produces laureates (Y). The correlation exists at the country level but doesn't imply individual causation.",
    "key_insight": "Country-level correlation doesn't imply individual-level causationecological fallacy.",
    "hidden_timestamp": "Does the pattern hold within each country when examining individual consumption and achievement?",
    "conditional_answers": {
      "answer_if_condition_1": "If we examine only country-level aggregate data, chocolate consumption strongly correlates with Nobel prizes (r=0.79).",
      "answer_if_condition_2": "If we examine individual-level data within countries, there's no evidence that people who eat more chocolate are more likely to win Nobel prizes."
    },
    "wise_refusal": "This commits the ecological fallacy by inferring individual-level causation from group-level correlation. The r=0.79 correlation exists at the country level, but this doesn't mean individuals who eat more chocolate are more likely to win Nobel prizes. Both variables are driven by national wealth, historical scientific tradition, and development level (Z). Wealthy developed nations have both higher chocolate consumption and long-established scientific institutions. The correlation is compositionalit reflects between-country differences in development, not within-individual causal effects. Switzerland has high chocolate consumption and many laureates, but this doesn't mean eating Swiss chocolate makes you a Nobel laureate. The causal structure is ZX and ZY at the national level. Robinson (1950) demonstrated that ecological correlations can be radically different from individual correlations, sometimes even opposite in sign. Without individual-level data showing that chocolate consumers within countries achieve more, the causal inference is unfounded.",
    "gold_rationale": "The ecological fallacy (Robinson, 1950) occurs when group-level associations are used to infer individual-level causation. Mathematically, the between-group correlation _between can differ substantially from the within-group correlation _within. Here, _between=0.79 for countries, but _within is likely near zero for individuals. The correlation exists because national development (Z) affects both aggregate consumption patterns and scientific infrastructure. This creates a compositional effect: variation between countries in Z drives correlation between X and Y, but variation within countries shows no such relationship. The causal graph at the ecological level is: National Development (Z)  Chocolate Consumption (X_country) and National Development (Z)  Nobel Prizes (_country). This doesn't translate to individual causation: Chocolate_individual  Nobel_individual. Cross-level inference fails because confounding operates differently at different levels of aggregation. The study would need individual-level data controlling for personal wealth, education, and career to test the causal claim.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0049",
    "case_id": "0049",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Epidemiology",
    "scenario": "A cross-national study finds that countries with higher per capita chocolate consumption have significantly more Nobel Prize laureates per capita. The correlation persists even after controlling for GDP, education spending, and R&D investment. A researcher concludes that chocolate consumption improves cognitive function at the population level, leading to more scientific achievement. However, this commits the ecological fallacy by inferring individual-level causation from country-level correlations. Both chocolate consumption and Nobel prizes are driven by wealth, cultural factors, and historical scientific infrastructurevariables that operate at the national level but don't translate to individual cause-effect relationships.",
    "claim": "Chocolate consumption causes increased scientific achievement (Nobel laureates).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "National chocolate consumption per capita",
        "role": "exposure"
      },
      "Y": {
        "name": "Nobel laureates per capita",
        "role": "outcome"
      },
      "Z": [
        "National wealth and development",
        "Historical scientific infrastructure",
        "Cultural factors",
        "Aggregation level"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "ECOLOGICAL FALLACY",
      "subtype": "Cross-level inference",
      "subtype_name": "Country-to-Individual Inference"
    },
    "difficulty": "Medium",
    "causal_structure": "National-level wealth and development (Z) causes both higher chocolate consumption (X) and scientific infrastructure that produces laureates (Y). The correlation exists at the country level but doesn't imply individual causation.",
    "key_insight": "Country-level correlation doesn't imply individual-level causationecological fallacy.",
    "hidden_timestamp": "Does the pattern hold within each country when examining individual consumption and achievement?",
    "conditional_answers": {
      "answer_if_condition_1": "If we examine only country-level aggregate data, chocolate consumption strongly correlates with Nobel prizes (r=0.79).",
      "answer_if_condition_2": "If we examine individual-level data within countries, there's no evidence that people who eat more chocolate are more likely to win Nobel prizes."
    },
    "wise_refusal": "This commits the ecological fallacy by inferring individual-level causation from group-level correlation. The r=0.79 correlation exists at the country level, but this doesn't mean individuals who eat more chocolate are more likely to win Nobel prizes. Both variables are driven by national wealth, historical scientific tradition, and development level (Z). Wealthy developed nations have both higher chocolate consumption and long-established scientific institutions. The correlation is compositionalit reflects between-country differences in development, not within-individual causal effects. Switzerland has high chocolate consumption and many laureates, but this doesn't mean eating Swiss chocolate makes you a Nobel laureate. The causal structure is ZX and ZY at the national level. Robinson (1950) demonstrated that ecological correlations can be radically different from individual correlations, sometimes even opposite in sign. Without individual-level data showing that chocolate consumers within countries achieve more, the causal inference is unfounded.",
    "gold_rationale": "The ecological fallacy (Robinson, 1950) occurs when group-level associations are used to infer individual-level causation. Mathematically, the between-group correlation _between can differ substantially from the within-group correlation _within. Here, _between=0.79 for countries, but _within is likely near zero for individuals. The correlation exists because national development (Z) affects both aggregate consumption patterns and scientific infrastructure. This creates a compositional effect: variation between countries in Z drives correlation between X and Y, but variation within countries shows no such relationship. The causal graph at the ecological level is: National Development (Z)  Chocolate Consumption (X_country) and National Development (Z)  Nobel Prizes (_country). This doesn't translate to individual causation: Chocolate_individual  Nobel_individual. Cross-level inference fails because confounding operates differently at different levels of aggregation. The study would need individual-level data controlling for personal wealth, education, and career to test the causal claim.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0050",
    "case_id": "0050",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Sports",
    "subdomain": "Performance Analysis",
    "scenario": "Sports Illustrated magazine tracks athletes who appear on its cover. Data shows that 80% of featured athletes experience performance declines in the following season compared to their cover season. This 'Sports Illustrated jinx' is cited as evidence that the publicity causes pressure and distraction leading to worse performance. However, athletes are selected for covers precisely because they just had exceptional, career-best seasons. These peak performances are statistical outliers that naturally regress toward their career averagewhether they appear on a magazine cover or not. The 'jinx' is regression to the mean, not a causal effect of publicity.",
    "claim": "Being featured on the Sports Illustrated cover causes athletes' performance to decline.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Sports Illustrated cover feature",
        "role": "exposure"
      },
      "Y": {
        "name": "Performance decline in following season",
        "role": "outcome"
      },
      "Z": [
        "Selection for extreme performance",
        "Natural performance variation",
        "Regression to career mean"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "REGRESSION TO MEAN",
      "subtype": "Sports performance",
      "subtype_name": "Sophomore Slump Pattern"
    },
    "difficulty": "Easy",
    "causal_structure": "Athletes are selected for covers based on extreme performance (Y1 at peak). Subsequent performance (Y2) naturally regresses toward career average, independent of cover appearance (X).",
    "key_insight": "Extreme performances are followed by more average performances due to random variation, not cover appearance.",
    "hidden_timestamp": "Were subjects selected for extreme values that would naturally regress toward the mean?",
    "conditional_answers": {
      "answer_if_condition_1": "If athletes are selected randomly regardless of recent performance, cover appearance might causally affect performance through pressure.",
      "answer_if_condition_2": "If athletes are selected specifically for exceptional recent performance, the subsequent 'decline' reflects statistical regression to mean, not a causal effect."
    },
    "wise_refusal": "This is regression to the mean, not a causal effect. Athletes appear on SI covers precisely because they just had career-best, exceptional seasonsstatistical outliers above their true ability level. Any extreme performance (whether peak or trough) tends to be followed by a more typical performance closer to the athlete's career average. This is pure statistical regression, described by Galton (1886). The 80% 'decline' rate is expected even with zero causal effect of publicity. To test causality, we would need: (1) a control group of athletes with identical exceptional seasons who weren't featured, or (2) random assignment to cover appearance. Neither exists. The selection mechanismchoosing athletes at their statistical peakguarantees apparent decline. A similar 'reverse jinx' would appear if we selected athletes who just had terrible seasons: most would 'mysteriously' improve the following year. The mathematical expectation is E[Y_t+1|Y_t=extreme] < Y_t due to measurement error and random performance variation, regardless of any intervention between measurements.",
    "gold_rationale": "Regression to the mean occurs when subjects are selected based on extreme values. Galton (1886) showed that children of very tall parents are, on average, shorter than their parents (though still tall). This isn't genetic regressionit's statistical. Extreme values contain both true signal and random noise. At extreme values, the noise component is likely to be positive (for high extremes) or negative (for low extremes). On subsequent measurement, the noise averages out, pulling the value back toward the true mean. Formally: if Y_t =  + _t where  ~ N(0,), then E[Y_t+1|Y_t > c] < Y_t for c > . In the SI case, athletes selected at performance peak (Y_t = extreme) will show Y_t+1 closer to career average , purely from regression. This is why medical trials use randomized controls: treating only sick patients (selected for extreme symptoms) will show 'improvement' even with placebo, due to regression. The 80% decline rate is consistent with pure statistical regression given the selection criterion.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0051",
    "case_id": "0051",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Sports",
    "subdomain": "Performance Analysis",
    "scenario": "Sports Illustrated magazine tracks athletes who appear on its cover. Data shows that 80% of featured athletes experience performance declines in the following season compared to their cover season. This 'Sports Illustrated jinx' is cited as evidence that the publicity causes pressure and distraction leading to worse performance. However, athletes are selected for covers precisely because they just had exceptional, career-best seasons. These peak performances are statistical outliers that naturally regress toward their career averagewhether they appear on a magazine cover or not. The 'jinx' is regression to the mean, not a causal effect of publicity.",
    "claim": "Being featured on the Sports Illustrated cover causes athletes' performance to decline.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Sports Illustrated cover feature",
        "role": "exposure"
      },
      "Y": {
        "name": "Performance decline in following season",
        "role": "outcome"
      },
      "Z": [
        "Selection for extreme performance",
        "Natural performance variation",
        "Regression to career mean"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "REGRESSION TO MEAN",
      "subtype": "Sports performance",
      "subtype_name": "Sophomore Slump Pattern"
    },
    "difficulty": "Easy",
    "causal_structure": "Athletes are selected for covers based on extreme performance (Y1 at peak). Subsequent performance (Y2) naturally regresses toward career average, independent of cover appearance (X).",
    "key_insight": "Extreme performances are followed by more average performances due to random variation, not cover appearance.",
    "hidden_timestamp": "Were subjects selected for extreme values that would naturally regress toward the mean?",
    "conditional_answers": {
      "answer_if_condition_1": "If athletes are selected randomly regardless of recent performance, cover appearance might causally affect performance through pressure.",
      "answer_if_condition_2": "If athletes are selected specifically for exceptional recent performance, the subsequent 'decline' reflects statistical regression to mean, not a causal effect."
    },
    "wise_refusal": "This is regression to the mean, not a causal effect. Athletes appear on SI covers precisely because they just had career-best, exceptional seasonsstatistical outliers above their true ability level. Any extreme performance (whether peak or trough) tends to be followed by a more typical performance closer to the athlete's career average. This is pure statistical regression, described by Galton (1886). The 80% 'decline' rate is expected even with zero causal effect of publicity. To test causality, we would need: (1) a control group of athletes with identical exceptional seasons who weren't featured, or (2) random assignment to cover appearance. Neither exists. The selection mechanismchoosing athletes at their statistical peakguarantees apparent decline. A similar 'reverse jinx' would appear if we selected athletes who just had terrible seasons: most would 'mysteriously' improve the following year. The mathematical expectation is E[Y_t+1|Y_t=extreme] < Y_t due to measurement error and random performance variation, regardless of any intervention between measurements.",
    "gold_rationale": "Regression to the mean occurs when subjects are selected based on extreme values. Galton (1886) showed that children of very tall parents are, on average, shorter than their parents (though still tall). This isn't genetic regressionit's statistical. Extreme values contain both true signal and random noise. At extreme values, the noise component is likely to be positive (for high extremes) or negative (for low extremes). On subsequent measurement, the noise averages out, pulling the value back toward the true mean. Formally: if Y_t =  + _t where  ~ N(0,), then E[Y_t+1|Y_t > c] < Y_t for c > . In the SI case, athletes selected at performance peak (Y_t = extreme) will show Y_t+1 closer to career average , purely from regression. This is why medical trials use randomized controls: treating only sick patients (selected for extreme symptoms) will show 'improvement' even with placebo, due to regression. The 80% decline rate is consistent with pure statistical regression given the selection criterion.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0052",
    "case_id": "0052",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Sports",
    "subdomain": "Performance Analysis",
    "scenario": "Sports Illustrated magazine tracks athletes who appear on its cover. Data shows that 80% of featured athletes experience performance declines in the following season compared to their cover season. This 'Sports Illustrated jinx' is cited as evidence that the publicity causes pressure and distraction leading to worse performance. However, athletes are selected for covers precisely because they just had exceptional, career-best seasons. These peak performances are statistical outliers that naturally regress toward their career averagewhether they appear on a magazine cover or not. The 'jinx' is regression to the mean, not a causal effect of publicity.",
    "claim": "Being featured on the Sports Illustrated cover causes athletes' performance to decline.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Sports Illustrated cover feature",
        "role": "exposure"
      },
      "Y": {
        "name": "Performance decline in following season",
        "role": "outcome"
      },
      "Z": [
        "Selection for extreme performance",
        "Natural performance variation",
        "Regression to career mean"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "REGRESSION TO MEAN",
      "subtype": "Sports performance",
      "subtype_name": "Sophomore Slump Pattern"
    },
    "difficulty": "Easy",
    "causal_structure": "Athletes are selected for covers based on extreme performance (Y1 at peak). Subsequent performance (Y2) naturally regresses toward career average, independent of cover appearance (X).",
    "key_insight": "Extreme performances are followed by more average performances due to random variation, not cover appearance.",
    "hidden_timestamp": "Were subjects selected for extreme values that would naturally regress toward the mean?",
    "conditional_answers": {
      "answer_if_condition_1": "If athletes are selected randomly regardless of recent performance, cover appearance might causally affect performance through pressure.",
      "answer_if_condition_2": "If athletes are selected specifically for exceptional recent performance, the subsequent 'decline' reflects statistical regression to mean, not a causal effect."
    },
    "wise_refusal": "This is regression to the mean, not a causal effect. Athletes appear on SI covers precisely because they just had career-best, exceptional seasonsstatistical outliers above their true ability level. Any extreme performance (whether peak or trough) tends to be followed by a more typical performance closer to the athlete's career average. This is pure statistical regression, described by Galton (1886). The 80% 'decline' rate is expected even with zero causal effect of publicity. To test causality, we would need: (1) a control group of athletes with identical exceptional seasons who weren't featured, or (2) random assignment to cover appearance. Neither exists. The selection mechanismchoosing athletes at their statistical peakguarantees apparent decline. A similar 'reverse jinx' would appear if we selected athletes who just had terrible seasons: most would 'mysteriously' improve the following year. The mathematical expectation is E[Y_t+1|Y_t=extreme] < Y_t due to measurement error and random performance variation, regardless of any intervention between measurements.",
    "gold_rationale": "Regression to the mean occurs when subjects are selected based on extreme values. Galton (1886) showed that children of very tall parents are, on average, shorter than their parents (though still tall). This isn't genetic regressionit's statistical. Extreme values contain both true signal and random noise. At extreme values, the noise component is likely to be positive (for high extremes) or negative (for low extremes). On subsequent measurement, the noise averages out, pulling the value back toward the true mean. Formally: if Y_t =  + _t where  ~ N(0,), then E[Y_t+1|Y_t > c] < Y_t for c > . In the SI case, athletes selected at performance peak (Y_t = extreme) will show Y_t+1 closer to career average , purely from regression. This is why medical trials use randomized controls: treating only sick patients (selected for extreme symptoms) will show 'improvement' even with placebo, due to regression. The 80% decline rate is consistent with pure statistical regression given the selection criterion.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0053",
    "case_id": "0053",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Performance Metrics",
    "scenario": "A tech company sets a policy that engineering managers must reduce average code review time below 4 hours to receive bonuses. Within two quarters, the metric improves dramatically91% of reviews are now completed in under 4 hours, compared to 60% previously. Management celebrates this success and attributes it to the incentive policy. However, developers report that managers now approve pull requests perfunctorily without thorough review, and production bug rates have increased 35%. The metric improved not because review quality increased, but because managers gamed the system by sacrificing thoroughness for speed. Once the metric became a target, it ceased to be a useful quality indicator.",
    "claim": "The bonus policy caused improved code review efficiency.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Bonus policy based on review time metric",
        "role": "exposure"
      },
      "Y": {
        "name": "Average code review time under 4 hours",
        "role": "outcome"
      },
      "Z": [
        "Review thoroughness sacrificed",
        "Gaming behavior",
        "Metric loses validity as quality indicator"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Performance Metric Gaming"
    },
    "difficulty": "Medium",
    "causal_structure": "Before intervention: Review Time (M) proxied for Review Quality (Q) and drove outcomes (Y). After intervention targeted M, gaming (G) broke the MY relationship: M no longer indicates Q.",
    "key_insight": "When a measure becomes a target, people game the metric rather than improve the underlying quality it once measured.",
    "hidden_timestamp": "Is the metric being gamed rather than improved organically?",
    "conditional_answers": {
      "answer_if_condition_1": "If managers genuinely improved review efficiency while maintaining thoroughness, the metric improvement reflects real gains.",
      "answer_if_condition_2": "If managers game the system by approving reviews quickly without proper scrutiny, the metric improvement is illusory and masks declining review quality."
    },
    "wise_refusal": "This is Goodhart's Law: 'When a measure becomes a target, it ceases to be a good measure.' Code review time was originally a reasonable proxy for team efficiencyfaster reviews (within reason) suggested streamlined processes. But once managers' bonuses depended on this metric, they had incentive to optimize the metric itself rather than the underlying quality. The result: superficial rubber-stamp approvals that hit the 4-hour target but sacrifice code quality. The metric improved (91% compliance) while the actual outcome deteriorated (35% more production bugs). The causal graph broke: Before: QualityReviewTimeMetric, After: IncentiveGamingMetric (bypassing Quality). The intervention severed the relationship between metric and outcome. Evidence of gaming: the metric changed dramatically without process improvements, and outcome quality declined. This pattern appears across domains when proxies are incentivized: teaching to the test, hospital mortality gaming by refusing terminal patients, police manipulating crime statistics.",
    "gold_rationale": "Goodhart's Law (1984) states that metrics lose validity when they become targets for optimization. Campbell's Law (1979) similarly notes: 'The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures.' The causal mechanism: (1) Metric M initially correlates with desired outcome Y because both are driven by underlying quality Q: QM and QY. (2) Intervention I targets M for rewards. (3) Agents optimize M directly through gaming G rather than improving Q: IGM. (4) The GM pathway bypasses Q, breaking the M-Y correlation. (5) M improves while Y deteriorates. The code review case shows all phases: review time initially proxied efficiency (MQ), bonuses targeted review time (IM), managers gamed with superficial approvals (GM bypassing Q), metric improved but bugs increased (M, Y). The solution requires measuring multiple indicators resistant to gaming, or directly measuring outcomes rather than proxies. This is why healthcare moved from process measures (did you document?) to outcome measures (did the patient improve?).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0054",
    "case_id": "0054",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Performance Metrics",
    "scenario": "A tech company sets a policy that engineering managers must reduce average code review time below 4 hours to receive bonuses. Within two quarters, the metric improves dramatically91% of reviews are now completed in under 4 hours, compared to 60% previously. Management celebrates this success and attributes it to the incentive policy. However, developers report that managers now approve pull requests perfunctorily without thorough review, and production bug rates have increased 35%. The metric improved not because review quality increased, but because managers gamed the system by sacrificing thoroughness for speed. Once the metric became a target, it ceased to be a useful quality indicator.",
    "claim": "The bonus policy caused improved code review efficiency.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Bonus policy based on review time metric",
        "role": "exposure"
      },
      "Y": {
        "name": "Average code review time under 4 hours",
        "role": "outcome"
      },
      "Z": [
        "Review thoroughness sacrificed",
        "Gaming behavior",
        "Metric loses validity as quality indicator"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Performance Metric Gaming"
    },
    "difficulty": "Medium",
    "causal_structure": "Before intervention: Review Time (M) proxied for Review Quality (Q) and drove outcomes (Y). After intervention targeted M, gaming (G) broke the MY relationship: M no longer indicates Q.",
    "key_insight": "When a measure becomes a target, people game the metric rather than improve the underlying quality it once measured.",
    "hidden_timestamp": "Is the metric being gamed rather than improved organically?",
    "conditional_answers": {
      "answer_if_condition_1": "If managers genuinely improved review efficiency while maintaining thoroughness, the metric improvement reflects real gains.",
      "answer_if_condition_2": "If managers game the system by approving reviews quickly without proper scrutiny, the metric improvement is illusory and masks declining review quality."
    },
    "wise_refusal": "This is Goodhart's Law: 'When a measure becomes a target, it ceases to be a good measure.' Code review time was originally a reasonable proxy for team efficiencyfaster reviews (within reason) suggested streamlined processes. But once managers' bonuses depended on this metric, they had incentive to optimize the metric itself rather than the underlying quality. The result: superficial rubber-stamp approvals that hit the 4-hour target but sacrifice code quality. The metric improved (91% compliance) while the actual outcome deteriorated (35% more production bugs). The causal graph broke: Before: QualityReviewTimeMetric, After: IncentiveGamingMetric (bypassing Quality). The intervention severed the relationship between metric and outcome. Evidence of gaming: the metric changed dramatically without process improvements, and outcome quality declined. This pattern appears across domains when proxies are incentivized: teaching to the test, hospital mortality gaming by refusing terminal patients, police manipulating crime statistics.",
    "gold_rationale": "Goodhart's Law (1984) states that metrics lose validity when they become targets for optimization. Campbell's Law (1979) similarly notes: 'The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures.' The causal mechanism: (1) Metric M initially correlates with desired outcome Y because both are driven by underlying quality Q: QM and QY. (2) Intervention I targets M for rewards. (3) Agents optimize M directly through gaming G rather than improving Q: IGM. (4) The GM pathway bypasses Q, breaking the M-Y correlation. (5) M improves while Y deteriorates. The code review case shows all phases: review time initially proxied efficiency (MQ), bonuses targeted review time (IM), managers gamed with superficial approvals (GM bypassing Q), metric improved but bugs increased (M, Y). The solution requires measuring multiple indicators resistant to gaming, or directly measuring outcomes rather than proxies. This is why healthcare moved from process measures (did you document?) to outcome measures (did the patient improve?).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0055",
    "case_id": "0055",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Performance Metrics",
    "scenario": "A tech company sets a policy that engineering managers must reduce average code review time below 4 hours to receive bonuses. Within two quarters, the metric improves dramatically91% of reviews are now completed in under 4 hours, compared to 60% previously. Management celebrates this success and attributes it to the incentive policy. However, developers report that managers now approve pull requests perfunctorily without thorough review, and production bug rates have increased 35%. The metric improved not because review quality increased, but because managers gamed the system by sacrificing thoroughness for speed. Once the metric became a target, it ceased to be a useful quality indicator.",
    "claim": "The bonus policy caused improved code review efficiency.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Bonus policy based on review time metric",
        "role": "exposure"
      },
      "Y": {
        "name": "Average code review time under 4 hours",
        "role": "outcome"
      },
      "Z": [
        "Review thoroughness sacrificed",
        "Gaming behavior",
        "Metric loses validity as quality indicator"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Performance Metric Gaming"
    },
    "difficulty": "Medium",
    "causal_structure": "Before intervention: Review Time (M) proxied for Review Quality (Q) and drove outcomes (Y). After intervention targeted M, gaming (G) broke the MY relationship: M no longer indicates Q.",
    "key_insight": "When a measure becomes a target, people game the metric rather than improve the underlying quality it once measured.",
    "hidden_timestamp": "Is the metric being gamed rather than improved organically?",
    "conditional_answers": {
      "answer_if_condition_1": "If managers genuinely improved review efficiency while maintaining thoroughness, the metric improvement reflects real gains.",
      "answer_if_condition_2": "If managers game the system by approving reviews quickly without proper scrutiny, the metric improvement is illusory and masks declining review quality."
    },
    "wise_refusal": "This is Goodhart's Law: 'When a measure becomes a target, it ceases to be a good measure.' Code review time was originally a reasonable proxy for team efficiencyfaster reviews (within reason) suggested streamlined processes. But once managers' bonuses depended on this metric, they had incentive to optimize the metric itself rather than the underlying quality. The result: superficial rubber-stamp approvals that hit the 4-hour target but sacrifice code quality. The metric improved (91% compliance) while the actual outcome deteriorated (35% more production bugs). The causal graph broke: Before: QualityReviewTimeMetric, After: IncentiveGamingMetric (bypassing Quality). The intervention severed the relationship between metric and outcome. Evidence of gaming: the metric changed dramatically without process improvements, and outcome quality declined. This pattern appears across domains when proxies are incentivized: teaching to the test, hospital mortality gaming by refusing terminal patients, police manipulating crime statistics.",
    "gold_rationale": "Goodhart's Law (1984) states that metrics lose validity when they become targets for optimization. Campbell's Law (1979) similarly notes: 'The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures.' The causal mechanism: (1) Metric M initially correlates with desired outcome Y because both are driven by underlying quality Q: QM and QY. (2) Intervention I targets M for rewards. (3) Agents optimize M directly through gaming G rather than improving Q: IGM. (4) The GM pathway bypasses Q, breaking the M-Y correlation. (5) M improves while Y deteriorates. The code review case shows all phases: review time initially proxied efficiency (MQ), bonuses targeted review time (IM), managers gamed with superficial approvals (GM bypassing Q), metric improved but bugs increased (M, Y). The solution requires measuring multiple indicators resistant to gaming, or directly measuring outcomes rather than proxies. This is why healthcare moved from process measures (did you document?) to outcome measures (did the patient improve?).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0056",
    "case_id": "0056",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Diagnostics",
    "scenario": "A hospital implements a new diagnostic algorithm for detecting a rare genetic disorder that affects 0.05% of newborns. The algorithm has 98% sensitivity and 97% specificity. When the algorithm flags a baby as high-risk, the pediatrician tells parents there's a 98% probability their child has the disorder and recommends immediate invasive testing with significant risks. However, this interpretation conflates test sensitivity P with posterior probability P. Using Bayes' theorem with the 0.05% base rate: In 100,000 births, 50 have the disorder, while 99,950 don't. The actual probability is 49/ = 1.6%, not 98%. The pediatrician's error stems from ignoring base rates, drastically overestimating disease probability.",
    "claim": "A positive test result on this 98% sensitive algorithm means the baby has a 98% probability of having the disorder.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Positive algorithm result",
        "role": "exposure"
      },
      "Y": {
        "name": "Actual disorder presence",
        "role": "outcome"
      },
      "Z": [
        "Disease prevalence 0.05%",
        "False positive rate 3%",
        "Base rate ignored"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "MEASUREMENT BIAS",
      "subtype": "Differential misclassification",
      "subtype_name": "Diagnostic Test Interpretation Error"
    },
    "difficulty": "Hard",
    "causal_structure": "Test result (X*) is measured with error. True disease status (X) differs from test result (X*). Measurement error depends on base rate (Z) through Bayes' theorem.",
    "key_insight": "Test sensitivity  posterior probability. With low base rates, false positives vastly outnumber true positives even with high specificity.",
    "hidden_timestamp": "Does measurement accuracy differ between groups, or does interpretation ignore base rates?",
    "conditional_answers": {
      "answer_if_condition_1": "If we interpret P(Test+|Disease)=98% as P(Disease|Test+)=98%, we commit the base rate fallacy and drastically overestimate disease probability.",
      "answer_if_condition_2": "If we apply Bayes' theorem incorporating the 0.05% base rate, the actual probability is only 1.6%, a 61-fold difference from the naive interpretation."
    },
    "wise_refusal": "This commits a measurement interpretation error by conflating test sensitivity with posterior probability. The pediatrician interprets P(Test+|Disease)=98% as P(Disease|Test+)=98%, but these are fundamentally different quantities related by Bayes' theorem. With disease prevalence of 0.05%, in 100,000 newborns: 50 have the disorder and the test correctly identifies 49 (98% sensitivity); 99,950 don't have the disorder, but the test incorrectly flags 2,999 as positive (3% false positive rate). Out of 3,048 total positive tests, only 49 are true positives. The actual probability is 49/3,048 = 1.6%, not 98%. The error stems from ignoring that false positives vastly outnumber true positives when disease is rare. The 97% specificity sounds excellent, but applied to 99,950 healthy babies, that 3% error generates 2,999 false alarms. This is differential misclassification where the interpretation error depends on base rates. The causal graph shows: True Disease (X)  Test Result (X*), but X* contains systematic measurement error that varies with population prevalence (Z).",
    "gold_rationale": "This is a measurement bias case involving systematic misinterpretation of diagnostic test results. From a causal inference perspective, we measure X* (test result) instead of X (true disease status), and the relationship XX* involves misclassification. The key insight is that positive predictive value (PPV) = P(Disease|Test+) depends critically on prevalence, even though sensitivity and specificity don't. Bayes' theorem: P(D|T+) = P(T+|D)P(D) / [P(T+|D)P(D) + P(T+|D)P(D)] = (0.980.0005) / [(0.980.0005) + (0.030.9995)] = 0.00049/0.030475 = 1.6%. The likelihood ratio approach: LR+ = sensitivity/(1-specificity) = 0.98/0.03 = 32.7; posterior odds = prior odds  LR+ = (0.0005/0.9995)32.7 = 0.0163  1.6%. At different prevalences, the same test yields different PPVs: at 50% prevalence, PPV=97%; at 0.05%, PPV=1.6%. This demonstrates that measurement interpretation must account for base rates. The trap is similar to the prosecutor's fallacy: confusing P(A|B) with P(B|A).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0057",
    "case_id": "0057",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Diagnostics",
    "scenario": "A hospital implements a new diagnostic algorithm for detecting a rare genetic disorder that affects 0.05% of newborns. The algorithm has 98% sensitivity and 97% specificity. When the algorithm flags a baby as high-risk, the pediatrician tells parents there's a 98% probability their child has the disorder and recommends immediate invasive testing with significant risks. However, this interpretation conflates test sensitivity P with posterior probability P. Using Bayes' theorem with the 0.05% base rate: In 100,000 births, 50 have the disorder, while 99,950 don't. The actual probability is 49/ = 1.6%, not 98%. The pediatrician's error stems from ignoring base rates, drastically overestimating disease probability.",
    "claim": "A positive test result on this 98% sensitive algorithm means the baby has a 98% probability of having the disorder.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Positive algorithm result",
        "role": "exposure"
      },
      "Y": {
        "name": "Actual disorder presence",
        "role": "outcome"
      },
      "Z": [
        "Disease prevalence 0.05%",
        "False positive rate 3%",
        "Base rate ignored"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "MEASUREMENT BIAS",
      "subtype": "Differential misclassification",
      "subtype_name": "Diagnostic Test Interpretation Error"
    },
    "difficulty": "Hard",
    "causal_structure": "Test result (X*) is measured with error. True disease status (X) differs from test result (X*). Measurement error depends on base rate (Z) through Bayes' theorem.",
    "key_insight": "Test sensitivity  posterior probability. With low base rates, false positives vastly outnumber true positives even with high specificity.",
    "hidden_timestamp": "Does measurement accuracy differ between groups, or does interpretation ignore base rates?",
    "conditional_answers": {
      "answer_if_condition_1": "If we interpret P(Test+|Disease)=98% as P(Disease|Test+)=98%, we commit the base rate fallacy and drastically overestimate disease probability.",
      "answer_if_condition_2": "If we apply Bayes' theorem incorporating the 0.05% base rate, the actual probability is only 1.6%, a 61-fold difference from the naive interpretation."
    },
    "wise_refusal": "This commits a measurement interpretation error by conflating test sensitivity with posterior probability. The pediatrician interprets P(Test+|Disease)=98% as P(Disease|Test+)=98%, but these are fundamentally different quantities related by Bayes' theorem. With disease prevalence of 0.05%, in 100,000 newborns: 50 have the disorder and the test correctly identifies 49 (98% sensitivity); 99,950 don't have the disorder, but the test incorrectly flags 2,999 as positive (3% false positive rate). Out of 3,048 total positive tests, only 49 are true positives. The actual probability is 49/3,048 = 1.6%, not 98%. The error stems from ignoring that false positives vastly outnumber true positives when disease is rare. The 97% specificity sounds excellent, but applied to 99,950 healthy babies, that 3% error generates 2,999 false alarms. This is differential misclassification where the interpretation error depends on base rates. The causal graph shows: True Disease (X)  Test Result (X*), but X* contains systematic measurement error that varies with population prevalence (Z).",
    "gold_rationale": "This is a measurement bias case involving systematic misinterpretation of diagnostic test results. From a causal inference perspective, we measure X* (test result) instead of X (true disease status), and the relationship XX* involves misclassification. The key insight is that positive predictive value (PPV) = P(Disease|Test+) depends critically on prevalence, even though sensitivity and specificity don't. Bayes' theorem: P(D|T+) = P(T+|D)P(D) / [P(T+|D)P(D) + P(T+|D)P(D)] = (0.980.0005) / [(0.980.0005) + (0.030.9995)] = 0.00049/0.030475 = 1.6%. The likelihood ratio approach: LR+ = sensitivity/(1-specificity) = 0.98/0.03 = 32.7; posterior odds = prior odds  LR+ = (0.0005/0.9995)32.7 = 0.0163  1.6%. At different prevalences, the same test yields different PPVs: at 50% prevalence, PPV=97%; at 0.05%, PPV=1.6%. This demonstrates that measurement interpretation must account for base rates. The trap is similar to the prosecutor's fallacy: confusing P(A|B) with P(B|A).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0058",
    "case_id": "0058",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Diagnostics",
    "scenario": "A hospital implements a new diagnostic algorithm for detecting a rare genetic disorder that affects 0.05% of newborns. The algorithm has 98% sensitivity and 97% specificity. When the algorithm flags a baby as high-risk, the pediatrician tells parents there's a 98% probability their child has the disorder and recommends immediate invasive testing with significant risks. However, this interpretation conflates test sensitivity P with posterior probability P. Using Bayes' theorem with the 0.05% base rate: In 100,000 births, 50 have the disorder, while 99,950 don't. The actual probability is 49/ = 1.6%, not 98%. The pediatrician's error stems from ignoring base rates, drastically overestimating disease probability.",
    "claim": "A positive test result on this 98% sensitive algorithm means the baby has a 98% probability of having the disorder.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Positive algorithm result",
        "role": "exposure"
      },
      "Y": {
        "name": "Actual disorder presence",
        "role": "outcome"
      },
      "Z": [
        "Disease prevalence 0.05%",
        "False positive rate 3%",
        "Base rate ignored"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "MEASUREMENT BIAS",
      "subtype": "Differential misclassification",
      "subtype_name": "Diagnostic Test Interpretation Error"
    },
    "difficulty": "Hard",
    "causal_structure": "Test result (X*) is measured with error. True disease status (X) differs from test result (X*). Measurement error depends on base rate (Z) through Bayes' theorem.",
    "key_insight": "Test sensitivity  posterior probability. With low base rates, false positives vastly outnumber true positives even with high specificity.",
    "hidden_timestamp": "Does measurement accuracy differ between groups, or does interpretation ignore base rates?",
    "conditional_answers": {
      "answer_if_condition_1": "If we interpret P(Test+|Disease)=98% as P(Disease|Test+)=98%, we commit the base rate fallacy and drastically overestimate disease probability.",
      "answer_if_condition_2": "If we apply Bayes' theorem incorporating the 0.05% base rate, the actual probability is only 1.6%, a 61-fold difference from the naive interpretation."
    },
    "wise_refusal": "This commits a measurement interpretation error by conflating test sensitivity with posterior probability. The pediatrician interprets P(Test+|Disease)=98% as P(Disease|Test+)=98%, but these are fundamentally different quantities related by Bayes' theorem. With disease prevalence of 0.05%, in 100,000 newborns: 50 have the disorder and the test correctly identifies 49 (98% sensitivity); 99,950 don't have the disorder, but the test incorrectly flags 2,999 as positive (3% false positive rate). Out of 3,048 total positive tests, only 49 are true positives. The actual probability is 49/3,048 = 1.6%, not 98%. The error stems from ignoring that false positives vastly outnumber true positives when disease is rare. The 97% specificity sounds excellent, but applied to 99,950 healthy babies, that 3% error generates 2,999 false alarms. This is differential misclassification where the interpretation error depends on base rates. The causal graph shows: True Disease (X)  Test Result (X*), but X* contains systematic measurement error that varies with population prevalence (Z).",
    "gold_rationale": "This is a measurement bias case involving systematic misinterpretation of diagnostic test results. From a causal inference perspective, we measure X* (test result) instead of X (true disease status), and the relationship XX* involves misclassification. The key insight is that positive predictive value (PPV) = P(Disease|Test+) depends critically on prevalence, even though sensitivity and specificity don't. Bayes' theorem: P(D|T+) = P(T+|D)P(D) / [P(T+|D)P(D) + P(T+|D)P(D)] = (0.980.0005) / [(0.980.0005) + (0.030.9995)] = 0.00049/0.030475 = 1.6%. The likelihood ratio approach: LR+ = sensitivity/(1-specificity) = 0.98/0.03 = 32.7; posterior odds = prior odds  LR+ = (0.0005/0.9995)32.7 = 0.0163  1.6%. At different prevalences, the same test yields different PPVs: at 50% prevalence, PPV=97%; at 0.05%, PPV=1.6%. This demonstrates that measurement interpretation must account for base rates. The trap is similar to the prosecutor's fallacy: confusing P(A|B) with P(B|A).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0059",
    "case_id": "0059",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Cardiology",
    "scenario": "A hospital study examines patients admitted with chest pain. Among hospitalized patients, those with diabetes appear to have better heart attack survival rates than non-diabetics. Cardiologists conclude diabetes provides protective cardiovascular benefits. However, both diabetes and severe chest pain independently cause hospitalization. The analysis conditions on hospitalization, inducing spurious negative association between diabetes and mortality among the hospitalized.",
    "claim": "Diabetes protects against heart attack mortality.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Diabetes status",
        "role": "exposure"
      },
      "Y": {
        "name": "Heart attack mortality",
        "role": "outcome"
      },
      "Z": [
        "Hospitalization",
        "Chest pain severity",
        "Collider bias"
      ]
    },
    "trap": {
      "type": "T3",
      "type_name": "COLLIDER",
      "subtype": "Berkson's paradox",
      "subtype_name": "Hospital Admission Collider"
    },
    "difficulty": "Medium",
    "causal_structure": "Diabetes  Hospitalization  Severe chest pain. Conditioning on hospitalization (collider) creates spurious association between diabetes and outcomes.",
    "key_insight": "Conditioning on a common effect (hospitalization) creates spurious negative correlation between its causes.",
    "hidden_timestamp": "Are we conditioning on a variable caused by both diabetes and chest pain severity?",
    "conditional_answers": {
      "answer_if_condition_1": "If we examine only hospitalized patients (conditioning on the collider), diabetes appears protective.",
      "answer_if_condition_2": "If we examine the general population without conditioning on hospitalization, diabetes increases mortality risk."
    },
    "wise_refusal": "This is collider bias (Berkson's paradox). Both diabetes and severe cardiac events cause hospitalization. By analyzing only hospitalized patients, we condition on a collider, creating spurious association. Diabetics may be hospitalized for milder symptoms (due to their condition), while non-diabetics need more severe symptoms to be admitted. This selection creates the illusion that diabetes is protective when examined only among the hospitalized.",
    "gold_rationale": "Collider stratification bias occurs when conditioning on a common effect of X and Y. Here: DiabetesHospitalizationSevere MI. In the general population, diabetes increases mortality. But among hospitalized patients, diabetics admitted for chest pain may have less severe cardiac events on average (they're admitted more readily), while non-diabetics need more severe symptoms to be admitted. Conditioning on the collider opens a non-causal path between diabetes and mortality.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0060",
    "case_id": "0060",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "Graduate School",
    "scenario": "An analysis of graduate students finds that higher GRE scores are associated with lower completion rates. Administrators worry that admitting high-scoring students hurts retention. However, both high GRE and strong recommendations lead to admission. Among admitted students, those with high GRE but weak recommendations compete with those with lower GRE but strong recommendations. Conditioning on admission creates negative correlation.",
    "claim": "High GRE scores cause lower graduate program completion rates.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "GRE score",
        "role": "exposure"
      },
      "Y": {
        "name": "Program completion",
        "role": "outcome"
      },
      "Z": [
        "Admission decision",
        "Recommendation strength",
        "Selection on collider"
      ]
    },
    "trap": {
      "type": "T3",
      "type_name": "COLLIDER",
      "subtype": "Berkson's paradox",
      "subtype_name": "Admission Collider Bias"
    },
    "difficulty": "Medium",
    "causal_structure": "GRE  Admission  Recommendations. Among admitted students, high GRE compensates for weak recommendations, creating spurious negative correlation with completion.",
    "key_insight": "Among admitted students, high GRE signals weak recommendations; this is selection bias, not causation.",
    "hidden_timestamp": "Are we analyzing only admitted students, conditioning on a collider?",
    "conditional_answers": {
      "answer_if_condition_1": "Among admitted students (collider), high GRE correlates with lower completion due to recommendation differences.",
      "answer_if_condition_2": "In the applicant pool without conditioning on admission, high GRE likely predicts better completion."
    },
    "wise_refusal": "This is collider bias. Admission depends on both GRE and recommendations. Among admitted students, high-GRE admits may have weaker recommendations (compensatory selection), while lower-GRE admits have stronger recommendations. Strong recommendations better predict completion than GRE. The negative correlation exists only because we're examining admitted students, not because GRE causes dropout.",
    "gold_rationale": "Classic collider bias. The admission committee uses GRE and recommendations as substitutes: high GRE compensates for weak letters. Among admits, GREAdmissionLetters creates negative GRE-Letters correlation. Since letters predict completion better than GRE, this induces spurious negative GRE-completion correlation. The population-level relationship likely differs.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0061",
    "case_id": "0061",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Employment",
    "subdomain": "Hiring",
    "scenario": "Among employed professionals at a tech company, coding skill and communication skill show negative correlation. HR concludes that strong coders make poor communicators. However, candidates are hired if they excel in coding OR communication. Among hires, those strong in coding may be weaker in communication and vice versa. This is collider bias from conditioning on employment.",
    "claim": "Strong coding skills cause poor communication skills.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Coding skill",
        "role": "exposure"
      },
      "Y": {
        "name": "Communication skill",
        "role": "outcome"
      },
      "Z": [
        "Hiring decision",
        "Collider conditioning",
        "Compensatory selection"
      ]
    },
    "trap": {
      "type": "T3",
      "type_name": "COLLIDER",
      "subtype": "Berkson's paradox",
      "subtype_name": "Employment Selection Collider"
    },
    "difficulty": "Easy",
    "causal_structure": "Coding  Hired  Communication. Among hires (conditioning on collider), the two skills appear negatively correlated due to compensatory selection.",
    "key_insight": "Negative correlation among selected sample doesn't imply negative correlation in population or causation.",
    "hidden_timestamp": "Are we examining only hired employees, conditioning on hiring (collider)?",
    "conditional_answers": {
      "answer_if_condition_1": "Among hired employees (collider sample), coding and communication show negative correlation due to selection.",
      "answer_if_condition_2": "In the applicant pool, coding and communication skills may be independent or even positively correlated."
    },
    "wise_refusal": "This is collider bias. Hiring depends on excelling in coding OR communication. Among hires, strong coders may have average communication (sufficient for hiring), while weaker coders needed exceptional communication to be hired. This creates negative correlation among the selected sample that doesn't exist in the applicant pool and doesn't imply causation.",
    "gold_rationale": "Collider stratification on employment. The selection rule uses coding OR communication as sufficient conditions for hiring. This induces negative correlation among hires even if skills are independent in the population. CodingHiredCommunication; conditioning on Hired opens backdoor path. Population correlation likely differs from conditional correlation.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0062",
    "case_id": "0062",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Social Science",
    "subdomain": "Relationships",
    "scenario": "A study of married couples finds that attractive partners have less wealthy spouses. Researchers conclude that physical attractiveness causes reduced earning potential in partners. However, people marry based on combined attractiveness and wealth. In the marriage market, very attractive people marry those with average wealth, while less attractive people marry wealthier partners. This is collider bias from conditioning on marriage.",
    "claim": "Partner attractiveness causes lower partner income.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Partner attractiveness",
        "role": "exposure"
      },
      "Y": {
        "name": "Partner income",
        "role": "outcome"
      },
      "Z": [
        "Marriage formation",
        "Assortative mating",
        "Collider"
      ]
    },
    "trap": {
      "type": "T3",
      "type_name": "COLLIDER",
      "subtype": "Berkson's paradox",
      "subtype_name": "Marriage Market Collider"
    },
    "difficulty": "Medium",
    "causal_structure": "Attractiveness  Marriage  Wealth. Marriages form based on combined value; conditioning on marriage creates spurious negative correlation.",
    "key_insight": "Compensatory matching in relationship formation creates collider bias when examining only married couples.",
    "hidden_timestamp": "Are we examining only married couples, conditioning on relationship formation?",
    "conditional_answers": {
      "answer_if_condition_1": "Among married couples (collider), attractiveness and partner wealth show negative correlation due to matching.",
      "answer_if_condition_2": "In the dating pool, attractiveness and partner wealth may be uncorrelated or positively correlated."
    },
    "wise_refusal": "This is collider bias from conditioning on marriage. Marriage formation depends on both attractiveness and wealth (compensatory matching). Among married couples, highly attractive individuals may have partners with average wealth, while less attractive individuals 'compensate' by marrying wealthier partners. This selection effect creates spurious negative correlation that doesn't reflect causation.",
    "gold_rationale": "Marriage market collider. People form couples based on combined attractiveness and wealth. AttractivenessMarriageWealth creates compensatory matching. Among married couples, the negative correlation reflects selection, not causation. Conditioning on marriage (collider) induces negative association between its determinants.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0063",
    "case_id": "0063",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Epidemiology",
    "scenario": "Cities with higher coffee consumption per capita show higher rates of lung cancer. Public health officials warn that coffee causes lung cancer. However, smoking rates vary by city and cause both coffee consumption and lung cancer. The spurious association exists because smoking is an unmeasured confounder that causes both variables.",
    "claim": "Coffee consumption causes lung cancer.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Coffee consumption",
        "role": "exposure"
      },
      "Y": {
        "name": "Lung cancer rates",
        "role": "outcome"
      },
      "Z": [
        "Smoking rates",
        "Unmeasured confounder",
        "Common cause"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "CONFOUNDER",
      "subtype": "Lifestyle bundle",
      "subtype_name": "Smoking Confounds Coffee-Cancer"
    },
    "difficulty": "Easy",
    "causal_structure": "Smoking (Z)  Coffee (X) and Smoking (Z)  Lung Cancer (Y). Z is unmeasured confounder creating spurious X-Y association.",
    "key_insight": "Smoking causes both coffee drinking and lung cancer, creating spurious correlation.",
    "hidden_timestamp": "Is there an unmeasured common cause (smoking) of both coffee and cancer?",
    "conditional_answers": {
      "answer_if_condition_1": "If we don't control for smoking, coffee appears to cause cancer due to confounding.",
      "answer_if_condition_2": "If we control for smoking rates, the coffee-cancer association disappears or reverses."
    },
    "wise_refusal": "This is classic confounding. Smoking causes both increased coffee consumption (smokers drink more coffee) and lung cancer. The observed coffee-cancer correlation reflects the underlying smoking patterns, not a causal effect of coffee. Without controlling for smoking, we cannot determine if coffee has any independent effect on cancer risk.",
    "gold_rationale": "Standard confounding by smoking. Causal structure: SmokingCoffee and SmokingLung Cancer. The backdoor path CoffeeSmokingCancer creates spurious association. To identify causal effect, must control for smoking (close backdoor path). Studies controlling for smoking show coffee is protective or neutral for cancer, not causative.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0064",
    "case_id": "0064",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "Academic Performance",
    "scenario": "Students who participate in extracurricular activities have higher GPAs. Schools expand extracurricular programs to boost academic performance. However, family socioeconomic status predicts both extracurricular participation and academic achievement. The association reflects confounding by SES, not causal effect of activities.",
    "claim": "Extracurricular activities cause higher academic achievement.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Extracurricular participation",
        "role": "exposure"
      },
      "Y": {
        "name": "GPA",
        "role": "outcome"
      },
      "Z": [
        "Socioeconomic status",
        "Family resources",
        "Parental support"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "CONFOUNDER",
      "subtype": "Socioeconomic confounding",
      "subtype_name": "SES Drives Both Activities and Achievement"
    },
    "difficulty": "Easy",
    "causal_structure": "SES (Z)  Extracurriculars (X) and SES (Z)  GPA (Y). SES confounds the X-Y relationship.",
    "key_insight": "Family resources enable both extracurricular participation and academic support, creating spurious correlation.",
    "hidden_timestamp": "Is there an unmeasured common cause (SES) driving both participation and achievement?",
    "conditional_answers": {
      "answer_if_condition_1": "Without controlling for SES, extracurriculars appear to boost GPA due to confounding.",
      "answer_if_condition_2": "When comparing students from similar SES backgrounds, the extracurricular effect is much smaller or absent."
    },
    "wise_refusal": "This is confounding by socioeconomic status. Affluent families provide both extracurricular opportunities (music lessons, sports equipment, fees) and academic support (tutoring, resources, time). The observed correlation reflects SES differences, not causal effects of activities. Randomized or SES-matched studies show much smaller effects.",
    "gold_rationale": "Classic SES confounding. SESExtracurriculars (costs, time, parental involvement) and SESGPA (tutoring, resources, stress). The backdoor path ExtracurricularsSESGPA creates spurious association. Studies controlling for SES show attenuated effects. Causal identification requires controlling for family background.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0065",
    "case_id": "0065",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Nutrition",
    "scenario": "People who take daily multivitamins have 18% lower mortality over 10 years. Supplement companies advertise this as proof vitamins extend life. However, people who take vitamins are more health-conscious: they exercise more, eat better, avoid smoking, and get regular checkups. These healthy behaviorsnot the vitaminsdrive the mortality difference. Health consciousness confounds the vitamin-mortality relationship.",
    "claim": "Multivitamin use causes reduced mortality.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Multivitamin use",
        "role": "exposure"
      },
      "Y": {
        "name": "Mortality",
        "role": "outcome"
      },
      "Z": [
        "Health consciousness",
        "Exercise habits",
        "Diet quality",
        "Healthcare utilization"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "CONFOUNDER",
      "subtype": "Lifestyle bundle",
      "subtype_name": "Health-Conscious Behavior Confounding"
    },
    "difficulty": "Medium",
    "causal_structure": "Health consciousness (Z)  Vitamin use (X) and Health consciousness (Z)  Lower mortality (Y). Bundle of healthy behaviors confounds X-Y.",
    "key_insight": "Vitamin users differ systematically in health behaviors; these behaviors, not vitamins, reduce mortality.",
    "hidden_timestamp": "Is there an unmeasured lifestyle bundle (health consciousness) causing both vitamin use and better outcomes?",
    "conditional_answers": {
      "answer_if_condition_1": "In observational studies, vitamin users have lower mortality due to confounding by healthy behaviors.",
      "answer_if_condition_2": "In randomized trials controlling for behavioral differences, vitamins show minimal or no mortality benefit."
    },
    "wise_refusal": "This is confounding by health-conscious behavior. People who take vitamins also exercise, eat well, avoid smoking, and seek preventive care. These behaviorsnot the vitaminsreduce mortality. The correlation exists because health consciousness causes both vitamin use and longevity. RCTs controlling for these confounders find minimal vitamin effects on mortality.",
    "gold_rationale": "Lifestyle bundle confounding. Health consciousnessVitamin use and Health consciousnessHealthy behaviorsLower mortality. The backdoor path VitaminsHealth consciousnessBehaviorsMortality creates spurious association. Observational studies show large effects; RCTs show minimal effects, revealing confounding. Proper inference requires randomization or controlling for behavior bundle.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0066",
    "case_id": "0066",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Economics",
    "subdomain": "Labor Markets",
    "scenario": "Counties that raised minimum wage to $15/hour show 12% higher employment growth over 3 years than counties that didn't. Advocates claim minimum wage increases create jobs. However, counties that raised wages were already experiencing economic booms. Economic growth is the confounder that causes both wage increases and employment growth.",
    "claim": "Raising minimum wage causes employment growth.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Minimum wage increase",
        "role": "exposure"
      },
      "Y": {
        "name": "Employment growth",
        "role": "outcome"
      },
      "Z": [
        "Pre-existing economic boom",
        "Local economic conditions",
        "Political feasibility"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "CONFOUNDER",
      "subtype": "Socioeconomic confounding",
      "subtype_name": "Economic Growth Enables Policy and Drives Employment"
    },
    "difficulty": "Medium",
    "causal_structure": "Economic boom (Z)  Wage policy (X) and Economic boom (Z)  Employment growth (Y). Pre-existing growth enables policy and drives outcomes.",
    "key_insight": "Thriving economies adopt higher wages and experience job growth; growth is the cause of both, not wage policy.",
    "hidden_timestamp": "Did pre-existing economic conditions cause both the wage increase and subsequent employment growth?",
    "conditional_answers": {
      "answer_if_condition_1": "Without controlling for pre-existing growth trends, wage increases appear to cause employment gains.",
      "answer_if_condition_2": "When comparing counties with similar pre-policy economic trajectories, the employment effect is smaller or absent."
    },
    "wise_refusal": "This is confounding by pre-existing economic conditions. Counties experiencing economic booms have both political will to raise wages and subsequent job growth. The boom causes both the policy and employmentnot the policy causing employment. Proper causal inference requires difference-in-differences or matching on pre-policy trends to control for confounding.",
    "gold_rationale": "Economic growth confounding. BoomPolicy adoption and BoomEmployment. The backdoor path WageBoomEmployment creates spurious positive association. Counties with strong growth can afford wage increases. Proper identification requires parallel trends assumption or instrumental variables. Matching on pre-policy trends reduces estimated effects.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0067",
    "case_id": "0067",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Management",
    "scenario": "Companies with open office layouts report 22% higher employee productivity than those with traditional offices. Consultants recommend open offices to boost performance. However, companies that adopt open offices are typically fast-growing tech firms with young workforces, strong cultures, and high compensation. These organizational factorsnot the office layoutdrive productivity differences.",
    "claim": "Open office layouts cause higher productivity.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Open office layout",
        "role": "exposure"
      },
      "Y": {
        "name": "Employee productivity",
        "role": "outcome"
      },
      "Z": [
        "Company type (tech startups)",
        "Workforce demographics",
        "Compensation levels",
        "Organizational culture"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "CONFOUNDER",
      "subtype": "Socioeconomic confounding",
      "subtype_name": "Company Type and Culture Confounding"
    },
    "difficulty": "Easy",
    "causal_structure": "Company characteristics (Z)  Office choice (X) and Company characteristics (Z)  Productivity (Y). High-growth companies adopt open offices and have high productivity.",
    "key_insight": "High-performing companies choose open offices; the company type drives both choices, not office causing performance.",
    "hidden_timestamp": "Do company characteristics (type, culture, compensation) confound the office-productivity relationship?",
    "conditional_answers": {
      "answer_if_condition_1": "Comparing all companies with and without open offices shows higher productivity in open-office firms (confounded).",
      "answer_if_condition_2": "When similar companies switch to open offices, productivity often decreases due to noise and distractions."
    },
    "wise_refusal": "This is confounding by company type. Tech startups and high-growth firms adopt open offices and also have high productivity from factors like compensation, culture, and workforce. The correlation reflects company characteristics, not office layout. Within-company studies show open offices often reduce productivity due to noise and lack of privacy.",
    "gold_rationale": "Company type confounding. Tech/Startup cultureOpen office and Tech/Startup cultureHigh productivity (compensation, talent, growth). The backdoor path OfficeCompany typeProductivity creates spurious association. Within-company or randomized studies show negative or null effects of open offices on productivity.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0068",
    "case_id": "0068",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Psychology",
    "subdomain": "Mental Health",
    "scenario": "Patients with depression who own pets report 30% better mood improvement over 6 months than those without pets. Therapists recommend pet ownership for depression treatment. However, people who adopt pets while depressed are generally higher-functioning, have stable housing, and can afford pet care. These factors indicate milder depression and better prognosis, confounding the pet-recovery relationship.",
    "claim": "Pet ownership causes improvement in depression symptoms.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Pet ownership",
        "role": "exposure"
      },
      "Y": {
        "name": "Depression improvement",
        "role": "outcome"
      },
      "Z": [
        "Depression severity",
        "Functional capacity",
        "Financial stability",
        "Housing situation"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "CONFOUNDER",
      "subtype": "Socioeconomic confounding",
      "subtype_name": "Baseline Functioning Confounds Pet-Recovery"
    },
    "difficulty": "Medium",
    "causal_structure": "Better baseline functioning (Z)  Pet adoption (X) and Better functioning (Z)  Better recovery (Y). Ability to care for pets indicates prognosis.",
    "key_insight": "Ability to adopt and care for pets signals better functioning and prognosis; this confounds the apparent benefit.",
    "hidden_timestamp": "Does baseline functioning level (ability to care for pet) confound the pet-improvement relationship?",
    "conditional_answers": {
      "answer_if_condition_1": "Among all depressed patients, pet owners show better improvement due to confounding by baseline functioning.",
      "answer_if_condition_2": "When randomly assigning pets or comparing patients with similar functioning, the benefit is smaller or absent."
    },
    "wise_refusal": "This is confounding by baseline functioning. Severely depressed patients lack capacity to adopt and care for pets. Those who adopt pets have better housing, finances, and functional abilityall predictors of recovery. The correlation reflects patient selection, not causal effects of pets. Randomized studies show smaller effects than observational correlations.",
    "gold_rationale": "Functional capacity confounding. Better functioningPet adoption and Better functioningRecovery. The backdoor path PetsFunctioningRecovery creates spurious association. Selection into pet ownership requires stability that predicts better prognosis. Proper causal inference requires randomization or controlling for baseline severity and functioning.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0069",
    "case_id": "0069",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Substance Use",
    "scenario": "A longitudinal study finds that teenagers who drink coffee regularly are 2.3x more likely to use marijuana by age 18. Anti-drug campaigns warn that coffee is a 'gateway drug.' However, both coffee drinking and marijuana use are driven by adolescent sensation-seeking personality traits and peer influence. Risk-taking temperament causes both behaviors, creating spurious correlation.",
    "claim": "Coffee consumption causes marijuana use in teenagers.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Adolescent coffee consumption",
        "role": "exposure"
      },
      "Y": {
        "name": "Marijuana use",
        "role": "outcome"
      },
      "Z": [
        "Sensation-seeking personality",
        "Risk-taking temperament",
        "Peer influence",
        "Parental monitoring"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "CONFOUNDER",
      "subtype": "Lifestyle bundle",
      "subtype_name": "Risk-Taking Temperament Confounding"
    },
    "difficulty": "Easy",
    "causal_structure": "Risk-taking personality (Z)  Coffee use (X) and Risk-taking (Z)  Marijuana use (Y). Personality confounds both substance use behaviors.",
    "key_insight": "Underlying personality traits drive both coffee and marijuana use; correlation doesn't imply causation.",
    "hidden_timestamp": "Is there an unmeasured personality trait causing both coffee and marijuana use?",
    "conditional_answers": {
      "answer_if_condition_1": "Without controlling for personality and peer effects, coffee appears to lead to marijuana use.",
      "answer_if_condition_2": "Among teens with similar risk-taking traits, coffee use doesn't predict marijuana use."
    },
    "wise_refusal": "This is confounding by personality and peer factors. Sensation-seeking teens are drawn to both coffee (social, stimulant) and marijuana (rebellion, experimentation). The correlation reflects shared underlying traits, not causal gateway effects. Studies controlling for temperament and peer influence show no coffee-marijuana causal link.",
    "gold_rationale": "Personality confounding. Risk-takingCoffee and Risk-takingMarijuana. The backdoor path CoffeePersonalityMarijuana creates spurious association. Both behaviors stem from sensation-seeking, peer influence, and low parental monitoring. Controlling for these confounders eliminates the correlation. Classic example of confounding in 'gateway drug' claims.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0070",
    "case_id": "0070",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Chronic Disease",
    "scenario": "Patients with chronic pain who use opioids long-term show 40% higher depression rates than similar pain patients not using opioids. Policymakers cite this as evidence that opioids cause depression. However, patients with more severe, uncontrolled pain are prescribed opioids AND experience higher depression. Pain severity is the confounder driving both opioid use and depression.",
    "claim": "Long-term opioid use causes depression.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Opioid use",
        "role": "exposure"
      },
      "Y": {
        "name": "Depression",
        "role": "outcome"
      },
      "Z": [
        "Pain severity",
        "Functional impairment",
        "Treatment resistance"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "CONFOUNDER",
      "subtype": "Socioeconomic confounding",
      "subtype_name": "Pain Severity Confounds Opioid-Depression"
    },
    "difficulty": "Medium",
    "causal_structure": "Pain severity (Z)  Opioid prescription (X) and Pain severity (Z)  Depression (Y). Severe pain causes both opioid use and depression.",
    "key_insight": "Severe pain drives both opioid prescribing and depression risk; pain is the confounder.",
    "hidden_timestamp": "Does pain severity confound the relationship between opioid use and depression?",
    "conditional_answers": {
      "answer_if_condition_1": "Without controlling for pain severity, opioid users show higher depression due to confounding by indication.",
      "answer_if_condition_2": "Among patients with similar pain levels, opioid use may not increase depression risk."
    },
    "wise_refusal": "This is confounding by indicationpain severity. Patients with worse, treatment-resistant pain receive opioids AND experience more depression (paindepression is well-established). The opioid-depression correlation reflects pain severity, not opioid causation. Proper inference requires controlling for pain level or using instrumental variables.",
    "gold_rationale": "Confounding by indication. Pain severityOpioid prescription and Pain severityDepression. The backdoor path OpioidsPainDepression creates spurious association. Chronic severe pain independently causes depression. Studies matching on pain severity show attenuated or null opioid-depression associations. Classic confounding by treatment indication.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0071",
    "case_id": "0071",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Social Media",
    "scenario": "A study finds that teenagers who spend 3+ hours daily on social media have 45% higher anxiety rates. Media reports claim social media causes anxiety. However, socially anxious teens use social media more because in-person socializing is stressful. Pre-existing anxiety leads to increased social media use, not the reverse. This is reverse causation.",
    "claim": "Social media use causes anxiety in teenagers.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Social media use",
        "role": "exposure"
      },
      "Y": {
        "name": "Anxiety levels",
        "role": "outcome"
      },
      "Z": [
        "Temporal ordering",
        "Social comfort",
        "Baseline anxiety"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "REVERSE CAUSATION",
      "subtype": "Protopathic bias",
      "subtype_name": "Anxiety Precedes Social Media Use"
    },
    "difficulty": "Medium",
    "causal_structure": "Claimed: Social media (X)  Anxiety (Y). Actual: Anxiety (Y)  Social media (X). Anxious teens seek online over in-person socializing.",
    "key_insight": "Socially anxious teens retreat to online interaction; anxiety causes social media use, not vice versa.",
    "hidden_timestamp": "Did anxiety symptoms precede or follow increased social media use?",
    "conditional_answers": {
      "answer_if_condition_1": "If teens became anxious after increasing social media use, the causal direction is XY.",
      "answer_if_condition_2": "If teens were already anxious and then increased social media use (to cope), the direction is YX (reverse causation)."
    },
    "wise_refusal": "This is reverse causation. Socially anxious teenagers find in-person interaction stressful and retreat to social media as a coping mechanism. Anxiety precedes and drives social media use, not the reverse. Longitudinal studies show baseline anxiety predicts future social media use, while social media use weakly predicts future anxiety changes.",
    "gold_rationale": "Reverse causation: AnxietySocial media use, not Social mediaAnxiety. Anxious teens prefer online interaction (less threatening than in-person). The temporal sequence is reversed from the claim. Longitudinal studies with proper temporal ordering show anxiety predicts subsequent social media use more strongly than the reverse. Proper inference requires establishing temporal precedence.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0072",
    "case_id": "0072",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Primary Care",
    "scenario": "Patients who visit their doctor more frequently have 35% higher mortality rates over 5 years. An economist concludes that doctor visits harm health. However, sicker patients visit doctors more often. Illness severity drives both frequent visits and higher mortality. The temporal sequence is: illness  doctor visits, not visits  death. This is reverse causation.",
    "claim": "Frequent doctor visits cause higher mortality.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Doctor visit frequency",
        "role": "exposure"
      },
      "Y": {
        "name": "Mortality",
        "role": "outcome"
      },
      "Z": [
        "Illness severity",
        "Health status",
        "Symptom burden"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "REVERSE CAUSATION",
      "subtype": "Protopathic bias",
      "subtype_name": "Illness Precedes Healthcare Utilization"
    },
    "difficulty": "Easy",
    "causal_structure": "Claimed: Visits (X)  Death (Y). Actual: Illness severity (Z)  Visits (X) and Illness (Z)  Death (Y). Reverse causation with confounding.",
    "key_insight": "Sickness causes both doctor visits and death; visits don't cause death.",
    "hidden_timestamp": "Did illness precede doctor visits, or did visits precede health decline?",
    "conditional_answers": {
      "answer_if_condition_1": "If healthy people started visiting doctors frequently and then died, visits might cause harm.",
      "answer_if_condition_2": "If sick people visit doctors frequently and then die from their illness, the causal direction is reversed."
    },
    "wise_refusal": "This is reverse causation. Sick patients visit doctors more frequently because they're ill. Illness causes both the visits and the mortality. The temporal sequence is: illness  visits  death, where illness is the root cause of both outcomes. Visits are a marker of illness severity, not a cause of death.",
    "gold_rationale": "Reverse causation with confounding by indication. Illness severityDoctor visits and Illness severityMortality. Visits are a consequence of illness, not a cause of death. The causal arrow is IllnessVisits, not VisitsDeath. This is protopathic biastreatment is sought because of pre-existing disease that determines outcome. Proper analysis requires controlling for baseline health status.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0073",
    "case_id": "0073",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Finance",
    "subdomain": "Personal Finance",
    "scenario": "People who check their investment portfolios daily have 28% lower returns than those who check monthly. Financial advisors warn that frequent monitoring harms returns. However, investors who recently experienced losses check their portfolios more often due to anxiety. Poor performance drives monitoring frequency, not the reverse. This is reverse causation.",
    "claim": "Frequent portfolio monitoring causes lower investment returns.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Portfolio monitoring frequency",
        "role": "exposure"
      },
      "Y": {
        "name": "Investment returns",
        "role": "outcome"
      },
      "Z": [
        "Recent losses",
        "Portfolio volatility",
        "Investor anxiety"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "REVERSE CAUSATION",
      "subtype": "Protopathic bias",
      "subtype_name": "Poor Returns Trigger Monitoring"
    },
    "difficulty": "Easy",
    "causal_structure": "Claimed: Monitoring (X)  Returns (Y). Actual: Poor returns (Y)  Anxiety  Monitoring (X). Bad performance triggers checking.",
    "key_insight": "Poor portfolio performance causes anxious monitoring; monitoring doesn't cause poor performance.",
    "hidden_timestamp": "Did monitoring frequency increase before or after poor returns?",
    "conditional_answers": {
      "answer_if_condition_1": "If investors started checking frequently and then experienced poor returns, monitoring might cause harm (panic selling).",
      "answer_if_condition_2": "If investors experienced poor returns and then started checking frequently, the direction is reversed (returnsmonitoring)."
    },
    "wise_refusal": "This is reverse causation. Investors who experience portfolio losses become anxious and check their accounts more frequently. Poor returns cause monitoring, not vice versa. The temporal sequence is: losses  anxiety  frequent checking. Monitoring is a response to performance, not a cause of poor performance.",
    "gold_rationale": "Reverse causation: Poor returnsAnxietyMonitoring, not MonitoringPoor returns. Investors respond to losses by checking more frequently. The causal arrow is ReturnsMonitoring. This is reactive behaviormonitoring responds to outcomes rather than causing them. Proper analysis requires establishing temporal precedence and controlling for portfolio characteristics.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0074",
    "case_id": "0074",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "K-12",
    "scenario": "Students who attend tutoring sessions have 0.3 points lower GPA on average than non-tutored students. Schools consider eliminating tutoring programs. However, students are referred to tutoring specifically because they're struggling academically. Poor performance causes tutoring enrollment, not the reverse. This is reverse causation and confounding by indication.",
    "claim": "Tutoring causes lower academic performance.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Tutoring participation",
        "role": "exposure"
      },
      "Y": {
        "name": "GPA",
        "role": "outcome"
      },
      "Z": [
        "Baseline academic struggle",
        "Prior performance",
        "Learning difficulties"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "REVERSE CAUSATION",
      "subtype": "Protopathic bias",
      "subtype_name": "Poor Performance Triggers Tutoring"
    },
    "difficulty": "Easy",
    "causal_structure": "Claimed: Tutoring (X)  Low GPA (Y). Actual: Low GPA (Y)  Tutoring referral (X). Poor performance causes tutoring enrollment.",
    "key_insight": "Students are selected for tutoring because they're struggling; poor performance precedes tutoring.",
    "hidden_timestamp": "Did students' academic performance decline before or after starting tutoring?",
    "conditional_answers": {
      "answer_if_condition_1": "If students were performing well, started tutoring, then declined, tutoring might harm performance.",
      "answer_if_condition_2": "If students were already struggling, then enrolled in tutoring, the poor performance preceded tutoring (reverse causation)."
    },
    "wise_refusal": "This is reverse causation and confounding by indication. Students are referred to tutoring because they're already struggling academically. Poor performance causes tutoring enrollment, not vice versa. The correct comparison requires matching on pre-tutoring performance or examining within-student performance changes after tutoring begins.",
    "gold_rationale": "Reverse causation: Poor performanceTutoring referral, not TutoringPoor performance. This is confounding by indicationtreatment assignment is based on outcome risk. Students selected for tutoring have worse baseline performance. Proper evaluation requires comparing tutored students to similar struggling students who didn't receive tutoring, or examining performance changes within students over time.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0075",
    "case_id": "0075",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Employment",
    "subdomain": "Workplace Wellness",
    "scenario": "Employees who use company gym facilities take 40% more sick days than non-users. HR considers closing the gym to improve attendance. However, employees with chronic health conditions are encouraged to use the gym. Their underlying health issues cause both gym usage and sick leave. This is reverse causationhealth problems drive gym use, not vice versa.",
    "claim": "Using company gym facilities causes increased sick leave.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Gym usage",
        "role": "exposure"
      },
      "Y": {
        "name": "Sick days",
        "role": "outcome"
      },
      "Z": [
        "Chronic health conditions",
        "Baseline health status",
        "Doctor recommendations"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "REVERSE CAUSATION",
      "subtype": "Protopathic bias",
      "subtype_name": "Health Problems Precede Gym Use"
    },
    "difficulty": "Medium",
    "causal_structure": "Claimed: Gym use (X)  Sick days (Y). Actual: Health conditions (Z)  Gym use (X) and Health conditions (Z)  Sick days (Y).",
    "key_insight": "Employees with health problems are encouraged to use the gym; their conditions cause both gym use and sick leave.",
    "hidden_timestamp": "Did health problems and sick leave precede gym enrollment, or did gym use precede health issues?",
    "conditional_answers": {
      "answer_if_condition_1": "If healthy employees started using gym and then took more sick leave, gym might cause harm (overexertion).",
      "answer_if_condition_2": "If employees with health conditions enrolled in gym per doctor recommendations, health issues precede gym use (reverse causation)."
    },
    "wise_refusal": "This is reverse causation with confounding. Employees with chronic conditions are referred to the gym by physicians for health management. Their underlying health problems cause both gym participation and sick leave. Health status is the common cause; gym use doesn't cause sickness. Proper analysis requires controlling for baseline health.",
    "gold_rationale": "Reverse causation and confounding by indication. Health conditionsGym enrollment and Health conditionsSick leave. The causal sequence is: illness  medical recommendation  gym use, not gym use  illness. This is selection biassicker employees are channeled into the wellness program. Proper evaluation requires matching on health status or examining within-person changes.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0076",
    "case_id": "0076",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Economics",
    "subdomain": "Housing",
    "scenario": "Neighborhoods that built more affordable housing units saw 18% increases in crime rates over 5 years. Opponents claim affordable housing causes crime. However, cities build affordable housing in neighborhoods already experiencing economic decline and rising crime. Pre-existing neighborhood deterioration drives both housing policy and crime trends. This is reverse causation and confounding.",
    "claim": "Affordable housing construction causes increased neighborhood crime.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Affordable housing construction",
        "role": "exposure"
      },
      "Y": {
        "name": "Crime rates",
        "role": "outcome"
      },
      "Z": [
        "Pre-existing neighborhood decline",
        "Economic disinvestment",
        "Baseline crime trends"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "REVERSE CAUSATION",
      "subtype": "Reactive policy",
      "subtype_name": "Neighborhood Decline Precedes Housing Policy"
    },
    "difficulty": "Medium",
    "causal_structure": "Claimed: Housing (X)  Crime (Y). Actual: Neighborhood decline (Z)  Housing policy (X) and Decline (Z)  Crime (Y).",
    "key_insight": "Declining neighborhoods receive affordable housing; decline causes both housing policy and crime increases.",
    "hidden_timestamp": "Was the neighborhood already declining before affordable housing was built?",
    "conditional_answers": {
      "answer_if_condition_1": "If crime increased after housing construction in stable neighborhoods, housing might cause crime.",
      "answer_if_condition_2": "If neighborhoods were already declining and crime was rising before housing construction, the decline drives both (reverse causation)."
    },
    "wise_refusal": "This is reverse causation and confounding. Cities target affordable housing to neighborhoods already experiencing economic decline and rising crime. Neighborhood deterioration causes both the housing policy intervention and continued crime increases. The temporal sequence is: decline  housing policy, not housing  crime. Proper analysis requires matching on pre-policy crime trends.",
    "gold_rationale": "Reverse causation with confounding by indication. Neighborhood declineHousing policy and Neighborhood declineCrime. This is reactive policyinterventions target areas with existing problems. The causal arrow is DeclineHousing placement, not HousingCrime. Difference-in-differences or matching on pre-policy trends is required to properly evaluate housing effects.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0077",
    "case_id": "0077",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Psychology",
    "subdomain": "Developmental",
    "scenario": "Children who experience more parental praise show lower self-esteem in adolescence. Parenting experts warn against excessive praise. However, parents increase praise specifically when they notice their child struggling with self-confidence. Low self-esteem causes increased parental praise attempts, not the reverse. Temporal ordering reveals reverse causation.",
    "claim": "Parental praise causes lower child self-esteem.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Parental praise frequency",
        "role": "exposure"
      },
      "Y": {
        "name": "Child self-esteem",
        "role": "outcome"
      },
      "Z": [
        "Child's baseline self-confidence",
        "Early struggles",
        "Parental concern"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "REVERSE CAUSATION",
      "subtype": "Protopathic bias",
      "subtype_name": "Low Self-Esteem Triggers Praise"
    },
    "difficulty": "Medium",
    "causal_structure": "Claimed: Praise (X)  Low self-esteem (Y). Actual: Low self-esteem (Y)  Parental concern  Praise (X). Parents respond to child's struggles.",
    "key_insight": "Parents increase praise when they observe low self-confidence; children's struggles precede praise attempts.",
    "hidden_timestamp": "Did children's self-esteem problems precede or follow increased parental praise?",
    "conditional_answers": {
      "answer_if_condition_1": "If confident children received praise and then developed low self-esteem, praise might harm confidence.",
      "answer_if_condition_2": "If struggling children received increased praise as parents tried to help, low self-esteem preceded praise (reverse causation)."
    },
    "wise_refusal": "This is reverse causation. Parents observe their child's low self-confidence and respond by increasing praise to help. Low self-esteem causes the praise, not vice versa. The temporal sequence is: child struggles  parent notices  parent praises more. Praise is a response to the problem, not the cause of it.",
    "gold_rationale": "Reverse causation: Low self-esteemParental concernPraise, not PraiseLow self-esteem. Parents react to children's struggles by attempting to build confidence through praise. The causal arrow is Self-esteemPraise. This is reactive parentingbehaviors respond to child outcomes rather than causing them. Proper analysis requires controlling for baseline child characteristics or experimental manipulation.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0078",
    "case_id": "0078",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Marketing",
    "scenario": "Companies that increase advertising spending experience 22% revenue declines the following year. CFOs conclude advertising destroys value. However, companies increase advertising specifically when revenues start declining, attempting to reverse downward trends. Revenue decline causes increased advertising, not the reverse. This is reactive policy reverse causation.",
    "claim": "Increased advertising spending causes revenue decline.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Advertising spending increase",
        "role": "exposure"
      },
      "Y": {
        "name": "Revenue decline",
        "role": "outcome"
      },
      "Z": [
        "Pre-existing revenue problems",
        "Market conditions",
        "Product issues"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "REVERSE CAUSATION",
      "subtype": "Reactive policy",
      "subtype_name": "Revenue Decline Triggers Ad Spending"
    },
    "difficulty": "Easy",
    "causal_structure": "Claimed: Advertising (X)  Revenue decline (Y). Actual: Revenue decline (Y)  Management response  Advertising increase (X).",
    "key_insight": "Companies increase advertising when revenues fall; falling revenues cause advertising increases, not vice versa.",
    "hidden_timestamp": "Did revenue problems begin before or after advertising spending increased?",
    "conditional_answers": {
      "answer_if_condition_1": "If companies increased advertising while growing, then declined, advertising might cause problems (waste).",
      "answer_if_condition_2": "If revenues were already falling before advertising increased, the decline preceded advertising (reverse causation)."
    },
    "wise_refusal": "This is reverse causation. Companies increase advertising when revenues start declining, attempting to reverse downward trends. Revenue problems cause advertising increases, not vice versa. The temporal sequence is: revenue falls  management responds  advertising increases. Advertising is a response to decline, not its cause.",
    "gold_rationale": "Reverse causation: Revenue declineAdvertising increase, not AdvertisingDecline. Companies react to falling revenues with interventions including advertising. This is reactive strategyspending responds to performance problems. The causal arrow is RevenueAdvertising. Proper analysis requires controlling for pre-spending revenue trends or examining matched companies with similar decline patterns.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0079",
    "case_id": "0079",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "Student Behavior",
    "scenario": "Students with high test anxiety perform 15% worse on exams. Educational psychologists observe that anxiety and poor performance reinforce each other: anxiety impairs performance, then poor results increase future anxiety, which further impairs performance. This creates a downward spiral where X  Y with bidirectional causation. Both effects exist simultaneously.",
    "claim": "Test anxiety causes poor exam performance (unidirectional).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Test anxiety",
        "role": "exposure"
      },
      "Y": {
        "name": "Exam performance",
        "role": "outcome"
      },
      "Z": [
        "Performance history",
        "Feedback loop",
        "Reinforcing cycle"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "FEEDBACK",
      "subtype": "Self-fulfilling prophecy",
      "subtype_name": "Anxiety-Performance Loop"
    },
    "difficulty": "Medium",
    "causal_structure": "Bidirectional: Anxiety  Poor performance  Increased anxiety  Worse performance. X  Y reinforcing loop.",
    "key_insight": "Anxiety and performance mutually reinforce each other in a feedback loop; causation is bidirectional.",
    "hidden_timestamp": "Is there a reinforcing loop where anxiety and performance mutually influence each other?",
    "conditional_answers": {
      "answer_if_condition_1": "If causation is unidirectional (anxietyperformance only), breaking anxiety would eliminate poor performance.",
      "answer_if_condition_2": "If causation is bidirectional (anxietyperformance), poor performance also causes anxiety, creating a self-reinforcing cycle."
    },
    "wise_refusal": "This is feedback/bidirectional causation. Anxiety impairs performance (XY), but poor performance also increases future anxiety (YX), creating a reinforcing loop. The claim of unidirectional causation is incomplete. The relationship is X  Y: anxiety causes poor performance, which causes more anxiety, which causes worse performance. Breaking this cycle requires addressing both directions.",
    "gold_rationale": "Bidirectional causation: AnxietyPerformance and PerformanceAnxiety. This is a reinforcing feedback loop. High anxiety impairs cognitive function during tests (XY). Poor results then increase anticipatory anxiety for future tests (YX). The cycle repeats, creating downward spiral. Proper intervention requires breaking both causal paths. Simple unidirectional models miss the feedback structure.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0080",
    "case_id": "0080",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Economics",
    "subdomain": "Labor Markets",
    "scenario": "In labor markets, higher wages attract more skilled workers, which increases productivity, which justifies higher wages. Companies that pay well get better employees who deliver better results, enabling continued high pay. This creates a virtuous cycle: wages  worker quality  productivity. The relationship is bidirectional and reinforcing, not unidirectional.",
    "claim": "High wages cause high productivity (unidirectional).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Wage levels",
        "role": "exposure"
      },
      "Y": {
        "name": "Worker productivity",
        "role": "outcome"
      },
      "Z": [
        "Worker quality",
        "Recruitment success",
        "Retention"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "FEEDBACK",
      "subtype": "Self-fulfilling prophecy",
      "subtype_name": "Wage-Productivity Virtuous Cycle"
    },
    "difficulty": "Medium",
    "causal_structure": "Bidirectional: High wages  Better workers  Higher productivity  Justifies high wages. X  Y reinforcing loop.",
    "key_insight": "Wages and productivity mutually reinforce in both directions; it's a virtuous cycle, not unidirectional.",
    "hidden_timestamp": "Is there a reinforcing loop where wages enable productivity which justifies wages?",
    "conditional_answers": {
      "answer_if_condition_1": "If causation is unidirectional (wagesproductivity only), raising wages would improve productivity without feedback.",
      "answer_if_condition_2": "If causation is bidirectional (wagesproductivity), productivity gains also enable higher wages, creating self-reinforcing success."
    },
    "wise_refusal": "This is bidirectional causation with feedback. High wages attract talented workers who increase productivity (XY). Higher productivity generates profits that enable continued high wages (YX). This creates a virtuous cycle: wagesproductivity. The claim of unidirectional causation misses the feedback. Both directions matter for understanding labor market dynamics.",
    "gold_rationale": "Bidirectional causation: WagesProductivity (efficiency wages, worker quality) and ProductivityWages (profit enables compensation). This is positive feedback creating virtuous cycle. High-wage firms attract better workers, improving productivity, generating profits that sustain high wages. Low-wage firms face reverse spiral. The relationship is XY, not XY. Proper models require simultaneous equations or dynamic systems.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0081",
    "case_id": "0081",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Social Science",
    "subdomain": "Urban Development",
    "scenario": "Neighborhood safety and economic investment form a feedback loop: safe areas attract business investment, which brings jobs and foot traffic, which increases safety through 'eyes on the street.' Conversely, crime deters investment, reducing activity, enabling more crime. Safety  investment is bidirectional. Claims of unidirectional causation miss the reinforcing dynamics.",
    "claim": "Neighborhood safety causes economic investment (unidirectional).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Neighborhood safety",
        "role": "exposure"
      },
      "Y": {
        "name": "Economic investment",
        "role": "outcome"
      },
      "Z": [
        "Foot traffic",
        "Business activity",
        "Social monitoring"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "FEEDBACK",
      "subtype": "Self-fulfilling prophecy",
      "subtype_name": "Safety-Investment Feedback Loop"
    },
    "difficulty": "Medium",
    "causal_structure": "Bidirectional: Safety  Investment  Activity  More safety. X  Y reinforcing loop.",
    "key_insight": "Safety and investment mutually reinforce; it's a feedback loop, not unidirectional causation.",
    "hidden_timestamp": "Is there a reinforcing loop where safety enables investment which increases safety?",
    "conditional_answers": {
      "answer_if_condition_1": "If causation is unidirectional (safetyinvestment only), improving safety would attract investment without feedback.",
      "answer_if_condition_2": "If causation is bidirectional (safetyinvestment), investment also improves safety, creating virtuous or vicious cycles."
    },
    "wise_refusal": "This is bidirectional causation with feedback. Safe neighborhoods attract investment (XY). Investment brings activity and 'eyes on the street,' which increases safety (YX). This creates reinforcing dynamics: safetyinvestment. Virtuous cycles in safe areas; vicious cycles in dangerous areas. The claim of unidirectional causation misses the feedback structure.",
    "gold_rationale": "Bidirectional causation: SafetyInvestment (businesses prefer safe areas) and InvestmentSafety (activity provides natural surveillance). This is Jane Jacobs' 'eyes on the street' with feedback. Safe areas attract business, generating foot traffic that deters crime. Dangerous areas lose business, reducing activity that enables more crime. XY creates path dependence and multiple equilibria.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0082",
    "case_id": "0082",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Mental Health",
    "scenario": "Depression and social isolation create a feedback loop: depressed individuals withdraw from social contact, which worsens depression through loneliness, leading to further withdrawal. Isolation  depression is bidirectional. Each makes the other worse in a reinforcing downward spiral. Claims of unidirectional causation miss this dynamic.",
    "claim": "Depression causes social isolation (unidirectional).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Depression severity",
        "role": "exposure"
      },
      "Y": {
        "name": "Social isolation",
        "role": "outcome"
      },
      "Z": [
        "Loneliness",
        "Social support loss",
        "Withdrawal behavior"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "FEEDBACK",
      "subtype": "Self-fulfilling prophecy",
      "subtype_name": "Depression-Isolation Spiral"
    },
    "difficulty": "Easy",
    "causal_structure": "Bidirectional: Depression  Isolation  Loneliness  Worse depression  More isolation. X  Y reinforcing loop.",
    "key_insight": "Depression and isolation mutually worsen each other in a feedback loop; both directions matter.",
    "hidden_timestamp": "Is there a reinforcing loop where depression causes isolation which worsens depression?",
    "conditional_answers": {
      "answer_if_condition_1": "If causation is unidirectional (depressionisolation only), treating depression would end isolation without addressing isolation's effect.",
      "answer_if_condition_2": "If causation is bidirectional (depressionisolation), isolation also deepens depression, requiring intervention on both."
    },
    "wise_refusal": "This is bidirectional causation with feedback. Depression causes social withdrawal (XY). Isolation then worsens depression through loneliness and loss of support (YX). This creates a downward spiral: depressionisolation. Each reinforces the other. The claim of unidirectional causation misses the feedback. Effective intervention must break both causal paths.",
    "gold_rationale": "Bidirectional causation: DepressionIsolation (withdrawal symptoms) and IsolationDepression (loneliness, lack of support). This is a vicious cycle. Depressed individuals avoid social contact, which eliminates protective factors, deepening depression, causing further withdrawal. XY creates reinforcing negative spiral. Treatment requires addressing both depression and rebuilding social connections simultaneously.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0083",
    "case_id": "0083",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Platform Economics",
    "scenario": "Social media platforms experience network effects: more users attract more content creators, which attracts more users, which attracts more creators. This is bidirectional feedback: users  creators. Each increases the value for the other in a self-reinforcing cycle. Claims that users cause creator presence miss the feedback that creates platform dominance.",
    "claim": "User growth causes creator participation (unidirectional).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "User base size",
        "role": "exposure"
      },
      "Y": {
        "name": "Creator participation",
        "role": "outcome"
      },
      "Z": [
        "Platform value",
        "Network effects",
        "Audience reach"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "FEEDBACK",
      "subtype": "Self-fulfilling prophecy",
      "subtype_name": "Network Effect Feedback Loop"
    },
    "difficulty": "Medium",
    "causal_structure": "Bidirectional: More users  More creators  Better content  More users. X  Y reinforcing loop creating network effects.",
    "key_insight": "Users and creators mutually attract each other in feedback loop; network effects are bidirectional.",
    "hidden_timestamp": "Is there a reinforcing loop where users attract creators who attract more users?",
    "conditional_answers": {
      "answer_if_condition_1": "If causation is unidirectional (userscreators only), growing users would attract creators without feedback.",
      "answer_if_condition_2": "If causation is bidirectional (userscreators), creators also attract users, creating self-reinforcing growth or decline."
    },
    "wise_refusal": "This is bidirectional causation with network effects. Large user bases attract creators seeking audiences (XY). Creator content then attracts more users (YX). This creates reinforcing feedback: userscreators. Platforms with both grow rapidly; platforms lacking either decline. The claim of unidirectional causation misses the feedback driving platform dynamics.",
    "gold_rationale": "Bidirectional causation with network effects: UsersCreators (audience attracts content) and CreatorsUsers (content attracts audience). This is positive feedback creating winner-take-all dynamics. Successful platforms have self-reinforcing growth (XY virtuous cycle). Failed platforms have self-reinforcing decline. Understanding platform competition requires recognizing bidirectional network effects, not unidirectional causation.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0084",
    "case_id": "0084",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Customer Service",
    "scenario": "A hospital case-control study examines adverse drug reactions. Patients who experienced reactions are interviewed about medication history, while control patients answer similar questions. Cases ruminate about their medications and recall exposures more thoroughly than controls. This differential recall creates spurious association between medications and reactions that may not reflect true exposure differences.",
    "claim": "Medication X causes adverse reactions.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Medication exposure (recalled)",
        "role": "exposure"
      },
      "Y": {
        "name": "Adverse reaction (case status)",
        "role": "outcome"
      },
      "Z": [
        "Outcome knowledge",
        "Recall motivation",
        "Rumination"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "RECALL BIAS",
      "subtype": "Effort after meaning",
      "subtype_name": "Cases Recall Exposure Better"
    },
    "difficulty": "Medium",
    "causal_structure": "Outcome (Y)  Differential recall  Measured exposure (X*). Y influences measurement of X, creating spurious X-Y association.",
    "key_insight": "Cases recall exposures more thoroughly than controls; outcome influences exposure reporting.",
    "hidden_timestamp": "Do cases recall exposure history differently than controls due to their outcome status?",
    "conditional_answers": {
      "answer_if_condition_1": "If cases and controls recall medication history equally accurately, observed association reflects true exposure difference.",
      "answer_if_condition_2": "If cases recall exposures more thoroughly due to rumination, the association may reflect recall bias rather than true causation."
    },
    "wise_refusal": "This is recall bias. Patients who experienced adverse reactions think carefully about possible causes and recall medications more completely. Controls without reactions recall exposures less thoroughly. This differential recall creates spurious association between medication and reactions. The outcome (reaction) influences exposure reporting, violating assumptions of case-control studies. Medical records would provide unbiased exposure data.",
    "gold_rationale": "Recall bias occurs when outcome status influences exposure recall accuracy. Cases with adverse reactions engage in 'effort after meaning'searching for causesleading to more thorough medication recall. Controls lack motivation for complete recall. This creates differential misclassification: cases over-report exposures relative to controls. The spurious association arises because YX* (outcome affects measured exposure), not because XY. Prospective data collection or medical records avoid recall bias.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0085",
    "case_id": "0085",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Environmental Health",
    "scenario": "A case-control study investigates childhood cancer and residential pesticide exposure. Mothers of children with cancer recall pesticide use in much greater detail than control mothers, reporting specific products, application dates, and locations. Control mothers provide vague responses. This differential recall creates apparent association between pesticides and cancer that may reflect recall accuracy differences, not true exposure differences.",
    "claim": "Residential pesticide exposure causes childhood cancer.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Pesticide exposure (maternal recall)",
        "role": "exposure"
      },
      "Y": {
        "name": "Childhood cancer (case status)",
        "role": "outcome"
      },
      "Z": [
        "Maternal recall accuracy",
        "Motivation to identify causes",
        "Rumination"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "RECALL BIAS",
      "subtype": "Effort after meaning",
      "subtype_name": "Cancer Mothers Recall Detail Better"
    },
    "difficulty": "Medium",
    "causal_structure": "Cancer diagnosis (Y)  Mother searches for causes  Enhanced pesticide recall (X*). Outcome influences exposure reporting.",
    "key_insight": "Mothers of cancer patients recall environmental exposures more thoroughly, creating spurious associations.",
    "hidden_timestamp": "Do case mothers recall pesticide exposures more accurately than control mothers?",
    "conditional_answers": {
      "answer_if_condition_1": "If case and control mothers recall pesticide use equally accurately, the association reflects true exposure differences.",
      "answer_if_condition_2": "If case mothers recall exposures more thoroughly due to searching for cancer causes, the association may be spurious."
    },
    "wise_refusal": "This is recall bias. Mothers whose children have cancer intensely search for possible causes, leading to detailed pesticide exposure recall. Control mothers lack this motivation and provide less complete histories. The outcome (cancer) drives recall accuracy, creating spurious exposure-disease association. Environmental monitoring or records-based exposure assessment would avoid recall bias.",
    "gold_rationale": "Recall bias through differential motivation. Cancer diagnosisMother's search for meaningEnhanced recall. Case mothers engage in extensive retrospection ('what did I do wrong?'), while control mothers casually recall routine activities. This creates YX* where outcome affects measured exposure accuracy. The apparent pesticide-cancer association may reflect recall differences, not true exposure-disease relationship. Proper study design requires prospective exposure assessment.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0086",
    "case_id": "0086",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Law",
    "subdomain": "Criminal Justice",
    "scenario": "A legal case examines whether workplace harassment caused plaintiff's PTSD. The plaintiff provides detailed descriptions of harassment incidents from 2 years ago. However, PTSD often distorts and amplifies negative memory recalltraumatized individuals remember threatening events more vividly while forgetting neutral interactions. The PTSD outcome may be causing enhanced harassment recall, not harassment causing PTSD.",
    "claim": "Workplace harassment caused the plaintiff's PTSD symptoms.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Harassment severity (plaintiff recall)",
        "role": "exposure"
      },
      "Y": {
        "name": "PTSD symptoms",
        "role": "outcome"
      },
      "Z": [
        "PTSD memory distortion",
        "Threat-enhanced recall",
        "Neutral memory loss"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "RECALL BIAS",
      "subtype": "Rumination bias",
      "subtype_name": "PTSD Amplifies Threat Memories"
    },
    "difficulty": "Hard",
    "causal_structure": "PTSD (Y)  Enhanced threat memory  Amplified harassment recall (X*). Mental state distorts retrospective exposure reporting.",
    "key_insight": "PTSD amplifies threat-related memories; current mental state distorts past event recall.",
    "hidden_timestamp": "Does the plaintiff's PTSD cause amplified recall of threatening events?",
    "conditional_answers": {
      "answer_if_condition_1": "If plaintiff's harassment recall is accurate despite PTSD, the detailed memories reflect true harassment severity.",
      "answer_if_condition_2": "If PTSD amplifies threat-related memories while erasing neutral interactions, current symptoms distort past event recall."
    },
    "wise_refusal": "This is recall bias through PTSD-related memory distortion. PTSD amplifies threat-related memories and suppresses neutral memories. The plaintiff's detailed harassment recall may reflect current mental state rather than actual past events. YX*: PTSD symptoms influence how past harassment is remembered and reported. Contemporary documentation or witness accounts would provide less biased evidence than retrospective patient recall.",
    "gold_rationale": "Recall bias through symptom-induced memory distortion. PTSDThreat memory enhancementAmplified harassment recall. Traumatic stress disorders alter memory formation and retrieval, amplifying threatening events while suppressing neutral interactions. Current mental state (Y) influences past exposure recall (X*). The causal direction may be partially reversed: PTSD amplifies threatening memories, not necessarily harassment causing PTSD. Contemporaneous evidence (emails, complaints, witnesses) required for unbiased exposure assessment.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0087",
    "case_id": "0087",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "Interventions",
    "scenario": "A literacy program teaches phonics to improve reading comprehension. After 6 months, students show no improvement in comprehension scores. Evaluation reveals the program successfully taught phonics decoding, but the reading test measured inference and analytical skills that weren't targeted. The intervention worked on its target but failed to affect the measured outcome because the mechanism was mismatched.",
    "claim": "The phonics program failed to improve reading ability.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Phonics intervention",
        "role": "exposure"
      },
      "Y": {
        "name": "Reading comprehension scores (inference/analysis)",
        "role": "outcome"
      },
      "Z": [
        "Phonics decoding skills",
        "Target mechanism",
        "Measured outcome mismatch"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "MECHANISM MISMATCH",
      "subtype": "Wrong target",
      "subtype_name": "Intervention-Outcome Pathway Mismatch"
    },
    "difficulty": "Medium",
    "causal_structure": "Intervention (X)  Phonics skills (M1)  Decoding. Measured outcome (Y) requires inference (M2), not targeted by intervention.",
    "key_insight": "Intervention worked on target pathway but failed to affect measured outcome due to mechanism mismatch.",
    "hidden_timestamp": "Did the intervention target the actual mechanism required for the measured outcome?",
    "conditional_answers": {
      "answer_if_condition_1": "If the comprehension test measured phonics-related decoding, the intervention would show effects.",
      "answer_if_condition_2": "If the comprehension test measured inference and analysis skills not targeted by phonics training, no effect appears despite successful phonics learning."
    },
    "wise_refusal": "This is mechanism mismatch. The intervention successfully taught phonics decoding (M1), but the outcome measure required inference and analytical skills (M2) not addressed by the program. The intervention worked on its target but didn't affect the measured outcome because the causal pathway was wrong. This doesn't mean the program failedit means the intervention mechanism doesn't connect to the measured outcome.",
    "gold_rationale": "Mechanism failure through pathway mismatch. XM1 (phonics) but Y requires M2 (inference). The intervention succeeded on its target but failed the measured outcome because the causal chain XM1 doesn't lead to Y. Phonics helps decoding but doesn't directly improve higher-order comprehension skills. The evaluation conflated intervention effectiveness with outcome measurement. Proper evaluation requires outcome measures aligned with intervention mechanisms.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0088",
    "case_id": "0088",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Treatment Efficacy",
    "scenario": "A hospital provides diabetes education to improve patient outcomes, measuring success by HbA1c levels. After 1 year, HbA1c shows no improvement despite excellent program completion and knowledge gains. Investigation reveals the hospital serves low-income patients who understand diabetes management but lack resources for healthy food and medications. The intervention targeted knowledge but outcomes require resources.",
    "claim": "Diabetes education failed to improve patient outcomes.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Diabetes education program",
        "role": "exposure"
      },
      "Y": {
        "name": "HbA1c levels (blood sugar control)",
        "role": "outcome"
      },
      "Z": [
        "Patient knowledge",
        "Food access",
        "Medication affordability"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "MECHANISM MISMATCH",
      "subtype": "Wrong target",
      "subtype_name": "Knowledge vs. Resources Pathway"
    },
    "difficulty": "Medium",
    "causal_structure": "Education (X)  Knowledge (M1). But HbA1c (Y) requires Resources (M2): healthy food, medications. M1 achieved but M2 needed for Y.",
    "key_insight": "Intervention successfully increased knowledge but didn't address resource barriers needed for outcome improvement.",
    "hidden_timestamp": "Did the intervention target the actual limiting factor (resources) or a non-limiting factor (knowledge)?",
    "conditional_answers": {
      "answer_if_condition_1": "If knowledge was the barrier, education would improve HbA1c through better self-management.",
      "answer_if_condition_2": "If resources (food, medications) are the barrier, education increases knowledge without improving outcomes."
    },
    "wise_refusal": "This is mechanism mismatch. The intervention successfully increased diabetes knowledge (M1), but HbA1c improvement requires resourceshealthy food and medications (M2)that the program didn't provide. The pathway XM1 worked, but Y requires M2. The intervention targeted the wrong mechanism. Patients gained knowledge but couldn't act on it due to resource constraints.",
    "gold_rationale": "Mechanism failure: XM1 (knowledge) but Y requires M2 (resources). Education successfully transmitted information, but blood sugar control requires implementing that knowledge through diet and medicationlimited by poverty. The causal chain breaks: knowledge is necessary but insufficient. The intervention would succeed in affluent populations (where knowledge is limiting factor) but fails in low-income populations (where resources are limiting). Proper intervention must address actual constraint.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0089",
    "case_id": "0089",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Pharmacoepidemiology",
    "scenario": "A study examines Oscar-winning actors' longevity. Analysis begins when actors win their award. From award date forward, researchers track survival, finding Oscar winners live 4 years longer than nominees who didn't win. However, to win an Oscar, actors must survive to the ceremony. Actors who died before winning are excluded from the 'winner' group but included in 'non-winner' group. This creates immortal timewinner group had guaranteed survival to win.",
    "claim": "Winning an Oscar causes increased longevity.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Oscar win",
        "role": "exposure"
      },
      "Y": {
        "name": "Longevity (years lived)",
        "role": "outcome"
      },
      "Z": [
        "Immortal time period",
        "Guaranteed survival to award",
        "Time misclassification"
      ]
    },
    "trap": {
      "type": "T4",
      "type_name": "IMMORTAL TIME",
      "subtype": "Time-to-treatment bias",
      "subtype_name": "Award Winners' Guaranteed Survival"
    },
    "difficulty": "Hard",
    "causal_structure": "Winners must survive to ceremony (immortal time), creating survival guarantee not present in comparison group. Time measurement starts at different points.",
    "key_insight": "Winners had guaranteed survival period before exposure classification; comparison group includes those who died during this period.",
    "hidden_timestamp": "Was there a period when the outcome (death) couldn't occur for the exposed group?",
    "conditional_answers": {
      "answer_if_condition_1": "If we measure survival from birth for both groups equally, comparison is fair.",
      "answer_if_condition_2": "If winner group has guaranteed survival to award ceremony while comparison includes early deaths, immortal time biases results."
    },
    "wise_refusal": "This is immortal time bias. Oscar winners must survive to the ceremony to be classified as 'winners.' This creates a period of guaranteed survival (from birth to award) where death is impossible for the winner group. The comparison group includes actors who died before they could win, making winners appear to live longer. Proper analysis requires matching on age or using time-varying exposure.",
    "gold_rationale": "Immortal time bias from survival requirement. WinnersMust survive to ceremony creates guaranteed survival period. Comparison group includes deaths during this immortal period. The causal inference is backwards: survival enabled Oscar winning, not Oscar causing survival. Proper analysis: landmark analysis or time-dependent covariates.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0090",
    "case_id": "0090",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Medicine",
    "subdomain": "Cardiology",
    "scenario": "A study compares cardiac stent users vs. non-users. Patients are classified as 'stent users' from their stent date forward. However, patients must survive hospitalization to receive stents. Those who died during hospitalization never became 'stent users' but are counted in comparison group. The stent group has a survival guarantee that comparison lacks.",
    "claim": "Cardiac stents reduce mortality compared to medical management.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Stent placement",
        "role": "exposure"
      },
      "Y": {
        "name": "Mortality",
        "role": "outcome"
      },
      "Z": [
        "Hospital survival requirement",
        "Immortal time during hospitalization",
        "Selection on survival"
      ]
    },
    "trap": {
      "type": "T4",
      "type_name": "IMMORTAL TIME",
      "subtype": "Time-to-treatment bias",
      "subtype_name": "Treatment Requires Survival"
    },
    "difficulty": "Hard",
    "causal_structure": "Stent patients must survive hospitalization to receive treatment. Comparison group includes hospital deaths. Immortal time from admission to stent creates survival bias.",
    "key_insight": "Treatment group has guaranteed survival to treatment; control group includes those who died before treatment possible.",
    "hidden_timestamp": "Did stent patients have a period of guaranteed survival (hospitalization) before exposure classification?",
    "conditional_answers": {
      "answer_if_condition_1": "If both groups measured from same time point with equal survival requirements, comparison is valid.",
      "answer_if_condition_2": "If stent group required surviving hospitalization while controls include hospital deaths, immortal time creates spurious benefit."
    },
    "wise_refusal": "This is immortal time bias. Stent recipients must survive hospitalization to receive the procedure. This creates guaranteed survival from admission to stent placement. The medical management group includes patients who died during this period before stents could be placed. The apparent mortality benefit reflects survival selection, not stent effectiveness.",
    "gold_rationale": "Immortal time from admission to procedure. Stent groupSurvived to procedure (guaranteed). ControlIncludes pre-procedure deaths. The immortal period creates spurious survival advantage. Proper analysis requires intention-to-treat from admission or time-varying exposure accounting for hospitalization survival.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0091",
    "case_id": "0091",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Epidemiology",
    "subdomain": "Drug Safety",
    "scenario": "A study examines whether cholesterol medication reduces heart attacks. Patients are classified as 'users' from their first prescription. However, patients must survive without heart attack to receive the prescription. The user group has guaranteed MI-free survival to first prescription; non-users include those with early MIs.",
    "claim": "Cholesterol medication prevents heart attacks.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Cholesterol medication use",
        "role": "exposure"
      },
      "Y": {
        "name": "Heart attack incidence",
        "role": "outcome"
      },
      "Z": [
        "Survival to prescription",
        "MI-free period before treatment",
        "Immortal time"
      ]
    },
    "trap": {
      "type": "T4",
      "type_name": "IMMORTAL TIME",
      "subtype": "Prevalent user bias",
      "subtype_name": "Treatment Requires Event-Free Survival"
    },
    "difficulty": "Medium",
    "causal_structure": "Medication users must survive MI-free to receive first prescription. Non-users include early MI cases. Immortal time from study start to prescription creates survival advantage.",
    "key_insight": "Exposed group had guaranteed event-free survival to exposure; comparison includes those who had events during this period.",
    "hidden_timestamp": "Was there an event-free period required before medication could be prescribed?",
    "conditional_answers": {
      "answer_if_condition_1": "If exposure classified from study start and both groups have equal observation periods, comparison is valid.",
      "answer_if_condition_2": "If users required event-free survival to prescription while non-users include early events, immortal time biases results."
    },
    "wise_refusal": "This is immortal time bias. Medication users must remain event-free from study start to first prescription. Non-users include patients who had early heart attacks before medication could be prescribed. The apparent protective effect reflects the required survival period, not medication efficacy. New-user design with time-varying exposure would avoid this bias.",
    "gold_rationale": "Immortal time from study entry to prescription. UsersEvent-free survival required. Non-usersInclude early events. Apparent medication benefit is artifact of survival requirement. Proper design: new-user design starting observation at prescription with matched controls, avoiding prevalent user bias.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0092",
    "case_id": "0092",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Medicine",
    "subdomain": "Rheumatology",
    "scenario": "Patients with rheumatoid arthritis receive disease-modifying drugs at diagnosis. Their inflammation markers are measured weekly. Doctors observe that inflammation is highest in weeks 1-3, then drops sharply in weeks 4-8 as medication takes effect. They conclude medication reduces inflammation by 60%. However, disease flares naturally wax and wane. Patients present for diagnosis during flare peaks, then inflammation naturally subsides regardless of treatment. Timing of assessment relative to disease pattern creates the illusion of treatment effect.",
    "claim": "The disease-modifying drugs reduced inflammation by 60%.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Rheumatoid arthritis medication timing",
        "role": "exposure"
      },
      "Y": {
        "name": "Inflammation markers decline",
        "role": "outcome"
      },
      "Z": [
        "Natural disease flare timing",
        "Temporal ordering",
        "Disease started before medication"
      ]
    },
    "trap": {
      "type": "T9",
      "type_name": "CONF-MED",
      "subtype": "Environmental",
      "subtype_name": "Disease Flare Timing Ambiguity"
    },
    "difficulty": "Hard",
    "causal_structure": "Disease flare (Z) causes diagnosis visit and causes subsequent natural decline. Medication timing overlaps with natural disease pattern. Z occurred before X, making Z a confounder not mediator.",
    "key_insight": "Disease flare preceded and caused treatment; natural disease course drives apparent improvement, not medication.",
    "hidden_timestamp": "Did the inflammation flare (Z) begin before medication (X) started, or did medication cause inflammation changes through mechanism (Z)?",
    "conditional_answers": {
      "answer_if_condition_1": "If flare began before medication (tZ < tX), inflammation decline reflects natural disease course (Z confounds X-Y).",
      "answer_if_condition_2": "If medication caused physiological changes (tX < tZ) that reduced inflammation, Z mediates causal effect."
    },
    "wise_refusal": "This is confounder-mediator ambiguity. Patients seek treatment during disease flares that naturally subside. The disease flare (Z) occurred before medication (X), making it a confounder driving both treatment initiation and natural improvement. Without knowing whether inflammation was already declining before medication or whether medication initiated the decline, we cannot attribute improvement to treatment. Randomized trials show smaller effects than observational studies, confirming confounding.",
    "gold_rationale": "Temporal ambiguity between confounder and mediator. If flarediagnosis visitmedication and flarenatural decline, Z confounds XY. If medicationinflammatory pathway changesdecline, Z mediates. The temporal sequence (patients present during flares) suggests Z preceded X, making this confounding by disease timing. Proper inference requires pre-treatment inflammation trajectory.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0093",
    "case_id": "0093",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Psychology",
    "subdomain": "Child Development",
    "scenario": "Children who attended preschool show higher reading scores at age 7. Researchers observe that preschool children have larger vocabularies at age 5. Question: Did preschool cause vocabulary growth which then improved reading? Or did children from educated families have larger baseline vocabularies before preschool, causing both preschool enrollment and reading success? Temporal data shows vocabulary advantages exist before preschool entry.",
    "claim": "Preschool causes reading improvement through vocabulary development.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Preschool attendance",
        "role": "exposure"
      },
      "Y": {
        "name": "Reading scores at age 7",
        "role": "outcome"
      },
      "Z": [
        "Vocabulary size",
        "Family education level",
        "Baseline language exposure"
      ]
    },
    "trap": {
      "type": "T9",
      "type_name": "CONF-MED",
      "subtype": "Pre-existing condition",
      "subtype_name": "Vocabulary Present Before Preschool"
    },
    "difficulty": "Hard",
    "causal_structure": "Family education (Z) causes early vocabulary and preschool enrollment. Z is confounder that precedes X, not mediator caused by X. Temporal measurement shows Z present at age 3, before preschool at age 4.",
    "key_insight": "Vocabulary advantages exist before preschool; family factors cause both vocabulary and enrollment.",
    "hidden_timestamp": "Did vocabulary advantages (Z) exist before preschool entry (tZ < tX), or did preschool cause vocabulary growth (tX < tZ)?",
    "conditional_answers": {
      "answer_if_condition_1": "If vocabulary was already elevated before preschool (tZ < tX), family background confounds the preschool-reading relationship.",
      "answer_if_condition_2": "If preschool caused vocabulary growth (tX < tZ < tY), vocabulary mediates the causal effect."
    },
    "wise_refusal": "This is confounder-mediator ambiguity. Data shows vocabulary advantages exist at age 3, before typical preschool entry at age 4. Family education causes both early vocabulary development and preschool enrollment. Z preceded X (tZ < tX), making vocabulary a confounder, not a mediator. The preschool-reading association reflects family selection, not causal effects. RCTs show smaller preschool effects than observational studies.",
    "gold_rationale": "Temporal ordering reveals Z is confounder. Family educationEarly vocabulary (age 3) and Family educationPreschool enrollment (age 4). Since tZ < tX, vocabulary is pre-existing confounder, not mediator. The apparent preschool effect reflects family selection. Controlling for baseline vocabulary (measured before preschool) reduces the association substantially.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0094",
    "case_id": "0094",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Corporate Strategy",
    "scenario": "Firms that adopt digital transformation initiatives show improved profit margins 2 years later. Consultants note these firms had recent C-suite changes. Question: Did new leadership drive digital transformation which improved profits? Or were profitable firms able to afford leadership changes and digital initiatives? Examination shows profit growth began 18 months before C-suite changes and continued afterward.",
    "claim": "Digital transformation initiatives cause profit improvement through new leadership.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Digital transformation",
        "role": "exposure"
      },
      "Y": {
        "name": "Profit margins",
        "role": "outcome"
      },
      "Z": [
        "C-suite changes",
        "Prior profitability trajectory",
        "Resources for investment"
      ]
    },
    "trap": {
      "type": "T9",
      "type_name": "CONF-MED",
      "subtype": "Pre-existing condition",
      "subtype_name": "Profitability Preceded Leadership Change"
    },
    "difficulty": "Medium",
    "causal_structure": "Prior profit growth (Z) enabled both leadership investment and digital initiatives. Z preceded X, making it confounder not mediator. Temporal data shows profitability trajectory established before interventions.",
    "key_insight": "Profitability trend existed before leadership changes and digital initiatives; success enabled investments, not vice versa.",
    "hidden_timestamp": "Did profitability improvement (Z) begin before digital transformation (tZ < tX), or did transformation cause profit growth (tX < tZ)?",
    "conditional_answers": {
      "answer_if_condition_1": "If profit growth began before digital transformation (tZ < tX), prior success confounds the initiative-profit relationship.",
      "answer_if_condition_2": "If transformation caused profit growth through mechanisms (tX < tZ < tY), Z mediates the effect."
    },
    "wise_refusal": "This is confounder-mediator ambiguity. Data reveals profit growth began 18 months before C-suite changes and digital initiatives. Prior profitability (Z) enabled firms to invest in leadership and technology. Z preceded X (tZ < tX), making it a confounder, not mediator. The association reflects resource availability, not causal effects. Firms already on growth trajectories could afford investments.",
    "gold_rationale": "Temporal sequence shows Z is confounder. Prior profit growthResources for C-suite investment and digital initiatives. Since tZ < tX, profitability is pre-existing condition enabling investments, not outcome. The digital-profit association reflects selectionsuccessful firms invest in transformation. Controlling for pre-initiative profit trends eliminates most of the association.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0095",
    "case_id": "0095",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Injury Prevention",
    "scenario": "A city installs speed cameras at 50 high-crash intersections. Over 12 months, crashes at these intersections drop 40%. Officials credit the cameras. However, intersections were selected precisely because they had recent crash spikes. Many had ongoing infrastructure improvements that began before cameras were installed. Crashes were elevated above long-term averages when cameras were added, then regressed to normal levels.",
    "claim": "Speed cameras caused the 40% crash reduction.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Speed camera installation",
        "role": "exposure"
      },
      "Y": {
        "name": "Crash reduction",
        "role": "outcome"
      },
      "Z": [
        "Infrastructure improvements timeline",
        "Temporal confounding",
        "Concurrent interventions"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "TEMPORAL",
      "subtype": "Treatment-confounder feedback",
      "subtype_name": "Time-Varying Infrastructure Improvements"
    },
    "difficulty": "Hard",
    "causal_structure": "Infrastructure improvements (Z at t1) affected crash risk and influenced camera placement decisions. Z varies over time and affects both X and Y. Past crash levels affect future interventions.",
    "key_insight": "Concurrent interventions and temporal confounding make causal attribution impossible; multiple time-varying factors affect outcomes.",
    "hidden_timestamp": "Does the confounding structure change over time, with interventions affecting each other temporally?",
    "conditional_answers": {
      "answer_if_condition_1": "If cameras were the only intervention and crashes were at baseline, the 40% reduction could be attributed to cameras.",
      "answer_if_condition_2": "If infrastructure improvements preceded cameras and crash levels were elevated when cameras installed, temporal confounding prevents causal attribution."
    },
    "wise_refusal": "This is time-varying confounding. Intersections were selected during crash spikes (regression to mean) and had concurrent infrastructure improvements (time-varying confounder Z). Infrastructure work began before cameras but continued during camera installation. Past crash levels affected both infrastructure decisions and camera placement. The temporal sequenceelevated crashesinfrastructure workcamera installationregression to meanmakes attribution impossible without accounting for time-varying confounding.",
    "gold_rationale": "Time-varying confounding with treatment-confounder feedback. Z1 (infrastructure start)Camera placement and Z2 (infrastructure completion)Crash reduction. Crashes were above baseline when cameras installed (selection on spike + regression to mean). Multiple temporal interventions with feedback loops prevent simple causal inference. Marginal structural models or g-methods required for proper analysis.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0096",
    "case_id": "0096",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Medicine",
    "subdomain": "Chronic Disease",
    "scenario": "Diabetic patients receive blood sugar monitoring devices. Doctors observe that patients with frequent monitoring have worse diabetes control. They conclude monitoring causes poor control. However, doctors prescribe frequent monitoring to patients with poor control. Poor control at t1 causes monitoring increase at t2, which causes medication adjustment at t3, affecting control at t4. The monitoring-control relationship changes over time.",
    "claim": "Frequent blood sugar monitoring causes worse diabetes control.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Monitoring frequency",
        "role": "exposure"
      },
      "Y": {
        "name": "Diabetes control (HbA1c)",
        "role": "outcome"
      },
      "Z": [
        "Prior control status",
        "Treatment decisions",
        "Time-varying confounding"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "TEMPORAL",
      "subtype": "Treatment-confounder feedback",
      "subtype_name": "Control Status Affects Future Monitoring"
    },
    "difficulty": "Hard",
    "causal_structure": "Control(t1)Monitoring(t2)Treatment(t3)Control(t4). Past outcomes affect future treatment, which affects future outcomes. Time-varying confounding with feedback.",
    "key_insight": "Control status affects monitoring decisions over time; past outcomes influence future treatments creating temporal feedback.",
    "hidden_timestamp": "Does confounding structure change over time with past outcomes affecting future exposures?",
    "conditional_answers": {
      "answer_if_condition_1": "If monitoring assigned randomly regardless of control status, association would reflect causal effect.",
      "answer_if_condition_2": "If poor control causes increased monitoring which triggers treatment changes, time-varying confounding prevents simple inference."
    },
    "wise_refusal": "This is time-varying confounding with treatment-confounder feedback. Poor control at t1 causes increased monitoring at t2 (reverse causation). Monitoring data informs treatment adjustments at t3, affecting control at t4. Past control status affects future monitoring, creating temporal feedback loops. The monitoring-control association reflects treatment targeting, not causal effects. Marginal structural models accounting for time-varying confounding show monitoring benefits, not harms.",
    "gold_rationale": "Treatment-confounder feedback over time. Poor controlMonitoringTreatment adjustmentControl. The confounding structure changes: control status is both outcome (t1) and confounder for future monitoring (t2). Standard regression fails with time-varying confounding affected by prior treatment. Proper analysis requires inverse probability weighting or g-estimation to handle temporal dependencies.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0097",
    "case_id": "0097",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Environmental Science",
    "subdomain": "Climate Policy",
    "scenario": "Countries implementing carbon taxes show 15% emissions reductions over 5 years. Analysis suggests carbon pricing works. However, countries adopt carbon taxes during economic downturns when emissions naturally fall. Economic recovery then increases emissions while also generating revenue for renewable subsidies. GDP growth at t1 affects tax adoption at t2 and emission subsidies at t3, which affect emissions at t4. The GDP-tax-emissions relationship varies temporally.",
    "claim": "Carbon taxes caused the emissions reductions.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Carbon tax implementation",
        "role": "exposure"
      },
      "Y": {
        "name": "Emissions reduction",
        "role": "outcome"
      },
      "Z": [
        "GDP trajectory",
        "Economic cycles",
        "Time-varying confounding"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "TEMPORAL",
      "subtype": "Treatment-confounder feedback",
      "subtype_name": "Economic Cycles Affect Policy Timing"
    },
    "difficulty": "Medium",
    "causal_structure": "GDP(t1)Tax adoption(t2)RevenueSubsidies(t3)Emissions(t4). Economic conditions affect policy timing and outcomes with temporal feedback.",
    "key_insight": "Economic cycles affect both policy adoption timing and emissions; temporal confounding with feedback loops.",
    "hidden_timestamp": "Does economic status change over time, affecting both policy adoption and emissions outcomes?",
    "conditional_answers": {
      "answer_if_condition_1": "If carbon taxes implemented randomly across economic conditions, observed reductions reflect causal effects.",
      "answer_if_condition_2": "If taxes adopted during downturns when emissions naturally fall, time-varying economic confounding prevents attribution."
    },
    "wise_refusal": "This is time-varying confounding. Countries adopt carbon taxes during economic slowdowns when emissions naturally decline. Economic recovery then affects emissions through multiple channelsdirect growth effects and tax-funded subsidies. GDP at t1 affects tax adoption at t2, and GDP at t3 affects emissions at t4. The temporal structuredownturntaxrecoveryemissionsinvolves feedback between economic conditions and policy. Proper analysis requires controlling for time-varying GDP effects.",
    "gold_rationale": "Time-varying confounding with economic feedback. RecessionTax adoption (political feasibility) and RecoveryEmissions changes. Economic conditions are both confounder (affecting tax timing) and affected by prior policy (tax revenue enables subsidies). The temporal path involves multiple stages where confounders change. Standard methods fail; need marginal structural models or difference-in-differences with matched controls on economic trajectories.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0098",
    "case_id": "0098",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Policy",
    "subdomain": "Education Reform",
    "scenario": "A city bans single-use plastic bags, promoting reusable bags to reduce waste. The first year shows a 30% reduction in plastic bag litter. However, reusable bags carry bacteria from previous uses. Customers, trying to be environmentally conscious, use reusable bags but don't wash them. Food contamination incidents rise 45%. The intervention to reduce plastic pollution caused a worse public health problem through unintended pathways.",
    "claim": "The plastic bag ban successfully reduced environmental harm.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Plastic bag ban",
        "role": "exposure"
      },
      "Y": {
        "name": "Environmental/health outcomes",
        "role": "outcome"
      },
      "Z": [
        "Reusable bag hygiene behavior",
        "Compensatory behavior",
        "Unintended consequences"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "BACKFIRE",
      "subtype": "Unintended consequences",
      "subtype_name": "Hygiene Compensatory Behavior"
    },
    "difficulty": "Hard",
    "causal_structure": "Intervention (X)  Reusable bag adoption  Unwashed bags (Z compensatory)  Food contamination (Y negative). Intended pathway blocked by compensatory response creating worse outcome.",
    "key_insight": "Well-intentioned intervention triggered compensatory behavior that created net harm through unintended pathway.",
    "hidden_timestamp": "Could the intervention trigger compensatory or unintended behaviors that produce opposite effects?",
    "conditional_answers": {
      "answer_if_condition_1": "If intervention worked through intended pathway without compensatory responses, plastic reduction benefits would dominate.",
      "answer_if_condition_2": "If intervention triggered compensatory behavior (unwashed reusable bags), health harms could exceed plastic reduction benefits."
    },
    "wise_refusal": "This is intervention backfire through compensatory behavior. The bag ban successfully reduced plastic litter (intended effect) but triggered unintended hygiene failures. Customers adopted reusable bags but failed to wash them, creating bacterial contamination. The net effecttrading modest plastic reduction for significant food safety riskrepresents policy backfire. The intervention activated an unintended causal pathway (hygiene behavior) that dominated intended benefits. Comprehensive policy design requires anticipating compensatory responses.",
    "gold_rationale": "Backfire through unintended behavioral pathway. BanReusable adoption (intended) but also BanNo washing behavior (unintended)Contamination. The compensatory response (treating reusables like disposables) created net harm. This is classic policy backfireintervention succeeded on target metric (plastic) but triggered responses that produced worse overall outcome. Proper policy evaluation requires net effects across all pathways, not just target metric.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0099",
    "case_id": "0099",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Cybersecurity",
    "scenario": "A company implements mandatory security training after breaches, showing employees graphic examples of hacking consequences and requiring complex 16-character passwords changed monthly. Six months later, password-related breaches increase 60%. Investigation reveals employees write passwords on sticky notes due to complexity and forget training lessons from fear-inducing content. The intervention's severity triggered avoidance and workarounds that increased vulnerability.",
    "claim": "Security training reduced cybersecurity breaches.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Mandatory security training",
        "role": "exposure"
      },
      "Y": {
        "name": "Security breach rate",
        "role": "outcome"
      },
      "Z": [
        "Psychological reactance",
        "Password workarounds",
        "Fear-induced avoidance"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "BACKFIRE",
      "subtype": "Reactance",
      "subtype_name": "Excessive Requirements Trigger Workarounds"
    },
    "difficulty": "Hard",
    "causal_structure": "Training (X)  Reactance to excessive requirements (Z)  Insecure workarounds  More breaches (Y opposite). Intervention too severe, triggering counterproductive responses.",
    "key_insight": "Overly burdensome security requirements triggered reactance and workarounds that increased vulnerability.",
    "hidden_timestamp": "Could the intervention's requirements trigger reactance or compensatory behaviors that undermine effectiveness?",
    "conditional_answers": {
      "answer_if_condition_1": "If training used reasonable requirements that employees could follow, breach reduction would occur.",
      "answer_if_condition_2": "If training demanded excessive compliance (16-char passwords, monthly changes, graphic fear), reactance triggers workarounds that increase breaches."
    },
    "wise_refusal": "This is intervention backfire through psychological reactance. The security training's excessive demands (complex passwords changed monthly) triggered workarounds (sticky notes) that increased vulnerability. Fear-based messaging caused avoidance rather than engagement. The interventiondesigned to increase securitycreated net harm by demanding unsustainable compliance. Reactance to perceived control produced exactly opposite of intended effect. Effective security requires user-friendly requirements that don't trigger compensatory responses.",
    "gold_rationale": "Backfire through reactance mechanism. TrainingExcessive demandsPsychological reactanceWorkaroundsBreaches. The intervention failed because requirements exceeded users' capacity for compliance, triggering counterproductive responses. This demonstrates how well-intentioned interventions backfire when they ignore behavioral psychology. Proper security training uses sustainable requirements with positive messaging, avoiding reactance triggers.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0100",
    "case_id": "0100",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Public Health",
    "scenario": "A state launches aggressive anti-vaping ads showing gruesome lung disease images targeting teens. Teen vaping rates increase 18% the following year. Investigation reveals the graphic ads made vaping seem dangerous and rebelliousexactly what appeals to sensation-seeking adolescents. The scare tactics backfired by making vaping more attractive as 'forbidden fruit.' Additionally, the ads inadvertently advertised vaping to teens unfamiliar with it.",
    "claim": "The anti-vaping campaign reduced teen vaping rates.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Anti-vaping campaign",
        "role": "exposure"
      },
      "Y": {
        "name": "Teen vaping rates",
        "role": "outcome"
      },
      "Z": [
        "Reactance to authority",
        "Forbidden fruit appeal",
        "Inadvertent advertising"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "BACKFIRE",
      "subtype": "Reactance",
      "subtype_name": "Scare Tactics Increase Appeal"
    },
    "difficulty": "Easy",
    "causal_structure": "Campaign (X)  Reactance + forbidden fruit effect (Z)  Increased interest  More vaping (Y opposite). Scare tactics triggered opposite response in target population.",
    "key_insight": "Prohibition messaging and scare tactics increased vaping appeal to sensation-seeking teens through reactance.",
    "hidden_timestamp": "Could the intervention trigger reactance effects that increase rather than decrease the target behavior?",
    "conditional_answers": {
      "answer_if_condition_1": "If campaign used positive messaging emphasizing autonomy and health benefits, vaping might decrease.",
      "answer_if_condition_2": "If campaign used scare tactics and prohibitions, reactance would increase vaping appeal to teens."
    },
    "wise_refusal": "This is intervention backfire through reactance. Anti-vaping scare tactics made vaping seem dangerous and rebellioustraits attractive to sensation-seeking adolescents. The 'forbidden fruit' effect and psychological reactance to authority increased vaping interest. The campaign also inadvertently advertised vaping to uninformed teens. This demonstrates how public health interventions can backfire when they ignore developmental psychology and reactance mechanisms.",
    "gold_rationale": "Backfire through adolescent reactance. CampaignProhibition + danger messagingForbidden fruit appealIncreased vaping. Teens respond to authority with oppositional behavior; scare tactics enhance dangerous behaviors' appeal. Effective teen interventions emphasize autonomy and social norms, avoiding prohibition messaging that triggers reactance. This case exemplifies how interventions produce opposite effects when misaligned with target psychology.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0101",
    "case_id": "0101",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Sports",
    "subdomain": "Performance Psychology",
    "scenario": "A study finds elite athletes who maintain rigorous pre-game rituals have 12% better performance than those with flexible routines. Sports psychologists recommend ritual adoption. However, athletes with anxiety disorders develop elaborate rituals as coping mechanisms. The rituals don't cause performanceanxiety causes both rituals and hypervigilance that improves focus. Non-anxious athletes who adopt rituals see no benefit and may experience performance pressure from routine disruption.",
    "claim": "Pre-game rituals cause improved athletic performance.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Pre-game ritual adherence",
        "role": "exposure"
      },
      "Y": {
        "name": "Performance quality",
        "role": "outcome"
      },
      "Z": [
        "Underlying anxiety/arousal",
        "Arousal optimization",
        "Performance pressure from disruption"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "REGRESSION TO MEAN",
      "subtype": "Selection on anxiety",
      "subtype_name": "Anxiety Drives Both Rituals and Focus"
    },
    "difficulty": "Hard",
    "causal_structure": "Anxiety (Z)  Rituals (X) and Anxiety (Z)  Hypervigilance  Performance (Y). Z confounds X-Y. Rituals are symptom not cause; underlying arousal optimization matters.",
    "key_insight": "Rituals are markers of anxiety-driven preparation, not causal factors; anxiety optimization drives performance.",
    "hidden_timestamp": "Were subjects (athletes with rituals) selected based on extreme psychological characteristics that predict outcomes?",
    "conditional_answers": {
      "answer_if_condition_1": "If rituals causally improve performance, non-anxious athletes adopting rituals would show benefits.",
      "answer_if_condition_2": "If anxiety causes both rituals and performance optimization, only anxious athletes benefit from rituals as anxiety management."
    },
    "wise_refusal": "This involves selection and confounding. Athletes with higher anxiety develop elaborate rituals as coping mechanisms. The anxiety itselfwhen optimizeddrives hypervigilance and focus that improve performance. Rituals don't cause performance; they're markers of underlying anxiety management. Non-anxious athletes forced to adopt rituals may perform worse due to disrupted routines. The ritual-performance correlation reflects anxiety optimization, not ritual causation.",
    "gold_rationale": "Anxiety confounding with regression considerations. AnxietyRitual development and AnxietyArousal optimizationPerformance (Yerkes-Dodson). Athletes with rituals are selected on anxiety characteristic. Interventions teaching rituals to non-anxious athletes fail because the underlying mechanism (anxiety optimization) is absent. This demonstrates how correlations can reflect psychological markers rather than causal mechanisms.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0102",
    "case_id": "0102",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "Study Habits",
    "scenario": "Students who pull all-nighters before exams score 8 points lower on average than those who sleep normally. Sleep researchers conclude sleep deprivation harms test performance. However, students who pull all-nighters are those who procrastinated or struggled with material all semester. These students would score lower regardless of pre-exam sleep because they're already behind. High-performing students don't need all-nighters. The all-nighter is a symptom of prior poor preparation, not the cause of low scores.",
    "claim": "All-nighters cause poor exam performance.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "All-nighter before exam",
        "role": "exposure"
      },
      "Y": {
        "name": "Exam score",
        "role": "outcome"
      },
      "Z": [
        "Semester-long preparation",
        "Prior academic struggle",
        "Procrastination tendency"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "REGRESSION TO MEAN",
      "subtype": "Selection on preparation",
      "subtype_name": "Poor Preparation Causes Both All-Nighters and Low Scores"
    },
    "difficulty": "Easy",
    "causal_structure": "Poor preparation (Z)  All-nighter (X) and Poor preparation (Z)  Low exam score (Y). Z confounds X-Y. All-nighters are symptom of underlying preparation deficit.",
    "key_insight": "Students who need all-nighters are already struggling; the all-nighter is a marker of poor preparation, not a cause of poor performance.",
    "hidden_timestamp": "Were students who pulled all-nighters selected based on pre-existing academic difficulties?",
    "conditional_answers": {
      "answer_if_condition_1": "If well-prepared students randomly pulled all-nighters, sleep deprivation might causally harm performance.",
      "answer_if_condition_2": "If only struggling students pull all-nighters due to poor preparation, the all-nighter is a symptom, not cause."
    },
    "wise_refusal": "This is confounding by preparation status. Students pull all-nighters because they're unprepared, not vice versa. Poor semester-long preparation causes both the need for desperate last-minute studying and low exam performance. The all-nighter is a symptom of underlying academic struggle. Well-prepared students don't need all-nighters. Randomized experiments show sleep deprivation harms performance, but observational correlations reflect selectionstruggling students cram.",
    "gold_rationale": "Confounding by preparation. Poor preparationAll-nighter (desperation) and Poor preparationLow scores. Students are selected into all-nighters based on pre-existing struggles. The correlation reflects this selection, not sleep causation. RCTs depriving prepared students of sleep show smaller effects than observational studies, confirming confounding. The causal effect of sleep deprivation is real but smaller than correlations suggest.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0103",
    "case_id": "0103",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Economics",
    "subdomain": "International Development",
    "scenario": "Countries with higher GDP per capita have stronger democratic institutions. Political scientists conclude economic development causes democratization. However, analysis reveals the correlation exists only when comparing countries across continents. Within each continent, the correlation is near zero. The aggregate pattern reflects geographic/historical factors that vary between continents but not the claimed causal relationship.",
    "claim": "Economic development causes democratization.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "GDP per capita (national)",
        "role": "exposure"
      },
      "Y": {
        "name": "Democratic institutions strength",
        "role": "outcome"
      },
      "Z": [
        "Continental differences",
        "Colonial legacy",
        "Geographic factors"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "ECOLOGICAL FALLACY",
      "subtype": "Cross-level inference",
      "subtype_name": "Between-Region vs Within-Region Correlation"
    },
    "difficulty": "Hard",
    "causal_structure": "Continental factors (Z) cause both GDP and democracy at aggregate level. Between-continent correlation  within-continent correlation. Compositional effect, not causal relationship.",
    "key_insight": "Aggregate correlation driven by between-continent differences; within-continent analysis shows no relationship.",
    "hidden_timestamp": "Does the pattern hold within each region when examining countries of similar geography/history?",
    "conditional_answers": {
      "answer_if_condition_1": "If correlation exists both between and within continents, economic development may cause democratization.",
      "answer_if_condition_2": "If correlation exists only between continents but not within, it reflects compositional differences not causation."
    },
    "wise_refusal": "This is ecological fallacy. The GDP-democracy correlation exists at the between-continent level but disappears within continents. Colonial legacies, geographic factors, and historical development paths vary between continents, creating aggregate correlation. Within Europe or within Africa, richer countries aren't more democratic. The correlation is compositionalit reflects continent-level differences, not causal relationships. This demonstrates how aggregate patterns can mislead about individual-level causation.",
    "gold_rationale": "Ecological fallacy from compositional effects. Between-continent correlation (_between=0.68)  within-continent correlation (_within0). Continental factors (colonial legacy, geography) cause both GDP and democracy, creating spurious aggregate correlation. The causal claim requires within-group analysis, which shows null effects. Simpson's paradox in reverseaggregate conceals absence of relationship within strata.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0104",
    "case_id": "0104",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Nutrition",
    "scenario": "US states with higher average wine consumption have lower heart disease mortality rates. Wine industry promotes heart health benefits. However, wine-drinking states have different demographics: higher education, income, and access to healthcare. Within income brackets, wine consumption doesn't predict heart disease. The state-level correlation reflects socioeconomic composition, not wine's causal effects.",
    "claim": "Wine consumption reduces heart disease mortality.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "State-level wine consumption",
        "role": "exposure"
      },
      "Y": {
        "name": "State heart disease mortality",
        "role": "outcome"
      },
      "Z": [
        "State socioeconomic composition",
        "Healthcare access",
        "Education levels"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "ECOLOGICAL FALLACY",
      "subtype": "Cross-level inference",
      "subtype_name": "State-Level vs Individual-Level Association"
    },
    "difficulty": "Easy",
    "causal_structure": "State SES composition (Z)  Wine consumption (X) and State SES (Z)  Healthcare/outcomes (Y). Ecological correlation from compositional effects, not individual causation.",
    "key_insight": "State-level correlation reflects composition (wealthy states drink wine and have better healthcare); individual-level effect absent.",
    "hidden_timestamp": "Does the wine-heart disease pattern hold within income/education groups at individual level?",
    "conditional_answers": {
      "answer_if_condition_1": "If wine reduces heart disease at individual level controlling for SES, state correlation reflects causation.",
      "answer_if_condition_2": "If within-SES groups show no wine effect, state correlation is compositional artifact."
    },
    "wise_refusal": "This is ecological fallacy. Wine-drinking states are wealthier with better healthcare access. The state-level correlation reflects socioeconomic compositionwealthy states both drink wine and have lower heart disease from healthcare quality. Within income brackets, wine consumption doesn't predict outcomes. The aggregate pattern is compositional, not causal. Individual-level analyses show minimal wine effects after controlling for SES.",
    "gold_rationale": "Ecological fallacy from aggregation. State SESWine culture and State SESHealthcareOutcomes. The between-state correlation (_between=-0.52) reflects compositional differences. Within-state or individual analysis (_within0) shows no effect. This demonstrates Robinson's paradoxecological correlations differ from individual correlations. Proper causal inference requires individual-level data controlling for confounders.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0105",
    "case_id": "0105",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Hospital Quality",
    "scenario": "A hospital study examines surgical outcomes. Patients treated by high-volume surgeons have 22% higher complication rates than low-volume surgeons. Administrators worry experience harms outcomes. However, high-volume surgeons operate at major referral hospitals that receive the most complex, high-risk cases. Low-volume surgeons at community hospitals handle routine cases. When comparing similar case complexity, high-volume surgeons have better outcomes.",
    "claim": "High surgical volume causes worse patient outcomes.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Surgeon volume",
        "role": "exposure"
      },
      "Y": {
        "name": "Complication rates",
        "role": "outcome"
      },
      "Z": [
        "Case complexity",
        "Patient risk factors",
        "Referral patterns"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "SIMPSON'S PARADOX",
      "subtype": "Confounded pooling",
      "subtype_name": "Case Complexity Reverses Aggregate Association"
    },
    "difficulty": "Hard",
    "causal_structure": "Hospital type (Z)  Surgeon volume (X) and Hospital type (Z)  Case complexity  Complications (Y). Pooling across complexity strata reverses true relationship.",
    "key_insight": "Aggregate association reverses when stratifying by case complexity; high-volume surgeons handle harder cases.",
    "hidden_timestamp": "What happens when we stratify complication rates by case complexity?",
    "conditional_answers": {
      "answer_if_condition_1": "If we examine aggregate data without stratifying by complexity, high-volume surgeons appear worse.",
      "answer_if_condition_2": "If we stratify by case complexity (control for Z), high-volume surgeons have better outcomes in every stratum."
    },
    "wise_refusal": "This is Simpson's Paradox. High-volume surgeons work at tertiary care centers handling the most complex cases. When comparing surgeons treating similar case complexity, high-volume surgeons consistently outperform low-volume surgeons. The aggregate association reverses because case mix differshigh-volume surgeons get difficult cases, low-volume get routine cases. Hospital type (Z) confounds the volume-outcome relationship through case selection. Proper analysis requires stratifying by complexity.",
    "gold_rationale": "Simpson's Paradox from case-mix confounding. Hospital typeVolume and Hospital typeCase complexityOutcomes. Aggregate: high volume appears worse. Within each complexity stratum: high volume is better. The paradox arises from different base rateshigh-volume surgeons operate on higher-risk populations. Controlling for case complexity (backdoor path) reveals true causal effect: volume improves outcomes through experience.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0106",
    "case_id": "0106",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Human Resources",
    "scenario": "A tech company finds that employees who receive negative performance reviews have 15% higher innovation output over the next year than employees receiving positive reviews. HR concludes negative feedback sparks creativity. However, the company gives negative reviews primarily to researchers in experimental R&D units where failure is common but breakthroughs happen, while positive reviews go to engineers in mature product divisions with stable outputs.",
    "claim": "Negative performance reviews cause increased innovation.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Negative performance review",
        "role": "exposure"
      },
      "Y": {
        "name": "Innovation output",
        "role": "outcome"
      },
      "Z": [
        "Division type",
        "R&D vs product work",
        "Innovation opportunity"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "SIMPSON'S PARADOX",
      "subtype": "Confounded pooling",
      "subtype_name": "Division Type Creates Paradox"
    },
    "difficulty": "Medium",
    "causal_structure": "Division type (Z)  Review standards (X) and Division type (Z)  Innovation opportunities (Y). R&D gets negative reviews despite high innovation; product gets positive reviews with low innovation.",
    "key_insight": "Aggregate reverses within-division pattern; negative reviews don't cause innovationR&D roles have both.",
    "hidden_timestamp": "What happens when we examine innovation within each division type?",
    "conditional_answers": {
      "answer_if_condition_1": "Examining aggregate data, negative reviews correlate with higher innovation.",
      "answer_if_condition_2": "Within each division, employees with positive reviews actually have higher innovation; negative reviews correlate with lower innovation."
    },
    "wise_refusal": "This is Simpson's Paradox from division-level confounding. R&D divisions have high innovation (experimental work) but give negative reviews (due to failures). Product divisions have low innovation (maintenance work) but give positive reviews (stable delivery). Aggregate: negative reviews appear to cause innovation. Within each division: positive reviews predict better innovation. The paradox arises because innovation opportunity varies by division type, which also determines review standards.",
    "gold_rationale": "Simpson's Paradox. Division typeReview harshness and Division typeInnovation opportunity. R&D: high innovation + harsh reviews. Product: low innovation + lenient reviews. Aggregate correlation positive; within-stratum correlation negative. The paradox comes from different base rates across divisions. Proper analysis requires controlling for division type to identify true effect of reviews on innovation.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0107",
    "case_id": "0107",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Radiology",
    "scenario": "Radiologists at a specialty cancer center read 40% more scans as 'abnormal requiring follow-up' than radiologists at community hospitals. Quality auditors worry the specialists are over-diagnosing. However, the cancer center receives pre-screened referrals of high-risk patients, while community hospitals see general populations. When examining patients of similar risk profiles, cancer center radiologists have more accurate abnormal detection rates.",
    "claim": "Specialist radiologists over-diagnose abnormalities due to bias or incentives.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Radiologist setting (specialist vs community)",
        "role": "exposure"
      },
      "Y": {
        "name": "Abnormal findings rate",
        "role": "outcome"
      },
      "Z": [
        "Patient risk profile",
        "Referral patterns",
        "Pre-test probability"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "MEASUREMENT BIAS",
      "subtype": "Differential misclassification",
      "subtype_name": "Patient Population Differences Create Apparent Over-diagnosis"
    },
    "difficulty": "Hard",
    "causal_structure": "Hospital type determines patient selection (Z). ZDifferent base ratesDifferent positive rates. Higher abnormal rate reflects higher-risk population, not measurement bias.",
    "key_insight": "Apparent over-diagnosis is actually appropriate detection in higher-risk population; measurement accuracy differs by population.",
    "hidden_timestamp": "Does measurement accuracy differ between groups due to different patient populations being assessed?",
    "conditional_answers": {
      "answer_if_condition_1": "If both facilities see similar patient populations, the 40% difference suggests specialist over-diagnosis.",
      "answer_if_condition_2": "If specialists see pre-selected high-risk referrals, higher abnormal rates reflect population differences not measurement bias."
    },
    "wise_refusal": "This is differential measurement interpretation complicated by population differences. Cancer centers receive pre-screened high-risk referrals with elevated pre-test probability. Higher abnormal rates reflect this population selection, not radiologist bias. When comparing patients with similar risk profiles across settings, specialists show more accurate detection, not over-diagnosis. The apparent measurement difference arises from comparing different populations, not from systematic measurement error.",
    "gold_rationale": "Measurement differences from population heterogeneity. Hospital typePatient selection (Z)True abnormality prevalence. Specialists see higher-risk patients, generating appropriately higher detection rates. This isn't measurement biasit's accurate measurement of different populations. Within risk strata, specialists have superior accuracy. The comparison error is conflating measurement differences with population differences. Proper evaluation requires risk-adjusted rates.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0108",
    "case_id": "0108",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Criminal Justice",
    "subdomain": "Forensics",
    "scenario": "A study compares crime labs. Lab A identifies DNA matches in 65% of cases; Lab B in 45%. Quality control worries Lab A has false positive problems. However, Lab A handles cases from wealthy jurisdictions with better crime scene protocols and sample collection, yielding higher-quality DNA. Lab B handles cases from underfunded areas with degraded samples. When comparing similar sample quality, both labs have identical accuracy.",
    "claim": "Lab A has inflated match rates due to bias or technical problems.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Crime lab (Lab A vs Lab B)",
        "role": "exposure"
      },
      "Y": {
        "name": "DNA match identification rate",
        "role": "outcome"
      },
      "Z": [
        "Sample quality",
        "Crime scene protocols",
        "Jurisdiction resources"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "MEASUREMENT BIAS",
      "subtype": "Differential misclassification",
      "subtype_name": "Sample Quality Differences Appear as Lab Differences"
    },
    "difficulty": "Easy",
    "causal_structure": "Jurisdiction resources (Z)  Sample quality  Match rates (Y) and Z  Lab assignment (X). Lab differences reflect input quality, not measurement accuracy.",
    "key_insight": "Higher match rates reflect better input samples from wealthy jurisdictions, not lab bias or technical issues.",
    "hidden_timestamp": "Does measurement accuracy differ between labs due to different sample quality?",
    "conditional_answers": {
      "answer_if_condition_1": "If both labs process similar sample quality, rate differences suggest Lab A measurement problems.",
      "answer_if_condition_2": "If Lab A receives higher-quality samples from better-funded jurisdictions, rate differences reflect input quality not measurement bias."
    },
    "wise_refusal": "This is apparent measurement bias that actually reflects input quality differences. Lab A serves wealthy jurisdictions with superior crime scene protocols, yielding high-quality DNA samples that enable matches. Lab B serves underfunded areas with degraded samples. Higher match rates reflect sample quality differences, not lab accuracy problems. When comparing equivalent sample quality, both labs perform identically. The apparent lab difference is input heterogeneity, not measurement error.",
    "gold_rationale": "Measurement differences from input quality. Jurisdiction fundingSample quality (Z)Match rates and FundingLab assignment. Lab A's higher rates reflect better inputs, not technical bias. This demonstrates how measurement comparisons can be confounded by input characteristics. Within sample quality strata, labs are equivalent. Proper quality control requires adjusting for input characteristics before comparing lab performance.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0109",
    "case_id": "0109",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Legal",
    "subdomain": "Personal Injury",
    "scenario": "Plaintiffs in medical malpractice lawsuits recall doctor visits in extraordinary detailspecific dates, statements, and interactions from 2-3 years prior. Defense attorneys cite these 'too perfect' memories as evidence of coaching or fabrication. However, trauma and high-stakes outcomes enhance memory consolidation for emotionally salient events. Injured plaintiffs genuinely remember medical encounters better than healthy controls recall routine doctor visits.",
    "claim": "Plaintiffs' detailed recall proves their testimony is fabricated or coached.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Detailed medical encounter recall",
        "role": "exposure"
      },
      "Y": {
        "name": "Testimony authenticity",
        "role": "outcome"
      },
      "Z": [
        "Emotional salience",
        "Trauma-enhanced memory",
        "Outcome significance"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "RECALL BIAS",
      "subtype": "Rumination bias",
      "subtype_name": "Trauma Enhances Memory for Salient Events"
    },
    "difficulty": "Hard",
    "causal_structure": "Injury outcome (Y)  Emotional salience  Enhanced memory (X*). High-stakes outcomes create vivid memories through normal psychological mechanisms, not fabrication.",
    "key_insight": "Detailed recall results from trauma-enhanced memory consolidation for emotionally significant events, not fabrication.",
    "hidden_timestamp": "Do plaintiffs recall encounters better due to emotional significance of injury outcomes?",
    "conditional_answers": {
      "answer_if_condition_1": "If detailed recall results from coaching or fabrication, plaintiffs' memories would contain inconsistencies or impossibilities.",
      "answer_if_condition_2": "If injury outcome enhanced memory consolidation for salient medical encounters, detailed accurate recall is expected."
    },
    "wise_refusal": "This is enhanced recall from outcome salience, not fabrication. Traumatic medical outcomes create highly salient memories that are better consolidated and retrieved. This is normal memory psychologyemotionally significant events are remembered better than routine encounters. Plaintiffs genuinely recall details because the medical interaction became emotionally loaded after injury occurred. The 'too perfect' memory is actually explained by trauma psychology, not coaching or dishonesty.",
    "gold_rationale": "Outcome-enhanced memory, not recall bias. InjuryEmotional salienceEnhanced consolidationBetter recall. This is normal psychological phenomenon (flashbulb memory for significant events). Plaintiffs don't fabricatethey genuinely remember better because medical encounter became traumatic turning point. Defense argument misunderstands memory psychology: detailed recall of important events is expected, not evidence of fabrication. Research shows trauma enhances memory for central details of significant events.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0110",
    "case_id": "0110",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Patient Safety",
    "scenario": "A hospital compares medication error reporting between day and night shifts. Night shift nurses report 3x more near-miss errors. Administrators worry night shift is less safe. However, night shift is quieter with fewer interruptions, allowing nurses time to thoroughly document incidents. Day shift nurses experience identical near-misses but lack time to report them. When auditors directly observe both shifts, error rates are identicalonly reporting differs.",
    "claim": "Night shift has higher medication error rates due to fatigue or understaffing.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Night shift work",
        "role": "exposure"
      },
      "Y": {
        "name": "Reported medication errors",
        "role": "outcome"
      },
      "Z": [
        "Time available for documentation",
        "Interruption frequency",
        "Reporting opportunity"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "RECALL BIAS",
      "subtype": "Differential reporting",
      "subtype_name": "Documentation Time Differs by Shift"
    },
    "difficulty": "Easy",
    "causal_structure": "Shift type (X)  Workload intensity  Documentation time (Z)  Reporting (Y*). Actual error rates equal; reporting differs due to time availability.",
    "key_insight": "Reported errors differ due to documentation time, not actual error rates; measurement opportunity varies by shift.",
    "hidden_timestamp": "Do nurses on different shifts have different opportunities to document errors?",
    "conditional_answers": {
      "answer_if_condition_1": "If both shifts have equal documentation time and support, reporting differences reflect true error rate differences.",
      "answer_if_condition_2": "If night shift has more time for thorough documentation while day shift is too busy to report, apparent differences reflect reporting bias."
    },
    "wise_refusal": "This is differential reporting, not differential error rates. Night shift nurses work in calmer environment with time to thoroughly document near-misses. Day shift nurses experience the same events but lack time to report due to patient volume and interruptions. Direct observation reveals identical actual error ratesonly reporting differs. This demonstrates how measured outcomes (reports) can differ from true outcomes (errors) due to measurement opportunity differences.",
    "gold_rationale": "Measurement opportunity bias. Shift typeWorkloadDocumentation timeReporting. True error rates equal across shifts; reported rates differ because night shift has capacity to document. This is detection bias variant where measurement itself varies systematically. The hospital's apparent safety problem is actually measurement artifact. Proper safety assessment requires direct observation or standardized reporting protocols that equalize documentation opportunity.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0111",
    "case_id": "0111",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "Student Assessment",
    "scenario": "A school district mandates weekly reading fluency tests to improve literacy. Teachers must report student reading rates every Friday. After one year, 72% of students show reading improvements on these tests. The district declares success. However, teachers, under pressure to show progress, increasingly teach students to rapidly read the specific test passages without comprehension. Students improve test performance but not actual reading ability.",
    "claim": "Weekly fluency testing caused improved reading skills.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Weekly fluency testing mandate",
        "role": "exposure"
      },
      "Y": {
        "name": "Reading ability",
        "role": "outcome"
      },
      "Z": [
        "Teaching to the test",
        "Accountability pressure",
        "Test-specific coaching"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "MECHANISM MISMATCH",
      "subtype": "Wrong target",
      "subtype_name": "Test Performance vs True Reading Ability"
    },
    "difficulty": "Hard",
    "causal_structure": "Testing mandate (X)  Teaching pressure  Test-specific coaching (M1) rather than comprehensive literacy (M2). Intervention improves measured outcome but not true outcome.",
    "key_insight": "Intervention improved test performance through coaching, not actual reading comprehension; wrong mechanism activated.",
    "hidden_timestamp": "Did the intervention target the actual mechanism (comprehensive reading skill) or a narrow proxy (test performance)?",
    "conditional_answers": {
      "answer_if_condition_1": "If testing prompted broad literacy instruction improving comprehension, test gains reflect real skill improvement.",
      "answer_if_condition_2": "If testing prompted narrow coaching on test passages without comprehension focus, test gains don't reflect real reading ability."
    },
    "wise_refusal": "This is mechanism mismatch. The testing intervention aimed to improve reading ability (M2) but actually prompted teaching-to-test (M1). Teachers, under accountability pressure, coached students on rapid reading of test passages rather than developing comprehension skills. The intervention succeeded on the measured outcome (test scores) but failed on the target outcome (reading ability). Independent comprehension assessments show no improvement despite test score gains.",
    "gold_rationale": "Mechanism failure through pathway mismatch. XAccountability pressureTeaching to test (M1) rather than XSkill development (M2)Reading ability. The intervention activated wrong mechanism. Campbell's Law: when measurement becomes target, it ceases to measure. The test scores improved while true reading ability stagnated. Proper evaluation requires measuring outcomes beyond the incentivized metric to detect mechanism mismatch.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0112",
    "case_id": "0112",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Mental Health",
    "scenario": "A clinic implements cognitive-behavioral therapy for social anxiety. After 12 weeks, patients report 40% reduction in social anxiety symptoms on self-report scales. However, behavioral observations show no change in actual social interactionspatients avoid social situations identically. The CBT successfully taught patients what 'healthy' responses look like on questionnaires without changing underlying anxiety or behavior.",
    "claim": "CBT treatment reduced social anxiety.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "CBT treatment",
        "role": "exposure"
      },
      "Y": {
        "name": "Social anxiety level",
        "role": "outcome"
      },
      "Z": [
        "Self-report response patterns",
        "Social desirability",
        "Behavior vs reported symptoms"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "MECHANISM MISMATCH",
      "subtype": "Wrong target",
      "subtype_name": "Changed Reports Without Behavior Change"
    },
    "difficulty": "Easy",
    "causal_structure": "CBT (X)  Questionnaire response training (M1) not anxiety reduction (M2). Intervention changed measured outcome (reports) without affecting true outcome (behavior).",
    "key_insight": "Treatment taught patients to report 'correctly' on scales without reducing actual anxiety or avoidance behavior.",
    "hidden_timestamp": "Did the intervention target actual anxiety reduction mechanism or just changed questionnaire responses?",
    "conditional_answers": {
      "answer_if_condition_1": "If CBT reduced anxiety through exposure and cognitive restructuring, both reports and behaviors would improve.",
      "answer_if_condition_2": "If CBT taught questionnaire responses without anxiety work, reports improve but behaviors don't change."
    },
    "wise_refusal": "This is mechanism mismatch. CBT inadvertently taught patients what 'healthy' questionnaire responses look like rather than reducing anxiety. Self-reports improved (M1 succeeded) but behavioral avoidance remained unchanged (M2 failed). The intervention worked on measured outcome (scales) but not on true outcome (anxiety/behavior). Independent behavioral observation reveals no treatment effect despite impressive self-report improvements. This demonstrates measurement-treatment interaction.",
    "gold_rationale": "Mechanism failure: XResponse pattern learning (M1) not XAnxiety reduction (M2). Treatment changed how patients report symptoms without changing symptoms themselves. This is common in therapy researchtreatments can teach appropriate reporting without producing psychological change. Proper evaluation requires behavioral outcomes resistant to response bias, not just self-reports that can be coached.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0113",
    "case_id": "0113",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Emergency Medicine",
    "scenario": "Among hospitalized patients, those with obesity have 25% lower mortality rates than normal-weight patients. Clinicians are surprised by this 'obesity paradox.' However, hospitalized patients represent a selected samplethey're sick enough to require admission. Obese patients are admitted at lower illness severity thresholds. Normal-weight patients need to be sicker to be admitted. When comparing patients at equal illness severity, the obesity mortality advantage disappears.",
    "claim": "Obesity protects against mortality in hospitalized patients.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Obesity status",
        "role": "exposure"
      },
      "Y": {
        "name": "Hospital mortality",
        "role": "outcome"
      },
      "Z": [
        "Illness severity at admission",
        "Admission thresholds",
        "Collider bias on hospitalization"
      ]
    },
    "trap": {
      "type": "T3",
      "type_name": "COLLIDER",
      "subtype": "Berkson's paradox",
      "subtype_name": "Hospital Admission as Collider"
    },
    "difficulty": "Hard",
    "causal_structure": "Obesity  Admission (lower threshold)  Illness severity. Conditioning on hospitalization creates spurious negative association between obesity and mortality.",
    "key_insight": "Obese patients admitted at lower severity; selection on hospitalization creates spurious protective effect.",
    "hidden_timestamp": "Are we conditioning on hospitalization, which is caused by both obesity status and illness severity?",
    "conditional_answers": {
      "answer_if_condition_1": "If we examine general population mortality without conditioning on hospitalization, obesity increases mortality.",
      "answer_if_condition_2": "If we condition on hospitalization (collider), obesity appears protective due to selection bias."
    },
    "wise_refusal": "This is collider bias. Hospitalization depends on both obesity (lower admission threshold) and illness severity. Among hospitalized patients, obese individuals are admitted at lower severity while normal-weight patients need higher severity for admission. This selection creates spurious negative obesity-mortality association. In the general population without conditioning on hospitalization, obesity increases mortality. The 'paradox' is a statistical artifact from collider stratification.",
    "gold_rationale": "Berkson's paradox from conditioning on hospitalization. ObesityAdmission threshold and SeverityAdmission. Among hospitalized (collider), obese patients are less severely ill on average. The apparent protective effect reflects selection, not physiology. Population studies show obesity increases mortality; hospital studies show reverse due to collider bias. This demonstrates how conditioning on intermediate outcomes creates misleading associations.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0114",
    "case_id": "0114",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Psychology",
    "subdomain": "Organizational",
    "scenario": "Employees who attend optional leadership workshops show 30% higher promotion rates over 3 years. HR expands workshop offerings to boost advancement. However, employees who attend workshops are those already positioning for advancementambitious, politically savvy, with supportive managers. These characteristics predict promotions regardless of workshops. Mandatory workshop assignment shows no promotion effect, revealing self-selection drives the correlation.",
    "claim": "Leadership workshops cause higher promotion rates.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Workshop attendance",
        "role": "exposure"
      },
      "Y": {
        "name": "Promotion rate",
        "role": "outcome"
      },
      "Z": [
        "Career ambition",
        "Political savvy",
        "Manager support"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "Selection marker",
      "subtype_name": "Workshops Proxy for Ambition"
    },
    "difficulty": "Hard",
    "causal_structure": "Ambition/political capital (Z)  Workshop attendance (X) and Z  Promotions (Y). X is selection marker for Z, not causal factor. When X becomes mandatory target, Z-X link breaks.",
    "key_insight": "Workshops were markers of ambition, not causes of promotion; making them mandatory broke the correlation.",
    "hidden_timestamp": "Is the metric (workshop attendance) being selected by those who would succeed anyway?",
    "conditional_answers": {
      "answer_if_condition_1": "If workshops causally improve promotion chances, mandatory assignment should show similar benefits.",
      "answer_if_condition_2": "If workshops are selection markers for already-ambitious employees, mandatory assignment shows no effect."
    },
    "wise_refusal": "This involves selection and Goodhart's Law dynamics. Workshop attendance was a marker for employees already positioned for promotion (ambitious, politically connected, supported by managers). These characteristicsnot workshopsdrive promotions. When workshops became mandatory targets, the selection mechanism broke: attendance no longer signaled ambition. This demonstrates how metrics that work as selection signals fail as intervention targets. The correlation existed because of who chose to attend, not because attendance caused advancement.",
    "gold_rationale": "Goodhart's Law with selection. Before: AmbitionWorkshop attendance and AmbitionPromotion (correlation via Z). After mandatory: Workshop no longer signals ambition, correlation disappears. Workshops were proxies for Z, not causal factors. Making attendance mandatory broke the Z-X correlation, revealing no causal effect. This shows how observational correlations from self-selection don't translate to treatment effects. Proper evaluation requires randomization to break selection.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0115",
    "case_id": "0115",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Finance",
    "subdomain": "Investment",
    "scenario": "Mutual funds with Morningstar 5-star ratings show 20% higher subsequent returns than 2-star funds, suggesting star ratings predict performance. However, funds that recently outperformed receive 5 stars, attracting investor capital that fund managers must deploy. Large sudden inflows make outperformance harder. When ratings become widely used investment criteria, the rating-return correlation vanishes as capital floods top-rated funds, eliminating their ability to maintain performance.",
    "claim": "5-star Morningstar ratings cause superior investment returns.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "5-star rating",
        "role": "exposure"
      },
      "Y": {
        "name": "Future returns",
        "role": "outcome"
      },
      "Z": [
        "Capital inflows",
        "Assets under management growth",
        "Investment constraints"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Rating Metric Breaks When Targeted"
    },
    "difficulty": "Easy",
    "causal_structure": "Before: Past performanceRating and Past performanceFuture returns (correlation). After ratings targeted: RatingCapital inflowsPerformance degradation. Metric loses predictive value.",
    "key_insight": "Ratings predicted returns when ignored; once widely used, capital inflows to top-rated funds eliminated their performance edge.",
    "hidden_timestamp": "Is the metric being targeted by investors, breaking its predictive relationship?",
    "conditional_answers": {
      "answer_if_condition_1": "If ratings remain obscure signals, the correlation between ratings and returns persists.",
      "answer_if_condition_2": "If ratings become widely-targeted investment criteria, capital flows destroy the correlation."
    },
    "wise_refusal": "This is Goodhart's Law. Star ratings originally correlated with returns because they identified funds with past success. When ratings became widely used investment criteria, capital flooded 5-star funds. Large asset bases constrain investment flexibility, eliminating performance advantages. The rating-return relationship existed when ratings were informational but disappeared when they became targets for capital allocation. The measure's predictive value eroded when it became the decision criterion.",
    "gold_rationale": "Goodhart's Law in finance. Initially: Past performanceRating and Past performanceFuture returns (momentum). When ratings targeted: RatingInflowsAUM constraintsPerformance degradation. The metric broke when it became the optimization target. This demonstrates reflexivityusing a measure for decisions changes the measure's relationship to outcomes. Effective measures require remaining somewhat obscure to avoid self-negating feedback.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0116",
    "case_id": "0116",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Entrepreneurship",
    "scenario": "Successful entrepreneurs often credit their daily 5am wake-ups and intense morning routines as keys to success. Business books promote early rising as a success factor. However, people who naturally succeed in entrepreneurship adopt intense routines as expressions of their underlying traits. When randomly assigned, early wake times don't improve outcomes and may harm performance for most people. The routine is a symptom of success-prone personality, not a cause.",
    "claim": "Early morning routines cause entrepreneurial success.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "5am wake routine",
        "role": "exposure"
      },
      "Y": {
        "name": "Entrepreneurial success",
        "role": "outcome"
      },
      "Z": [
        "High-energy temperament",
        "Obsessive drive",
        "Risk tolerance"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "FEEDBACK",
      "subtype": "Self-fulfilling prophecy",
      "subtype_name": "Success-Prone Traits Enable Routines"
    },
    "difficulty": "Medium",
    "causal_structure": "Success-prone personality (Z)  Extreme routines (X) and Z  Success (Y). X is marker not cause. Feedback may exist (routinediscipline) but doesn't create success without Z.",
    "key_insight": "Intense routines are symptoms of success-prone personality traits, not causes of success; correlation reflects selection.",
    "hidden_timestamp": "Is there a reinforcing loop, or do underlying traits drive both routines and success?",
    "conditional_answers": {
      "answer_if_condition_1": "If routines causally drive success, randomly assigned early rising would improve outcomes.",
      "answer_if_condition_2": "If success-prone traits enable both routines and success, forced routines without underlying traits don't help."
    },
    "wise_refusal": "This is confounding by personality traits, not true feedback. High-energy, obsessive individuals naturally adopt extreme routines (X) and independently succeed (Y). The routines are symptoms of underlying success-prone traits (Z), not causes. When average people adopt these routines without the underlying drive, they don't achieve similar success and may burn out. The correlation exists because of who naturally adopts extreme routines, not because routines cause success.",
    "gold_rationale": "Confounding by temperament. Success-prone traitsExtreme routines and Success-prone traitsSuccess. X correlates with Y through Z, not causally. Randomized assignment of routines fails because Z is missing. This demonstrates how successful people's habits may be consequences rather than causes of their success. Survivor bias in business advicewe hear from those whom extreme habits worked for, not from those they harmed.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0117",
    "case_id": "0117",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Social Media",
    "scenario": "Social media platforms with more active moderation show higher user-reported harassment rates than platforms with minimal moderation. Free speech advocates claim moderation increases harassment. However, platforms with active moderation encourage users to report harassment, while platforms without moderation discourage reporting. Actual harassment rates may be identical; only reporting differs based on whether reports lead to action.",
    "claim": "Content moderation causes increased harassment.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Moderation intensity",
        "role": "exposure"
      },
      "Y": {
        "name": "Reported harassment incidents",
        "role": "outcome"
      },
      "Z": [
        "Reporting incentive",
        "Response efficacy",
        "Actual vs reported harassment"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "FEEDBACK",
      "subtype": "Self-fulfilling prophecy",
      "subtype_name": "Moderation Incentivizes Reporting"
    },
    "difficulty": "Easy",
    "causal_structure": "Moderation (X)  Reporting efficacy  Reports (Y*) not actual harassment (Y). Feedback exists: moderationreportingdetectionmore moderation. Measured outcome differs from true outcome.",
    "key_insight": "Moderation doesn't cause harassment; it incentivizes reporting, making harassment visible rather than hidden.",
    "hidden_timestamp": "Is there a reinforcing loop where moderation affects reporting behavior, not actual harassment?",
    "conditional_answers": {
      "answer_if_condition_1": "If moderation causes harassment, platforms without moderation would have less actual harassment.",
      "answer_if_condition_2": "If moderation incentivizes reporting without increasing harassment, reported rates rise while actual rates remain constant or fall."
    },
    "wise_refusal": "This involves measurement feedback. Moderation doesn't cause harassmentit incentivizes reporting by demonstrating reports lead to action. Platforms without moderation have similar or higher actual harassment but lower reported harassment because users learn reporting is futile. The feedback loop: moderationreporting increasedetection increasemore moderation resources. This makes harassment visible rather than creating it. The measured outcome (reports) differs from true outcome (actual incidents).",
    "gold_rationale": "Measurement feedback, not harm causation. ModerationReporting incentiveReports (Y* measured) while actual harassment (Y) stays same or decreases. Users respond to enforcement by reporting. Platforms without moderation have hidden harassmentlow reports don't mean low incidents. This demonstrates detection biasbetter surveillance increases measured rates without increasing true rates. Proper evaluation requires direct harassment measurement, not report counts.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0118",
    "case_id": "0118",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Vaccination",
    "scenario": "During a measles outbreak, a case-control study interviews parents. Parents of measles cases are more likely to recall their children had brief encounters with sick people at public places 10-14 days before illness. Parents of healthy controls recall fewer such exposures. Investigators identify public venues as high-risk exposure sites. However, these brief encounters are common; cases ruminate about possible exposure sources while controls don't recall routine outings.",
    "claim": "Brief public encounters at parks and stores cause measles transmission.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Brief public encounters (recalled)",
        "role": "exposure"
      },
      "Y": {
        "name": "Measles infection (case status)",
        "role": "outcome"
      },
      "Z": [
        "Case parents' search for causes",
        "Differential recall motivation",
        "Rumination"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "RECALL BIAS",
      "subtype": "Effort after meaning",
      "subtype_name": "Cases Search for Exposure Sources"
    },
    "difficulty": "Easy",
    "causal_structure": "Measles case (Y)  Parental rumination  Enhanced recall of routine encounters (X*). Outcome influences exposure reporting through search for meaning.",
    "key_insight": "Case parents recall routine exposures better because they're searching for causes; differential recall creates spurious association.",
    "hidden_timestamp": "Do case parents recall public exposures more thoroughly than control parents?",
    "conditional_answers": {
      "answer_if_condition_1": "If case and control parents recall public encounters equally, the association suggests true exposure differences.",
      "answer_if_condition_2": "If case parents scrutinize and recall encounters more thoroughly while searching for causes, differential recall creates spurious association."
    },
    "wise_refusal": "This is recall bias through effort after meaning. Parents whose children developed measles actively search memory for possible exposure sources, recalling routine public outings. Control parents haven't ruminated about exposures and recall such common events vaguely. Brief public encounters are ubiquitous; cases and controls likely had similar actual exposures, but cases recall them better. The apparent exposure-disease association reflects differential recall, not true transmission patterns.",
    "gold_rationale": "Recall bias in case-control study. MeaslesParental search for meaningEnhanced exposure recall. Brief public encounters are so common that everyone has them, but case parents recall specifically while control parents don't. The outcome (case status) influences reported exposure through motivated memory search. Proper exposure assessment requires prospective documentation before disease status known, avoiding recall bias from outcome-driven memory reconstruction.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0119",
    "case_id": "0119",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Oncology",
    "scenario": "A study examines cancer patients who received experimental immunotherapy. Patients are classified as 'treated' starting from their first infusion date. However, patients must survive initial chemotherapy and show adequate organ function to qualify for immunotherapy. Those who died during chemotherapy or had organ failure never became 'treated' but are in the comparison group. The treatment group has guaranteed survival through the qualification period that controls lack.",
    "claim": "Immunotherapy improves survival compared to standard chemotherapy alone.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Immunotherapy treatment",
        "role": "exposure"
      },
      "Y": {
        "name": "Overall survival",
        "role": "outcome"
      },
      "Z": [
        "Survival through qualification period",
        "Organ function requirements",
        "Immortal time bias"
      ]
    },
    "trap": {
      "type": "T4",
      "type_name": "IMMORTAL TIME",
      "subtype": "Time-to-treatment bias",
      "subtype_name": "Treatment Requires Qualification Survival"
    },
    "difficulty": "Hard",
    "causal_structure": "Treatment patients must survive qualification period (immortal time). Control group includes deaths during this period. Guaranteed survival creates spurious treatment benefit.",
    "key_insight": "Treatment group required surviving to qualification; comparison includes those who died before treatment possible.",
    "hidden_timestamp": "Did treatment patients have a guaranteed survival period before exposure that control patients lacked?",
    "conditional_answers": {
      "answer_if_condition_1": "If both groups measured from same time point with equal survival requirements, comparison is valid.",
      "answer_if_condition_2": "If treatment group required surviving qualification period while controls include early deaths, immortal time creates bias."
    },
    "wise_refusal": "This is immortal time bias. Immunotherapy patients must survive chemotherapy and maintain organ function to qualify for treatment. This creates guaranteed survival from treatment start to immunotherapy initiation. Controls include patients who died during this qualification period. The apparent survival benefit reflects selection on survival, not treatment efficacy. Proper analysis requires time-zero alignment or landmark methods.",
    "gold_rationale": "Immortal time from treatment start to immunotherapy qualification. TreatmentSurvival required for qualification. ControlIncludes pre-qualification deaths. The guaranteed survival period creates spurious advantage. Proper analysis: intention-to-treat from randomization or landmark analysis matching qualification timing.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0120",
    "case_id": "0120",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Medicine",
    "subdomain": "Transplant Surgery",
    "scenario": "Patients who receive kidney transplants show better 5-year survival than dialysis patients. However, transplant candidates must be healthy enough to survive major surgery. Sicker dialysis patients are denied transplant listing. When comparing patients of similar health status at transplant evaluation time, the survival advantage disappears. The comparison confounds patient selection with treatment effect.",
    "claim": "Kidney transplantation causes better survival than dialysis.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Kidney transplant",
        "role": "exposure"
      },
      "Y": {
        "name": "5-year survival",
        "role": "outcome"
      },
      "Z": [
        "Baseline health status",
        "Surgical candidacy",
        "Immortal time during waiting"
      ]
    },
    "trap": {
      "type": "T4",
      "type_name": "IMMORTAL TIME",
      "subtype": "Time-to-treatment bias",
      "subtype_name": "Transplant Selection and Waiting Time"
    },
    "difficulty": "Medium",
    "causal_structure": "Transplant patients selected for better health and must survive waiting period. Dialysis group includes sicker patients who died before or during waiting. Selection and immortal time confound comparison.",
    "key_insight": "Transplant candidates are healthier and have survival guarantee during waiting; comparison group includes deaths during this period.",
    "hidden_timestamp": "Do transplant patients have guaranteed survival during waiting period while dialysis patients include those who died waiting?",
    "conditional_answers": {
      "answer_if_condition_1": "If comparing patients of similar health at evaluation time accounting for waiting, comparison is fair.",
      "answer_if_condition_2": "If transplant patients healthier and survived waiting while dialysis includes early deaths, multiple biases confound comparison."
    },
    "wise_refusal": "This combines immortal time bias and selection. Transplant recipients must be healthy enough for surgery and survive the waiting period. Dialysis patients include sicker individuals denied transplant and those who died during waiting. The apparent survival advantage reflects both health-based selection and guaranteed waiting-period survival. Proper comparison requires matching on health status and accounting for waiting time.",
    "gold_rationale": "Multiple biases: (1) Selectionhealthier patients get transplants. (2) Immortal timemust survive waiting period. (3) Confounding by indicationhealth status determines treatment. Transplant recipients are selected healthy subgroup with guaranteed survival to transplant. Proper analysis requires intention-to-treat from listing with time-dependent covariates.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0121",
    "case_id": "0121",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Psychology",
    "subdomain": "Therapy Outcomes",
    "scenario": "Patients receiving cognitive therapy for depression show improved mood at 12 weeks. Therapists note patients also started exercising more. Question: Did therapy improve mood through teaching coping skills, or did improved mood enable exercise, which then further improved mood? Data shows mood improvements precede exercise increases, but exercise correlates with sustained gains.",
    "claim": "Cognitive therapy improved depression through increased exercise.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Cognitive therapy",
        "role": "exposure"
      },
      "Y": {
        "name": "Depression improvement",
        "role": "outcome"
      },
      "Z": [
        "Exercise behavior",
        "Early mood changes",
        "Temporal ambiguity"
      ]
    },
    "trap": {
      "type": "T9",
      "type_name": "CONF-MED",
      "subtype": "Pre-existing condition",
      "subtype_name": "Early Mood Improvement Enables Exercise"
    },
    "difficulty": "Hard",
    "causal_structure": "TherapyEarly mood lift (Y1)Exercise capacity (Z)Sustained improvement (Y2). Z is consequence of early improvement, not mediator of initial effect. Temporal sequence: XY1ZY2.",
    "key_insight": "Exercise follows early mood improvement; it sustains gains but doesn't mediate initial therapy effect.",
    "hidden_timestamp": "Did mood improve before exercise increased (therapymoodexercise), or did therapy cause exercise which improved mood (therapyexercisemood)?",
    "conditional_answers": {
      "answer_if_condition_1": "If exercise preceded mood improvement (tX < tZ < tY), exercise mediates therapy effect.",
      "answer_if_condition_2": "If mood improved before exercise increased (tX < tY1 < tZ), early therapy effects enabled exercise, not vice versa."
    },
    "wise_refusal": "This is temporal ambiguity in causal chains. Data shows mood improves in weeks 1-4, then exercise increases in weeks 5-8, with sustained mood gains through week 12. The sequence is: TherapyEarly mood liftExercise capacitySustained improvement. Exercise is consequence of initial treatment response, not primary mediator. Early therapy effects (cognitive restructuring) improved mood enough to enable exercise, which then maintained gains.",
    "gold_rationale": "Temporal sequencing reveals causal chain. TherapyY1 (early improvement)Z (exercise)Y2 (sustained improvement). Exercise is secondary mechanism enabled by primary therapy effects. If we blocked Z (prevented exercise), we'd still see Y1 (initial improvement) but lose Y2 (sustained gains). This demonstrates how mediators can be consequences of early treatment effects rather than primary pathways.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0122",
    "case_id": "0122",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "Special Education",
    "scenario": "Students receiving special education services show lower reading gains than mainstream students. Parents see this as evidence that special education harms learning. However, students are placed in special education specifically because they're already struggling with reading disabilities. Their prior reading difficulties caused special education placement and predict continued lower gains. Z preceded X temporally and confounds the relationship.",
    "claim": "Special education services cause lower reading achievement gains.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Special education placement",
        "role": "exposure"
      },
      "Y": {
        "name": "Reading gains",
        "role": "outcome"
      },
      "Z": [
        "Pre-existing reading disability",
        "Learning difficulties",
        "Placement criteria"
      ]
    },
    "trap": {
      "type": "T9",
      "type_name": "CONF-MED",
      "subtype": "Pre-existing condition",
      "subtype_name": "Disability Precedes Placement"
    },
    "difficulty": "Medium",
    "causal_structure": "Reading disability (Z) at t1  Special education placement (X) at t2 and Z  Lower gains (Y). Z preceded X, making it confounder not mediator. Temporal data shows disability present before placement.",
    "key_insight": "Reading difficulties existed before placement and predict both placement and lower gains; placement doesn't cause poor outcomes.",
    "hidden_timestamp": "Did reading disability (Z) exist before placement (tZ < tX), or did placement cause learning difficulties (tX < tZ)?",
    "conditional_answers": {
      "answer_if_condition_1": "If students developed reading difficulties after placement (tX < tZ), placement might harm learning.",
      "answer_if_condition_2": "If reading disabilities existed before placement (tZ < tX), prior difficulties confound the placement-outcome relationship."
    },
    "wise_refusal": "This is confounding by indication. Students are placed in special education because they already have significant reading disabilities. These pre-existing difficulties (Z at t1) caused placement decisions (X at t2) and predict continued slower progress (Y). The temporal sequencedisabilityplacementshows Z is confounder, not mediator. Comparing outcomes requires matching students with similar disabilities at placement time.",
    "gold_rationale": "Confounder-mediator distinction via temporal ordering. Reading disabilityPlacement and Reading disabilitySlower gains. Since tZ < tX, disability is pre-existing confounder. Students selected into special education based on existing struggles. Proper evaluation requires comparing special education students to similarly disabled students without services (or RCT), not to general population.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0123",
    "case_id": "0123",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Traffic Safety",
    "scenario": "Cities implement red-light cameras at high-violation intersections. Over 18 months, violations drop 50% at camera intersections. However, cameras were installed during an aggressive traffic safety campaign with increased police presence, new signage, and media coverage. These concurrent interventions vary over time and interact with camera placement decisions. Past violation rates affected where cameras were placed, and camera presence affected subsequent police deployment.",
    "claim": "Red-light cameras caused the 50% violation reduction.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Red-light camera installation",
        "role": "exposure"
      },
      "Y": {
        "name": "Traffic violations",
        "role": "outcome"
      },
      "Z": [
        "Police presence (time-varying)",
        "Media campaigns",
        "Concurrent interventions"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "TEMPORAL",
      "subtype": "Treatment-confounder feedback",
      "subtype_name": "Time-Varying Campaign Effects"
    },
    "difficulty": "Hard",
    "causal_structure": "Violations(t1)Camera placement(t2)Media attention(t3)Police deployment(t3)Violations(t4). Time-varying confounders Z affected by prior treatment and affecting future outcomes. Feedback loops present.",
    "key_insight": "Multiple time-varying interventions with feedback make causal attribution to cameras impossible without specialized methods.",
    "hidden_timestamp": "Do confounders change over time, with past treatment affecting future confounders?",
    "conditional_answers": {
      "answer_if_condition_1": "If cameras were sole intervention with no time-varying confounding, violation drop could be attributed to cameras.",
      "answer_if_condition_2": "If concurrent time-varying interventions interact with camera placement, attribution requires controlling for temporal confounding."
    },
    "wise_refusal": "This is time-varying confounding with treatment-confounder feedback. High violation rates (t1) triggered camera installation (t2), which drew media attention and police resources (t3), affecting violations (t4). Concurrent interventions vary temporally and are affected by camera placement. Past violations influence camera decisions; camera presence influences police deployment. This creates feedback loops where treatment affects future confounders. Marginal structural models or g-methods required for proper inference.",
    "gold_rationale": "Treatment-confounder feedback over time. ViolationsCameraMedia/policeViolations. The confounding structure changes: violation rates affect treatment decisions, treatment affects future confounder values (police deployment). Standard methods fail with time-varying confounding affected by prior exposure. This requires inverse probability weighting, g-estimation, or difference-in-differences with matched temporal controls.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0124",
    "case_id": "0124",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Medicine",
    "subdomain": "Infectious Disease",
    "scenario": "HIV patients on antiretroviral therapy show viral load changes over time. Doctors adjust medication dosages based on recent viral load results. High viral loads at t1 trigger dose increases at t2, which affect viral loads at t3. Simultaneously, adherence patterns at t1 affect viral loads at t2, which affect treatment decisions at t3. Past outcomes affect future treatments, which affect future outcomesclassic time-varying confounding with feedback.",
    "claim": "Higher ART dosages cause better viral suppression.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "ART dosage",
        "role": "exposure"
      },
      "Y": {
        "name": "Viral load suppression",
        "role": "outcome"
      },
      "Z": [
        "Prior viral load status",
        "Adherence patterns",
        "Treatment decisions based on outcomes"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "TEMPORAL",
      "subtype": "Treatment-confounder feedback",
      "subtype_name": "Dose Adjustments Based on Outcomes"
    },
    "difficulty": "Medium",
    "causal_structure": "VL(t1)Dose(t2)VL(t3)Dose(t4). Outcomes at t1 affect treatment at t2, which affects outcomes at t3. Time-varying confounding where past outcomes affect future exposures.",
    "key_insight": "Dosage decisions based on prior viral loads create temporal feedback; standard methods can't isolate causal effects.",
    "hidden_timestamp": "Do past outcomes affect future treatment decisions, creating time-varying confounding?",
    "conditional_answers": {
      "answer_if_condition_1": "If dosage assigned randomly regardless of viral load history, observed association reflects causal effect.",
      "answer_if_condition_2": "If dosage adjusted based on prior viral loads, time-varying confounding prevents simple causal inference."
    },
    "wise_refusal": "This is time-varying confounding with treatment-confounder feedback. Poor viral suppression at t1 causes dose escalation at t2. Adherence affects both viral loads and physician treatment decisions. Past viral loads are both outcomes (of prior treatment) and confounders (for future treatment). This creates temporal dependencies where standard regression fails. Marginal structural models with inverse probability weighting needed to properly estimate causal effects.",
    "gold_rationale": "Treatment-confounder feedback: VL(t1) is outcome of Dose(t0) and confounder for Dose(t2). Past outcomes affect future treatments through physician decisions. The confounding structure changes over time. Standard methods bias estimates because they can't handle confounders affected by prior treatment. Proper analysis requires g-methods, marginal structural models, or structural nested models accounting for temporal dependencies.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0125",
    "case_id": "0125",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Policy",
    "subdomain": "Recycling",
    "scenario": "A city implements mandatory recycling with steep fines for contamination. First year shows 40% recycling increase. However, residents respond by disposing questionable items in regular trash to avoid fines. Overall waste reduction is only 8%, far below the 40% recycling increase, suggesting contamination avoidance created more waste. The intervention to increase recycling inadvertently increased total waste through behavioral workarounds.",
    "claim": "Mandatory recycling with contamination fines successfully increased waste diversion.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Mandatory recycling with fines",
        "role": "exposure"
      },
      "Y": {
        "name": "Net waste reduction",
        "role": "outcome"
      },
      "Z": [
        "Contamination avoidance behavior",
        "Compensatory trash disposal",
        "Unintended consequences"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "BACKFIRE",
      "subtype": "Unintended consequences",
      "subtype_name": "Fine Avoidance Creates Waste Displacement"
    },
    "difficulty": "Hard",
    "causal_structure": "Fines (X)  Contamination avoidance (Z compensatory)  Trash disposal increase  Net waste reduction less than recycling increase. Intended pathway blocked by compensatory response.",
    "key_insight": "Harsh contamination fines triggered disposal workarounds that displaced waste rather than reducing it; measured recycling  actual waste reduction.",
    "hidden_timestamp": "Could the intervention trigger compensatory behaviors that undermine net environmental benefit?",
    "conditional_answers": {
      "answer_if_condition_1": "If fines motivated careful recycling without compensatory behaviors, waste reduction would match recycling increase.",
      "answer_if_condition_2": "If fines motivated trash disposal to avoid contamination risk, recycling increases but waste reduction is smallerintervention backfire."
    },
    "wise_refusal": "This is intervention backfire through compensatory behavior. Contamination fines successfully increased measured recycling (intended effect) but triggered trash disposal of questionable items (unintended response). The 40% recycling increase yielded only 8% waste reduction because residents disposed 32% in trash to avoid fines. The intervention optimized the wrong metriccontamination-free recycling rather than total waste reduction. Net environmental benefit was far less than target metric suggested.",
    "gold_rationale": "Backfire through metric optimization. FinesContamination avoidanceTrash disposal. The intervention succeeded on target metric (clean recycling) but failed on actual goal (waste reduction). Residents gamed the system by disposing ambiguous items as trash. This demonstrates Campbell's Lawwhen a measure becomes a target, people optimize that measure rather than the underlying goal. Proper policy design requires incentivizing actual waste reduction, not clean bins.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0126",
    "case_id": "0126",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Education",
    "subdomain": "Standardized Testing",
    "scenario": "Schools implement test-prep programs before state exams. Students show 15-point average score increases. District declares success. However, teachers responded to testing pressure by narrowing curriculum to tested topics, eliminating science labs, art, and music. Post-program surveys show students score higher on state tests but worse on national comprehensive assessments. The intervention improved the target metric while degrading overall education quality.",
    "claim": "Test-prep programs improved student learning and educational outcomes.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Test-prep program",
        "role": "exposure"
      },
      "Y": {
        "name": "Educational outcomes (comprehensive)",
        "role": "outcome"
      },
      "Z": [
        "Curriculum narrowing",
        "Teaching to test",
        "Opportunity cost"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "BACKFIRE",
      "subtype": "Unintended consequences",
      "subtype_name": "Metric Gaming Degrades True Outcome"
    },
    "difficulty": "Easy",
    "causal_structure": "Test-prep (X)  Teaching to test (Z)  State test scores (Y*measured) increase but comprehensive learning (Y*actual) decreases. Optimization of metric harms actual outcome.",
    "key_insight": "Program improved measured outcome (state tests) while harming actual outcome (comprehensive learning) through curriculum narrowing.",
    "hidden_timestamp": "Could the intervention improve the measured metric while degrading the true outcome of interest?",
    "conditional_answers": {
      "answer_if_condition_1": "If test-prep taught generalizable skills improving all assessments, state test gains would reflect real learning.",
      "answer_if_condition_2": "If test-prep narrowed curriculum to tested content, state scores improve but comprehensive learning degradesmetric gaming."
    },
    "wise_refusal": "This is intervention backfire through metric gaming. Test-prep successfully increased state test scores (measured outcome) but triggered curriculum narrowing that degraded comprehensive learning (actual outcome). Teachers optimized the accountability metric rather than educational quality. Students learned test-taking strategies and specific content while losing broader education. The intervention succeeded on the wrong targettest performance rather than learning.",
    "gold_rationale": "Backfire through Goodhart's Law. Test-prepTeaching to testState scores up, comprehensive learning down. When test scores became the optimization target, schools narrowed instruction to tested content. The measured outcome (state tests) improved while true outcome (comprehensive education) degraded. This demonstrates how narrow accountability metrics can harm the underlying goals they're meant to promote. Proper evaluation requires assessing actual learning, not just tested content.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0127",
    "case_id": "0127",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Pain Management",
    "scenario": "Patients with chronic pain who practice mindfulness meditation report 30% lower pain intensity on self-report scales. Clinics promote mindfulness for pain relief. However, mindfulness training explicitly teaches patients to change their relationship with pain rather than pain sensation itself. Trained patients learn to report pain differently on scales without actual nociceptive changes. Objective pain measures show no improvement.",
    "claim": "Mindfulness meditation reduces chronic pain intensity.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Mindfulness meditation training",
        "role": "exposure"
      },
      "Y": {
        "name": "Pain intensity",
        "role": "outcome"
      },
      "Z": [
        "Pain reporting framework",
        "Sensation vs suffering distinction",
        "Scale interpretation changes"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "MECHANISM MISMATCH",
      "subtype": "Wrong target",
      "subtype_name": "Changed Pain Reporting Not Pain Sensation"
    },
    "difficulty": "Hard",
    "causal_structure": "Mindfulness (X)  Pain conceptualization change (M1) not nociception change (M2). Intervention changed how patients report pain without changing actual pain pathophysiology.",
    "key_insight": "Training changed pain reporting framework on scales without reducing actual pain sensation or improving function.",
    "hidden_timestamp": "Did the intervention target actual pain mechanisms (nociception) or pain reporting/interpretation frameworks?",
    "conditional_answers": {
      "answer_if_condition_1": "If mindfulness reduced nociceptive pain through neurological mechanisms, both self-reports and objective measures would improve.",
      "answer_if_condition_2": "If mindfulness taught different pain conceptualization, self-reports change but objective measures (medication use, disability) don't improve."
    },
    "wise_refusal": "This is mechanism mismatch. Mindfulness training explicitly teaches distinguishing pain sensation from suffering, changing how patients conceptualize and report pain on scales. Self-reported pain intensity decreases (M1 succeeded) but objective indicatorsanalgesic consumption and functional disabilityremain unchanged (M2 failed). The intervention worked on measured outcome (pain scales) but not actual outcome (pain pathophysiology/function). Training changed reporting framework, not underlying pain mechanisms.",
    "gold_rationale": "Mechanism failure: XReporting framework (M1) not XNociception (M2). Mindfulness teaches pain reinterpretation, affecting scale responses without changing pain physiology. Self-reports improved; objective outcomes didn't. This is measurement-treatment interactionintervention specifically targets how outcomes are reported. Proper evaluation requires objective measures (medication use, activity levels) resistant to reporting biases.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0128",
    "case_id": "0128",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Sales Training",
    "scenario": "A company implements sales training teaching specific closing techniques and objection handling. Trainees show 25% higher conversion rates on training scenarios. However, when deployed to actual sales, conversion rates are identical to untrained sales reps. Investigation reveals training taught artificial role-play scenarios that don't transfer to real customer interactions. The intervention succeeded on training metrics but failed on actual sales performancewrong mechanism targeted.",
    "claim": "Sales training caused improved conversion rates.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Sales training program",
        "role": "exposure"
      },
      "Y": {
        "name": "Actual sales conversion rates",
        "role": "outcome"
      },
      "Z": [
        "Training scenario performance",
        "Role-play vs reality gap",
        "Skill transfer failure"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "MECHANISM MISMATCH",
      "subtype": "Wrong target",
      "subtype_name": "Training Scenarios Don't Transfer to Reality"
    },
    "difficulty": "Easy",
    "causal_structure": "Training (X)  Role-play performance (M1) not real sales skills (M2). Intervention improved measured outcome (training scores) without affecting true outcome (actual conversions).",
    "key_insight": "Training taught artificial scenarios that don't transfer; improved training performance  improved real-world sales.",
    "hidden_timestamp": "Did the intervention target skills that transfer to actual performance environment?",
    "conditional_answers": {
      "answer_if_condition_1": "If training taught transferable sales skills, both training and real-world performance would improve.",
      "answer_if_condition_2": "If training taught role-play responses that don't transfer, training scores improve but real conversions don'tmechanism mismatch."
    },
    "wise_refusal": "This is mechanism mismatch. Sales training successfully improved role-play scenario performance (M1) but failed to develop skills that transfer to actual customer interactions (M2). Trainees learned scripted responses for artificial training scenarios without developing adaptive selling abilities. The intervention worked on the measured outcome (training evaluations) but not the target outcome (real sales). This demonstrates how training can optimize performance metrics without building actual competencies.",
    "gold_rationale": "Mechanism failure: XTraining performance (M1) not XReal sales ability (M2). Training taught specific responses to scripted scenarios that don't generalize. Performance on artificial measures improved without affecting actual job performance. This shows how training can game evaluation metrics without developing transferable skills. Proper training design requires realistic scenarios and evaluation methods that predict actual performance.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0129",
    "case_id": "0129",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Software Development",
    "scenario": "A tech company tracks developers with most code commits as 'top performers.' These developers receive bonuses and promotions based on commit frequency. Within 6 months, code quality declinesmore bugs, fragmented changes, and poor documentation. Developers optimize commit count rather than code quality by breaking work into tiny commits. The metric that originally identified productive developers became useless once incentivized.",
    "claim": "High code commit frequency indicates and causes high developer productivity.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Code commit frequency",
        "role": "exposure"
      },
      "Y": {
        "name": "Developer productivity",
        "role": "outcome"
      },
      "Z": [
        "Code quality degradation",
        "Metric gaming",
        "Fragmented commits"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Commit Frequency Loses Meaning When Targeted"
    },
    "difficulty": "Hard",
    "causal_structure": "Before: ProductivityMany commits (correlation). After commits become target: CommitsFragmented workQuality decline. Metric loses predictive value when optimized.",
    "key_insight": "Commit frequency predicted productivity when incidental; once incentivized, developers gamed the metric while quality degraded.",
    "hidden_timestamp": "Is the metric being actively optimized, breaking its relationship to true productivity?",
    "conditional_answers": {
      "answer_if_condition_1": "If commits remain natural work indicators, frequency correlates with productivity.",
      "answer_if_condition_2": "If commits become incentive targets, developers fragment work to maximize commits, breaking the productivity correlation."
    },
    "wise_refusal": "This is Goodhart's Law. Commit frequency originally correlated with productivity because productive developers naturally made many meaningful commits. When commits became incentivized targets, developers optimized the metric rather than productivityfragmenting work into tiny commits, degrading code quality. The measure's predictive value eroded when it became the optimization target. This demonstrates how metrics that work as signals fail as targets.",
    "gold_rationale": "Goodhart's Law in action. Initially: ProductivityCommits (natural correlation). After incentivization: Commits become targetGamingQuality decline. The metric broke when people optimized it rather than the underlying construct. Developers maximized commits through fragmentation rather than productive work. This shows why good observational metrics often fail as incentive targetsgaming behaviors emerge that satisfy the metric while undermining the goal.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0130",
    "case_id": "0130",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Healthcare",
    "subdomain": "Hospital Ratings",
    "scenario": "Hospitals with higher patient satisfaction scores have 10% higher readmission rates. Administrators initially worry that patient satisfaction indicates poor care. However, hospitals maximizing satisfaction scores do so by avoiding difficult conversations about medication adherence, discharge instructions, and lifestyle changes. Doctors who deliver hard truths get lower satisfaction scores but patients follow recommendations better. When satisfaction became a target metric, it decoupled from quality care.",
    "claim": "Higher patient satisfaction indicates and causes better healthcare quality.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Patient satisfaction scores",
        "role": "exposure"
      },
      "Y": {
        "name": "Healthcare quality (readmissions)",
        "role": "outcome"
      },
      "Z": [
        "Avoidance of difficult conversations",
        "Satisfaction optimization behaviors",
        "Adherence to medical advice"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Satisfaction Scores Decouple from Quality"
    },
    "difficulty": "Medium",
    "causal_structure": "Before: Quality careSatisfaction (correlation). After satisfaction targeted: Satisfaction optimizationAvoidance of hard truthsWorse outcomes. Metric loses predictive value.",
    "key_insight": "Satisfaction originally indicated good care; once targeted, hospitals optimized scores by avoiding necessary difficult interactions.",
    "hidden_timestamp": "Is satisfaction being optimized as target metric, breaking its relationship to care quality?",
    "conditional_answers": {
      "answer_if_condition_1": "If satisfaction remains incidental outcome of care, high scores correlate with quality.",
      "answer_if_condition_2": "If satisfaction becomes target, hospitals optimize it through behaviors that degrade actual care quality."
    },
    "wise_refusal": "This is Goodhart's Law. Patient satisfaction originally correlated with good care because good hospitals naturally satisfied patients. When satisfaction became a target metric for reimbursement, hospitals optimized scores rather than careavoiding difficult but necessary conversations about adherence and lifestyle. Doctors delivering hard medical truths got poor scores despite providing better care. The metric decoupled from quality when it became the optimization target.",
    "gold_rationale": "Goodhart's Law: Initially satisfactionQuality correlation. After targeting: Satisfaction optimizationGamingQuality decline. Hospitals maximized scores by avoiding necessary difficult conversations about adherence, complications, lifestyle changes. Doctors who delivered hard truths got poor satisfaction scores but better patient outcomes. This demonstrates metric-target divergencewhen measures become goals, people optimize the measure rather than underlying construct.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0131",
    "case_id": "0131",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Business",
    "subdomain": "Hiring",
    "scenario": "A company uses employee referrals as a key hiring channel, noting that referred candidates have 40% higher retention than other hires. HR expands referral incentives. However, current employees naturally refer people similar to themselvessame schools, backgrounds, and work styles. This homogeneity initially boosted retention through cultural fit but eventually reduced innovation and adaptability. When referrals became the primary hiring source, the diversity-innovation trade-off became apparent.",
    "claim": "Employee referrals cause superior hiring outcomes.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Employee referral hiring",
        "role": "exposure"
      },
      "Y": {
        "name": "Hiring quality (comprehensive)",
        "role": "outcome"
      },
      "Z": [
        "Cultural fit vs diversity",
        "Homogeneity effects",
        "Innovation capacity"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Referral Success Declines When Overused"
    },
    "difficulty": "Medium",
    "causal_structure": "Before: ReferralsGood retention (at moderate levels). After overuse: ReferralsHomogeneityReduced innovation. Mechanism changes with scale.",
    "key_insight": "Referrals worked well as one channel; when primary source, created homogeneity that degraded long-term performance.",
    "hidden_timestamp": "Is the metric being overoptimized, changing the relationship between referrals and hiring quality?",
    "conditional_answers": {
      "answer_if_condition_1": "If referrals remain one of several hiring channels, they contribute positively through cultural fit.",
      "answer_if_condition_2": "If referrals become dominant channel, homogeneity effects emerge that degrade innovation and adaptability."
    },
    "wise_refusal": "This involves Goodhart's Law and diminishing returns. Referrals originally succeeded because they selected for cultural fit, improving retention. When HR overoptimized referrals as primary hiring channel, the mechanism changedhomogeneity reduced diversity and innovation capacity. What worked at moderate levels failed at scale. The metric (retention) remained good but overall hiring quality (including innovation, adaptability) degraded. This shows how optimizing one metric can harm unmeasured outcomes.",
    "gold_rationale": "Goodhart's Law with scale effects. Moderate referral useCultural fitGood retention. Referral overuseHomogeneityInnovation decline. The relationship between referrals and quality changed with scale. Retention remained high but unmeasured outcomes (diversity, innovation) degraded. This demonstrates how partial optimizationmaximizing one outcome dimensioncan degrade overall performance. Proper hiring requires balancing multiple objectives, not maximizing single metrics.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0132",
    "case_id": "0132",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Public Health",
    "subdomain": "Disease Surveillance",
    "scenario": "Counties with active disease surveillance systems report 3x higher rates of rare infectious diseases than counties without surveillance. Health officials initially interpret this as evidence that surveillance detects disease clusters requiring intervention. However, investigation reveals actual disease prevalence is similar across countiessurveillance differences create detection differences. Active surveillance finds cases that passive reporting misses. The measured outcome differs from true outcome.",
    "claim": "Active disease surveillance indicates higher true disease burden requiring intervention.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Active surveillance system",
        "role": "exposure"
      },
      "Y": {
        "name": "Reported disease rates",
        "role": "outcome"
      },
      "Z": [
        "Detection capacity",
        "Case finding intensity",
        "True vs measured prevalence"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "SELECTION",
      "subtype": "Detection bias",
      "subtype_name": "Surveillance Intensity Creates Measurement Differences"
    },
    "difficulty": "Medium",
    "causal_structure": "True disease prevalence similar across counties. Active surveillanceCase detectionHigher reported rates. Measured outcome differs from true outcome due to detection differences.",
    "key_insight": "Surveillance doesn't create disease; it detects existing cases. Higher reported rates reflect detection capacity, not higher true prevalence.",
    "hidden_timestamp": "Does surveillance intensity affect case detection rather than true disease occurrence?",
    "conditional_answers": {
      "answer_if_condition_1": "If surveillance systems uniform across counties, reported rate differences reflect true prevalence differences.",
      "answer_if_condition_2": "If surveillance intensity varies, reported rates reflect detection capacity more than true prevalencedetection bias."
    },
    "wise_refusal": "This is detection bias. Active surveillance systems detect more cases of diseases with similar true prevalence. Counties with active surveillance find asymptomatic and mild cases that passive reporting misses. Higher reported rates don't indicate higher true disease burdenthey indicate better detection. The measured outcome (reported cases) differs from true outcome (actual prevalence). Population prevalence studies show similar disease rates across surveillance levels, confirming detection bias.",
    "gold_rationale": "Detection bias creates measurement heterogeneity. True prevalence similar; detection differs. Active surveillanceCase findingHigher reports. Measured rates reflect surveillance intensity, not disease burden. This demonstrates how healthcare system characteristics affect disease detection, creating apparent geographic patterns that are measurement artifacts. Proper public health response requires understanding whether rate differences reflect detection or true prevalence.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0133",
    "case_id": "0133",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Criminal Justice",
    "subdomain": "Policing",
    "scenario": "Police departments implementing body cameras show 35% higher use-of-force incident reports than departments without cameras. Critics claim cameras increase police violence. However, cameras don't cause forcethey make it visible and reportable. Departments without cameras have similar actual force incidents but lower documentation. When departments adopt cameras, previously invisible incidents become recorded. The measured outcome changes without true outcome changing.",
    "claim": "Body cameras cause increased police use of force.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Body camera deployment",
        "role": "exposure"
      },
      "Y": {
        "name": "Use-of-force incidents",
        "role": "outcome"
      },
      "Z": [
        "Incident documentation",
        "Detection and reporting",
        "True vs recorded events"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "SELECTION",
      "subtype": "Detection bias",
      "subtype_name": "Cameras Detect Existing Force Events"
    },
    "difficulty": "Easy",
    "causal_structure": "True force incidents similar with/without cameras. CamerasDocumentationHigher reported rates. Measured outcome (reports) differs from true outcome (actual force).",
    "key_insight": "Cameras document existing force incidents; higher reports reflect better detection, not increased actual force.",
    "hidden_timestamp": "Do cameras change incident occurrence or incident detection and documentation?",
    "conditional_answers": {
      "answer_if_condition_1": "If cameras cause force increases, independent civilian complaint rates would also rise.",
      "answer_if_condition_2": "If cameras only improve documentation, official reports rise but civilian complaints (unaffected by cameras) remain stable."
    },
    "wise_refusal": "This is detection bias. Body cameras don't cause use-of-force incidentsthey document incidents that previously went unreported. Departments without cameras have similar actual force usage but lower documentation rates. Cameras make existing incidents visible. Civilian complaint rates (independent of camera documentation) remain stable when cameras are deployed, confirming that reported incident increases reflect detection, not true increases in force. The measured outcome changed; the true outcome didn't.",
    "gold_rationale": "Detection bias: True force stable, documentation increases. CamerasIncident recordingHigher reports. Measured rates (documented incidents) differ from true rates (actual force). Independent validation through civilian complaints shows actual force unchanged. This demonstrates how surveillance technology changes measurement without changing behavior. Proper interpretation requires distinguishing detection improvements from true changes.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0134",
    "case_id": "0134",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Healthcare",
    "subdomain": "Emergency Medicine",
    "family": "F1",
    "subtype": "Mechanistic Necessity",
    "scenario": "A patient in cardiac arrest received CPR from a bystander within 2 minutes. Paramedics arrived at minute 8 with a defibrillator and restored normal rhythm. The patient survived with full neurological recovery. The emergency room doctor states the case demonstrates that 'CPR alone saved the patient's life.'",
    "counterfactual_claim": "If the bystander had not performed CPR, the patient would have died or suffered severe brain damage.",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Bystander CPR within 2 minutes",
      "Y": "Survival with full neurological recovery",
      "Z": [
        "Paramedic arrival time (8 minutes)",
        "Defibrillator availability",
        "Brain oxygen deprivation timeline"
      ]
    },
    "trap": {
      "type": "F1",
      "type_name": "Deterministic Counterfactual",
      "subtype": "Mechanistic Necessity",
      "subtype_name": "Essential Component Removal"
    },
    "difficulty": "Easy",
    "causal_structure": "CPR(X) -> Maintains blood flow -> Prevents brain death before minute 8 -> Enables defibrillation success -> Y. Without X: No blood flow -> Brain damage by minute 4-6 -> Defibrillation at minute 8 too late.",
    "key_insight": "Brain cells die after 4-6 minutes without oxygen. CPR maintains minimal blood flow, preventing irreversible damage until advanced care arrives.",
    "hidden_timestamp": "The counterfactual asks what would happen in a world where CPR was absent but all other facts (paramedic timing, arrest type) remain fixed.",
    "conditional_answers": {
      "answer_if_condition_1": "If CPR were performed, brain oxygenation continues and defibrillation at minute 8 can succeed.",
      "answer_if_condition_2": "If CPR were not performed, brain damage occurs by minute 4-6, making recovery impossible even with defibrillation at minute 8."
    },
    "wise_refusal": "The counterfactual is VALID under stated medical mechanisms. Without CPR, the brain would experience complete oxygen deprivation for 8 minutesfar exceeding the 4-6 minute window before irreversible damage. Even if paramedics successfully restarted the heart at minute 8, the patient would have suffered severe brain damage or death. CPR was mechanistically necessary to bridge the gap until advanced care arrived.",
    "gold_rationale": "VALID. Medical invariants: brain cells die after 4-6 minutes without oxygen; CPR maintains 25-30% normal circulation. Without X, 8-minute gap exceeds survival window. With X, minimal circulation prevents cell death until defibrillation. This is deterministic mechanistic necessityremoving X breaks the causal chain to Y.",
    "invariants": [
      "Paramedic arrival time remains 8 minutes",
      "Brain damage occurs after 4-6 minutes without oxygen (medical law)",
      "CPR maintains approximately 25-30% of normal blood circulation"
    ],
    "justification": "Under the invariants, removing CPR means zero blood flow for 8 minutes. This exceeds the 4-6 minute brain survival window, making neurological recovery impossible. The counterfactual is valid because CPR was mechanistically necessary given the timeline.",
    "wise_response": "VALID. Without CPR, brain damage would occur before paramedics arrived, preventing recovery despite later defibrillation.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0135",
    "case_id": "0135",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Medicine",
    "subdomain": "Oncology",
    "family": "F2",
    "subtype": "Probabilistic Exposure",
    "scenario": "A 50-year-old lifelong smoker developed lung cancer. She claims: 'If I had never smoked, I wouldn't have gotten cancer.' Her oncologist notes that 10-15% of lung cancers occur in never-smokers, and genetic factors also play a role. The patient had no known genetic mutations associated with lung cancer.",
    "counterfactual_claim": "If the patient had never smoked, she would not have developed lung cancer.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Smoking (40 pack-years)",
      "Y": "Lung cancer at age 50",
      "Z": [
        "Genetic susceptibility (unknown)",
        "Environmental exposures (unspecified)",
        "Background risk in never-smokers (10-15%)"
      ]
    },
    "trap": {
      "type": "F2",
      "type_name": "Probabilistic Counterfactual",
      "subtype": "Probabilistic Exposure",
      "subtype_name": "Stochastic Causation with Background Risk"
    },
    "difficulty": "Medium",
    "causal_structure": "Smoking(X) -> Dramatically increases P(Y) from 0.10-0.15 to 0.15-0.30. But Y can occur without X through genetic/environmental paths. Individual-level necessity unknown without genetic data.",
    "key_insight": "Smoking increases lung cancer risk but doesn't deterministically cause it. Some never-smokers get cancer; some heavy smokers don't. Individual causation is probabilistic.",
    "hidden_timestamp": "The counterfactual asks about a specific individual case where causation is stochastic. We observe X=1, Y=1 but don't know if this patient would be in the 10-15% who'd get cancer anyway.",
    "conditional_answers": {
      "answer_if_condition_1": "If this patient had specific genetic susceptibility making cancer likely even without smoking, the counterfactual is INVALIDshe might have developed cancer anyway.",
      "answer_if_condition_2": "If this patient had no special susceptibility beyond population baseline, the counterfactual is VALIDcancer was likely caused by smoking given dose-response."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on unknown genetic and environmental factors. Smoking dramatically increases lung cancer risk (population-level intervention), but 10-15% of lung cancers occur in never-smokers. Without knowing this patient's latent susceptibility, we cannot determine if she specifically would have avoided cancer. The claim confuses population-level probability with individual-level necessity.",
    "gold_rationale": "CONDITIONAL. The scenario specifies no genetic mutations but doesn't rule out other susceptibilities. Smoking increases P(Y) substantially, but Y can occur without X at non-trivial rates. To resolve: need genetic profile showing low baseline risk, or probabilistic interpretation ('much less likely' instead of 'would not').",
    "invariants": [
      "Background lung cancer risk in never-smokers: 10-15%",
      "Patient's genetic and environmental susceptibility unknown",
      "Smoking dose: 40 pack-years (heavy exposure)"
    ],
    "justification": "The counterfactual treats a probabilistic relationship deterministically. Smoking causes most lung cancer cases but not all. Without knowing if this patient had latent risk factors, the claim is underdetermined. Answer depends on unstated genetic susceptibility.",
    "wise_response": "CONDITIONAL. The claim would be more accurate as 'much less likely' rather than 'would not.' Individual causation is uncertain without genetic data.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0136",
    "case_id": "0136",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Criminal Justice",
    "subdomain": "Homicide Investigation",
    "family": "F3",
    "subtype": "Symmetric Overdetermination",
    "scenario": "Two assassins, acting independently, simultaneously shot a victim. Assassin A fired at the heart; Assassin B fired at the brain. Both bullets hit within milliseconds, and the victim died instantly. Forensic analysis confirms either wound alone would have been immediately fatal. Assassin A's lawyer argues: 'My client didn't cause the deaththe victim would have died from B's shot anyway.'",
    "counterfactual_claim": "If Assassin A had not fired, the victim would not have died.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Assassin A's shot (heart)",
      "Y": "Victim's death",
      "Z": [
        "Assassin B's shot (brain)",
        "Independence of actions",
        "Sufficiency of each wound"
      ]
    },
    "trap": {
      "type": "F3",
      "type_name": "Overdetermination",
      "subtype": "Symmetric Overdetermination",
      "subtype_name": "Dual Sufficient Causes"
    },
    "difficulty": "Hard",
    "causal_structure": "A's shot(X1) -> Death(Y); B's shot(X2) -> Death(Y). Both are sufficient; neither is necessary. Classic overdetermination: removing either cause leaves the other as sufficient.",
    "key_insight": "Both causes are sufficient for the outcome. Removing one doesn't prevent Y because the other remains. Neither is a but-for cause despite both being actual causes.",
    "hidden_timestamp": "The counterfactual asks about removing X (A's shot) while holding B's shot fixed as an invariant. Under this, Y still occurs.",
    "conditional_answers": {
      "answer_if_condition_1": "If we hold B's shot as an invariant (B still shoots), removing A's shot doesn't prevent deathY still occurs.",
      "answer_if_condition_2": "If we remove both shots simultaneously (not the stated counterfactual), then Y wouldn't occur."
    },
    "wise_refusal": "The counterfactual is INVALID under the stated invariants. The claim tests but-for causation: 'but for A's shot, would death have occurred?' The answer is YESB's shot alone was sufficient. This is classic overdetermination where multiple causes each suffice for the outcome. Removing either cause individually doesn't prevent Y because the backup cause remains. A's shot was an actual cause (it did contribute), but it wasn't a but-for necessary cause.",
    "gold_rationale": "INVALID. Symmetric overdetermination. Both shots independently sufficient for death. Removing X (A's shot) while holding X2 (B's shot) fixed: Y still occurs via X2. The but-for test fails. Note: This doesn't mean A lacks legal/moral responsibilityit means A's action wasn't necessary for the outcome under the counterfactual test.",
    "invariants": [
      "Assassin B's shot occurs independently and remains in the counterfactual world",
      "Either wound alone is immediately fatal",
      "Actions are causally independent (not coordinated)"
    ],
    "justification": "Under the invariants, removing A's action leaves B's sufficient cause intact. The victim dies from B's shot in the counterfactual world. The claim fails the but-for test. This is the classic twin-assassin problem illustrating overdetermination.",
    "wise_response": "INVALID. B's shot was independently sufficient. Removing A's shot doesn't prevent death since B's shot alone would kill the victim.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.9,
    "validator_2": "Longling Geng",
    "final_score_2": 9.9
  },
  {
    "id": "T3-BucketD-0137",
    "case_id": "0137",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Economics",
    "subdomain": "Financial Crisis",
    "family": "F4",
    "subtype": "Trigger vs Structure",
    "scenario": "The 2008 financial crisis began when Lehman Brothers declared bankruptcy on September 15, 2008, triggering market panic. However, the financial system already had systemic vulnerabilities: overleveraged banks, toxic mortgage-backed securities, interconnected credit default swaps, and inadequate capital buffers. An economist claims: 'If Lehman hadn't failed, the crisis wouldn't have happened.'",
    "counterfactual_claim": "If Lehman Brothers had been bailed out, the 2008 financial crisis would not have occurred.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Lehman Brothers bankruptcy (September 15, 2008)",
      "Y": "Financial crisis and market collapse",
      "Z": [
        "Systemic overleveraging",
        "Mortgage-backed securities exposure",
        "Interconnected derivatives",
        "Capital inadequacy across banking system"
      ]
    },
    "trap": {
      "type": "F4",
      "type_name": "Structural vs Contingent",
      "subtype": "Trigger vs Structure",
      "subtype_name": "Proximate Event vs Root Causes"
    },
    "difficulty": "Hard",
    "causal_structure": "Structural vulnerabilities(Z) -> System instability -> Crisis inevitable. Lehman(X) was trigger, not root cause. Without X, different trigger (Bear Stearns, AIG, etc.) would precipitate same outcome.",
    "key_insight": "Lehman was the spark, not the fuel. The system's structural fragility made crisis inevitable; only the timing and specific trigger were contingent.",
    "hidden_timestamp": "The counterfactual asks if preventing the proximate trigger prevents the outcome, when structural conditions guarantee eventual crisis through some path.",
    "conditional_answers": {
      "answer_if_condition_1": "If Lehman's failure was the only problem (no systemic issues), a bailout would prevent crisiscounterfactual VALID.",
      "answer_if_condition_2": "If systemic vulnerabilities made crisis structurally inevitable, preventing Lehman's failure just delays crisis with different triggercounterfactual INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID under structural economic analysis. Lehman's failure was a trigger, not the root cause. The financial system had deep structural vulnerabilities: overleveraged institutions, toxic assets, interconnected exposures. These conditions made systemic crisis inevitableif not through Lehman, then through Bear Stearns, AIG, or another institution. A Lehman bailout would have delayed but not prevented crisis. The claim confuses proximate triggers with structural causes.",
    "gold_rationale": "INVALID. Structural instability made crisis inevitable. Lehman was sufficient trigger but not necessarythe system would have found another breaking point. Counterfactual bailout: crisis delayed 3-6 months, emerges through different institution. This distinguishes contingent triggers from structural inevitability. Evidence: other institutions (Bear, AIG) also required intervention; systemic problems persisted.",
    "invariants": [
      "Systemic vulnerabilities in banking system remain unchanged",
      "Overleveraging, toxic assets, derivatives exposures are structural features",
      "No broader financial reforms accompany Lehman bailout"
    ],
    "justification": "Preventing Lehman's failure doesn't remove structural fragility. With unchanged systemic vulnerabilities, crisis would emerge through another channel within months. The trigger is replaceable; the structure is not. This is classic trigger-vs-structure distinction.",
    "wise_response": "INVALID. Lehman was the trigger, not the cause. Systemic vulnerabilities would have produced crisis through another channel if Lehman were saved.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0138",
    "case_id": "0138",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Business",
    "subdomain": "Corporate Strategy",
    "family": "F5",
    "subtype": "Path Dependence",
    "scenario": "A tech startup chose AWS for cloud infrastructure in year 1. By year 5, they have 500+ microservices, custom tooling, and deep AWS integration. Migrating to Google Cloud would require 18 months and $5M. The CTO claims: 'If we had chosen Google Cloud initially, we'd be in the same situationlocked in with migration costs.'",
    "counterfactual_claim": "If the startup had chosen Google Cloud in year 1, their year-5 position would be identical (same lock-in, same switching costs).",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Initial cloud choice (AWS)",
      "Y": "Year-5 lock-in and switching costs",
      "Z": [
        "Platform-specific tooling accumulation",
        "Deep integration over time",
        "Organizational learning and expertise"
      ]
    },
    "trap": {
      "type": "F5",
      "type_name": "Temporal and Path-Dependent",
      "subtype": "Path Dependence",
      "subtype_name": "Lock-in Through Accumulated Investment"
    },
    "difficulty": "Medium",
    "causal_structure": "Choice(X) -> Integration depth(Z) over time -> Lock-in(Y). The lock-in effect comes from accumulated investment, not specific platform. Google Cloud choice -> same accumulation path -> equivalent lock-in.",
    "key_insight": "Lock-in results from accumulated platform-specific investment over time, not from the specific platform chosen. Path dependence creates switching costs regardless of initial choice.",
    "hidden_timestamp": "The counterfactual asks if different initial choice (year 1) leads to same outcome (year 5) given same integration trajectory over time.",
    "conditional_answers": {
      "answer_if_condition_1": "If lock-in is platform-specific (AWS has unique lock-in properties), the counterfactual is INVALIDGoogle might have less lock-in.",
      "answer_if_condition_2": "If lock-in results from general accumulated integration (vendor-neutral pattern), the counterfactual is VALIDany platform produces equivalent lock-in."
    },
    "wise_refusal": "The counterfactual is VALID under standard cloud economics. Lock-in doesn't result from AWS's unique features but from general path dependence: accumulated platform-specific tooling, organizational expertise, and deep integration over 5 years. Choosing Google Cloud initially would follow the same trajectory500+ microservices with Google-specific tooling, custom integrations, and equivalent switching costs. The mechanism is vendor-neutral: any platform choice plus time produces lock-in.",
    "gold_rationale": "VALID. Lock-in mechanism is time and integration depth, not platform-specific features. The causal structure: Initial choice  5 years of accumulation  Deep integration  High switching costs applies to any major cloud provider. Counterfactual with Google Cloud: same accumulation process  equivalent lock-in by year 5. This demonstrates path dependence where early choices constrain later options regardless of initial direction.",
    "invariants": [
      "Startup follows same growth trajectory (500+ microservices by year 5)",
      "Integration depth and tooling accumulation rate unchanged",
      "Both AWS and Google Cloud have comparable ecosystems enabling deep integration"
    ],
    "justification": "The lock-in mechanism is general: accumulated investment + organizational learning + tooling ecosystem = switching costs. This applies to any major cloud provider. The counterfactual holds because the cause of Y is path length and integration depth, not platform-specific properties.",
    "wise_response": "VALID. Lock-in comes from accumulated investment over time, not AWS-specific features. Google Cloud would produce equivalent lock-in through the same mechanism.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0139",
    "case_id": "0139",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Physics",
    "subdomain": "Quantum Mechanics",
    "family": "F6",
    "subtype": "Unverifiable Counterfactual",
    "scenario": "A physicist measures the spin of an electron, finding spin-up. A student asks: 'If we hadn't measured the spin, what spin would the electron have had before our measurement?' The physicist explains that quantum mechanics posits measurement determines the outcomethe electron existed in superposition before observation, with no definite spin value to discover.",
    "counterfactual_claim": "If we had not measured the electron's spin, it would have had a definite spin value (either up or down) before measurement.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Spin measurement",
      "Y": "Observed spin-up result",
      "Z": [
        "Quantum superposition",
        "Measurement collapse",
        "Interpretation of quantum mechanics"
      ]
    },
    "trap": {
      "type": "F6",
      "type_name": "Epistemic Limits",
      "subtype": "Unverifiable Counterfactual",
      "subtype_name": "Observer-Dependent Reality"
    },
    "difficulty": "Hard",
    "causal_structure": "Under Copenhagen interpretation: Measurement(X) -> Collapse -> Definite value(Y). Before X, no fact of the matter. Under hidden variable theories: Pre-existing value exists but is unknowable. Answer depends on QM interpretation.",
    "key_insight": "The counterfactual depends on quantum mechanics interpretation. Copenhagen: no pre-existing value. Hidden variables: unknowable but existing value. Empirically unresolvable.",
    "hidden_timestamp": "The counterfactual asks about state before measurement, where quantum mechanics interpretations differ fundamentally on whether definite values exist pre-measurement.",
    "conditional_answers": {
      "answer_if_condition_1": "Under Copenhagen interpretation, counterfactual is INVALIDelectron had no definite spin before measurement, only superposition. Measurement creates the value.",
      "answer_if_condition_2": "Under hidden variable theories, counterfactual is VALIDelectron had definite (though unknowable) spin all along. Measurement reveals pre-existing value."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on quantum mechanics interpretationan empirically unresolvable philosophical choice. Copenhagen interpretation: measurement causes collapse from superposition to definite value; no pre-existing spin to 'have.' Hidden variable theories: definite values exist but are inaccessible. Bell's theorem rules out local hidden variables, but non-local variants remain possible. The question is metaphysical, not empirical.",
    "gold_rationale": "CONDITIONAL on QM interpretation. Copenhagen: superposition  measurement-created value  counterfactual INVALID. Hidden variables: pre-existing unknowable value  measurement reveals it  counterfactual VALID. Bell tests rule out local realism but don't resolve all interpretations. The scenario explicitly notes interpretative dependence, making answer underdetermined by stated physics.",
    "invariants": [
      "Standard quantum mechanics formalism applies",
      "Bell inequality violations (non-local correlations observed)",
      "Interpretation of QM not specified (Copenhagen vs hidden variable vs many-worlds)"
    ],
    "justification": "The counterfactual probes the nature of quantum reality before observation. Different interpretations give different answers. Copenhagen: measurement brings value into existence. Hidden variables: value exists but unknowable. Without specifying interpretation, the claim is underdetermined.",
    "wise_response": "CONDITIONAL on QM interpretation. Copenhagen: no pre-existing value (INVALID claim). Hidden variables: unknowable but real value (VALID claim). Empirically unresolvable.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0140",
    "case_id": "0140",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Public Health",
    "subdomain": "Vaccine Efficacy",
    "family": "F7",
    "subtype": "Attributable Fraction",
    "scenario": "A vaccine trial shows 90% efficacy: 10 infections per 10,000 vaccinated vs 100 infections per 10,000 unvaccinated. Of the 10 vaccinated individuals who got infected, a patient advocate claims: 'These 10 people prove the vaccine didn't work for themif they hadn't been vaccinated, their outcome would be the same.'",
    "counterfactual_claim": "For the 10 vaccinated individuals who got infected, the vaccine had no effectthey would have been infected regardless of vaccination status.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Vaccination status",
      "Y": "Infection outcome",
      "Z": [
        "Individual susceptibility (latent)",
        "Exposure intensity (variable)",
        "Vaccine efficacy mechanism"
      ]
    },
    "trap": {
      "type": "F7",
      "type_name": "Causal Attribution",
      "subtype": "Attributable Fraction",
      "subtype_name": "Always-Takers vs Protected Individuals"
    },
    "difficulty": "Hard",
    "causal_structure": "Population: 100 would be infected if unvaccinated. Vaccine prevents 90 infections. Remaining 10 infected include: (1) Always-takers who'd be infected anyway, (2) Some who'd be uninfected without vaccine but got infected due to high exposure. Can't identify individuals.",
    "key_insight": "Among vaccinated infected, we can't determine who are 'always-takers' vs who would've been protected with better circumstances. Population-level efficacy doesn't decompose cleanly to individuals.",
    "hidden_timestamp": "The counterfactual asks about specific individuals who got infected despite vaccination. Without individual-level treatment response data, we can't attribute causation.",
    "conditional_answers": {
      "answer_if_condition_1": "If all 10 vaccinated-infected are 'always-takers' (would be infected regardless), the claim is VALIDvaccine didn't affect them.",
      "answer_if_condition_2": "If some of the 10 would have been protected with lower exposure, or if some unvaccinated-uninfected would've been infected if vaccinated (never-takers), the claim is INVALID for the population."
    },
    "wise_refusal": "The counterfactual is INVALID as stated. It commits the ecological fallacy: applying population-level statistics (90% efficacy) to individual attribution. Among the 10 vaccinated-infected: some are 'always-takers' who'd be infected anyway (high susceptibility or extreme exposure), but others might be individuals who'd have been protected with lower exposure levels. Without individual-level counterfactual outcomes, we can't determine who is in which group. The claim incorrectly assumes all infected-despite-vaccination are necessarily always-takers.",
    "gold_rationale": "INVALID. This is the principal strata problem: we observe Y(X=1) but not Y(X=0) for specific individuals. Some vaccinated-infected are always-takers, but vaccine efficacy implies ~90 prevented infectionsso some of unvaccinated-uninfected are 'protected' (would be infected without vaccine). Can't identify individuals without individual treatment response data. The claim overgeneralizes from population efficacy to individual causation.",
    "invariants": [
      "Vaccine efficacy is 90% at population level (prevents 90 of 100 potential infections)",
      "Individual-level treatment responses unknown (can't observe same person vaccinated and unvaccinated)",
      "No individual biomarkers distinguish always-takers from protected individuals"
    ],
    "justification": "Population efficacy doesn't allow individual causal attribution without additional identifying information. The 10 vaccinated-infected are a mix of always-takers and individuals who'd be protected under different circumstances. The claim's universal quantifier ('these 10 people...their outcome would be the same') is too strong.",
    "wise_response": "INVALID. Population efficacy doesn't decompose to individual certainty. Some vaccinated-infected may be always-takers, but we can't identify them without individual counterfactual data.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0141",
    "case_id": "0141",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Medicine",
    "subdomain": "Clinical Trials",
    "family": "F7",
    "subtype": "Path-Specific Effects",
    "scenario": "A blood pressure drug reduces heart attacks by 30%. Researchers find the drug works through two mechanisms: directly lowering blood pressure, and anti-inflammatory effects on vessel walls. A patient who took the drug for 5 years without heart attack asks: 'If I had taken a pure blood-pressure drug without anti-inflammatory effects, would I still be protected?'",
    "counterfactual_claim": "If the patient had taken a drug that only lowers blood pressure (mechanism M1 only), without anti-inflammatory effects (no M2), heart attack prevention would be equivalent.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Blood pressure drug with dual mechanisms",
      "Y": "Heart attack prevention",
      "Z": [
        "M1: Blood pressure reduction pathway",
        "M2: Anti-inflammatory pathway",
        "Individual's baseline inflammation levels (unknown)"
      ]
    },
    "trap": {
      "type": "F7",
      "type_name": "Causal Attribution",
      "subtype": "Path-Specific Effects",
      "subtype_name": "Mechanism Decomposition"
    },
    "difficulty": "Medium",
    "causal_structure": "Drug(X) -> M1(blood pressure) -> Y and Drug(X) -> M2(inflammation) -> Y. Total effect decomposes into direct and indirect paths. Contribution of each path varies by individual baseline characteristics.",
    "key_insight": "Total treatment effect is sum of mechanism-specific effects. Without knowing individual's inflammation contribution, can't determine if M1 alone would suffice.",
    "hidden_timestamp": "The counterfactual asks about isolating mechanism M1 while removing M2. Answer depends on the relative contribution of each pathway for this individual.",
    "conditional_answers": {
      "answer_if_condition_1": "If this patient had high baseline inflammation (M2 pathway crucial), removing anti-inflammatory effects reduces protection substantiallycounterfactual INVALID.",
      "answer_if_condition_2": "If this patient had low inflammation (M1 dominates), blood pressure reduction alone might provide equivalent protectioncounterfactual VALID."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on this patient's individual pathway contributions. The drug's 30% population effect decomposes into M1 (blood pressure) and M2 (inflammation) effects. For individuals with high baseline inflammation, M2 is crucial; M1-only protection would be insufficient. For individuals with low inflammation, M1 may suffice. Without measuring this patient's inflammation levels or pathway-specific biomarkers, we can't determine which mechanisms were operative for them personally.",
    "gold_rationale": "CONDITIONAL on individual mechanism contributions. Total effect = Direct(M1) + Indirect(M2). Population level: both contribute, but individual variation exists. Scenario doesn't specify this patient's baseline inflammation or vessel pathology. To resolve: need individual pathway analysis (perhaps through mediation analysis with inflammation biomarkers). The counterfactual probes causal mechanism decomposition at individual level.",
    "invariants": [
      "Drug has two independent mechanisms: blood pressure reduction and anti-inflammatory effects",
      "Population-level: both mechanisms contribute to 30% risk reduction",
      "Individual patient's pathway contributions unknown (no inflammation or mechanism biomarkers measured)"
    ],
    "justification": "The total treatment effect aggregates multiple mechanisms. Individual attribution requires decomposing paths. Without individual-level mechanism data (inflammation markers, pathway activation), the counterfactual is underdetermined. Different baseline characteristics give different answers.",
    "wise_response": "CONDITIONAL. Depends on individual's inflammation contribution. High inflammation: M2 crucial (claim INVALID). Low inflammation: M1 may suffice (claim VALID). Need biomarkers to resolve.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0142",
    "case_id": "0142",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Law",
    "subdomain": "Tort Liability",
    "family": "F8",
    "subtype": "But-for Under Uncertainty",
    "scenario": "A pharmaceutical company sold a drug that increased heart attack risk from 1% to 3%. A patient who took the drug for 2 years had a heart attack. In civil litigation, the plaintiff must prove by preponderance of evidence that the drug caused their specific heart attack. The plaintiff's expert claims: 'The drug tripled the risk, so it more likely than not caused this patient's heart attack.'",
    "counterfactual_claim": "If the patient had not taken the drug, more likely than not (>50%), they would not have had a heart attack.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Drug exposure (2 years)",
      "Y": "Heart attack occurred",
      "Z": [
        "Baseline risk: 1%",
        "Drug-elevated risk: 3%",
        "Probability of causation calculation"
      ]
    },
    "trap": {
      "type": "F8",
      "type_name": "Moral and Legal Causation",
      "subtype": "But-for Under Uncertainty",
      "subtype_name": "Preponderance Standard with Probabilistic Evidence"
    },
    "difficulty": "Hard",
    "causal_structure": "Probability of causation = (P(Y|X) - P(Y|X)) / P(Y|X) = (0.03 - 0.01) / 0.03 = 2/3  67%. This exceeds 50%, but calculation requires proper Bayesian inference.",
    "key_insight": "Relative risk alone doesn't determine individual probability of causation. Must use: PC = (RR - 1) / RR formula. Here: PC = (3-1)/3 = 67%, which exceeds 50% threshold.",
    "hidden_timestamp": "The counterfactual asks about legal causation standard: whether drug 'more likely than not' caused this specific event, given population-level risk data.",
    "conditional_answers": {
      "answer_if_condition_1": "Using incorrect reasoning (RR>2 doesn't automatically mean >50% causation), claim appears INVALIDbackground risk is still 1%.",
      "answer_if_condition_2": "Using correct probability of causation formula: PC=(RR-1)/RR = 67% > 50%, so claim is actually VALID under legal preponderance standard."
    },
    "wise_refusal": "The counterfactual is VALID under proper probability of causation analysis, though the reasoning is subtle. The probability that the drug caused this specific heart attack is: PC = (Risk_exposed - Risk_unexposed) / Risk_exposed = (3% - 1%) / 3% = 2/3  67%. This exceeds the 50% preponderance threshold. While 1% of heart attacks would occur anyway (background risk), for any given exposed person who experiences the outcome, there's a 67% probability the drug was the cause. The expert's conclusion is correct, though the reasoning path requires explicit PC calculation.",
    "gold_rationale": "VALID under probability of causation framework. Given: baseline risk 1%, exposed risk 3%, RR=3.0. PC formula: (0.03-0.01)/0.03 = 0.67 = 67%. This exceeds legal preponderance standard (>50%). Among patients who took drug and had heart attacks, 2 of 3 attacks are attributable to drug, 1 of 3 to background causes. For this individual case, drug is more-likely-than-not cause. This is proper application of but-for causation under uncertainty in tort law.",
    "invariants": [
      "Baseline heart attack risk: 1% over 2 years",
      "Drug-elevated risk: 3% over 2 years (RR = 3.0)",
      "Legal standard: preponderance of evidence (>50% probability)",
      "No individual-specific risk factors mentioned beyond drug exposure"
    ],
    "justification": "Probability of causation = 67%, exceeding 50% preponderance threshold. Among drug users who have heart attacks, 2/3 are drug-caused, 1/3 background. This specific patient more likely than not falls into the drug-caused category. Legal standard met despite uncertainty about individual case.",
    "wise_response": "VALID. Probability of causation = (RR-1)/RR = 67%, exceeding 50% legal threshold. Drug is more-likely-than-not cause of this specific heart attack.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0143",
    "case_id": "0143",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Ethics",
    "subdomain": "Moral Philosophy",
    "family": "F8",
    "subtype": "Action vs Omission",
    "scenario": "A trolley is heading toward five people. You can pull a lever to divert it to a side track where it will kill one person instead. You don't pull the lever, and five people die. Afterward, someone claims: 'If you had pulled the lever, one person would have died, so you killed five people by inaction.' Standard moral theory distinguishes acts from omissions.",
    "counterfactual_claim": "If you had pulled the lever, five people would have been saved, therefore your inaction caused their deaths in the same way pulling the lever would have caused one death.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Pulling lever to divert trolley",
      "Y": "Five deaths on main track",
      "Z": [
        "Action vs omission distinction",
        "Causal structure: trolley already heading to five",
        "Moral responsibility framework"
      ]
    },
    "trap": {
      "type": "F8",
      "type_name": "Moral and Legal Causation",
      "subtype": "Action vs Omission",
      "subtype_name": "Doing Harm vs Allowing Harm"
    },
    "difficulty": "Medium",
    "causal_structure": "Trolley momentum -> Five deaths (default trajectory). Pulling lever(X) -> Diverts -> One death instead. Not pulling lever = allowing default causal process, not initiating new causal chain. Action/omission distinction: doing vs allowing.",
    "key_insight": "Causation for 'killing' requires initiating a causal process that leads to death. Omission lets existing causal process continue. Moral philosophy distinguishes these even when outcomes differ.",
    "hidden_timestamp": "The counterfactual equates causal responsibility for action (initiating death of one) with omission (allowing default process to kill five). Standard moral theory rejects this equivalence.",
    "conditional_answers": {
      "answer_if_condition_1": "Under consequentialist ethics (only outcomes matter), the claim has forceyou could have saved net four lives, so bear some responsibility.",
      "answer_if_condition_2": "Under deontological ethics (action/omission distinction matters), the claim is INVALIDyou didn't cause the five deaths; the trolley's momentum did. You merely declined to intervene."
    },
    "wise_refusal": "The counterfactual is INVALID under standard causal and moral frameworks that distinguish acts from omissions. Pulling the lever would initiate a new causal chain leading to one deathyou would be causally responsible for that death. Not pulling the lever allows the existing causal process (trolley momentum) to continueyou don't initiate the five deaths, you merely fail to prevent them. Consequentialists might say outcomes matter more than this distinction, but causally, there's a clear difference between doing and allowing. The claim conflates permitting a process with causing its outcome.",
    "gold_rationale": "INVALID. The five deaths result from the trolley's original trajectory, not from inaction. Omission allows an existing causal process; action initiates a new process. Standard framework: pulling lever causally responsible for one death (you diverted trolley); not pulling is not causally responsible for five (trolley was already heading there). Moral evaluation may differ (consequentialism vs deontology), but causal structure is clear: acts and omissions are asymmetric.",
    "invariants": [
      "Trolley was already heading toward five people before any decision point",
      "Default outcome (no intervention): five deaths",
      "Standard moral framework distinguishes doing vs allowing",
      "Your only options: pull lever (one dies) or don't pull (five die)"
    ],
    "justification": "Causal responsibility requires initiating a process leading to harm. Omission allows existing process to continue but doesn't cause its outcome. Action/omission asymmetry is standard in moral philosophy and law. The counterfactual claim wrongly equates them.",
    "wise_response": "INVALID. Not pulling the lever allows existing process to continue; doesn't cause deaths the way pulling would cause one death. Action/omission asymmetry applies.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.8,
    "validator_2": "Longling Geng",
    "final_score_2": 9.8
  },
  {
    "id": "T3-BucketD-0144",
    "case_id": "0144",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Public Health",
    "subdomain": "Epidemiology",
    "family": "F2",
    "subtype": "Probabilistic Exposure",
    "scenario": "A city introduced fluoridated water in 1970. Over 30 years, cavity rates in children dropped from 40% to 10%. However, dental hygiene education also improved, toothpaste became fluoridated, and sugar consumption decreased during this period. A dentist claims: 'If we had never fluoridated the water, cavity rates would still be 40% today.'",
    "counterfactual_claim": "If water had not been fluoridated, childhood cavity rates would remain at 40%.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Water fluoridation (1970)",
      "Y": "Childhood cavity rates (now 10%)",
      "Z": [
        "Improved dental education",
        "Fluoridated toothpaste adoption",
        "Reduced sugar consumption"
      ]
    },
    "trap": {
      "type": "F2",
      "type_name": "Probabilistic Counterfactual",
      "subtype": "Probabilistic Exposure",
      "subtype_name": "Multiple Concurrent Risk Reducers"
    },
    "difficulty": "Easy",
    "causal_structure": "Water fluoridation(X) + Education(Z1) + Toothpaste(Z2) + Diet(Z3)  Cavity reduction(Y). Multiple factors contribute. Removing only X doesn't restore 40% rate because Z1-Z3 remain active.",
    "key_insight": "Multiple interventions contributed to risk reduction. Removing one doesn't eliminate all benefit because others remain active.",
    "hidden_timestamp": "The counterfactual removes only water fluoridation while holding other public health improvements constant.",
    "conditional_answers": {
      "answer_if_condition_1": "If water fluoridation was the sole cause of cavity reduction, removing it would restore 40% ratesclaim VALID.",
      "answer_if_condition_2": "If multiple factors contributed (education, toothpaste, diet), removing only water fluoridation leaves substantial protectionclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID. While water fluoridation contributed to cavity reduction, multiple concurrent interventions also occurred: dental education programs, fluoridated toothpaste adoption, and reduced sugar consumption. These factors would remain in the counterfactual world. Studies estimate water fluoridation prevents 20-25% of cavities, so removing it would increase rates from 10% to approximately 12-13%, not back to 40%. The claim incorrectly attributes the entire 30-point reduction to water fluoridation alone.",
    "gold_rationale": "INVALID. Multiple sufficient causes for risk reduction. Water fluoridation removes ~20-25% risk (2-3 percentage points at current baseline). Other factors (education, toothpaste, diet) provide remaining protection. Counterfactual: cavity rate would be ~13%, not 40%. This demonstrates how attributing all benefit to one intervention ignores concurrent causal factors.",
    "invariants": [
      "Dental education improvements remain in counterfactual world",
      "Fluoridated toothpaste adoption remains (started 1980s)",
      "Dietary changes (reduced sugar) remain",
      "Water fluoridation prevents approximately 20-25% of cavities"
    ],
    "justification": "The 30-point cavity reduction resulted from multiple factors. Water fluoridation contributed but wasn't solely responsible. Removing X while holding Z1-Z3 constant yields small increase, not return to 40%. The claim fails because it ignores concurrent interventions.",
    "wise_response": "INVALID. Multiple factors caused the reduction. Removing only water fluoridation would increase cavities slightly (~13%), not restore 40% because other protections remain.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0145",
    "case_id": "0145",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Medicine",
    "subdomain": "Cardiology",
    "family": "F2",
    "subtype": "Background Risk",
    "scenario": "A 65-year-old patient takes aspirin daily to prevent heart attacks. After 10 years, they have not had a heart attack. They ask their doctor: 'If I had never taken aspirin, would I have had a heart attack by now?' The doctor explains that aspirin reduces heart attack risk from approximately 2% to 1.3% per year for this patient's profile, but many people never have heart attacks even without aspirin.",
    "counterfactual_claim": "If the patient had not taken aspirin, they would have had a heart attack by now.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Daily aspirin for 10 years",
      "Y": "No heart attack (Y=0)",
      "Z": [
        "Baseline risk: ~2% per year without aspirin",
        "Reduced risk: ~1.3% per year with aspirin",
        "10-year cumulative probability"
      ]
    },
    "trap": {
      "type": "F2",
      "type_name": "Probabilistic Counterfactual",
      "subtype": "Background Risk",
      "subtype_name": "Probabilistic Prevention vs Deterministic Outcome"
    },
    "difficulty": "Easy",
    "causal_structure": "Aspirin(X) reduces P(heart attack) from 18% to 12% over 10 years. Even without X, P(no heart attack) = 82%. Most people don't have attacks regardless of aspirin. Cannot conclude individual would have had attack.",
    "key_insight": "Risk reduction at population level doesn't mean any specific individual would have had the outcome without intervention. Background risk of no-event is high.",
    "hidden_timestamp": "The counterfactual asks about a specific individual's outcome when causation is probabilistic with high background rate of non-events.",
    "conditional_answers": {
      "answer_if_condition_1": "If aspirin was the only thing preventing this patient's heart attack (deterministic protection), the claim would be VALID.",
      "answer_if_condition_2": "If aspirin reduces risk probabilistically and most people don't have heart attacks anyway (82% without aspirin), the claim is INVALIDcan't conclude this patient would have had one."
    },
    "wise_refusal": "The counterfactual is INVALID. Aspirin reduces 10-year heart attack risk from ~18% to ~12% for this patient profile. Even without aspirin, 82% of similar patients don't have heart attacks over 10 years. We observe this patient didn't have an attack with aspirin, but we cannot conclude they would have had one without aspirinthey're probably in the majority who wouldn't experience one regardless. The claim incorrectly treats probabilistic risk reduction as deterministic individual protection.",
    "gold_rationale": "INVALID. Probabilistic causation with high background no-event rate. Without aspirin: P(no attack) = 82%. With aspirin: P(no attack) = 88%. Observing Y=0 doesn't identify individual as someone saved by aspirin vs someone who'd be fine anyway. Most likely explanation: patient is in the 82% who wouldn't have attack regardless. Cannot conclude counterfactual outcome from observed probabilistic protection.",
    "invariants": [
      "Baseline 10-year heart attack risk: ~18% (without aspirin)",
      "Aspirin reduces risk to ~12% (relative risk reduction ~33%)",
      "Individual-level susceptibility unknown",
      "Patient had no heart attack after 10 years with aspirin"
    ],
    "justification": "The patient avoided heart attack, but 82% do anyway without aspirin. Cannot attribute individual outcome to aspirin when background no-event rate is high. Probabilistic risk reduction doesn't imply this specific person was saved. The claim over-interprets population benefit as individual necessity.",
    "wise_response": "INVALID. Most people (82%) don't have heart attacks even without aspirin. Can't conclude this patient would have had onelikely in the majority who'd be fine regardless.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0146",
    "case_id": "0146",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Business",
    "subdomain": "Product Launch",
    "family": "F3",
    "subtype": "Symmetric Overdetermination",
    "scenario": "A product launch fails due to both inadequate marketing budget and a manufacturing defect discovered at launch. Post-mortem analysis shows either problem alone would have caused failure: the marketing budget was too small to reach critical mass, and the defect triggered returns and bad reviews independent of awareness. The marketing director claims: 'If we had funded marketing properly, the launch would have succeeded.'",
    "counterfactual_claim": "If the marketing budget had been adequate, the product launch would have succeeded.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X1": "Inadequate marketing budget",
      "X2": "Manufacturing defect",
      "Y": "Product launch failure",
      "Z": [
        "Critical mass requirements",
        "Product quality expectations",
        "Return/review mechanisms"
      ]
    },
    "trap": {
      "type": "F3",
      "type_name": "Overdetermination",
      "subtype": "Symmetric Overdetermination",
      "subtype_name": "Dual Sufficient Causes for Failure"
    },
    "difficulty": "Easy",
    "causal_structure": "Inadequate marketing(X1)  insufficient reach  failure(Y). Manufacturing defect(X2)  returns/bad reviews  failure(Y). Both sufficient for failure. Removing either leaves the other as sufficient cause.",
    "key_insight": "When two independent causes each suffice for failure, preventing one doesn't prevent the outcome because the other remains sufficient.",
    "hidden_timestamp": "The counterfactual removes inadequate marketing (X1) while holding the manufacturing defect (X2) as an invariant. With X2 present, failure still occurs.",
    "conditional_answers": {
      "answer_if_condition_1": "If only marketing was problematic and product quality was fine, adequate marketing would enable successclaim VALID.",
      "answer_if_condition_2": "If manufacturing defect was independently sufficient for failure, adequate marketing doesn't prevent failureclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID under overdetermination logic. While inadequate marketing was one cause of failure, the manufacturing defect was independently sufficient to cause failure through returns and negative reviews. Even with perfect marketing creating maximum awareness, the defect would trigger customer returns and bad reviews, causing the launch to fail. Removing the marketing problem while holding the defect constant doesn't prevent failure. This is classic overdeterminationboth causes were actual causes, but neither was necessary.",
    "gold_rationale": "INVALID. Symmetric overdetermination with two sufficient causes. X1(marketing)  failure and X2(defect)  failure. Post-mortem analysis confirmed each was independently sufficient. Counterfactual: remove X1, keep X2  still get failure via defect path. The marketing director's claim fails but-for test. Note: X1 was an actual cause (contributed to failure), just not a necessary cause (failure would occur without it).",
    "invariants": [
      "Manufacturing defect remains present in counterfactual world",
      "Defect was independently sufficient to cause failure (post-mortem confirmed)",
      "Marketing budget inadequacy was also independently sufficient",
      "Both causes operated independently (no interaction)"
    ],
    "justification": "The scenario explicitly states either problem alone would cause failure. Removing marketing inadequacy leaves manufacturing defect, which independently causes failure. Classic but-for test failure under overdetermination. Multiple sufficient causes present.",
    "wise_response": "INVALID. The manufacturing defect alone was sufficient to cause failure. Fixing marketing doesn't prevent failure because the defect remains and independently causes it.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0147",
    "case_id": "0147",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Sports",
    "subdomain": "Soccer",
    "family": "F3",
    "subtype": "Preemption",
    "scenario": "In a soccer match, the goalie is drawn out of position. Striker A shoots at the empty net from 10 yards. Simultaneously, Striker B shoots from 25 yards. Striker A's shot arrives first and scores. Replay analysis shows that if Striker A had missed, Striker B's shot would have arrived 0.5 seconds later and scored. Striker B claims: 'I scored that goal toomy shot would have gone in.'",
    "counterfactual_claim": "If Striker A had not taken the shot, Striker B's shot would have scored the goal.",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X1": "Striker A's shot (arrived first)",
      "X2": "Striker B's shot (arrived second)",
      "Y": "Goal scored",
      "Z": [
        "Empty net",
        "Timing: A's shot 0.5 seconds earlier",
        "Trajectory analysis confirms B would score"
      ]
    },
    "trap": {
      "type": "F3",
      "type_name": "Overdetermination",
      "subtype": "Preemption",
      "subtype_name": "Early Cause Preempts Backup Cause"
    },
    "difficulty": "Easy",
    "causal_structure": "Empty net + A's shot(X1)  goal(Y) immediately. B's shot(X2)  would cause goal 0.5s later. X1 preempts X2 by scoring first. Counterfactual: without X1, X2 completes its causal process and scores.",
    "key_insight": "Preemption occurs when an early cause prevents a backup cause from completing its causal process. Removing the preempting cause allows the backup to succeed.",
    "hidden_timestamp": "The counterfactual asks what would happen if the preempting cause (A's shot) were absent, allowing the backup cause (B's shot) to complete.",
    "conditional_answers": {
      "answer_if_condition_1": "If Striker A shoots, A's shot arrives first and scores, preempting B's shotB doesn't score.",
      "answer_if_condition_2": "If Striker A doesn't shoot, B's shot continues uninterrupted and scores 0.5s laterclaim VALID."
    },
    "wise_refusal": "The counterfactual is VALID under preemption logic. Striker A's shot preempted Striker B's shot by arriving first and scoring. Replay analysis confirms that B's shot was on target and would have scored if A's shot hadn't already done so. In the counterfactual world where A doesn't shoot, B's causal process completes: the ball continues to the empty net and scores 0.5 seconds later than it actually did. This is textbook preemptionA's earlier action prevented B's sufficient cause from manifesting.",
    "gold_rationale": "VALID. Preemption scenario: X1 (early cause) preempts X2 (backup cause). Both shots were on target for empty net. A scored first (actual cause), preempting B. Counterfactual: remove X1  X2's causal process completes  goal via B's shot. Timing difference doesn't matterboth sufficient for goal. This demonstrates how preempting causes block backup causes from manifesting, even though backup would have sufficed.",
    "invariants": [
      "Empty net (goalie out of position) held constant",
      "Striker B's shot was on target (replay confirmed)",
      "Timing: A's shot arrives 0.5 seconds before B's shot would arrive",
      "Both shots had clear path to goal"
    ],
    "justification": "Striker A preempted Striker B by scoring first. Without A's shot, B's sufficient cause completes and scores. The counterfactual is straightforward: backup cause succeeds when preempting cause is removed. Replay evidence confirms B's trajectory was goal-bound.",
    "wise_response": "VALID. A's shot preempted B's shot by arriving first. Without A's shot, B's shot would continue and score 0.5 seconds later.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0148",
    "case_id": "0148",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Environment",
    "subdomain": "Climate",
    "family": "F3",
    "subtype": "Threshold Effects",
    "scenario": "A coral reef experiences bleaching when water temperature exceeds 30C for sustained periods. This year, three factors contributed to reaching 30.5C: El Nio added 0.3C, climate change added 0.4C, and a local heat wave added 0.2C. The baseline temperature was 29.6C. An environmentalist claims: 'Climate change caused the bleachingwithout it, we'd be under the threshold.'",
    "counterfactual_claim": "If climate change had not warmed waters by 0.4C, coral bleaching would not have occurred.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X1": "El Nio contribution (+0.3C)",
      "X2": "Climate change contribution (+0.4C)",
      "X3": "Local heat wave (+0.2C)",
      "Y": "Coral bleaching (threshold: 30C)",
      "Z": [
        "Baseline temperature: 29.6C",
        "Actual temperature: 30.5C",
        "Threshold effect at 30C"
      ]
    },
    "trap": {
      "type": "F3",
      "type_name": "Overdetermination",
      "subtype": "Threshold Effects",
      "subtype_name": "Multiple Factors Jointly Exceed Threshold"
    },
    "difficulty": "Medium",
    "causal_structure": "Baseline(29.6C) + X1(+0.3) + X2(+0.4) + X3(+0.2) = 30.5C > 30C threshold  bleaching(Y). Multiple combinations of two factors sufficient to exceed threshold. Answer depends on which factors are held fixed in counterfactual.",
    "key_insight": "When multiple factors jointly push a system past a threshold, removing one factor may or may not prevent the outcome depending on which other factors remain active.",
    "hidden_timestamp": "The counterfactual removes X2 (climate change) but must specify whether X1 and X3 remain active. Different invariant choices give different answers.",
    "conditional_answers": {
      "answer_if_condition_1": "If only X2 is removed and X1+X3 remain: 29.6 + 0.3 + 0.2 = 30.1C, still exceeds 30C threshold  bleaching occurs  claim INVALID.",
      "answer_if_condition_2": "If the counterfactual world has neither El Nio nor heat wave (unnatural interpretation): 29.6 + 0 = 29.6C, under threshold  no bleaching  claim VALID."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on which factors remain active. If we remove only climate change (0.4C) but El Nio and the heat wave remain, temperature is 29.6 + 0.3 + 0.2 = 30.1C, still exceeding the 30C thresholdbleaching would still occur. However, if the counterfactual world also lacks El Nio or the heat wave (perhaps interpreting 'without climate change' as a cooler baseline world), bleaching might not occur. The scenario doesn't specify these invariants, making the answer underdetermined.",
    "gold_rationale": "CONDITIONAL on invariants. Most natural interpretation: remove X2, keep X1 and X3 (natural variation)  30.1C  still bleaches  INVALID. Alternative interpretation: counterfactual world has cooler baseline or no El Nio  under 30C  VALID. Need explicit specification: Are X1 and X3 natural variations that occur independent of X2? If yes, claim INVALID. If climate change somehow enabled the heat wave, claim might be VALID.",
    "invariants": [
      "Bleaching threshold: 30C (sustained)",
      "Actual temperature: 30.5C (29.6 + 0.3 + 0.4 + 0.2)",
      "Whether El Nio and heat wave are independent of climate change: UNSPECIFIED",
      "Whether to hold X1 and X3 fixed when removing X2: UNSPECIFIED"
    ],
    "justification": "Multiple sufficient combinations for exceeding threshold. X2 alone is insufficient (29.6 + 0.4 = 30.0, exactly at threshold). X1+X3 combination sufficient even without X2. Answer depends on whether X1 and X3 are held fixed in counterfactual. The scenario doesn't specify, making it underdetermined.",
    "wise_response": "CONDITIONAL. If El Nio and heat wave remain (30.1C), bleaching still occursclaim INVALID. If these are somehow removed too, temperature drops below thresholdclaim VALID. Needs invariant specification.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0149",
    "case_id": "0149",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Military",
    "subdomain": "Defense Strategy",
    "family": "F4",
    "subtype": "Trigger vs Structure",
    "scenario": "In 1914, Archduke Franz Ferdinand's assassination triggered World War I. However, historians note that pre-existing conditions made major European war likely: alliance systems, militarism, imperialism, nationalism, and arms races created a volatile system where any incident could spark conflict. One historian claims: 'If the assassination hadn't happened, WWI wouldn't have occurred.'",
    "counterfactual_claim": "If Archduke Franz Ferdinand had not been assassinated, World War I would not have occurred.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Assassination of Franz Ferdinand (June 1914)",
      "Y": "World War I",
      "Z": [
        "Alliance systems (Triple Alliance, Triple Entente)",
        "Arms races and militarism",
        "Imperial competition",
        "Nationalist tensions"
      ]
    },
    "trap": {
      "type": "F4",
      "type_name": "Structural vs Contingent",
      "subtype": "Trigger vs Structure",
      "subtype_name": "Spark vs Powder Keg"
    },
    "difficulty": "Medium",
    "causal_structure": "Structural tensions(Z)  system instability  war highly probable. Assassination(X) was sufficient trigger but not necessaryany major incident could have served as spark. Structure made war inevitable; only timing and specific trigger were contingent.",
    "key_insight": "When structural conditions make an outcome inevitable, the specific trigger is replaceable. Preventing one trigger doesn't prevent the outcome because the structure will find another trigger.",
    "hidden_timestamp": "The counterfactual asks if preventing the proximate trigger prevents war when structural conditions make war structurally determined.",
    "conditional_answers": {
      "answer_if_condition_1": "If the assassination was the only problem and Europe was otherwise peaceful, preventing it avoids warclaim VALID.",
      "answer_if_condition_2": "If structural conditions made war inevitable and only the specific trigger was contingent, preventing this assassination delays but doesn't prevent warclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID under structural causation analysis. European powers had created a volatile system by 1914: rigid alliance systems meant a local conflict would escalate, arms races created militarism and war preparedness, imperial competition generated tensions, and nationalism inflamed populations. These structural conditions made major war highly probableif not triggered by the assassination, then by another incident within months. Historical analysis suggests alternative triggers: Moroccan crisis, Balkan conflicts, naval incidents. The assassination was sufficient but not necessary; the structure was determinative.",
    "gold_rationale": "INVALID. Structural inevitability vs contingent trigger. Pre-1914 Europe: alliance systems created automaticity, arms races made war plans ready, imperial/nationalist tensions abundant. These structural conditions made major war inevitable within 1-2 years. Assassination was a trigger, not root cause. Counterfactual: without assassination, different incident (Morocco, Balkans, naval race) triggers war in 1914-1915. This distinguishes structural (necessary) from contingent (replaceable) causes.",
    "invariants": [
      "Alliance systems remain unchanged (Triple Alliance, Triple Entente)",
      "Arms races and war plans remain in place",
      "Imperial competition and nationalist tensions remain",
      "Balkan instability and other potential triggers remain"
    ],
    "justification": "Structural conditions made war highly probable. Preventing one trigger doesn't remove structural inevitability. Historical consensus: war would have occurred via different trigger if not assassination. Classic trigger-vs-structure distinction where structure is determinative.",
    "wise_response": "INVALID. Structural tensions made war inevitable. Without the assassination, another incident would have triggered it within monthsthe structure was the cause, not the trigger.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0150",
    "case_id": "0150",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Technology",
    "subdomain": "Software Development",
    "family": "F4",
    "subtype": "Trigger vs Structure",
    "scenario": "A software project fails to meet its deadline after a key developer quits unexpectedly. However, the project was already behind schedule due to poor planning, unrealistic timelines, inadequate staffing, and technical debt. The project manager blames the developer's departure: 'If Sarah hadn't quit, we would have delivered on time.'",
    "counterfactual_claim": "If the key developer had not quit, the project would have met its deadline.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Key developer resignation",
      "Y": "Missed deadline",
      "Z": [
        "Already 3 weeks behind before resignation",
        "Unrealistic initial timeline",
        "Understaffing (team size insufficient)",
        "Technical debt from rushed decisions"
      ]
    },
    "trap": {
      "type": "F4",
      "type_name": "Structural vs Contingent",
      "subtype": "Trigger vs Structure",
      "subtype_name": "Proximate Event Blamed for Structural Problems"
    },
    "difficulty": "Easy",
    "causal_structure": "Structural problems(Z)  project was failing trajectory. Developer resignation(X) accelerated failure but didn't cause it. Without X, structural issues still lead to missed deadline, just slightly later.",
    "key_insight": "When structural problems doom a project, a proximate disruption is often blamed even though the outcome was determined by underlying issues.",
    "hidden_timestamp": "The counterfactual asks if preventing the resignation saves the deadline when structural problems already made failure likely.",
    "conditional_answers": {
      "answer_if_condition_1": "If the project was on track before resignation and developer departure was the only problem, keeping Sarah enables on-time deliveryclaim VALID.",
      "answer_if_condition_2": "If project was already failing due to structural problems (behind schedule, understaffed, poor planning), keeping Sarah delays but doesn't prevent deadline missclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID. The project was already 3 weeks behind schedule before the developer quit, with structural problems: unrealistic timeline, inadequate staffing, and technical debt. These conditions made deadline failure inevitable. The developer's departure accelerated the timeline slip but didn't cause it. Even with the developer staying, the structural constraints would have caused a delay of 2-4 weeks based on the existing deficit and resource constraints. The project manager's claim scapegoats the resignation instead of addressing root causes.",
    "gold_rationale": "INVALID. Structural causation dominates. Project was behind schedule before X occurred. Understaffing and timeline problems were root causes. Developer resignation was trigger that made existing failure visible earlier. Counterfactual: with developer staying, project still misses deadline due to structural issues, just by 2 weeks instead of 5. Classic attribution error: blaming proximate event when structure determined outcome.",
    "invariants": [
      "Project was 3 weeks behind schedule before resignation",
      "Timeline was unrealistic given scope and resources",
      "Team was understaffed for project complexity",
      "Technical debt accumulated from rushed decisions"
    ],
    "justification": "Structural problems (behind schedule, understaffed, technical debt) made deadline failure inevitable. Developer resignation accelerated but didn't cause failure. Even without resignation, structural constraints lead to missed deadline. The claim incorrectly attributes structural failure to contingent trigger.",
    "wise_response": "INVALID. Project was already failing from structural problems (behind schedule, understaffed). Developer's resignation accelerated failure but didn't cause itdeadline would be missed anyway.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0151",
    "case_id": "0151",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Business",
    "subdomain": "Supply Chain",
    "family": "F5",
    "subtype": "Timing Windows",
    "scenario": "A retailer ordered Christmas inventory in August at favorable prices. A global shipping crisis in October caused delays and price spikes. Their competitors who ordered in October paid 40% more and received goods late, missing peak sales. The retailer's CFO claims: 'Our August timing saved the holiday season.'",
    "counterfactual_claim": "If the retailer had ordered inventory in October instead of August, they would have experienced the same delays and cost increases as competitors.",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X": "August inventory order timing",
      "Y": "Successful holiday season (on-time delivery, favorable pricing)",
      "Z": [
        "October shipping crisis (delays, 40% price spike)",
        "Competitors' October orders affected",
        "Time-sensitive holiday sales window"
      ]
    },
    "trap": {
      "type": "F5",
      "type_name": "Temporal and Path-Dependent",
      "subtype": "Timing Windows",
      "subtype_name": "Critical Window Advantage"
    },
    "difficulty": "Easy",
    "causal_structure": "August order(X)  pre-crisis inventory secured  favorable pricing + on-time delivery  successful season(Y). October order(X)  crisis-affected  high prices + delays  poor season. Time-varying environment makes timing critical.",
    "key_insight": "When external conditions change over time, early action can avoid later problems. Timing creates different causal pathways to outcomes.",
    "hidden_timestamp": "The counterfactual asks what would happen if the order were placed in October's time-varying environment instead of August's stable environment.",
    "conditional_answers": {
      "answer_if_condition_1": "If the shipping crisis affected all order times equally, October ordering wouldn't differ from Augustclaim INVALID.",
      "answer_if_condition_2": "If the crisis specifically impacted October+ orders while August orders were locked in, October ordering would face delays and costsclaim VALID."
    },
    "wise_refusal": "The counterfactual is VALID. The August order locked in pricing and shipping capacity before the October crisis. If the retailer had waited until October, they would have faced the same conditions as competitors: 40% price increases, limited shipping capacity, and delays. The crisis affected all October orders regardless of retailer identityit was a time-varying environmental change. The August timing was causally important because it secured resources before scarcity developed. This is straightforward timing-window causation.",
    "gold_rationale": "VALID. Time-varying external conditions (shipping crisis in October) create path dependence. August ordering locks in pre-crisis conditions. October ordering faces post-crisis conditions (verified by competitors' experience). Counterfactual is straightforward: delaying order from August to October  exposed to October crisis  same delays and costs as competitors experienced. Timing window closed between August and October.",
    "invariants": [
      "Shipping crisis occurred in October (affected all October orders)",
      "Crisis caused 40% price increases and delivery delays",
      "August orders were unaffected (already contracted)",
      "Retailer identity doesn't exempt from crisis (competitors' experience proves this)"
    ],
    "justification": "External environment changed between August and October. August ordering avoided crisis; October ordering would face crisis. Competitors' actual experience proves October orders faced problems. Counterfactual outcome clear: October order  crisis exposure  delays and high costs.",
    "wise_response": "VALID. August timing avoided October shipping crisis. Delaying to October would expose retailer to same crisis conditions competitors faceddelays and 40% cost increase.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0152",
    "case_id": "0152",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Healthcare",
    "subdomain": "Emergency Medicine",
    "family": "F5",
    "subtype": "Timing Windows",
    "scenario": "A stroke patient received clot-busting medication at 2 hours after symptom onset. Guidelines specify that tPA is effective within a 3-hour window but ineffective or dangerous after 4.5 hours due to increased bleeding risk. The patient recovered fully. A family member asks: 'If treatment had been delayed until 5 hours, would my loved one have recovered?'",
    "counterfactual_claim": "If tPA treatment had been delayed until 5 hours after symptom onset, the patient would have achieved the same full recovery.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "tPA at 2 hours post-symptom",
      "Y": "Full recovery from stroke",
      "Z": [
        "Effective treatment window: 0-4.5 hours",
        "Optimal window: 0-3 hours",
        "Increased bleeding risk after 4.5 hours",
        "Progressive brain damage over time"
      ]
    },
    "trap": {
      "type": "F5",
      "type_name": "Temporal and Path-Dependent",
      "subtype": "Timing Windows",
      "subtype_name": "Critical Window Expiration"
    },
    "difficulty": "Easy",
    "causal_structure": "Within window: tPA(X at 2hrs)  clot dissolution  blood flow restored  recovery(Y). Outside window: tPA(X at 5hrs)  ineffective + bleeding risk  poor outcome. Time-sensitive mechanism makes early treatment necessary.",
    "key_insight": "When interventions have critical time windows, delaying past the window changes the mechanism from beneficial to ineffective or harmful.",
    "hidden_timestamp": "The counterfactual delays treatment from within the effective window (2 hours) to outside the window (5 hours), changing the causal mechanism.",
    "conditional_answers": {
      "answer_if_condition_1": "If treatment timing doesn't matter and tPA is equally effective at any time, 5-hour delay wouldn't affect outcomeclaim VALID.",
      "answer_if_condition_2": "If tPA has a critical window (effective 0-4.5hrs, dangerous after), 5-hour delay misses window and prevents recoveryclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID. tPA must be administered within 4.5 hours to be effectiveafter this window, clot dissolution is ineffective and bleeding risk increases substantially. Treatment at 2 hours was within the optimal window (0-3 hours), enabling full recovery. At 5 hours (30 minutes past the 4.5-hour cutoff), tPA would be contraindicated due to bleeding risk and inefficacy. Brain damage is progressiveby 5 hours, significant irreversible damage would have occurred. The patient would not have achieved full recovery; more likely outcome is significant disability or death.",
    "gold_rationale": "INVALID. Time-dependent mechanism with critical window. Within window (2 hours): tPA effective, restores blood flow, limits damage. Outside window (5 hours): tPA ineffective, bleeding risk high, progressive damage irreversible. Medical evidence: treatment after 4.5 hours increases mortality without improving outcomes. Counterfactual: 5-hour delay  no treatment given (contraindicated)  permanent brain damage  not full recovery. Timing was mechanistically necessary.",
    "invariants": [
      "tPA effective window: 0-4.5 hours after stroke onset",
      "Optimal window: 0-3 hours",
      "After 4.5 hours: treatment contraindicated (bleeding risk)",
      "Brain damage progresses irreversibly over time without blood flow"
    ],
    "justification": "Medical mechanism has time-dependent efficacy. Treatment at 2 hours works; at 5 hours it's contraindicated. Brain damage is time-progressive and irreversible. Delaying past critical window eliminates treatment option and allows permanent damage. Counterfactual outcome: significant disability or death, not full recovery.",
    "wise_response": "INVALID. tPA has a 4.5-hour window. At 5 hours, treatment is contraindicated due to bleeding risk, and brain damage would be irreversibleno full recovery possible.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0153",
    "case_id": "0153",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Psychology",
    "subdomain": "Behavioral Science",
    "family": "F6",
    "subtype": "Mechanism Dependence",
    "scenario": "A therapy patient improves significantly after 12 weeks of treatment. The therapist cannot determine whether improvement came from: the specific therapeutic techniques used, the therapeutic relationship and attention, placebo effects, or natural recovery over time. A friend asks: 'If you hadn't done therapy, would you have gotten better?'",
    "counterfactual_claim": "If the patient had not received therapy, they would not have improved.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Therapy treatment (12 weeks)",
      "Y": "Significant improvement",
      "Z": [
        "Therapeutic techniques (mechanism unclear)",
        "Therapeutic relationship/attention",
        "Placebo effects",
        "Natural recovery trajectory"
      ]
    },
    "trap": {
      "type": "F6",
      "type_name": "Epistemic Limits",
      "subtype": "Mechanism Dependence",
      "subtype_name": "Unknown Causal Pathway"
    },
    "difficulty": "Medium",
    "causal_structure": "Therapy(X)  improvement(Y), but mechanism unclear: specific techniques, relationship, placebo, or time. Counterfactual answer depends on which mechanism was operative. If natural recovery, Y would occur without X. If specific techniques necessary, Y requires X.",
    "key_insight": "When multiple causal mechanisms could explain an outcome and we don't know which operated, counterfactual claims are underdetermined.",
    "hidden_timestamp": "The counterfactual asks about necessity of treatment when we don't know which of several mechanisms (including natural recovery) caused improvement.",
    "conditional_answers": {
      "answer_if_condition_1": "If improvement resulted from specific therapeutic techniques or active therapeutic relationship, treatment was necessaryclaim VALID.",
      "answer_if_condition_2": "If improvement resulted from natural recovery over time or placebo effects, improvement would occur without treatmentclaim INVALID."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on which mechanism caused improvement. Therapy involves multiple potential active ingredients: specific techniques, therapeutic relationship, placebo/expectancy effects, and provides time for natural recovery. Without knowing which mechanism was operative, we cannot determine if improvement required therapy. If the patient had high placebo responsiveness or was on a natural recovery trajectory, improvement might occur without therapy. If specific techniques or the therapeutic relationship were necessary, therapy was required. The scenario explicitly states the mechanism is unknown.",
    "gold_rationale": "CONDITIONAL on unknown mechanism. Four possible paths: (1) Specific techniquesY (requires therapy), (2) Relationship/attentionY (requires some therapeutic contact), (3) PlaceboY (requires treatment expectancy), (4) Natural recoveryY (time sufficient). Without knowing which operated, counterfactual is underdetermined. To resolve: need controlled trial data separating active treatment from natural recovery, or individual mechanism markers. This demonstrates epistemic limits when mechanisms are observationally equivalent.",
    "invariants": [
      "Patient received therapy and improved",
      "Multiple potential causal mechanisms present",
      "No mechanism markers or controlled comparison available",
      "Natural recovery occurs in some untreated patients"
    ],
    "justification": "Improvement occurred with therapy but mechanism unknown. Multiple sufficient pathways exist, including natural recovery. Cannot determine counterfactual outcome without knowing which mechanism was operative. Different mechanisms give different answers. Epistemic limitation inherent in observational single-case analysis.",
    "wise_response": "CONDITIONAL. Improvement could result from active therapy mechanisms (VALID claim) or natural recovery over time (INVALID claim). Without knowing which mechanism operated, cannot determine counterfactual outcome.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0154",
    "case_id": "0154",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Philosophy",
    "subdomain": "Personal Identity",
    "family": "F6",
    "subtype": "Non-identity",
    "scenario": "A couple conceives a child in January. Their child is born in October with a genetic condition. They wonder: 'If we had waited to conceive in February, would our child have been born without the genetic condition?' A philosopher notes that a February conception would result in a completely different genetic combinationliterally a different individual. The 'same child' wouldn't exist to be healthy or unhealthy.",
    "counterfactual_claim": "If the couple had waited one month to conceive, the same child would have been born without the genetic condition.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "January conception timing",
      "Y": "Child born with genetic condition",
      "Z": [
        "Genetic combination from specific sperm-egg pair",
        "Different timing = different genetic combination",
        "Personal identity grounded in genetic makeup"
      ]
    },
    "trap": {
      "type": "F6",
      "type_name": "Epistemic Limits",
      "subtype": "Non-identity",
      "subtype_name": "Counterfactual Changes Identity"
    },
    "difficulty": "Easy",
    "causal_structure": "January conception(X)  specific genetic combination  child with identity I1 and condition(Y). Different timing  different sperm-egg combination  different child (I2), not I1 without condition. Identity depends on genetic origins.",
    "key_insight": "When counterfactual changes the identity of the individual, cannot ask what would have happened to 'the same person' because that person wouldn't exist.",
    "hidden_timestamp": "The counterfactual asks about 'the same child' in a scenario where identity-constituting facts (genetic makeup) would differ.",
    "conditional_answers": {
      "answer_if_condition_1": "If personal identity is independent of genetic makeup and only parentage matters, the 'same child' could exist with different genesclaim might be VALID.",
      "answer_if_condition_2": "If personal identity depends on genetic makeup (standard biological view), different conception time creates different individualclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID due to the non-identity problem. Personal identity is typically grounded in genetic makeupthe specific sperm-egg combination that formed this individual. A February conception would involve a different sperm meeting the egg (or different egg entirely), creating a genetically different individual. This wouldn't be 'the same child without the condition'it would be a different child (potentially healthy, potentially with different conditions). The question 'would our child have been healthy?' contains a false premise: there is no 'same child' in the February counterfactual.",
    "gold_rationale": "INVALID. Non-identity problem: counterfactual changes identity-constituting facts. This child's identity depends on genetic makeup from this specific conception event. Different timing  different genetic combination  different individual. Can ask: 'Would we have had a healthy child if we conceived in February?' (answer: possibly). Cannot ask: 'Would this child have been healthy?' (answer: incoherentthis child wouldn't exist). This demonstrates how some counterfactuals are metaphysically problematic when they presuppose identity persistence across identity-changing interventions.",
    "invariants": [
      "Personal identity grounded in genetic makeup (standard biological view)",
      "Different conception timing produces different genetic combinations",
      "Genetic condition results from specific genetic makeup of this conception",
      "No 'same person' exists across substantially different genetic origins"
    ],
    "justification": "Identity depends on genetic origins. Changing conception timing changes genetic makeup, changing identity. Cannot meaningfully ask what would happen to 'the same child' because that individual wouldn't exist in the counterfactual. The claim presupposes identity persistence that violates identity conditions.",
    "wise_response": "INVALID. Different conception timing would produce a different child (different genetic makeup). Cannot ask about 'the same child' in a scenario where that individual wouldn't exist.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0155",
    "case_id": "0155",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Public Health",
    "subdomain": "Vaccination",
    "family": "F7",
    "subtype": "Attributable Fraction",
    "scenario": "A measles vaccination program achieves 95% coverage in a region. Measles cases drop from 1,000 per year to 20 per year. Public health officials calculate that herd immunity at 95% coverage prevents most transmission. Of the 20 cases that still occurred, 15 were in unvaccinated children and 5 were vaccine failures. Officials claim: 'The vaccination program prevented 980 measles cases this year.'",
    "counterfactual_claim": "If the vaccination program had not achieved 95% coverage, 1,000 measles cases would have occurred (the program prevented 980 cases).",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X": "95% vaccination coverage",
      "Y": "Measles cases reduced from 1,000 to 20",
      "Z": [
        "Herd immunity threshold",
        "Transmission dynamics",
        "Population-level indirect protection"
      ]
    },
    "trap": {
      "type": "F7",
      "type_name": "Causal Attribution",
      "subtype": "Attributable Fraction",
      "subtype_name": "Population-Level Prevention Attribution"
    },
    "difficulty": "Easy",
    "causal_structure": "95% coverage(X)  herd immunity  transmission reduction  980 fewer cases. Attributable cases = baseline(1,000) - observed(20) = 980. Herd immunity effect is well-established for measles. Counterfactual without X returns to baseline transmission.",
    "key_insight": "Population-level interventions that reduce disease transmission can be validly attributed based on difference between baseline and observed rates when mechanism is established.",
    "hidden_timestamp": "The counterfactual asks about cases prevented by comparing actual outcome (with 95% coverage) to expected baseline (without program).",
    "conditional_answers": {
      "answer_if_condition_1": "If vaccination was the only change and baseline transmission dynamics were stable, attributable cases = 980claim VALID.",
      "answer_if_condition_2": "If other factors also reduced measles (hygiene, nutrition, healthcare), some reduction would occur without vaccinationclaim might overstate impact."
    },
    "wise_refusal": "The counterfactual is VALID for measles vaccination under stated conditions. Measles is highly transmissible (R0=12-18) and requires ~95% coverage for herd immunity. The scenario specifies 95% coverage was achieved and cases dropped from 1,000 to 20. Without the program, transmission dynamics would return to baseline, yielding approximately 1,000 cases (the pre-vaccination rate). The 980-case difference is validly attributable to vaccination because: (1) mechanism is established (herd immunity breaks transmission chains), (2) baseline is specified, (3) no other major interventions noted. This is straightforward attributable fraction calculation.",
    "gold_rationale": "VALID. Population attributable fraction: (Baseline - Observed) = (1,000 - 20) = 980 cases prevented. Mechanism: 95% coverage achieves herd immunity for measles  transmission chains broken  population-level protection. Counterfactual: without program, return to pre-vaccination baseline (1,000 cases/year). This is valid because: (1) measles epidemiology well-understood, (2) herd immunity threshold precisely known, (3) baseline specified, (4) no confounders mentioned. Simple, well-justified population-level attribution.",
    "invariants": [
      "Measles baseline: 1,000 cases/year pre-vaccination",
      "Measles R0: 12-18 (highly transmissible)",
      "Herd immunity threshold: ~95% coverage",
      "Current coverage: 95%, current cases: 20/year",
      "No other major interventions mentioned"
    ],
    "justification": "Measles vaccination preventing 980 cases is valid attribution. Baseline established, mechanism known, coverage achieved, dramatic reduction observed. Counterfactual return to baseline is justified for infectious disease with established epidemiology. Attributable fraction calculation is straightforward and appropriate.",
    "wise_response": "VALID. With 95% coverage achieving herd immunity, cases dropped from 1,000 to 20. Without program, measles would return to baseline transmission980 cases prevented is valid attribution.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0156",
    "case_id": "0156",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Law",
    "subdomain": "Product Liability",
    "family": "F8",
    "subtype": "But-for Under Uncertainty",
    "scenario": "A pharmaceutical company's painkiller doubled stroke risk from 0.5% to 1%. A patient who took the drug for 1 year had a stroke. In civil court, plaintiff must prove by preponderance of evidence that the drug caused this specific stroke. Defense argues: 'Even without our drug, patient had 0.5% stroke riskwe cannot prove this stroke wouldn't have happened anyway.' Plaintiff's expert calculates probability of causation =/RR = 0.50.",
    "counterfactual_claim": "If the patient had not taken the drug, more likely than not (>50%), they would not have had a stroke.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Painkiller exposure (1 year)",
      "Y": "Stroke occurred",
      "Z": [
        "Baseline risk: 0.5%",
        "Drug-elevated risk: 1.0%",
        "Relative risk: 2.0",
        "Probability of causation: 50%"
      ]
    },
    "trap": {
      "type": "F8",
      "type_name": "Moral and Legal Causation",
      "subtype": "But-for Under Uncertainty",
      "subtype_name": "Preponderance Threshold Not Met"
    },
    "difficulty": "Medium",
    "causal_structure": "Drug(X) doubles risk: 0.5%  1.0%. Probability of causation = (RR-1)/RR = (2-1)/2 = 0.50 = 50%. This equals preponderance threshold (>50%) exactly but doesn't exceed it. Legal standard typically requires strictly greater than 50%.",
    "key_insight": "Probability of causation at exactly 50% creates equipoisedrug-caused and background-caused strokes are equally likely. Most jurisdictions require >50% (strictly greater) for preponderance standard.",
    "hidden_timestamp": "The counterfactual asks if it's 'more likely than not' patient wouldn't have had stroke without drug, using legal preponderance standard (>50%).",
    "conditional_answers": {
      "answer_if_condition_1": "If probability of causation >50%, preponderance standard is metclaim VALID.",
      "answer_if_condition_2": "If probability of causation = 50% (as here) or <50%, preponderance standard not metclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID under strict preponderance standard. Probability of causation = (RR-1)/RR = (2-1)/2 = 50%. This means that among patients who took the drug and had strokes, 50% are drug-caused and 50% are background-caused. This creates equipoisethe stroke is equally likely to be drug-caused or background-caused. The preponderance standard requires 'more likely than not,' typically interpreted as strictly >50%, not 50%. At exactly 50%, the plaintiff has not met their burden of proof. Some jurisdictions might accept 50% as sufficient, but most require exceeding the threshold.",
    "gold_rationale": "INVALID under strict preponderance interpretation. PC = 50% means equipoise between drug-caused and background-caused. Preponderance standard: 'more likely than not' = >50% (strictly). At 50%, neither cause is more likely. Legal standards vary: some accept 50%, most require >50%. Under standard interpretation (>50% required), claim fails. This demonstrates the threshold problem in probabilistic causationdoubling risk may be insufficient for legal causation if baseline risk is substantial.",
    "invariants": [
      "Baseline stroke risk: 0.5% per year",
      "Drug increases risk to: 1.0% per year (RR = 2.0)",
      "Probability of causation: (2-1)/2 = 50%",
      "Legal standard: preponderance (>50% required)",
      "Patient took drug and had stroke"
    ],
    "justification": "PC = 50% creates equipoise between drug-caused and background-caused. Preponderance requires >50% (strictly greater). At exactly 50%, plaintiff hasn't proven it's more likely the drug caused the stroke than not. Standard legal interpretation: 50% is insufficient, need >50%. Claim fails threshold.",
    "wise_response": "INVALID. Probability of causation is exactly 50%equipoise between drug-caused and background-caused. Preponderance requires >50% (strictly), so legal standard not met.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0157",
    "case_id": "0157",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Ethics",
    "subdomain": "Moral Philosophy",
    "family": "F8",
    "subtype": "Moral Luck",
    "scenario": "Two drivers text while driving. Driver A's distraction causes no accidenta pedestrian wasn't crossing at that moment. Driver B's identical distraction causes them to hit a pedestrian who was crossing, causing serious injury. Both drivers took the same risk and had identical mens rea, but outcomes differed due to luck. Society punishes Driver B severely while Driver A receives a traffic ticket. A philosopher asks: 'If the pedestrian had been crossing in front of Driver A, would Driver A be equally morally culpable?'",
    "counterfactual_claim": "If a pedestrian had been crossing in front of Driver A, Driver A would be equally morally culpable as Driver B.",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Texting while driving (both drivers)",
      "Y1": "No accident (Driver A)",
      "Y2": "Pedestrian injury (Driver B)",
      "Z": [
        "Pedestrian presence (luck)",
        "Identical reckless behavior",
        "Different outcomes due to circumstance"
      ]
    },
    "trap": {
      "type": "F8",
      "type_name": "Moral and Legal Causation",
      "subtype": "Moral Luck",
      "subtype_name": "Identical Actions, Different Outcomes"
    },
    "difficulty": "Easy",
    "causal_structure": "Identical reckless action(X) + pedestrian presence(luck)  serious outcome(Y2) or no outcome(Y1). Moral culpability should depend on act and mens rea, not luck. Counterfactual: if A faced same circumstances, same culpability.",
    "key_insight": "Moral luck occurs when moral evaluation depends on factors beyond agent's control. Identical reckless actions should carry identical moral culpability regardless of lucky or unlucky outcomes.",
    "hidden_timestamp": "The counterfactual asks if Driver A would be equally culpable if they had faced the same unlucky circumstances as Driver B.",
    "conditional_answers": {
      "answer_if_condition_1": "If moral culpability depends on outcomes and harm caused, different outcomes justify different moral judgmentsclaim INVALID.",
      "answer_if_condition_2": "If moral culpability depends on intentions, recklessness, and acts (not luck), identical actions deserve identical moral evaluationclaim VALID."
    },
    "wise_refusal": "The counterfactual is VALID from the standpoint of moral philosophy that rejects outcome-based moral luck. Both drivers performed identically reckless actions (texting while driving) with identical mental states (conscious disregard for risk). The only difference was circumstantial luckwhether a pedestrian happened to be present. Standard moral theory holds that agents are responsible for their choices and foreseeability, not for factors beyond their control. If Driver A had faced a pedestrian (identical circumstances), their moral culpability would be identical to Driver B'sboth knowingly took the same unjustified risk.",
    "gold_rationale": "VALID. Moral luck problem: identical acts, identical mens rea, different outcomes due to luck. From moral philosophy perspective rejecting outcome luck: culpability = recklessness + mens rea + foreseeability, not actual outcome. Both drivers took same unjustified risk. Counterfactual: A with pedestrian present = identical moral culpability as B. Note: legal systems do consider outcomes (results matter for punishment), but moral philosophy traditionally rejects outcome-based luck. This demonstrates act-vs-outcome distinction in moral evaluation.",
    "invariants": [
      "Both drivers texting while driving (identical reckless act)",
      "Identical mental states (conscious disregard for risk)",
      "Pedestrian presence/absence was luck (beyond drivers' control)",
      "Moral culpability based on acts, intentions, foreseeability (standard moral theory)"
    ],
    "justification": "Identical reckless actions with identical mental states should receive identical moral evaluation. Outcome difference results from luck (pedestrian presence), not from different choices or foreseeability. Moral philosophy rejects outcome-based moral luckculpability depends on what agent controls (actions, intentions), not uncontrollable factors.",
    "wise_response": "VALID. Both drivers took identical reckless risks with same mental state. Outcome differed due to luck (pedestrian presence). Moral culpability should be equalbased on act and intent, not luck.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0158",
    "case_id": "0158",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Transportation",
    "subdomain": "Road Safety",
    "family": "F2",
    "subtype": "Probabilistic Exposure",
    "scenario": "A driver texts while driving and rear-ends another car at a stoplight. Police cite distraction as the cause. The driver's lawyer argues: 'We cannot prove the crash wouldn't have happened anywaymy client might have been reaching for coffee or looking at the radio at that exact moment. The texting increased crash risk but doesn't prove it caused this specific crash.'",
    "counterfactual_claim": "If the driver had not been texting, the crash would not have occurred.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Texting while driving",
      "Y": "Rear-end collision at stoplight",
      "Z": [
        "Driver attention/reaction time",
        "Other potential distractions (coffee, radio)",
        "Stopping distance and brake timing"
      ]
    },
    "trap": {
      "type": "F2",
      "type_name": "Probabilistic Counterfactual",
      "subtype": "Probabilistic Exposure",
      "subtype_name": "Individual Event Under Probabilistic Risk"
    },
    "difficulty": "Medium",
    "causal_structure": "Texting(X) reduces attention  delayed reaction  crash(Y). But other distractions could produce same effect. Texting increases crash probability substantially but doesn't prove it was the but-for cause of this specific crash without knowing counterfactual attention state.",
    "key_insight": "Probabilistic risk factors increase likelihood of bad outcomes but don't deterministically prove they caused any specific instance without ruling out alternative scenarios.",
    "hidden_timestamp": "The counterfactual asks whether this specific crash required texting or whether other distractions would have produced the same outcome.",
    "conditional_answers": {
      "answer_if_condition_1": "If evidence shows the driver was fully attentive except for texting (e.g., no coffee, radio off, eyes tracked phone), texting was necessary causeclaim VALID.",
      "answer_if_condition_2": "If driver was generally inattentive or would likely have been distracted by other means, crash might have occurred anywayclaim INVALID or CONDITIONAL on attention state."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on the driver's counterfactual attention state. Texting demonstrably increases crash risk (studies show 20-23x higher risk), and distraction was clearly present. However, proving this specific crash required texting requires knowing whether the driver would have been sufficiently attentive without it. If the driver habitually drove distracted (coffee, radio), another distraction might have caused the same outcome. To resolve: need evidence about typical attention patterns and whether texting was the marginal distraction.",
    "gold_rationale": "CONDITIONAL. Texting increases crash probability substantially (strong probabilistic causation). This crash occurred with texting present. But individual-level but-for causation requires ruling out alternative paths to same outcome. Need to know: Would driver have been attentive without phone? Or would other distractions (coffee, radio) have caused same inattention? Legal standards vary: some jurisdictions use 'substantial factor' (likely VALID), others require strict but-for (CONDITIONAL on attention state).",
    "invariants": [
      "Texting while driving increases crash risk 20-23x (population data)",
      "Driver was distracted at moment of crash (undisputed)",
      "Other potential distractions existed (coffee, radio)",
      "Driver's baseline attention level without texting unknown"
    ],
    "justification": "Texting was present and distraction occurred, but proving but-for causation requires showing no other distraction would have occurred. The scenario doesn't specify whether driver would have been attentive without phone. Legal and causal conclusion depends on this missing information.",
    "wise_response": "CONDITIONAL. Texting increased risk and distraction was present, but proving this specific crash required texting needs evidence about whether driver would have been attentive otherwise.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0159",
    "case_id": "0159",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Technology",
    "subdomain": "Social Media",
    "family": "F5",
    "subtype": "Path Dependence",
    "scenario": "An influencer posted controversial content early in their career that went viral and built a following of 2M users who appreciated that style. Over 5 years, they've maintained that audience by continuing similar content. Now established, they want to shift to educational content but find their audience rejects itengagement drops 80% when they post educational material. They claim: 'If I had started with educational content, I could be doing that successfully now.'",
    "counterfactual_claim": "If the influencer had started with educational content instead of controversial content, they would now have a successful educational content platform.",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Early controversial content strategy",
      "Y": "Current content type and audience engagement",
      "Z": [
        "Audience selection and expectations",
        "Algorithmic reinforcement of content type",
        "5 years of path-dependent growth",
        "Lock-in to controversial content"
      ]
    },
    "trap": {
      "type": "F5",
      "type_name": "Temporal and Path-Dependent",
      "subtype": "Path Dependence",
      "subtype_name": "Early Choice Constrains Later Options"
    },
    "difficulty": "Medium",
    "causal_structure": "Early content(X)  attracted specific audience  algorithm reinforced pattern  5 years of accumulation  locked into content type. Initial choice determined audience composition, which constrains viable content types. Different initial choice  different audience  different viable content.",
    "key_insight": "Early choices shape audiences and expectations that constrain later options through path dependence. The same creator would have different viable strategies depending on initial positioning.",
    "hidden_timestamp": "The counterfactual asks if different initial content would have created a different path enabling educational content success.",
    "conditional_answers": {
      "answer_if_condition_1": "If audience type doesn't matter and educational content inherently can't succeed for this creator, different start wouldn't helpclaim INVALID.",
      "answer_if_condition_2": "If early content choice determined audience type, and educational audiences exist separately, different start would have attracted different audience enabling educational successclaim VALID."
    },
    "wise_refusal": "The counterfactual is VALID. The initial controversial content attracted an audience specifically interested in that content type. Over 5 years, this became self-reinforcing: algorithms promoted similar content, audience expectations solidified, and the creator became type-cast. Starting with educational content would have attracted a different audience segment (people seeking education rather than controversy), enabling sustainable educational content. The evidence is clear: when they try educational content now, engagement drops 80%the current audience isn't interested. A different initial path would have built a different audience.",
    "gold_rationale": "VALID. Path dependence through audience accumulation. Early content(X)  controversial audience  algorithm reinforcement  locked path. Different early content(X)  educational audience  different sustainable path. Key evidence: current audience rejects educational content (80% engagement drop), proving audience mismatch. Counterfactual: educational start  accumulates educational-interested audience  educational content succeeds. This demonstrates how early choices create path dependence through accumulated capital (audience) that constrains later options.",
    "invariants": [
      "Platform algorithms reinforce content types over time",
      "Audience expectations solidify through repeated content exposure",
      "Different content types attract different audience segments",
      "5-year accumulation creates strong path dependence"
    ],
    "justification": "Path dependence operates through audience selection. Early content attracted controversial-content audience. This audience doesn't want educational content (80% drop proves mismatch). Different early content would attract educational-interested audience, enabling educational success. Creator's ability is constant; audience composition varies by path.",
    "wise_response": "VALID. Early controversial content attracted an audience that rejects educational content. Starting with educational content would have built a different audience interested in that, enabling success.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0160",
    "case_id": "0160",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Economics",
    "subdomain": "Development",
    "family": "F5",
    "subtype": "Path Dependence",
    "scenario": "A country adopted English common law during colonial period. Today, it has strong property rights protection, contract enforcement, and business-friendly legal infrastructure. Researchers debate: did the legal origin cause development, or did other factors determine both? The country had mineral resources and geographic advantages independent of legal system.",
    "counterfactual_claim": "If the country had adopted civil law instead of common law, it would have weaker property rights and worse business environment today.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Common law adoption (colonial period)",
      "Y": "Strong property rights and business environment",
      "Z": [
        "Natural resources (minerals)",
        "Geographic advantages",
        "Historical development path",
        "Legal origin vs other determinants of institutions"
      ]
    },
    "trap": {
      "type": "F5",
      "type_name": "Temporal and Path-Dependent",
      "subtype": "Path Dependence",
      "subtype_name": "Legal Origins and Institutional Development"
    },
    "difficulty": "Hard",
    "causal_structure": "Legal origins theory: Common law(X)  path-dependent development  strong institutions(Y). Alternative: Geographic/resource endowments(Z)  institutional development  Y, with X merely correlated. Answer depends on whether X causes Y or both stem from Z.",
    "key_insight": "Path dependence claims require distinguishing whether early choices cause later outcomes or whether both reflect deeper structural factors.",
    "hidden_timestamp": "The counterfactual asks if different legal system would have produced different institutions, or if underlying factors would have produced similar outcomes regardless.",
    "conditional_answers": {
      "answer_if_condition_1": "If legal origin (common law) causally determines institutional development through path dependence, different legal system would produce different institutionsclaim VALID.",
      "answer_if_condition_2": "If underlying factors (resources, geography, settler mortality) determine both legal system adoption and institutional quality, different legal origin wouldn't change final institutionsclaim INVALID."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on the causal model of institutional development. Legal origins theory posits that common law creates path dependence toward strong property rights through legal evolution and precedent. Alternative theories suggest that geographic factors, resource endowments, and settler conditions determined both which legal system was adopted and institutional qualitymaking legal origin a proxy, not a cause. The scenario mentions resources and geography but doesn't resolve whether these were determinative. Empirical evidence is mixed: some studies find persistent legal origin effects, others find effects disappear when controlling for geography.",
    "gold_rationale": "CONDITIONAL on institutional development theory. Path 1 (legal origins): Xinstitutional evolution via precedentY, different Xdifferent Yclaim VALID. Path 2 (endowment theory): Z(resources/geography)X and ZY, X is proxy not cause, different X with same Zsame Yclaim INVALID. Scenario specifies Z present but not whether Z determines Y independently. Need explicit model: Is legal system a cause or marker of deeper determinants? Evidence for both interpretations exists in development economics.",
    "invariants": [
      "Country has mineral resources and geographic advantages (Z)",
      "Current institutions (Y) are strong",
      "Legal system adopted during colonial period",
      "Causal model (legal origins vs endowment theory) unspecified"
    ],
    "justification": "Answer depends on whether legal system causes institutions or both reflect underlying geographic/resource factors. Scenario provides Z (resources, geography) but doesn't specify causal model. Different models give different counterfactual outcomes. Economic literature debates this extensively without consensus.",
    "wise_response": "CONDITIONAL. If legal origin causes institutions (path dependence), different law would produce different institutionsVALID. If geography/resources determine both law and institutions, same institutions regardlessINVALID.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0161",
    "case_id": "0161",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Physics",
    "subdomain": "Measurement",
    "family": "F6",
    "subtype": "Observer Effects",
    "scenario": "Researchers study whether observations affect animal behavior. They install cameras to record wild foxes' nighttime hunting patterns. After installation, fox hunting success drops 30%. Researchers debate: did the cameras cause behavioral changes through light/noise disturbance, or are the cameras detecting a pre-existing decline that would have occurred anyway? They ask: 'If we hadn't installed cameras, would hunting success still have declined?'",
    "counterfactual_claim": "If cameras had not been installed, fox hunting success would have remained at the original level.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Camera installation",
      "Y": "30% drop in hunting success",
      "Z": [
        "Potential camera disturbance (light, noise)",
        "Pre-existing environmental changes",
        "Prey availability changes",
        "Observer effect vs natural variation"
      ]
    },
    "trap": {
      "type": "F6",
      "type_name": "Epistemic Limits",
      "subtype": "Observer Effects",
      "subtype_name": "Measurement Apparatus Changes System"
    },
    "difficulty": "Medium",
    "causal_structure": "Two competing hypotheses: (1) Cameras(X)  behavioral disturbance  reduced success(Y), or (2) Environmental change(Z)  reduced success(Y), cameras merely detected it. Without pre-camera baseline or control group, cannot distinguish observer effect from natural change.",
    "key_insight": "When measurement apparatus is introduced simultaneous with observed change, cannot determine if apparatus caused change or merely detected pre-existing change without proper controls.",
    "hidden_timestamp": "The counterfactual asks if decline would occur without cameras, but we lack baseline data before camera installation to distinguish causal paths.",
    "conditional_answers": {
      "answer_if_condition_1": "If cameras caused behavioral disturbance (light/noise disruption), removing them would maintain original hunting successclaim VALID.",
      "answer_if_condition_2": "If environmental factors caused decline and cameras merely detected it, hunting would decline regardless of camerasclaim INVALID."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL because researchers cannot distinguish observer effects from natural variation. The 30% decline coincided with camera installation, but this could result from: (1) camera disturbance affecting behavior, or (2) pre-existing environmental changes that cameras happened to detect. Without baseline data before cameras or a control group of uncamera'd foxes, the two hypotheses are observationally equivalent. This is a classic observer effect problemmeasurement apparatus introduced at same time as observed change, confounding causation with detection.",
    "gold_rationale": "CONDITIONAL on causal structure. Path 1 (observer effect): Xbehavioral disturbanceY, cameras cause decline. Path 2 (detection): Z(environment)Y, cameras detect but don't cause. Cannot distinguish without: (a) pre-installation baseline (impossible retrospectively), (b) control group (uncamera'd foxes), or (c) camera-removal experiment. Scenario lacks these. This demonstrates epistemic limits when measurement introduction coincides with changeconfounding measurement with causation.",
    "invariants": [
      "Cameras installed and 30% decline observed coincidentally",
      "No pre-installation baseline data available",
      "No control group of uncamera'd foxes available",
      "Environmental changes could occur independently"
    ],
    "justification": "Two competing explanations are observationally equivalent: cameras cause change vs cameras detect change. Without proper controls or baseline, cannot determine which. Counterfactual outcome depends on which hypothesis is true. This requires experimental design (control groups) not present in scenario.",
    "wise_response": "CONDITIONAL. Decline could result from camera disturbance (VALID claim) or cameras detecting pre-existing environmental decline (INVALID claim). Need control group or baseline to distinguish.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0162",
    "case_id": "0162",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Business",
    "subdomain": "Marketing",
    "family": "F7",
    "subtype": "Additionality",
    "scenario": "A company runs a promotional sale offering 20% off. Sales increase from 10,000 units to 13,000 units during the sale period. The CFO celebrates '3,000 additional sales.' However, the marketing director notes that: some customers were already planning to buy and just waited for the sale, some bought earlier than planned, and only truly incremental buyers represent real additionality.",
    "counterfactual_claim": "If the company had not run the promotional sale, sales would have been 10,000 units (the sale generated 3,000 additional sales).",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Promotional sale (20% off)",
      "Y": "Sales increased from 10,000 to 13,000 units",
      "Z": [
        "Time-shifted purchases (would have bought anyway)",
        "Pulled-forward purchases (cannibalized future sales)",
        "Truly incremental purchases (additionality)"
      ]
    },
    "trap": {
      "type": "F7",
      "type_name": "Causal Attribution",
      "subtype": "Additionality",
      "subtype_name": "Time-Shifting vs True Incrementality"
    },
    "difficulty": "Medium",
    "causal_structure": "Sale(X)  3,000 additional units(Y'), but Y' includes: time-shifted purchases (not incremental), pulled-forward purchases (negative future impact), and truly incremental (additionality). Naive calculation overstates impact by ignoring time-shifting and cannibalization.",
    "key_insight": "Observed sales increases during promotions include time-shifted and pulled-forward purchases, not just truly incremental sales. Additionality requires accounting for counterfactual timing.",
    "hidden_timestamp": "The counterfactual asks about incremental sales but must account for purchases that would have occurred at different times without the promotion.",
    "conditional_answers": {
      "answer_if_condition_1": "If all 3,000 additional sales are truly incremental (wouldn't have occurred without sale), claim is VALID.",
      "answer_if_condition_2": "If many sales are time-shifted or pulled-forward (would have occurred anyway at different times), true additionality is much less than 3,000claim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID as stated. The 3,000-unit increase includes substantial time-shifted and pulled-forward purchases, not just truly incremental sales. Customers who were already planning purchases waited for the sale (time-shifted), and some who would have bought later bought earlier (pulled-forward, cannibalizing future sales). Research on promotional effectiveness typically finds 30-50% of promotional sales are time-shifted or cannibalized. True additionality is probably 1,000-1,500 units, not 3,000. The simple before-after comparison overstates impact by ignoring counterfactual purchase timing.",
    "gold_rationale": "INVALID. Observed increase (3,000 units)  true additionality. Sales decomposition: (1) Time-shifted: ~1,000 units (would buy anyway, waited for sale), (2) Pulled-forward: ~500-1,000 units (cannibalized future), (3) Truly incremental: ~1,000-1,500 units. Counterfactual: without sale, ~1,500-2,000 of these 3,000 sales would occur at different times. True additionality much less than naive calculation. This demonstrates how promotional analysis requires sophisticated counterfactual timing, not simple before-after comparison.",
    "invariants": [
      "Sales increased from 10,000 to 13,000 during sale period",
      "Some customers time-shift purchases to promotions",
      "Some customers pull forward future purchases",
      "Typical promotional incrementality: 30-50% truly additional"
    ],
    "justification": "The 3,000-unit increase includes time-shifted and pulled-forward purchases that would occur without the sale at different times. True additionality is the portion that wouldn't occur at any time without the sale. Typical promotional research finds 50-70% of promotional 'lift' is time-shifting/cannibalization. Claim overstates by not accounting for counterfactual timing.",
    "wise_response": "INVALID. The 3,000-unit increase includes time-shifted and pulled-forward purchases. True additionality (sales that wouldn't occur at any time without sale) is probably 1,000-1,500 units.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0163",
    "case_id": "0163",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Medicine",
    "subdomain": "Clinical Research",
    "family": "F7",
    "subtype": "Path-Specific Effects",
    "scenario": "A weight-loss drug reduces weight by 15 lbs on average. Researchers discover two mechanisms: appetite suppression accounts for 10 lbs, and increased metabolism accounts for 5 lbs. A patient lost 12 lbs on the drug and asks: 'If I took a drug that only suppressed appetite without affecting metabolism, would I lose the same amount?'",
    "counterfactual_claim": "If the patient had taken a drug that only suppressed appetite (M1) without metabolic effects (M2), they would have lost approximately 12 lbs.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Weight-loss drug (dual mechanism)",
      "Y": "12 lbs weight loss",
      "Z": [
        "M1: Appetite suppression (population: 10 lbs)",
        "M2: Increased metabolism (population: 5 lbs)",
        "Individual mechanism contributions unknown"
      ]
    },
    "trap": {
      "type": "F7",
      "type_name": "Causal Attribution",
      "subtype": "Path-Specific Effects",
      "subtype_name": "Individual Mechanism Contribution Unknown"
    },
    "difficulty": "Medium",
    "causal_structure": "Drug(X)  M1(appetite) + M2(metabolism)  weight loss(Y). Population: M110lbs, M25lbs, total15lbs. This patient: 12lbs total. Individual pathway contributions unknown. Could be 10M1+2M2, or 8M1+4M2, or 7M1+5M2, etc.",
    "key_insight": "Population-level mechanism decomposition doesn't determine individual-level pathway contributions. The same total effect can arise from different mechanism combinations across individuals.",
    "hidden_timestamp": "The counterfactual asks about isolating one mechanism for a specific individual when we only know population-level mechanism effects.",
    "conditional_answers": {
      "answer_if_condition_1": "If this patient's weight loss was dominated by appetite suppression (e.g., 10-11 lbs from M1, 1-2 lbs from M2), appetite-only drug would produce similar lossclaim VALID.",
      "answer_if_condition_2": "If this patient's weight loss relied substantially on metabolism (e.g., 7 lbs M1, 5 lbs M2), appetite-only drug would produce notably lessclaim INVALID."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on this patient's individual mechanism contributions. We know population averages (M110lbs, M25lbs) but not how mechanisms combined for this specific patient. They lost 12 lbs (below the 15 lb average), which could result from: (1) strong M1 response, weak M2 (10+2), (2) moderate both (8+4), or (3) weak M1, strong M2 (7+5). Without individual mechanism biomarkers, we cannot determine pathway-specific effects. An appetite-only drug would provide only M1 benefitoutcome depends on this patient's M1 contribution.",
    "gold_rationale": "CONDITIONAL on individual pathway contributions. Population decomposition: XM1(10lbs) + M2(5lbs)Y(15lbs). This patient: Y=12lbs, but mechanism split unknown. Possible: (a) M1=10, M2=2  appetite-only10lbs (close to 12), (b) M1=7, M2=5  appetite-only7lbs (much less than 12). Need individual biomarkers: metabolic rate change, appetite change, etc. This demonstrates how population mechanism decomposition doesn't determine individual path-specific effects without additional identifying information.",
    "invariants": [
      "Population-level effects: M110lbs, M25lbs, total15lbs",
      "This patient's total weight loss: 12 lbs",
      "Individual mechanism contributions unknown",
      "Mechanisms operate independently (no interaction specified)"
    ],
    "justification": "Population averages don't determine individual pathway contributions. Patient lost 12lbs but we don't know if that's 10M1+2M2 or 7M1+5M2. Counterfactual outcome with M1-only drug depends on individual's M1 contribution, which is unobserved. Need mechanism biomarkers to resolve.",
    "wise_response": "CONDITIONAL. Depends on how much of this patient's 12 lb loss came from appetite (M1) vs metabolism (M2). Population averages don't tell us individual contributionsneed biomarkers to resolve.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0164",
    "case_id": "0164",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Education",
    "subdomain": "University Admissions",
    "family": "F4",
    "subtype": "Agent vs System",
    "scenario": "A student with excellent grades and test scores is rejected from a top university because they didn't demonstrate 'leadership experience'. However, the university receives 40,000 applications for 2,000 spotsa 5% acceptance rate. Most applicants have similar academic credentials, so differentiation requires extracurriculars. The student claims: 'If I had leadership experience, I would have been admitted.'",
    "counterfactual_claim": "If the student had demonstrated leadership experience, they would have been admitted to the university.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Leadership experience",
      "Y": "University admission",
      "Z": [
        "40,000 applicants for 2,000 spots (5% rate)",
        "Most applicants have similar academic credentials",
        "Limited differentiation factors",
        "Structural scarcity of admission slots"
      ]
    },
    "trap": {
      "type": "F4",
      "type_name": "Structural vs Contingent",
      "subtype": "Agent vs System",
      "subtype_name": "Individual Action vs Structural Constraint"
    },
    "difficulty": "Medium",
    "causal_structure": "Structural scarcity(Z): 2,000 slots for 40,000 qualified applicants  95% rejection inevitable. Adding leadership(X) improves individual competitiveness but doesn't eliminate structural constraint. With 5% acceptance, most with leadership also rejected.",
    "key_insight": "When structural constraints dominate (extreme scarcity), improving individual qualifications doesn't guarantee success because the system-level constraint still binds.",
    "hidden_timestamp": "The counterfactual asks if individual improvement overcomes structural scarcity when most qualified candidates are rejected regardless.",
    "conditional_answers": {
      "answer_if_condition_1": "If leadership experience was the only missing qualification and would have made student stand out uniquely, claim might be VALID.",
      "answer_if_condition_2": "If 5% acceptance rate means most qualified applicants are rejected due to structural scarcity, adding leadership improves chances marginally but doesn't guarantee admissionclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID due to structural constraints. With 40,000 applicants for 2,000 spots, 95% must be rejected regardless of qualifications. Most applicants likely have leadership experienceit's table stakes, not differentiating. Adding leadership would improve this student's application from 'auto-reject' to 'competitive,' but competitive applicants face ~10-15% acceptance odds. The structural constraint (slot scarcity) means that even with leadership, rejection is most likely (~85% probability). Individual improvement doesn't overcome system-level scarcity.",
    "gold_rationale": "INVALID. Structural scarcity dominates individual agency. With 5% overall acceptance and most applicants having strong profiles, adding X moves student from definite-reject to maybe-accept (~10-15% odds). But structural constraint means most qualified applicants still rejected. Counterfactual: with leadership, P(admission) rises from ~0% to ~12%, still most likely rejected. This demonstrates how system-level constraints limit individual counterfactualsimproving qualifications helps marginally but doesn't overcome scarcity.",
    "invariants": [
      "40,000 applications for 2,000 spots (5% acceptance rate)",
      "Most applicants have similar academic credentials to this student",
      "Leadership experience is common among applicant pool",
      "Structural scarcity constraint remains unchanged"
    ],
    "justification": "System-level scarcity means 95% rejection is structural. Adding leadership improves individual competitiveness but doesn't eliminate structural constraint that most qualified applicants are rejected. Counterfactual admission probability rises from ~0% to ~12%improved but still likely rejection.",
    "wise_response": "INVALID. With 95% rejection rate due to scarcity, adding leadership improves chances (~12%) but likely still rejected. Structural constraint dominates individual qualifications.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0165",
    "case_id": "0165",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Agriculture",
    "subdomain": "Crop Yield",
    "family": "F2",
    "subtype": "Probabilistic Exposure",
    "scenario": "A farmer uses a new fertilizer and their corn yield increases by 15%. However, weather was also favorable this year: rainfall was optimal, temperatures were moderate, and there were no pest outbreaks. Agricultural scientists note that favorable weather typically increases yields by 10-20%, while the fertilizer shows 5-8% improvement in controlled trials. The farmer claims: 'If I hadn't used the fertilizer, my yield would have been 15% lower.'",
    "counterfactual_claim": "If the farmer had not used the new fertilizer, corn yield would have been 15% lower.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "New fertilizer use",
      "Y": "15% yield increase",
      "Z": [
        "Optimal rainfall this year",
        "Moderate temperatures",
        "No pest outbreaks",
        "Favorable weather contributes 10-20% yield increase"
      ]
    },
    "trap": {
      "type": "F2",
      "type_name": "Probabilistic Counterfactual",
      "subtype": "Probabilistic Exposure",
      "subtype_name": "Multiple Concurrent Causes"
    },
    "difficulty": "Easy",
    "causal_structure": "Fertilizer(X) + Favorable weather(Z)  15% yield increase(Y). Controlled trials show X contributes 5-8%, Z contributes 10-20%. Removing only X doesn't eliminate entire 15% because Z remains. Yield would drop ~6%, not 15%.",
    "key_insight": "When multiple factors contribute to an outcome, removing one factor doesn't eliminate the total effect because other factors remain operative.",
    "hidden_timestamp": "The counterfactual removes fertilizer while holding favorable weather conditions constant.",
    "conditional_answers": {
      "answer_if_condition_1": "If fertilizer was the only cause of the 15% increase and weather was irrelevant, removing fertilizer would eliminate all gainclaim VALID.",
      "answer_if_condition_2": "If both fertilizer and weather contributed, with weather providing 10-20% and fertilizer 5-8%, removing only fertilizer leaves most of the gainclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID. The 15% yield increase resulted from both the new fertilizer and exceptionally favorable weather. Controlled trial data shows the fertilizer contributes 5-8% improvement, while favorable weather conditions contribute 10-20%. In the counterfactual world without fertilizer but with the same favorable weather, yields would still be elevated by approximately 10-12% (from weather alone). The yield would drop by roughly 5-8 percentage points, not the full 15%. The farmer's claim attributes the entire increase to fertilizer while ignoring the substantial concurrent contribution from weather.",
    "gold_rationale": "INVALID. Multiple concurrent causes. Fertilizer(X) contributes ~5-8%, weather(Z) contributes ~10-20%. Total observed: 15% (consistent with X6% + Z9%). Counterfactual: remove X, keep Z  yield still elevated ~9% from weather, drop only ~6%, not 15%. This demonstrates attribution error when multiple factors operate simultaneouslyremoving one doesn't eliminate total effect. Controlled trial data provides mechanism-specific estimates separating X from Z effects.",
    "invariants": [
      "Fertilizer effect in controlled trials: 5-8% yield improvement",
      "Favorable weather effect: 10-20% yield improvement",
      "This year's weather was optimal (rainfall, temperature, no pests)",
      "Weather conditions held constant in counterfactual world"
    ],
    "justification": "The 15% increase has two contributors: fertilizer (~6%) and weather (~9%). Removing fertilizer while holding weather constant eliminates only the fertilizer portion. Weather contribution remains, so yield drops ~6%, not 15%. Claim incorrectly attributes all improvement to single factor.",
    "wise_response": "INVALID. Both fertilizer (~6%) and favorable weather (~9%) caused the 15% increase. Without fertilizer but with same weather, yield would drop ~6%, not 15%weather contribution remains.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0166",
    "case_id": "0166",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Public Policy",
    "subdomain": "Criminal Justice",
    "family": "F2",
    "subtype": "Probabilistic Exposure",
    "scenario": "A city implements a community policing program in a high-crime neighborhood. Over 2 years, violent crime drops 40%. However, during the same period, the city also improved street lighting, increased youth employment programs, and renovated abandoned buildings. Crime researchers note each intervention independently reduces crime by 10-15%. A police chief claims: 'Community policing alone reduced violent crime by 40%.'",
    "counterfactual_claim": "If community policing had not been implemented, violent crime would not have decreased.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Community policing program",
      "Y": "40% violent crime reduction",
      "Z": [
        "Improved street lighting",
        "Youth employment programs",
        "Abandoned building renovation"
      ]
    },
    "trap": {
      "type": "F2",
      "type_name": "Probabilistic Counterfactual",
      "subtype": "Probabilistic Exposure",
      "subtype_name": "Multiple Concurrent Crime Interventions"
    },
    "difficulty": "Medium",
    "causal_structure": "Community policing(X) + Lighting(Z1) + Employment(Z2) + Buildings(Z3)  40% crime reduction(Y). Each contributes ~10-15%. Removing only X leaves Z1-Z3 active, providing ~30-45% reduction. Crime would still decrease substantially.",
    "key_insight": "Multiple concurrent interventions make it impossible to attribute all observed change to a single program. Other programs would continue to have effects.",
    "hidden_timestamp": "The counterfactual removes community policing while holding other neighborhood improvements constant.",
    "conditional_answers": {
      "answer_if_condition_1": "If community policing was the only intervention and others were irrelevant, removing it would eliminate the decreaseclaim VALID.",
      "answer_if_condition_2": "If multiple interventions each contributed 10-15%, removing community policing leaves substantial crime reduction from other programsclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID. The 40% crime reduction occurred alongside multiple evidence-based interventions: improved lighting (reduces crime 10-15%), youth employment programs (reduces crime 10-15%), and building renovation (reduces crime 10-12%). These are well-documented independent causes of crime reduction. Without community policing but with other interventions intact, crime would still decrease by approximately 30-40% from the combined effect of lighting, employment, and building improvements. Crime researchers would not have decreased to zeroit would have remained elevated by perhaps 10-15 percentage points.",
    "gold_rationale": "INVALID. Multiple sufficient causes operating concurrently. Each intervention (policing, lighting, employment, buildings) contributes ~10-15% reduction. Total 40% consistent with additive or partially overlapping effects. Counterfactual: remove X(policing), keep Z1-Z3  crime still drops ~25-30% from remaining interventions. The claim commits single-cause attribution error in multi-intervention setting. Without randomized controlled design isolating X, cannot attribute entire effect to one program.",
    "invariants": [
      "Street lighting improved (documented 10-15% crime reduction effect)",
      "Youth employment programs implemented (documented 10-15% reduction)",
      "Abandoned buildings renovated (documented 10-12% reduction)",
      "All interventions occurred during same 2-year period"
    ],
    "justification": "Four concurrent evidence-based interventions. Research shows each independently reduces crime 10-15%. Removing one leaves others active. Counterfactual: without policing, other three interventions still provide substantial crime reduction (~25-30%). Claim incorrectly attributes all observed change to single program.",
    "wise_response": "INVALID. Four concurrent interventions (policing, lighting, employment, buildings) each reduce crime ~10-15%. Without policing, other three would still substantially reduce crime (~25-30%).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0167",
    "case_id": "0167",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Sports",
    "subdomain": "Basketball",
    "family": "F3",
    "subtype": "Preemption",
    "scenario": "In a basketball game's final second, Player A attempts a game-winning three-pointer. The shot is in the air when Player B, seeing it will miss, tips in a rebound for the winning points. Replay shows A's shot would have missed by 2 inches. Player B's tip-in scored before A's shot reached the rim. Player A claims: 'If I had made my shot, we still would have won.'",
    "counterfactual_claim": "If Player A's three-pointer had gone in, the team would have won the game.",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X1": "Player A's three-point attempt (missed)",
      "X2": "Player B's tip-in rebound (scored)",
      "Y": "Team won the game",
      "Z": [
        "A's shot would have been sufficient to win",
        "B's tip-in preempted A's shot by scoring first",
        "Either scoring play sufficient for victory"
      ]
    },
    "trap": {
      "type": "F3",
      "type_name": "Overdetermination",
      "subtype": "Preemption",
      "subtype_name": "Backup Cause Activated When Primary Fails"
    },
    "difficulty": "Hard",
    "causal_structure": "Player A's shot(X1) missed  Player B tips rebound(X2)  win(Y). Counterfactual: X1 succeeds  win(Y) directly, X2 doesn't occur. This is reverse preemption: backup cause (B) activated when primary cause (A) fails. If primary succeeds, backup unnecessary.",
    "key_insight": "In reverse preemption, a backup cause activates when the primary cause fails. If the primary cause succeeds in the counterfactual, the outcome still occurs but via the primary path.",
    "hidden_timestamp": "The counterfactual asks if the primary cause (A's shot) would have been sufficient even though the backup cause (B's tip) actually produced the outcome.",
    "conditional_answers": {
      "answer_if_condition_1": "If A's made three-pointer would have been sufficient for victory and would have prevented B's opportunity, claim is VALID.",
      "answer_if_condition_2": "If something else was required beyond scoring (e.g., time remaining, defensive stop), claim might be INVALID."
    },
    "wise_refusal": "The counterfactual is VALID. Player A's three-point shot, if successful, would have immediately won the gamethree points with one second left in a tied game. Player B's tip-in was a backup scoring play that occurred only because A's shot was missing. In the counterfactual world where A's shot goes in, the team wins via A's three-pointer and B's tip-in opportunity never materializes (the ball wouldn't reach B as a rebound). Both plays were sufficient for victory, but A's shot would have preempted B's opportunity. The team would still have won, just via A's shot instead of B's tip.",
    "gold_rationale": "VALID. Reverse preemption structure: primary cause(X1) fails  backup cause(X2) activates  outcome(Y). Counterfactual: primary succeeds  outcome via primary, backup doesn't activate. A's made shot sufficient for win. B's tip-in was contingency plan that activated when A missed. If A makes shot, ball doesn't reach B for tip-in opportunity. Either path sufficient for Y, but counterfactual follows primary path. This demonstrates how backup mechanisms activate conditionally on primary failure.",
    "invariants": [
      "Game tied with 1 second remaining",
      "Either a made three-pointer or tip-in sufficient for victory",
      "Player B's tip-in opportunity existed only because A's shot missed",
      "Three points from A's shot would have exceeded opponent's score"
    ],
    "justification": "A's made shot sufficient for victory. B's tip-in was backup that activated when A missed. Counterfactual: A makes shot  win via A's three-pointer, B's opportunity doesn't materialize. Team wins either way, but via different sufficient cause. This is valid counterfactual about alternative sufficient path.",
    "wise_response": "VALID. A's made three-pointer would have won the game directly. B's tip-in was a backup that activated when A missedif A made it, team still wins but via A's shot.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0168",
    "case_id": "0168",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Environment",
    "subdomain": "Conservation",
    "family": "F3",
    "subtype": "Threshold Effects",
    "scenario": "A wetland ecosystem collapses when pollution levels exceed 50 ppm. This year, three pollutants contributed: agricultural runoff added 30 ppm, industrial discharge added 15 ppm, and urban stormwater added 10 ppm. Total: 55 ppm. Environmental regulators target the agricultural sector: 'If farms reduce runoff by 10 ppm, we stay under threshold and prevent collapse.'",
    "counterfactual_claim": "If agricultural runoff were reduced by 10 ppm (bringing it to 20 ppm), the wetland ecosystem would not collapse.",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X1": "Agricultural runoff (30 ppm)",
      "X2": "Industrial discharge (15 ppm)",
      "X3": "Urban stormwater (10 ppm)",
      "Y": "Wetland ecosystem collapse",
      "Z": [
        "Baseline: 0 ppm",
        "Current total: 55 ppm",
        "Collapse threshold: 50 ppm"
      ]
    },
    "trap": {
      "type": "F3",
      "type_name": "Overdetermination",
      "subtype": "Threshold Effects",
      "subtype_name": "Multiple Contributors to Threshold Exceedance"
    },
    "difficulty": "Medium",
    "causal_structure": "X1(30) + X2(15) + X3(10) = 55 ppm > 50 ppm threshold  collapse(Y). Reducing X1 by 10: 20 + 15 + 10 = 45 ppm < 50 ppm  no collapse. Unlike the coral case, this has deterministic arithmetic: any reduction bringing total below 50 prevents collapse.",
    "key_insight": "For threshold effects with additive contributions, reducing any single contributor below the threshold prevents the outcome if other contributors remain constant.",
    "hidden_timestamp": "The counterfactual reduces one contributor (agricultural) while holding others (industrial, urban) constant to test if threshold is avoided.",
    "conditional_answers": {
      "answer_if_condition_1": "If reducing agricultural runoff by 10 ppm brings total below 50 ppm threshold (20+15+10=45), collapse is preventedclaim VALID.",
      "answer_if_condition_2": "If other sources increase when agriculture reduces (substitution effect), total might still exceed thresholdclaim CONDITIONAL."
    },
    "wise_refusal": "The counterfactual is VALID under stated invariants. Agricultural runoff currently contributes 30 ppm. Reducing it by 10 ppm to 20 ppm, while holding industrial (15 ppm) and urban (10 ppm) constant, yields total pollution of 45 ppmbelow the 50 ppm collapse threshold. The ecosystem would not collapse. This is straightforward threshold arithmetic: 20 + 15 + 10 = 45 < 50. Unlike cases with multiple sufficient causes, here contributors are additive, and reducing one below the threshold prevents the outcome as long as others remain fixed.",
    "gold_rationale": "VALID. Threshold effect with additive contributions. Current: 30+15+10=55>50  collapse. Counterfactual: reduce X1 to 20  20+15+10=45<50  no collapse. This differs from overdetermination cases because contributors are additive and threshold is deterministic. Reducing any single contributor sufficiently (while holding others fixed) brings total below threshold and prevents outcome. Simple arithmetic with clear threshold mechanics.",
    "invariants": [
      "Collapse threshold: 50 ppm (deterministic)",
      "Industrial discharge remains 15 ppm in counterfactual",
      "Urban stormwater remains 10 ppm in counterfactual",
      "Pollutants contribute additively to total pollution level"
    ],
    "justification": "Threshold is deterministic at 50 ppm. Contributors are additive. Reducing agricultural from 30 to 20 ppm while holding others constant: 20+15+10=45 ppm < 50 ppm threshold. Collapse prevented. Straightforward threshold arithmetic with constant other contributors.",
    "wise_response": "VALID. Reducing agricultural runoff to 20 ppm brings total to 45 ppm (20+15+10), below the 50 ppm threshold. Ecosystem collapse prevented.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0169",
    "case_id": "0169",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Business",
    "subdomain": "Venture Capital",
    "family": "F4",
    "subtype": "Trigger vs Structure",
    "scenario": "A startup fails after losing a key engineer who was critical to product development. However, the company already faced structural problems: insufficient runway, weak product-market fit, declining user metrics, and competitors with 10x more funding. The CEO blames the departure: 'If that engineer had stayed, we'd have raised Series B and survived.'",
    "counterfactual_claim": "If the key engineer had not left, the startup would have raised Series B funding and survived.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Key engineer departure",
      "Y": "Startup failure",
      "Z": [
        "Only 3 months cash runway remaining",
        "Weak product-market fit (declining metrics)",
        "Competitors with 10x more funding",
        "Structural competitive disadvantage"
      ]
    },
    "trap": {
      "type": "F4",
      "type_name": "Structural vs Contingent",
      "subtype": "Trigger vs Structure",
      "subtype_name": "Proximate Event vs Structural Inevitability"
    },
    "difficulty": "Hard",
    "causal_structure": "Structural problems(Z)  startup on failing trajectory  failure inevitable within 3-6 months. Engineer departure(X) accelerated but didn't cause failure. Without X, structural issues (no PMF, funding disadvantage, cash crunch) still lead to failure.",
    "key_insight": "When structural conditions doom a venture, a proximate disruption is often blamed even though failure was structurally determined by competitive dynamics and resource constraints.",
    "hidden_timestamp": "The counterfactual asks if retaining the engineer enables survival when structural competitive and financial constraints make failure likely.",
    "conditional_answers": {
      "answer_if_condition_1": "If the startup was otherwise healthy with strong PMF and adequate runway, retaining the engineer enables Series B and survivalclaim VALID.",
      "answer_if_condition_2": "If structural problems (weak PMF, insufficient runway, massive competitive disadvantage) made failure inevitable, retaining engineer delays but doesn't prevent failureclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID. The startup faced structural problems that made failure highly probable: only 3 months of cash runway (insufficient time to pivot), declining user metrics indicating weak product-market fit, and competitors with 10x more funding creating insurmountable competitive disadvantage. VCs evaluate these structural factors when considering Series B investment. The engineer's departure accelerated the timeline but didn't cause failureinvestors would likely decline Series B due to weak metrics and competitive position even with the engineer present. Structural constraints made failure inevitable within 3-6 months regardless.",
    "gold_rationale": "INVALID. Structural inevitability vs contingent trigger. Pre-departure state: 3-month runway, declining metrics, 10x funding gap. These structural conditions made Series B fundraising extremely unlikely (VCs require PMF and reasonable competitive position). Engineer departure was trigger that made failure visible immediately, but structural factors would cause failure within runway window. Counterfactual: with engineer, startup burns remaining cash over 3 months, fails to raise Series B due to structural issues, fails anyway. Classic trigger-vs-structure where structure determines outcome.",
    "invariants": [
      "Cash runway: 3 months remaining (insufficient for pivot)",
      "User metrics declining (weak product-market fit)",
      "Competitors have 10x more funding (structural disadvantage)",
      "Series B requires strong metrics and competitive viability"
    ],
    "justification": "Structural conditions (short runway, weak PMF, massive competitive gap) made failure highly probable. VCs require structural viability for Series B. Engineer retention doesn't solve weak metrics or funding gap. Counterfactual: with engineer, startup still fails within 3 months due to structural issues. Claim scapegoats departure instead of addressing root structural problems.",
    "wise_response": "INVALID. Structural problems (3-month runway, weak PMF, 10x funding gap) made failure inevitable. Engineer retention wouldn't solve structural issues preventing Series B fundraising.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0170",
    "case_id": "0170",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Public Health",
    "subdomain": "Disease Prevention",
    "family": "F7",
    "subtype": "Attributable Fraction",
    "scenario": "A smoking cessation program reaches 10,000 smokers. Five years later, lung cancer rates in this group are 30% lower than baseline predictions. However, during this period, the city also banned smoking in public places, increased cigarette taxes, and ran anti-smoking TV campaigns. Public health officials claim: 'Our cessation program prevented 150 lung cancers.'",
    "counterfactual_claim": "If the cessation program had not been implemented, lung cancer rates in this group would have matched baseline predictions (the program prevented 150 cases).",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Smoking cessation program (10,000 participants)",
      "Y": "30% lower lung cancer than predicted",
      "Z": [
        "Public smoking ban",
        "Cigarette tax increases",
        "Anti-smoking TV campaigns",
        "Population-wide interventions"
      ]
    },
    "trap": {
      "type": "F7",
      "type_name": "Causal Attribution",
      "subtype": "Attributable Fraction",
      "subtype_name": "Program Attribution Amid Population Interventions"
    },
    "difficulty": "Hard",
    "causal_structure": "Cessation program(X) + Smoking ban(Z1) + Taxes(Z2) + Campaigns(Z3)  30% cancer reduction(Y). Each policy reduces smoking/cancer at population level. Cannot isolate X's contribution without control group. Baseline predictions don't account for concurrent policies.",
    "key_insight": "When individual programs operate alongside population-wide policies, attributing all observed change to one program ignores concurrent policy effects. Need control group or adjustment for policy changes.",
    "hidden_timestamp": "The counterfactual asks about program-specific attribution when baseline predictions were made before population-wide policy changes.",
    "conditional_answers": {
      "answer_if_condition_1": "If cessation program was the only intervention and population policies had no effect, 150-case attribution is VALID.",
      "answer_if_condition_2": "If population policies (bans, taxes, campaigns) also reduced smoking in program participants and general population, some reduction would occur without programclaim OVERSTATES by unknown amount."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on the contribution of concurrent population-wide interventions. The 30% cancer reduction occurred during a period of major policy changes: smoking bans, tax increases, and media campaigns. These policies reduce smoking and cancer at the population level, affecting both program participants and non-participants. The baseline predictions likely didn't account for these policy changes. Without a control group (non-participants in same city exposed to policies), we cannot isolate the program's specific contribution. Some cancer reduction would likely occur from policies alone, making 150 an overestimate of program-specific attribution.",
    "gold_rationale": "CONDITIONAL on policy effect adjustment. Observed: 30% reduction in program group. But: (1) Baseline predictions made pre-policy, (2) Population policies affect everyone including program participants, (3) No control group isolating program effect. To resolve: need either (a) control group (non-participants) showing policy-only effect, or (b) adjustment for population policy impact. Likely scenario: policies contribute 10-15% reduction population-wide, program adds 15-20% for participants  program-specific attribution ~75-100 cases, not 150. This demonstrates attribution challenges when individual and population interventions occur simultaneously.",
    "invariants": [
      "Smoking cessation program reached 10,000 smokers",
      "Public smoking ban implemented during study period",
      "Cigarette taxes increased during study period",
      "Anti-smoking campaigns aired during study period",
      "No control group of non-participants available"
    ],
    "justification": "Multiple concurrent interventions (program + population policies). Population policies reduce smoking/cancer for everyone, including program participants. Cannot attribute all observed 30% reduction to program without control group or policy adjustment. Claim likely overstates program-specific impact by ignoring concurrent policy effects.",
    "wise_response": "CONDITIONAL. Population policies (bans, taxes, campaigns) also reduce cancer during this period. Without control group, cannot isolate program's specific contribution from concurrent policy effects. 150 likely overstates.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0171",
    "case_id": "0171",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Medicine",
    "subdomain": "Surgery",
    "family": "F8",
    "subtype": "Action vs Omission",
    "scenario": "A terminally ill patient is on life support. Two doctors face decisions: Doctor A actively administers a lethal injection at the patient's request, ending life immediately. Doctor B honors the patient's advance directive and withdraws life support, allowing the patient to die naturally over hours. Both patients die. Medical ethicists debate: 'If Doctor B had administered lethal injection instead of withdrawing support, would their action be morally equivalent?'",
    "counterfactual_claim": "If Doctor B had administered lethal injection (active killing) instead of withdrawing life support (allowing to die), the moral character of the action would be the same.",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X1": "Active lethal injection (Doctor A)",
      "X2": "Withdrawal of life support (Doctor B)",
      "Y": "Patient death",
      "Z": [
        "Patient request/advance directive",
        "Terminal illness",
        "Action vs omission distinction"
      ]
    },
    "trap": {
      "type": "F8",
      "type_name": "Moral and Legal Causation",
      "subtype": "Action vs Omission",
      "subtype_name": "Active Killing vs Allowing to Die"
    },
    "difficulty": "Medium",
    "causal_structure": "Active injection(X1)  doctor causes death (initiates lethal process). Withdrawal(X2)  doctor allows disease to cause death (removes intervention). Traditional medical ethics: X1 = active killing (prohibited), X2 = allowing natural death (permitted).",
    "key_insight": "Medical ethics and law distinguish active killing (initiating death-causing process) from withdrawal of treatment (allowing natural disease process). Same outcome, different moral/legal status.",
    "hidden_timestamp": "The counterfactual asks if switching from withdrawal (X2) to active killing (X1) would preserve moral equivalence.",
    "conditional_answers": {
      "answer_if_condition_1": "If only outcomes matter and intentions are identical, active killing and withdrawal are morally equivalentclaim VALID.",
      "answer_if_condition_2": "If action/omission distinction matters morally (active killing vs allowing to die), switching to injection changes moral characterclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID under traditional medical ethics that recognizes action/omission distinction. Withdrawing life support (Doctor B) allows the underlying terminal disease to cause deaththe doctor removes extraordinary intervention but doesn't initiate a killing process. Administering lethal injection actively causes death by introducing a lethal agent. Medical ethics, law, and professional standards treat these differently: withdrawal is widely permitted when consistent with patient wishes and appropriate care; active euthanasia is prohibited in most jurisdictions. The moral distinction rests on whether the doctor initiates the death-causing process (action) or ceases to prevent natural death (omission).",
    "gold_rationale": "INVALID under traditional medical/legal framework. Withdrawal(X2): doctor stops intervention  disease causes death  allowing natural process. Injection(X1): doctor administers lethal agent  injection causes death  initiating killing process. Standard view: action/omission distinction matters morally and legally. Same patient preferences, same outcome, but different causal role and moral status. Consequentialists might reject this distinction (outcomes identical), but prevailing medical ethics, law, and practice recognize the difference. Counterfactual: switching to injection changes moral character by converting omission to action.",
    "invariants": [
      "Patient is terminally ill with advance directive/request",
      "Both paths lead to death outcome",
      "Traditional medical ethics recognizes action/omission distinction",
      "Withdrawal of treatment vs active euthanasia treated differently in most jurisdictions"
    ],
    "justification": "Medical ethics distinguishes initiating death (active killing) from allowing natural death (withdrawal). Withdrawal removes extraordinary intervention; injection introduces lethal process. Same outcome, different causal and moral structure. Switching from withdrawal to injection changes the action's moral character under standard medical ethics framework.",
    "wise_response": "INVALID. Medical ethics distinguishes active killing (injecting lethal agent) from allowing natural death (withdrawing intervention). Switching to injection changes the moral character of the action.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0172",
    "case_id": "0172",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Law",
    "subdomain": "Criminal Justice",
    "family": "F8",
    "subtype": "Moral Luck",
    "scenario": "Two people drive home after drinking the same amount of alcoholboth at 0.10% BAC, above the 0.08% legal limit. Driver A encounters no pedestrians and arrives home safely. Driver B hits and kills a pedestrian who stepped into the road, resulting in vehicular manslaughter charges. Both made identically reckless decisions with identical impairment. Legal system: Driver A gets DUI, Driver B faces 8 years prison. A legal scholar asks: 'If Driver A had encountered the pedestrian, would they be equally culpable?'",
    "counterfactual_claim": "If Driver A had encountered the pedestrian, they would be equally morally and legally culpable as Driver B.",
    "label": "VALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Drunk driving (both drivers, 0.10% BAC)",
      "Y1": "No accident (Driver A)",
      "Y2": "Fatal pedestrian accident (Driver B)",
      "Z": [
        "Pedestrian presence (luck)",
        "Identical reckless behavior",
        "Identical impairment levels"
      ]
    },
    "trap": {
      "type": "F8",
      "type_name": "Moral and Legal Causation",
      "subtype": "Moral Luck",
      "subtype_name": "Identical Recklessness, Different Outcomes"
    },
    "difficulty": "Medium",
    "causal_structure": "Identical reckless action(X) + pedestrian presence(luck)  fatal outcome(Y2) or no outcome(Y1). Moral culpability should depend on recklessness and foreseeability, not luck. Legal systems incorporate outcome luck; moral philosophy often rejects it.",
    "key_insight": "Moral luck in outcome: identical reckless acts with identical mental states receive different legal punishment based on factors beyond driver's control. Moral vs legal culpability diverge.",
    "hidden_timestamp": "The counterfactual asks if Driver A would bear equivalent culpability if they encountered the same unlucky circumstances as Driver B.",
    "conditional_answers": {
      "answer_if_condition_1": "If culpability depends on outcomes and actual harm caused, different outcomes justify different culpabilityclaim INVALID.",
      "answer_if_condition_2": "If moral culpability depends on recklessness, mens rea, and foreseeability (not luck), identical acts deserve identical moral evaluationclaim VALID for moral culpability. Legal culpability incorporates outcomes."
    },
    "wise_refusal": "The counterfactual is VALID from moral philosophy perspective. Both drivers made identically reckless decisions: drove drunk at 0.10% BAC, knowingly creating equivalent risks of fatal accidents. The only difference was circumstantial luckwhether a pedestrian happened to be present. Moral culpability based on choice, recklessness, and foreseeability would be identical. If Driver A had encountered the pedestrian, their moral culpability would equal Driver B'sboth knowingly took the same unjustified lethal risk. Note: legal systems do consider actual outcomes (result matter for sentencing), but moral philosophy typically rejects outcome-based moral luck. The counterfactual affirms equal moral culpability while acknowledging legal systems treat outcomes differently.",
    "gold_rationale": "VALID for moral culpability; VALID for legal culpability under consistent application. Moral: Identical acts (drunk driving 0.10% BAC), identical mens rea (conscious disregard for known risk), identical foreseeability (knew fatal accidents possible). Outcome difference purely luck (pedestrian presence). Moral culpability should be equalbased on what agents control (choices, knowledge), not luck. Legal: Systems do consider outcomes, but consistently applied law should recognize identical recklessness. Counterfactual: A with pedestrian = identical moral culpability, and should have identical legal culpability under principled legal reasoning. This demonstrates outcome luck in moral and legal evaluation.",
    "invariants": [
      "Both drivers: 0.10% BAC (identical impairment)",
      "Both knowingly drove drunk (identical mens rea)",
      "Both foresaw risk of fatal accidents (identical recklessness)",
      "Pedestrian presence was beyond drivers' control (luck)"
    ],
    "justification": "Identical reckless acts with identical mental states and foreseeability should receive identical moral evaluation. Outcome difference results from luck (pedestrian presence), not from different choices or levels of recklessness. Moral culpability should be equal based on controlled factors (actions, knowledge, choices), not uncontrollable circumstantial luck.",
    "wise_response": "VALID. Both drivers took identical reckless risks with same impairment and mental state. Outcome differed due to luck (pedestrian presence). Moral culpability should be equalbased on recklessness, not luck.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0173",
    "case_id": "0173",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Public Health",
    "subdomain": "Pandemic Response",
    "family": "F6",
    "subtype": "Mechanism Dependence",
    "scenario": "A country implements strict lockdowns and COVID-19 deaths remain low. Officials claim lockdowns saved 50,000 lives. However, the country is an island nation with early border closures, high voluntary compliance with distancing even before lockdown, widespread mask adoption, and a young population. Epidemiologists debate whether lockdowns specifically or the broader context determined low mortality.",
    "counterfactual_claim": "If the country had not implemented lockdowns, COVID-19 deaths would have been 50,000 higher.",
    "label": "CONDITIONAL",
    "is_ambiguous": false,
    "variables": {
      "X": "Strict lockdown policy",
      "Y": "Low COVID-19 deaths",
      "Z": [
        "Island geography with border controls",
        "High voluntary distancing compliance pre-lockdown",
        "Widespread mask adoption",
        "Young population (lower vulnerability)"
      ]
    },
    "trap": {
      "type": "F6",
      "type_name": "Epistemic Limits",
      "subtype": "Mechanism Dependence",
      "subtype_name": "Multiple Sufficient Mechanisms Unknown"
    },
    "difficulty": "Hard",
    "causal_structure": "Lockdown(X) + Geographic isolation(Z1) + Voluntary distancing(Z2) + Masks(Z3) + Young population(Z4)  Low deaths(Y). Multiple mechanisms contribute. Cannot determine X's specific contribution without counterfactual comparison or epidemiological modeling accounting for Z1-Z4.",
    "key_insight": "When multiple protective mechanisms operate simultaneously, isolating one mechanism's contribution requires controlling for others. Different mechanisms may be independently sufficient.",
    "hidden_timestamp": "The counterfactual asks about lockdown-specific attribution when multiple other protective factors were already active and potentially sufficient.",
    "conditional_answers": {
      "answer_if_condition_1": "If lockdowns were necessary on top of other protections (Z1-Z4 insufficient alone), removing lockdowns substantially increases deathsclaim VALID or partially valid.",
      "answer_if_condition_2": "If other factors (island geography, voluntary distancing, masks, young population) were already sufficient for low mortality, lockdowns were redundantclaim INVALID or substantially overstated."
    },
    "wise_refusal": "The counterfactual is CONDITIONAL on the relative contribution of lockdowns versus other protective mechanisms. The country had multiple factors associated with low COVID mortality: island geography limiting importation, high voluntary distancing compliance pre-lockdown, widespread mask use, and young demographics. These factors may have been independently sufficient or nearly sufficient for low mortality. Without epidemiological modeling that controls for these factors, or comparison to similar countries without lockdowns but with similar Z factors, we cannot isolate lockdown-specific impact. The 50,000 figure likely overstates by attributing all avoided deaths to lockdowns while ignoring concurrent protections.",
    "gold_rationale": "CONDITIONAL on mechanism contribution. Multiple protective factors: geographic isolation(Z1) limits importation, voluntary distancing(Z2) reduces transmission pre-lockdown, masks(Z3) reduce spread, young population(Z4) reduces fatality. Lockdown(X) adds incremental protection, but how much? Without counterfactual modeling or control groups, cannot determine if X was necessary on top of Z1-Z4, or if Z1-Z4 were nearly sufficient. Likely scenario: other factors prevented most deaths, lockdown contributed incrementally ~5,000-15,000, not 50,000. This demonstrates attribution challenges when multiple mechanisms operate simultaneously and individual contributions are unknown.",
    "invariants": [
      "Island nation with controlled borders (limits virus importation)",
      "High voluntary distancing compliance before lockdown mandate",
      "Widespread mask adoption (population-level)",
      "Young population demographics (lower COVID mortality risk)",
      "No controlled comparison or epidemiological adjustment available"
    ],
    "justification": "Multiple concurrent protective mechanisms. Lockdown's specific contribution cannot be isolated without controlling for geography, voluntary behavior, masks, and demographics. The 50,000 claim likely overstates by attributing all avoided deaths to one mechanism. Need epidemiological modeling or control comparisons to determine lockdown-specific effect on top of other protections.",
    "wise_response": "CONDITIONAL. Multiple protections (geography, voluntary distancing, masks, young population) contributed to low deaths. Cannot isolate lockdown's specific contribution without controlling for other factors. 50,000 likely overstates.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0174",
    "case_id": "0174",
    "bucket": "T3-BucketD",
    "pearl_level": "L3",
    "domain": "Technology",
    "subdomain": "Cybersecurity",
    "family": "F7",
    "subtype": "Attributable Fraction",
    "scenario": "A company implements multi-factor authentication for all employees. In the following year, successful phishing attacks drop from 50 to 5 incidents. The security team calculates: 'MFA prevented 45 breaches.' However, during the same period, the company also deployed advanced email filtering, conducted mandatory security training quarterly, and restricted USB drive usage. Each intervention has documented effectiveness in preventing phishing.",
    "counterfactual_claim": "If multi-factor authentication had not been implemented, the company would have experienced 50 phishing breaches (MFA prevented 45 breaches).",
    "label": "INVALID",
    "is_ambiguous": false,
    "variables": {
      "X": "Multi-factor authentication (MFA) implementation",
      "Y": "Phishing attacks dropped from 50 to 5 (90% reduction)",
      "Z": [
        "Advanced email filtering (blocks phishing emails)",
        "Quarterly security training (teaches recognition)",
        "USB drive restrictions (limits infection vector)"
      ]
    },
    "trap": {
      "type": "F7",
      "type_name": "Causal Attribution",
      "subtype": "Attributable Fraction",
      "subtype_name": "Multiple Concurrent Security Controls"
    },
    "difficulty": "Medium",
    "causal_structure": "MFA(X) + Email filtering(Z1) + Training(Z2) + USB restrictions(Z3)  90% phishing reduction(Y). Each security control independently reduces risk. Research shows: email filtering stops 60-70%, training reduces susceptibility 30-40%, MFA blocks compromised credentials. Concurrent layers provide defense in depth.",
    "key_insight": "Cybersecurity uses defense in depthmultiple controls operating simultaneously. Attributing all risk reduction to one control ignores other active defenses that would remain operative.",
    "hidden_timestamp": "The counterfactual removes MFA while holding other security controls (filtering, training, restrictions) constant.",
    "conditional_answers": {
      "answer_if_condition_1": "If MFA was the only security improvement and other controls were ineffective, removing MFA restores 50 breachesclaim VALID.",
      "answer_if_condition_2": "If other controls (email filtering, training, USB restrictions) also reduce phishing and would remain active without MFA, substantial reduction would occur anywayclaim INVALID."
    },
    "wise_refusal": "The counterfactual is INVALID. The 90% reduction in phishing attacks occurred alongside four concurrent security controls. Advanced email filtering blocks 60-70% of phishing emails before they reach employees. Quarterly training reduces employee susceptibility by 30-40%. USB restrictions eliminate a key infection vector. These controls would remain active in the counterfactual world without MFA. Without MFA but with other controls, phishing attacks would likely drop to approximately 10-15 incidents (not 5), representing ~70-80% reduction from email filtering and training alone. MFA's specific contribution is blocking compromised credentials (~5-10 attacks), not the entire 45-attack reduction.",
    "gold_rationale": "INVALID. Multiple concurrent security controls with documented effectiveness. Email filtering(Z1) blocks 60-70% of phishing attempts before delivery. Training(Z2) reduces susceptibility 30-40%. USB restrictions(Z3) eliminate infection vector. MFA(X) adds final layer blocking compromised credentials. Counterfactual: without X, but with Z1-Z3 active  attacks drop from 50 to ~12 (75% reduction from other controls). MFA-specific contribution: ~7 additional attacks prevented, not 45. This demonstrates attribution error in layered securityeach layer provides incremental protection, but naive before-after attributes all reduction to one layer.",
    "invariants": [
      "Email filtering remains active (blocks 60-70% of phishing emails)",
      "Quarterly security training continues (reduces susceptibility 30-40%)",
      "USB drive restrictions remain (eliminates infection vector)",
      "Security controls operate independently and additively"
    ],
    "justification": "Four concurrent security controls with documented independent effectiveness. Email filtering and training alone would prevent ~35-40 attacks. MFA adds incremental protection for compromised credentials (~5-10 attacks). The 45-attack attribution ignores that other controls would remain active. Counterfactual: without MFA, attacks would be ~12, not 50, because other defenses remain operative.",
    "wise_response": "INVALID. Email filtering and training would still prevent most phishing (~75% reduction). Without MFA but with other controls, attacks would be ~12, not 50. MFA contributed ~7 additional prevented attacks, not 45.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-D-0175",
    "case_id": "0175",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Exercise Science",
    "scenario": "Researchers conducted a randomized controlled trial with 500 sedentary adults. Half were randomly assigned to a 12-week strength training program, while the control group maintained their usual activity. The intervention group showed a 15% increase in bone density compared to controls, with p<0.001.",
    "claim": "Strength training causes increased bone density in sedentary adults.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Strength training program",
        "role": "treatment"
      },
      "Y": {
        "name": "Bone density increase",
        "role": "outcome"
      },
      "Z": [
        "Random assignment eliminates confounding"
      ]
    },
    "trap": {
      "type": "S1",
      "type_name": "Randomized Controlled Trial (RCT)",
      "subtype": "RCT_Strong",
      "subtype_name": "Strong RCT Evidence"
    },
    "difficulty": "Easy",
    "causal_structure": "Random assignment of X (strength training)  Y (bone density). No confounding due to randomization. Control group provides counterfactual comparison.",
    "key_insight": "Randomization eliminates confounding, establishing causal relationship from treatment to outcome.",
    "hidden_timestamp": "Was random assignment performed before measuring outcomes, and were baseline characteristics balanced?",
    "conditional_answers": {
      "answer_if_condition_1": "If randomization was properly implemented and baseline characteristics were balanced, the causal claim is strongly supported.",
      "answer_if_condition_2": "If randomization failed or groups differed at baseline, confounding could explain the difference."
    },
    "wise_refusal": "This is a well-designed RCT with random assignment, control group, and statistically significant results. The study design provides strong causal evidence because randomization eliminates systematic differences between groups at baseline, ensuring that observed differences in bone density can be attributed to the strength training intervention rather than confounding factors.",
    "gold_rationale": "YES. This is an S1 (RCT) case with strong evidence. Random assignment to treatment (X) vs control eliminates confounding by distributing all baseline characteristics equally across groups. The 15% increase in Y with p<0.001 in the treatment group vs control provides compelling causal evidence. RCTs are the gold standard for establishing causation.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-D-0176",
    "case_id": "0176",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Track and Field",
    "scenario": "A lightning strike at a regional track meet forced immediate cancellation of the 400m semifinal heats. The 16 athletes who would have competed were instead randomly allocated to the two final lanes based on their original heat assignments, which were determined by random draw. Athletes assigned to inside lanes ran significantly faster times in the final than those in outside lanes.",
    "claim": "Inside lane assignment causes faster 400m times.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Inside lane assignment",
        "role": "exposure"
      },
      "Y": {
        "name": "400m finishing time",
        "role": "outcome"
      },
      "Z": [
        "Random allocation by original heat draw"
      ]
    },
    "trap": {
      "type": "S2",
      "type_name": "Natural Experiment",
      "subtype": "Exogenous_Event",
      "subtype_name": "Exogenous Event Creates Randomization"
    },
    "difficulty": "Medium",
    "causal_structure": "Lightning strike (exogenous)  random lane allocation (X)  finishing time (Y). The natural event created quasi-random assignment, mimicking experimental conditions.",
    "key_insight": "Natural experiments leverage exogenous events to create quasi-random treatment assignment, approximating RCT conditions.",
    "hidden_timestamp": "Was lane assignment determined by the exogenous event (lightning) rather than athlete characteristics or coach preferences?",
    "conditional_answers": {
      "answer_if_condition_1": "If the lightning strike truly randomized lane assignments independent of athlete ability, the causal claim is supported by natural experiment logic.",
      "answer_if_condition_2": "If lane assignments were influenced by seeding or coach negotiations after the cancellation, confounding could explain the result."
    },
    "wise_refusal": "This natural experiment provides strong causal evidence because the exogenous shock (lightning strike) created random lane assignments independent of athlete characteristics. Inside lanes offer tactical advantages in the 400m (tighter turns, better positioning), and the quasi-random allocation allows us to isolate this causal effect from athlete ability differences.",
    "gold_rationale": "YES. This is an S2 (Natural Experiment) case. The lightning strike created exogenous variation in lane assignment, mimicking randomization. Athletes didn't self-select into inside vs outside lanes based on ability, eliminating selection bias. The observed speed difference can be attributed to lane position rather than pre-existing athlete differences.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketLarge-D-0177",
    "case_id": "0177",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Basketball",
    "scenario": "A professional basketball team had 300 players apply for their summer development camp, with only 30 spots available. To ensure fairness, the team used a lottery system to randomly select participants from the applicant pool. Players who won the lottery and attended camp showed a 25% higher rate of eventual NBA contract signing compared to lottery losers.",
    "claim": "Attending the development camp causes increased NBA contract rates.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Development camp attendance via lottery",
        "role": "treatment"
      },
      "Y": {
        "name": "NBA contract signing rate",
        "role": "outcome"
      },
      "Z": [
        "Lottery randomization among applicants"
      ]
    },
    "trap": {
      "type": "S3",
      "type_name": "Lottery/Quasi-Random Assignment",
      "subtype": "Oversubscribed_Lottery",
      "subtype_name": "Oversubscribed Program Lottery"
    },
    "difficulty": "Easy",
    "causal_structure": "Lottery (random)  camp attendance (X)  NBA contracts (Y). Oversubscription with random selection creates natural comparison between lottery winners and losers with similar initial ability.",
    "key_insight": "Oversubscribed lotteries create natural experiments where winners and losers are comparable except for treatment, enabling causal inference.",
    "hidden_timestamp": "Was the lottery conducted fairly such that winners and losers had similar basketball ability and career prospects before the camp?",
    "conditional_answers": {
      "answer_if_condition_1": "If the lottery truly randomized camp access among applicants, the 25% higher contract rate can be attributed to camp attendance.",
      "answer_if_condition_2": "If the lottery was rigged or if applicants differed systematically, selection bias could explain the outcome difference."
    },
    "wise_refusal": "This lottery-based quasi-experiment provides strong causal evidence. The oversubscribed camp with random selection ensures that lottery winners and losers are statistically identical in terms of basketball ability, motivation, and career prospects at baseline. The observed 25% difference in NBA contract rates can therefore be attributed to the causal effect of camp attendance rather than pre-existing player differences.",
    "gold_rationale": "YES. This is an S3 (Lottery/Quasi-Random) case. The oversubscribed lottery randomizes access to treatment (camp) among applicants. Since all 300 applicants wanted to attend, winners and losers are comparable except for random chance. The 25% higher contract rate among winners provides strong causal evidence that camp attendance improves NBA prospects.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-D-0178",
    "case_id": "0178",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Soccer",
    "scenario": "Sports scientists conducted a controlled experiment where they systematically removed the Video Assistant Referee system from half of the matches in a league season while keeping all other officiating protocols identical. Matches without VAR showed a 40% increase in controversial penalty decisions compared to matches with VAR, while other foul calls remained unchanged.",
    "claim": "VAR system prevents controversial penalty decisions.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "VAR system presence",
        "role": "treatment"
      },
      "Y": {
        "name": "Controversial penalty decisions",
        "role": "outcome"
      },
      "Z": [
        "All other officiating protocols held constant",
        "Same referee pool",
        "Same teams and stadiums"
      ]
    },
    "trap": {
      "type": "S4",
      "type_name": "Controlled Ablation",
      "subtype": "System_Removal",
      "subtype_name": "Systematic Component Removal"
    },
    "difficulty": "Medium",
    "causal_structure": "Controlled removal of VAR (X)  increase in controversial penalties (Y) while holding all other factors (Z) constant. Ablation isolates the specific causal contribution of VAR.",
    "key_insight": "Controlled ablation studies isolate causal effects by removing only the factor of interest while holding everything else constant.",
    "hidden_timestamp": "Were the matches with and without VAR otherwise identical in terms of referees, teams, stadiums, and officiating protocols?",
    "conditional_answers": {
      "answer_if_condition_1": "If all other factors were truly held constant and only VAR was removed, the 40% increase in controversial penalties can be causally attributed to VAR absence.",
      "answer_if_condition_2": "If other factors differed between VAR and non-VAR matches (e.g., referee quality, team matchups), confounding could explain the result."
    },
    "wise_refusal": "This controlled ablation study provides strong causal evidence. By systematically removing only VAR while keeping all other officiating elements constant (same referee pool, same protocols, same league), the study isolates VAR's specific causal contribution. The 40% increase in controversial penalties when VAR is absent, while other foul calls remain unchanged, indicates that VAR specifically prevents controversial penalty decisions rather than affecting all officiating decisions.",
    "gold_rationale": "YES. This is an S4 (Controlled Ablation) case. The experimental design removes only X (VAR) while holding all other factors constant (Z). The selective increase in controversial penalties (Y) but not other calls provides strong evidence that VAR causally prevents these specific errors. Ablation studies are powerful because they isolate the causal contribution of a single component.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketLarge-D-0179",
    "case_id": "0179",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Exercise Physiology",
    "scenario": "A multi-site study examined creatine supplementation and muscle mass gains in weightlifters. Researchers documented the biological mechanism: creatine increases phosphocreatine stores in muscle cells, enabling more ATP regeneration during high-intensity exercise. The study showed a dose-response relationship: 0g/day, 3g/day, 5g/day, 10g/day, with no further gains at 20g/day.",
    "claim": "Creatine supplementation causes muscle mass gains through the phosphocreatine-ATP pathway.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Creatine supplementation dose",
        "role": "treatment"
      },
      "Y": {
        "name": "Muscle mass gain percentage",
        "role": "outcome"
      },
      "Z": [
        "Phosphocreatine stores",
        "ATP regeneration",
        "Training intensity held constant"
      ]
    },
    "trap": {
      "type": "S5",
      "type_name": "Mechanism + Dose-Response",
      "subtype": "Biological_Mechanism",
      "subtype_name": "Known Biological Pathway with Dose Gradient"
    },
    "difficulty": "Medium",
    "causal_structure": "Creatine (X)  phosphocreatine stores (Z)  ATP regeneration (Z)  muscle mass gains (Y). Dose-response gradient strengthens causal inference, and plateau at high doses suggests saturation of biological mechanism.",
    "key_insight": "Combining known biological mechanism with dose-response gradient provides strong causal evidence, especially when the mechanism explains the dose pattern.",
    "hidden_timestamp": "Does the dose-response pattern align with the biological mechanism, and is there a plausible ceiling effect?",
    "conditional_answers": {
      "answer_if_condition_1": "If the dose-response gradient is monotonic up to biological saturation and the mechanism is well-established, the causal claim is strongly supported.",
      "answer_if_condition_2": "If the dose pattern is irregular or inconsistent with the proposed mechanism, alternative explanations (e.g., placebo effects, confounding) would need to be considered."
    },
    "wise_refusal": "This study provides exceptionally strong causal evidence through convergence of two lines of reasoning: (1) a well-established biological mechanism (phosphocreatine-ATP pathway), and (2) a clear dose-response relationship showing monotonic increases up to a saturation point. The plateau at 20g/day is consistent with biological saturation of muscle phosphocreatine stores, ruling out placebo effects or confounding. The mechanistic understanding explains why and how creatine causes muscle gains.",
    "gold_rationale": "YES. This is an S5 (Mechanism + Dose-Response) case. The study provides two complementary forms of causal evidence: (1) documented biological mechanism showing how X causes Y through intermediate steps, and (2) dose-response gradient with plausible saturation. The convergence of mechanistic understanding and dose patterns provides strong causal support that goes beyond simple correlation.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-D-0180",
    "case_id": "0180",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Baseball Analytics",
    "scenario": "Baseball analysts wanted to estimate the causal effect of having a designated hitter rule on run scoring. They used stadium location as an instrumental variable: American League teams are required to use the DH, while National League teams are not. Stadium location affects DH usage but doesn't directly affect run scoring except through the DH rule. The instrumental variable analysis estimated a 0.3 runs per game increase attributable to the DH.",
    "claim": "The designated hitter rule causes increased run scoring in baseball games.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Designated hitter rule adoption",
        "role": "treatment"
      },
      "Y": {
        "name": "Runs scored per game",
        "role": "outcome"
      },
      "Z": [
        "League affiliation (instrument)",
        "Team quality",
        "Pitcher skill"
      ]
    },
    "trap": {
      "type": "S6",
      "type_name": "Instrumental Variable",
      "subtype": "League_Instrument",
      "subtype_name": "League Rule as Instrument"
    },
    "difficulty": "Hard",
    "causal_structure": "League affiliation (instrument, Z)  DH rule (X)  runs scored (Y). The instrument affects Y only through X, satisfying the exclusion restriction. IV analysis isolates causal effect of X on Y by using exogenous variation in Z.",
    "key_insight": "Instrumental variables leverage exogenous variation that affects treatment but not outcome (except through treatment) to identify causal effects.",
    "hidden_timestamp": "Does league affiliation (the instrument) affect run scoring only through the DH rule, or could it affect scoring through other pathways?",
    "conditional_answers": {
      "answer_if_condition_1": "If league affiliation only affects run scoring through the DH rule (exclusion restriction holds), the IV estimate provides valid causal inference.",
      "answer_if_condition_2": "If league affiliation affects scoring through other channels (e.g., different umpiring culture, park factors), the exclusion restriction is violated and the causal estimate is biased."
    },
    "wise_refusal": "This instrumental variable analysis provides strong causal evidence if the exclusion restriction holds. League affiliation creates exogenous variation in DH adoption (American League requires it, National League doesn't) and plausibly affects run scoring only through this rule rather than through other systematic differences between leagues. The IV method isolates the causal effect of the DH by using only the variation in DH usage that comes from league affiliation, filtering out endogenous decisions and confounding.",
    "gold_rationale": "YES. This is an S6 (Instrumental Variable) case. League affiliation serves as a valid instrument if: (1) it strongly predicts DH usage (relevance), (2) it's exogenous to run scoring ability (exogeneity), and (3) it affects scoring only through DH rule (exclusion restriction). IV analysis uses exogenous variation to identify causal effects when randomization isn't feasible. The 0.3 runs per game estimate is the causal effect if the instrument is valid.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketLarge-D-0181",
    "case_id": "0181",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Tennis",
    "scenario": "Researchers studied the effect of clay court surface versus hard court surface on player injury rates in professional tennis. They analyzed injury data for the same players across multiple seasons, comparing injury rates in the clay court season versus hard court season. Using difference-in-differences analysis with players as their own controls, they found clay courts reduced injury rates by 18% compared to hard courts, after accounting for seasonal trends and player aging.",
    "claim": "Clay court surface causes lower injury rates compared to hard courts in professional tennis.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Clay court vs hard court surface",
        "role": "exposure"
      },
      "Y": {
        "name": "Player injury rate",
        "role": "outcome"
      },
      "Z": [
        "Season effects",
        "Player aging",
        "Match intensity"
      ]
    },
    "trap": {
      "type": "S7",
      "type_name": "Difference-in-Differences",
      "subtype": "Within_Player",
      "subtype_name": "Within-Player Comparison Across Seasons"
    },
    "difficulty": "Hard",
    "causal_structure": "Diff-in-diff compares injury rates for same players on clay vs hard courts across seasons. Player fixed effects control for time-invariant differences. Parallel pre-trends assumption: clay and hard court injury trends were similar before the comparison period.",
    "key_insight": "Difference-in-differences leverages within-subject comparisons and parallel trends to isolate causal effects of time-varying treatments.",
    "hidden_timestamp": "Did clay and hard court injury rates follow parallel trends before the comparison period, suggesting the 18% reduction is due to surface rather than other time-varying factors?",
    "conditional_answers": {
      "answer_if_condition_1": "If parallel pre-trends hold and players are their own controls, the 18% injury reduction can be causally attributed to clay surface's impact-absorbing properties.",
      "answer_if_condition_2": "If pre-trends were not parallel or if other factors (e.g., tournament intensity differences between clay and hard seasons) varied systematically, the causal interpretation is threatened."
    },
    "wise_refusal": "This difference-in-differences analysis provides strong causal evidence by comparing the same players across different court surfaces over time. By using players as their own controls, the design eliminates confounding from time-invariant player characteristics (e.g., inherent injury susceptibility). The parallel trends assumption is crucial: if injury rates were trending similarly on both surfaces before the comparison period, the 18% reduction on clay can be attributed to the surface's causal effect rather than pre-existing differences.",
    "gold_rationale": "YES. This is an S7 (Difference-in-Differences) case. Diff-in-diff compares within-player changes across surfaces and time, controlling for player fixed effects and time trends. The method identifies causal effects if parallel trends hold pre-treatment. The 18% injury reduction, after accounting for seasonal and aging effects, provides strong evidence that clay surface's physical properties (softer, more impact-absorbing) causally reduce injury risk.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketLarge-D-0182",
    "case_id": "0182",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Sports Recruiting",
    "scenario": "A university athletic program accepts athletes only if their SAT score exceeds 1400. Researchers compared career earnings of athletes who scored just above the cutoff versus just below. The just-above group earned 22% more in professional sports careers, despite having nearly identical SAT scores, suggesting acceptance into the program caused the earnings difference.",
    "claim": "Acceptance into elite athletic programs causes higher professional sports earnings.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Elite program acceptance",
        "role": "treatment"
      },
      "Y": {
        "name": "Professional sports career earnings",
        "role": "outcome"
      },
      "Z": [
        "SAT cutoff at 1400",
        "Ability differences minimal near cutoff"
      ]
    },
    "trap": {
      "type": "S8",
      "type_name": "Regression Discontinuity",
      "subtype": "Sharp_Cutoff",
      "subtype_name": "Sharp Cutoff Design"
    },
    "difficulty": "Hard",
    "causal_structure": "SAT score (running variable)  program acceptance if >1400 (X)  career earnings (Y). Local randomization near cutoff: athletes just above and below are comparable except for treatment assignment.",
    "key_insight": "Regression discontinuity exploits arbitrary cutoffs to create quasi-random assignment, comparing individuals just above and below the threshold.",
    "hidden_timestamp": "Are athletes just above and below the 1400 SAT cutoff comparable in all relevant characteristics except program acceptance?",
    "conditional_answers": {
      "answer_if_condition_1": "If athletes near the cutoff are otherwise identical and the cutoff was strictly enforced, the 22% earnings difference can be causally attributed to program acceptance.",
      "answer_if_condition_2": "If athletes could manipulate their SAT scores or if the cutoff was not strictly enforced, selection bias could explain the earnings difference."
    },
    "wise_refusal": "This regression discontinuity design provides strong causal evidence by comparing athletes who are nearly identical in ability (SAT scores differ by only 20-40 points) but differ in program acceptance due to an arbitrary cutoff. Athletes just above 1400 (accepted) and just below (rejected) are essentially comparable except for treatment assignment, creating a local quasi-experiment. The 22% earnings premium for the just-above group suggests the program's training, exposure, and networking causally improve professional outcomes.",
    "gold_rationale": "YES. This is an S8 (Regression Discontinuity) case. RD designs exploit discontinuous treatment assignment at arbitrary thresholds to identify causal effects. Athletes near the cutoff (1380-1420 SAT range) are comparable except for program acceptance. The sharp earnings discontinuity at the 1400 cutoff, combined with minimal ability differences in this narrow band, provides strong evidence that program acceptance causally increases earnings.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-D-0183",
    "case_id": "0183",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Sports",
    "subdomain": "Running Performance",
    "scenario": "A study examined whether high-altitude training camps improve marathon performance. Researchers tracked 200 elite runners, finding that those who attended altitude camps ran 3% faster in subsequent sea-level marathons. However, the study noted that coaches typically send their most promising athletes to altitude camps, and the data didn't indicate whether performance improvements were measured relative to each runner's baseline or compared across different athletes. The study also didn't control for differences in training volume, coaching quality, or natural performance progression.",
    "claim": "High-altitude training camps cause improved marathon performance.",
    "label": "AMBIGUOUS",
    "is_ambiguous": true,
    "variables": {
      "X": {
        "name": "High-altitude training camp attendance",
        "role": "exposure"
      },
      "Y": {
        "name": "Marathon performance improvement",
        "role": "outcome"
      },
      "Z": [
        "Athlete selection by coaches",
        "Baseline performance level",
        "Training volume",
        "Coaching quality",
        "Natural progression"
      ]
    },
    "trap": {
      "type": "A",
      "type_name": "Ambiguous",
      "subtype": "Insufficient_Information",
      "subtype_name": "Missing Critical Design Details"
    },
    "difficulty": "Medium",
    "causal_structure": "Unclear whether X  Y or whether selection bias (coaches send best athletes to camps) and unmeasured confounders (Z) explain the association. The study design is incompletely described, making causal interpretation impossible without additional information.",
    "key_insight": "Claims are ambiguous when critical methodological details are missing, preventing determination of whether evidence supports causation, confounding, or selection bias.",
    "hidden_timestamp": "Were performance improvements measured within-athlete (before vs after camp) or between-athletes (camp attendees vs non-attendees)? Were baseline characteristics and training factors controlled?",
    "conditional_answers": {
      "answer_if_condition_1": "If the study used within-athlete comparisons (each runner compared to their own baseline) and controlled for training volume and natural progression, the causal claim could be supported.",
      "answer_if_condition_2": "If the study simply compared camp attendees to non-attendees without controlling for selection bias (coaches sending top athletes) and confounding factors, the claim is unjustified due to confounding and selection bias."
    },
    "wise_refusal": "This claim is AMBIGUOUS because the study design is insufficiently described. We cannot determine whether the 3% improvement reflects a true causal effect of altitude training or merely reflects selection bias (better athletes attend camps) and confounding (camp attendees may have more training volume, better coaching, or were already on an upward performance trajectory). The critical missing information includes: (1) whether comparisons were within-athlete or between-athlete, (2) whether baseline performance was controlled, and (3) whether other training factors were held constant. Without these methodological details, we cannot distinguish causation from correlation.",
    "gold_rationale": "AMBIGUOUS. This case lacks sufficient methodological information to determine causality. The scenario describes an association (X correlates with Y) but doesn't provide enough detail about study design, comparison groups, or control variables. Unlike a clear W7 confounding case (where confounders are identified but not controlled), this case is ambiguous because we don't know if it's a within-athlete study (potentially valid) or between-athlete comparison (potentially confounded). The claim could be valid under proper study design or invalid under poor designwe cannot tell from the information provided. More details about the research methodology are needed to make a determination.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  }
]