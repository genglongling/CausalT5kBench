[
  {
    "case_id": "0048",
    "id": "T3-BucketD-0048",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Public Policy",
    "scenario": "Cities with more police officers per capita tend to have higher recorded crime rates.",
    "claim": "Hiring more police causes crime to increase.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "REVERSE",
      "subtype": "Outcome-driven Selection"
    },
    "variables": {
      "X": "Police officers per capita",
      "Y": "Recorded crime rate",
      "Z": [
        "Underlying crime pressure"
      ]
    },
    "gold_rationale": "Cities often hire more police in response to higher crime (or its drivers). The direction of influence is plausibly from crime pressure to staffing, so the observed association does not justify the causal claim that police hiring increases crime.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Public Policy",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that hiring more police causes crime to increase because cities often hire more police in response to higher crime (or its drivers). The direction of influence is plausibly from crime pressure to staffing, so the observed association does not justify the causal claim that police hiring increases crime. This suggests a potential REVERSE issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If changes in Police officers per capita clearly precede changes in Recorded crime rate in time, the claim is more likely to be true.",
      "answer_if_condition_2": "If Recorded crime rate actually drives Police officers per capita (reverse causality), then manipulating Police officers per capita will not produce the expected result in Recorded crime rate."
    },
    "hidden_timestamp": "Did Underlying crime pressure occur or change before the exposure?",
    "causal_structure": "Underlying crime pressure -> Police officers per capita, Underlying crime pressure -> Recorded crime rate",
    "key_insight": "Cities often hire more police in response to higher crime (or its drivers). The direction of influen",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0049",
    "id": "T3-BucketD-0049",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Education",
    "scenario": "In a school district, students who attend after-school tutoring have higher GPAs than students who do not.",
    "claim": "Tutoring causes students to have higher GPAs.",
    "label": "AMBIGUOUS",
    "is_ambiguous": true,
    "trap": {
      "type": "CONFOUNDING",
      "subtype": "Socioeconomic"
    },
    "variables": {
      "X": "Tutoring attendance",
      "Y": "GPA",
      "Z": [
        "Family resources and support"
      ]
    },
    "gold_rationale": "Students who attend tutoring may differ systematically in family resources, baseline preparedness, or parental support, which can also affect GPA. Without information on selection into tutoring or controls for these factors, the causal claim is underdetermined.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Hard",
    "subdomain": "Education",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that tutoring causes students to have higher gpas because students who attend tutoring may differ systematically in family resources, baseline preparedness, or parental support, which can also affect GPA. Without information on selection into tutoring or controls for these factors, the causal claim is underdetermined. This suggests a potential CONFOUNDING issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the relationship between Tutoring attendance and GPA persists even when we control for Family resources and support, then there may be a causal link.",
      "answer_if_condition_2": "If the observed correlation vanishes when we compare individuals with the same Family resources and support, then the relationship is spurious."
    },
    "hidden_timestamp": "Did Family resources and support occur or change before the exposure?",
    "causal_structure": "Family resources and support -> Tutoring attendance, Family resources and support -> GPA",
    "key_insight": "Students who attend tutoring may differ systematically in family resources, baseline preparedness, o",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0052",
    "id": "T3-BucketD-0052",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Psychology",
    "scenario": "A person notices that whenever they carry an umbrella, it rains later that day.",
    "claim": "Carrying an umbrella causes it to rain.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "CONFOUNDING",
      "subtype": "Omitted Variable"
    },
    "variables": {
      "X": "Carrying an umbrella",
      "Y": "Rain occurrence",
      "Z": [
        "Weather forecast or dark clouds"
      ]
    },
    "gold_rationale": "People tend to carry umbrellas when rain is already likely based on forecasts or visible weather cues. Those cues predict rain and also influence umbrella-carrying, so the observed correlation is not causal.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Psychology",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that carrying an umbrella causes it to rain because people tend to carry umbrellas when rain is already likely based on forecasts or visible weather cues. Those cues predict rain and also influence umbrella-carrying, so the observed correlation is not causal. This suggests a potential CONFOUNDING issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the relationship between Carrying an umbrella and Rain occurrence persists even when we control for Weather forecast or dark clouds, then there may be a causal link.",
      "answer_if_condition_2": "If the observed correlation vanishes when we compare individuals with the same Weather forecast or dark clouds, then the relationship is spurious."
    },
    "hidden_timestamp": "Did Weather forecast or dark clouds occur or change before the exposure?",
    "causal_structure": "Weather forecast or dark clouds -> Carrying an umbrella, Weather forecast or dark clouds -> Rain occurrence",
    "key_insight": "People tend to carry umbrellas when rain is already likely based on forecasts or visible weather cue",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0147",
    "id": "T3-BucketD-0147",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Public Policy",
    "scenario": "A report finds that neighborhoods with more police patrols have higher recorded crime rates. The same report notes that the city increased patrols specifically in areas where residents had complained about recent crime spikes. Commentators conclude that police patrols increase crime.",
    "claim": "Increasing police patrols causes crime to increase.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "REVERSE",
      "subtype": "Outcome-driven Selection"
    },
    "variables": {
      "X": "Police patrol intensity",
      "Y": "Recorded crime rate",
      "Z": [
        "Prior crime conditions driving patrol deployment"
      ]
    },
    "gold_rationale": "Patrols are deployed because crime is already high or rising, so the outcome (or its causes) influences exposure. The observed association does not support the claimed causal direction.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Public Policy",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that increasing police patrols causes crime to increase because patrols are deployed because crime is already high or rising, so the outcome (or its causes) influences exposure. The observed association does not support the claimed causal direction. This suggests a potential REVERSE issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If changes in Police patrol intensity clearly precede changes in Recorded crime rate in time, the claim is more likely to be true.",
      "answer_if_condition_2": "If Recorded crime rate actually drives Police patrol intensity (reverse causality), then manipulating Police patrol intensity will not produce the expected result in Recorded crime rate."
    },
    "hidden_timestamp": "Did Prior crime conditions driving patrol deployment occur or change before the exposure?",
    "causal_structure": "Prior crime conditions driving patrol deployment -> Police patrol intensity, Prior crime conditions driving patrol deployment -> Recorded crime rate",
    "key_insight": "Patrols are deployed because crime is already high or rising, so the outcome (or its causes) influen",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0148",
    "id": "T3-BucketD-0148",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Education",
    "scenario": "Students who attend private tutoring tend to have higher standardized test scores. In the same dataset, families who purchase tutoring also report higher household income and greater access to educational resources. Some parents conclude that tutoring itself is the reason for the higher scores.",
    "claim": "Tutoring causes students to score higher on standardized tests.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "CONFOUNDING",
      "subtype": "Socioeconomic"
    },
    "variables": {
      "X": "Tutoring attendance",
      "Y": "Test scores",
      "Z": [
        "Socioeconomic status"
      ]
    },
    "gold_rationale": "Socioeconomic status affects both the likelihood of receiving tutoring and test performance. The association can be explained without attributing a causal effect to tutoring.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Education",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that tutoring causes students to score higher on standardized tests because socioeconomic status affects both the likelihood of receiving tutoring and test performance. The association can be explained without attributing a causal effect to tutoring. This suggests a potential CONFOUNDING issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the relationship between Tutoring attendance and Test scores persists even when we control for Socioeconomic status, then there may be a causal link.",
      "answer_if_condition_2": "If the observed correlation vanishes when we compare individuals with the same Socioeconomic status, then the relationship is spurious."
    },
    "hidden_timestamp": "Did Socioeconomic status occur or change before the exposure?",
    "causal_structure": "Socioeconomic status -> Tutoring attendance, Socioeconomic status -> Test scores",
    "key_insight": "Socioeconomic status affects both the likelihood of receiving tutoring and test performance. The ass",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0151",
    "id": "T3-BucketD-0151",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Psychology",
    "scenario": "A stress-reduction study begins with 200 participants and measures stress after 8 weeks. Many highly stressed participants stop responding to follow-up surveys, while lower-stress participants are more likely to complete the final questionnaire. The final report claims the program reduced stress because the remaining sample shows lower stress.",
    "claim": "The stress-reduction program caused stress to decrease.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "SELECTION",
      "subtype": "Attrition Bias"
    },
    "variables": {
      "X": "Participation in the program",
      "Y": "Measured stress at 8 weeks",
      "Z": [
        "Dropout correlated with baseline stress"
      ]
    },
    "gold_rationale": "Because dropout is not random, the observed reduction can be explained by selective attrition rather than a true effect of the program.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Psychology",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that the stress-reduction program caused stress to decrease because because dropout is not random, the observed reduction can be explained by selective attrition rather than a true effect of the program. This suggests a potential SELECTION issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the sample data is truly representative of the general population involving Participation in the program and Measured stress at 8 weeks, the conclusion stands.",
      "answer_if_condition_2": "If the selection process was biased by Dropout correlated with baseline stress or other factors, the observation does not generalize to the population."
    },
    "hidden_timestamp": "Did Dropout correlated with baseline stress occur or change before the exposure?",
    "causal_structure": "Dropout correlated with baseline stress -> Participation in the program, Dropout correlated with baseline stress -> Measured stress at 8 weeks",
    "key_insight": "Because dropout is not random, the observed reduction can be explained by selective attrition rather",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0152",
    "id": "T3-BucketD-0152",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Education",
    "scenario": "A university looks only at admitted students and finds that among admits, higher test scores are associated with slightly weaker personal essays. Admissions officers argue this shows test scores and essay quality trade off naturally. However, admission depends on both test scores and essay strength.",
    "claim": "Higher test scores cause weaker personal essays.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "COLLIDER",
      "subtype": "Conditioning on Participation"
    },
    "variables": {
      "X": "Test score",
      "Y": "Essay strength",
      "Z": [
        "Admission decision (selected sample)"
      ]
    },
    "gold_rationale": "Conditioning on admission (a common effect of test scores and essays) induces a spurious association between them. The observed pattern does not reflect a causal relationship.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Education",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that higher test scores cause weaker personal essays because conditioning on admission (a common effect of test scores and essays) induces a spurious association between them. The observed pattern does not reflect a causal relationship. This suggests a potential COLLIDER issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the analysis is performed without conditioning on Admission decision (selected sample) (the collider), the true relationship can be seen.",
      "answer_if_condition_2": "If we control for Admission decision (selected sample), we induce a spurious association between Test score and Essay strength."
    },
    "hidden_timestamp": "Did Admission decision (selected sample) occur or change before the exposure?",
    "causal_structure": "Admission decision (selected sample) -> Test score, Admission decision (selected sample) -> Essay strength",
    "key_insight": "Conditioning on admission (a common effect of test scores and essays) induces a spurious association",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0153",
    "id": "T3-BucketD-0153",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Public Policy",
    "scenario": "A national dataset shows that a job training program appears harmful overall, with participants having lower average earnings than non-participants. When analysts split the data by age group, the program appears beneficial within every age bracket. A headline concludes the program reduces earnings.",
    "claim": "Participating in the job training program reduces earnings.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "SIMPSONS",
      "subtype": "Aggregation Bias"
    },
    "variables": {
      "X": "Training participation",
      "Y": "Earnings",
      "Z": [
        "Age group (lurking stratifier)"
      ]
    },
    "gold_rationale": "The aggregate association reverses compared to each subgroup due to differing group proportions. The overall conclusion is an artifact of aggregation.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Public Policy",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that participating in the job training program reduces earnings because the aggregate association reverses compared to each subgroup due to differing group proportions. The overall conclusion is an artifact of aggregation. This suggests a potential SIMPSONS issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the trend holds true within each subgroup defined by Age group (lurking stratifier), the aggregate trend is valid.",
      "answer_if_condition_2": "If the trend reverses within subgroups of Age group (lurking stratifier), the aggregate correlation is misleading."
    },
    "hidden_timestamp": "Did Age group (lurking stratifier) occur or change before the exposure?",
    "causal_structure": "Age group (lurking stratifier) -> Training participation, Age group (lurking stratifier) -> Earnings",
    "key_insight": "The aggregate association reverses compared to each subgroup due to differing group proportions. The",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0156",
    "id": "T3-BucketD-0156",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Psychology",
    "scenario": "A mental health screening test has a 95% true positive rate and a 95% true negative rate for a rare condition affecting 1 in 1,000 people. A person tests positive, and a friend confidently says the person almost certainly has the condition. The friend ignores how rare the condition is in the first place.",
    "claim": "Because the test is 95% accurate and the result is positive, the person almost certainly has the condition.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "BASE_RATE",
      "subtype": "Prior Ignorance"
    },
    "variables": {
      "X": "Positive test result",
      "Y": "Having the condition",
      "Z": [
        "Low base rate of the condition"
      ]
    },
    "gold_rationale": "With a very low base rate, false positives can outnumber true positives even for accurate tests. Ignoring the prior probability leads to an invalid inference.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Psychology",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that because the test is 95% accurate and the result is positive, the person almost certainly has the condition because with a very low base rate, false positives can outnumber true positives even for accurate tests. Ignoring the prior probability leads to an invalid inference. This suggests a potential BASE_RATE issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If we account for the prior probability (base rate) of Having the condition, the evidence Positive test result might be less strong.",
      "answer_if_condition_2": "If we ignore the base rate, we might overestimate the likelihood of Having the condition given Positive test result."
    },
    "hidden_timestamp": "Did Low base rate of the condition occur or change before the exposure?",
    "causal_structure": "Low base rate of the condition -> Positive test result, Low base rate of the condition -> Having the condition",
    "key_insight": "With a very low base rate, false positives can outnumber true positives even for accurate tests. Ign",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0157",
    "id": "T3-BucketD-0157",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Education",
    "scenario": "Students who own personal laptops tend to have higher GPAs. These students also disproportionately come from higher-income households with more academic support at home. Observers conclude that owning a laptop improves academic performance.",
    "claim": "Owning a laptop causes students to earn higher GPAs.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "CONFOUNDING",
      "subtype": "Socioeconomic"
    },
    "variables": {
      "X": "Laptop ownership",
      "Y": "GPA",
      "Z": [
        "Household income"
      ]
    },
    "gold_rationale": "Socioeconomic status affects both access to laptops and academic performance, explaining the association without a causal effect.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Education",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that owning a laptop causes students to earn higher gpas because socioeconomic status affects both access to laptops and academic performance, explaining the association without a causal effect. This suggests a potential CONFOUNDING issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the relationship between Laptop ownership and GPA persists even when we control for Household income, then there may be a causal link.",
      "answer_if_condition_2": "If the observed correlation vanishes when we compare individuals with the same Household income, then the relationship is spurious."
    },
    "hidden_timestamp": "Did Household income occur or change before the exposure?",
    "causal_structure": "Household income -> Laptop ownership, Household income -> GPA",
    "key_insight": "Socioeconomic status affects both access to laptops and academic performance, explaining the associa",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0158",
    "id": "T3-BucketD-0158",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Public Policy",
    "scenario": "Cities with more homeless shelters report higher homelessness counts. These shelters are typically built in cities where homelessness is already severe. Commentators argue that shelters cause homelessness to increase.",
    "claim": "Building homeless shelters increases homelessness.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "REVERSE",
      "subtype": "Outcome-driven Selection"
    },
    "variables": {
      "X": "Number of shelters",
      "Y": "Homelessness count",
      "Z": [
        "Pre-existing homelessness levels"
      ]
    },
    "gold_rationale": "Shelters are built in response to homelessness, not the cause of it.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Public Policy",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that building homeless shelters increases homelessness because shelters are built in response to homelessness, not the cause of it. This suggests a potential REVERSE issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If changes in Number of shelters clearly precede changes in Homelessness count in time, the claim is more likely to be true.",
      "answer_if_condition_2": "If Homelessness count actually drives Number of shelters (reverse causality), then manipulating Number of shelters will not produce the expected result in Homelessness count."
    },
    "hidden_timestamp": "Did Pre-existing homelessness levels occur or change before the exposure?",
    "causal_structure": "Pre-existing homelessness levels -> Number of shelters, Pre-existing homelessness levels -> Homelessness count",
    "key_insight": "Shelters are built in response to homelessness, not the cause of it.",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0161",
    "id": "T3-BucketD-0161",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Psychology",
    "scenario": "A mental health program reports lower anxiety levels among participants at the end of the study. However, many participants with severe anxiety stopped responding to surveys before the final measurement. Researchers claim the program reduced anxiety.",
    "claim": "The mental health program reduced anxiety.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "SELECTION",
      "subtype": "Attrition Bias"
    },
    "variables": {
      "X": "Program participation",
      "Y": "Measured anxiety",
      "Z": [
        "Non-random dropout"
      ]
    },
    "gold_rationale": "Selective dropout of highly anxious participants biases the observed outcomes.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Psychology",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that the mental health program reduced anxiety because selective dropout of highly anxious participants biases the observed outcomes. This suggests a potential SELECTION issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the sample data is truly representative of the general population involving Program participation and Measured anxiety, the conclusion stands.",
      "answer_if_condition_2": "If the selection process was biased by Non-random dropout or other factors, the observation does not generalize to the population."
    },
    "hidden_timestamp": "Did Non-random dropout occur or change before the exposure?",
    "causal_structure": "Non-random dropout -> Program participation, Non-random dropout -> Measured anxiety",
    "key_insight": "Selective dropout of highly anxious participants biases the observed outcomes.",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0162",
    "id": "T3-BucketD-0162",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Education",
    "scenario": "A university examines only admitted students and finds that higher recommendation scores are associated with lower test scores. Admissions officers argue that strong recommendations compensate for weaker academics.",
    "claim": "Strong recommendations cause lower test scores.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "COLLIDER",
      "subtype": "Conditioning on Participation"
    },
    "variables": {
      "X": "Recommendation strength",
      "Y": "Test scores",
      "Z": [
        "Admission decision"
      ]
    },
    "gold_rationale": "Conditioning on admission induces a spurious association between recommendations and test scores.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Education",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that strong recommendations cause lower test scores because conditioning on admission induces a spurious association between recommendations and test scores. This suggests a potential COLLIDER issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the analysis is performed without conditioning on Admission decision (the collider), the true relationship can be seen.",
      "answer_if_condition_2": "If we control for Admission decision, we induce a spurious association between Recommendation strength and Test scores."
    },
    "hidden_timestamp": "Did Admission decision occur or change before the exposure?",
    "causal_structure": "Admission decision -> Recommendation strength, Admission decision -> Test scores",
    "key_insight": "Conditioning on admission induces a spurious association between recommendations and test scores.",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0163",
    "id": "T3-BucketD-0163",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Public Policy",
    "scenario": "A nationwide dataset shows that a health program appears ineffective overall. When analysts split the data by region, the program is beneficial in every region. A report concludes the program does not work.",
    "claim": "The health program is ineffective.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "SIMPSONS",
      "subtype": "Aggregation Bias"
    },
    "variables": {
      "X": "Program participation",
      "Y": "Health outcomes",
      "Z": [
        "Region"
      ]
    },
    "gold_rationale": "The aggregate association reverses compared to all subgroups due to different group weights.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Public Policy",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that the health program is ineffective because the aggregate association reverses compared to all subgroups due to different group weights. This suggests a potential SIMPSONS issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If the trend holds true within each subgroup defined by Region, the aggregate trend is valid.",
      "answer_if_condition_2": "If the trend reverses within subgroups of Region, the aggregate correlation is misleading."
    },
    "hidden_timestamp": "Did Region occur or change before the exposure?",
    "causal_structure": "Region -> Program participation, Region -> Health outcomes",
    "key_insight": "The aggregate association reverses compared to all subgroups due to different group weights.",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0164",
    "id": "T3-BucketD-0164",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Arts",
    "scenario": "Well-known artists receive more gallery invitations than lesser-known artists. Observers argue that gallery invitations increase artistic reputation. In reality, reputation determines who is invited.",
    "claim": "Gallery invitations cause artists to become well known.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "REVERSE",
      "subtype": "Outcome-driven Selection"
    },
    "variables": {
      "X": "Gallery invitations",
      "Y": "Artist reputation",
      "Z": [
        "Existing fame"
      ]
    },
    "gold_rationale": "Artists are invited because they are already well known, reversing the causal direction.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Arts",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that gallery invitations cause artists to become well known because artists are invited because they are already well known, reversing the causal direction. This suggests a potential REVERSE issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If changes in Gallery invitations clearly precede changes in Artist reputation in time, the claim is more likely to be true.",
      "answer_if_condition_2": "If Artist reputation actually drives Gallery invitations (reverse causality), then manipulating Gallery invitations will not produce the expected result in Artist reputation."
    },
    "hidden_timestamp": "Did Existing fame occur or change before the exposure?",
    "causal_structure": "Existing fame -> Gallery invitations, Existing fame -> Artist reputation",
    "key_insight": "Artists are invited because they are already well known, reversing the causal direction.",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "case_id": "0166",
    "id": "T3-BucketD-0166",
    "bucket": "BucketLarge-D",
    "pearl_level": "L1",
    "domain": "Psychology",
    "scenario": "A diagnostic test for a rare disorder has high accuracy. A person tests positive, and a clinician assumes the disorder is almost certain. The disorder affects fewer than 1 in 10,000 people.",
    "claim": "Because the test is accurate and positive, the person almost certainly has the disorder.",
    "label": "NO",
    "is_ambiguous": false,
    "trap": {
      "type": "BASE_RATE",
      "subtype": "Prior Ignorance"
    },
    "variables": {
      "X": "Positive test result",
      "Y": "Having the disorder",
      "Z": [
        "Low base rate"
      ]
    },
    "gold_rationale": "Ignoring the rarity of the condition leads to a severe overestimate of the probability.",
    "annotation": {
      "author": "Samantha van Rijs",
      "num_annotators": 1,
      "adjudicated": false
    },
    "difficulty": "Medium",
    "subdomain": "Psychology",
    "initial_author": "Samantha van Rijs",
    "validator": "Manolo Alvarez",
    "wise_refusal": "We cannot definitively conclude that because the test is accurate and positive, the person almost certainly has the disorder because ignoring the rarity of the condition leads to a severe overestimate of the probability. This suggests a potential BASE_RATE issue.",
    "conditional_answers": {
      "answer_if_condition_1": "If we account for the prior probability (base rate) of Having the disorder, the evidence Positive test result might be less strong.",
      "answer_if_condition_2": "If we ignore the base rate, we might overestimate the likelihood of Having the disorder given Positive test result."
    },
    "hidden_timestamp": "Did Low base rate occur or change before the exposure?",
    "causal_structure": "Low base rate -> Positive test result, Low base rate -> Having the disorder",
    "key_insight": "Ignoring the rarity of the condition leads to a severe overestimate of the probability.",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-J-1.1",
    "bucket": "BucketLarge-J",
    "case_id": "0001",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Digital Media",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "An organization reports a very positive statistic for Average star rating based only on observations from a subset of people.\nThe subset is formed by Who leaves reviews that is voluntary or outcome-dependent.\nInternal notes suggest people with negative experiences are less likely to be observed in the dataset.",
    "claim": "An organization reports a very positive statistic for Average star rating based only on observations from a subset of people",
    "variables": {
      "X": {
        "name": "Who leaves reviews",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Average star rating",
        "role": "Outcome"
      },
      "Z": [
        "Underlying true outcome (positive/negative)"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Sampling-on-the-Outcome",
      "subtype_name": "Sampling Bias"
    },
    "label": "YES",
    "causal_structure": "Z affects whether an observation is recorded (X), and Y is computed only among observed cases.",
    "key_insight": "Observed outcomes reflect who is observed, not the full population.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Underlying true outcome (positive/negative)); otherwise Who leaves reviews–Average star rating differences may reflect selection rather than effect.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Underlying true outcome (positive/negative)); otherwise Who leaves reviews–Average star rating differences may reflect selection rather than effect.",
    "hidden_timestamp": "At what point were units selected into the observed sample—before or after Average star rating occurred—and is selection related to Underlying true outcome (positive/negative) or Average star rating?",
    "conditional_answers": {
      "A": "Answer if Who leaves reviews is randomly assigned: A difference in Average star rating across Who leaves reviews groups can be interpreted causally.",
      "B": "Answer if participation/exposure is voluntary or selected (e.g., Underlying true outcome (positive/negative)): The Who leaves reviews vs not-Who leaves reviews difference in Average star rating is biased by who ends up observed/treated.",
      "C": "Answer if you can measure the selection drivers (e.g., Underlying true outcome (positive/negative)) and adjust (matching/weighting/IV): The conclusion becomes CONDITIONAL on those assumptions and model quality."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.87,
    "validator_2": "Longling Geng",
    "final_score_2": 9.62
  },
  {
    "id": "T3-BucketLarge-J-1.10",
    "bucket": "BucketLarge-J",
    "case_id": "0010",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Media Economics",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A blog analyzes “what makes a film profitable” by looking only at movies that won major awards. The author finds that award-winning films have high budgets and concludes that increasing budgets causes higher profits.\n\nThe dataset excludes many high-budget films that were not nominated or that failed commercially. Award status is a filter for inclusion.",
    "claim": "increasing budgets causes higher profits",
    "variables": {
      "X": {
        "name": "Production budget",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Profit",
        "role": "Outcome"
      },
      "Z": [
        "Award nomination/win status"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Sampling-on-the-Outcome",
      "subtype_name": "Sampling Bias"
    },
    "label": "YES",
    "causal_structure": "Conditioning on Z (award inclusion) selects a non-representative subset; X–Y relationship differs from full population.",
    "key_insight": "Analyzing only visible successes distorts relationships between inputs and outcomes.",
    "gold_rationale": "I can’t draw a causal conclusion without data on non-award films and a clear sampling frame that includes both successes and failures.",
    "wise_refusal": "I can’t draw a causal conclusion without data on non-award films and a clear sampling frame that includes both successes and failures.",
    "hidden_timestamp": "Is award status determined before profits are realized, or is the dataset effectively filtered after outcomes are known?",
    "conditional_answers": {
      "A": "Answer if awards are unrelated to profit (unlikely): Restriction would be less problematic.",
      "B": "Answer if awards filter on quality/visibility correlated with profit: Include all films to avoid selection bias.",
      "C": "Answer if you can model nomination probability: Any correction remains assumption-dependent."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.17,
    "validator_2": "Longling Geng",
    "final_score_2": 8.92
  },
  {
    "id": "T3-BucketLarge-J-1.11",
    "bucket": "BucketLarge-J",
    "case_id": "0011",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Labor Policy",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A city runs a six-month workforce training program and reports that participants’ average wages increased by 20%. Officials conclude the program boosted earnings.\n\nHowever, 40% of participants dropped out and are missing from the final wage measurement. The report analyzes only participants who completed the program.",
    "claim": "participants’ average wages increased by 20%",
    "variables": {
      "X": {
        "name": "Training program enrollment",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Post-program wage",
        "role": "Outcome"
      },
      "Z": [
        "Program completion (complete vs. dropout)"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Attrition Bias",
      "subtype_name": "Attrition Bias"
    },
    "label": "YES",
    "causal_structure": "Completion is selected post-enrollment; completers differ from dropouts in factors affecting Y.",
    "key_insight": "Attrition can make observed improvements unrepresentative of the full enrolled group.",
    "gold_rationale": "I can’t estimate overall impact without outcomes (or credible imputations) for dropouts and evidence about why participants left.",
    "wise_refusal": "I can’t estimate overall impact without outcomes (or credible imputations) for dropouts and evidence about why participants left.",
    "hidden_timestamp": "Did dropout occur after participants could have benefited (or been harmed) by the program, making completion a post-treatment selection?",
    "conditional_answers": {
      "A": "Answer if dropout is random: Completer outcomes may approximate all enrollees.",
      "B": "Answer if dropout is related to constraints or low baseline readiness: Use intent-to-treat or obtain administrative wage data for dropouts.",
      "C": "Answer if dropouts can be followed up: Measuring outcomes for all reduces attrition bias."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.61,
    "validator_2": "Longling Geng",
    "final_score_2": 9.36
  },
  {
    "id": "T3-BucketLarge-J-1.12",
    "bucket": "BucketLarge-J",
    "case_id": "0012",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Policy",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "A school district observes that students who attend private tutoring have higher math scores than students who do not. Administrators conclude tutoring causes higher scores.\n\nStudents who get tutoring are more likely to come from higher-income families with more educational resources at home.",
    "claim": "A school district observes that students who attend private tutoring have higher math scores than students who do not",
    "variables": {
      "X": {
        "name": "Tutoring attendance",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Math test score",
        "role": "Outcome"
      },
      "Z": [
        "Socioeconomic resources"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Socioeconomic",
      "subtype_name": "Socioeconomic"
    },
    "label": "YES",
    "causal_structure": "Z influences both X and Y, creating a spurious X–Y association.",
    "key_insight": "A common cause can make correlation look like causation.",
    "gold_rationale": "I can’t make a causal claim without baseline scores, resource measures, and a credible strategy to compare similar students.",
    "wise_refusal": "I can’t make a causal claim without baseline scores, resource measures, and a credible strategy to compare similar students.",
    "hidden_timestamp": "Were family resources present before tutoring began, making them a baseline confounder?",
    "conditional_answers": {
      "A": "Answer if tutoring were randomly assigned: Score differences could be attributed to tutoring.",
      "B": "Answer if tutoring is purchased mostly by higher-resource families: Adjust for baseline resources and prior scores; residual confounding may remain.",
      "C": "Answer if comparing within the same school and income bracket: Confounding is reduced but not eliminated."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.48,
    "validator_2": "Longling Geng",
    "final_score_2": 9.23
  },
  {
    "id": "T3-BucketLarge-J-1.13",
    "bucket": "BucketLarge-J",
    "case_id": "0013",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Urban Policy",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "A city analyst finds that days with higher ice cream sales in parks also have more reported minor injuries. They argue ice cream vendors create unsafe conditions.\n\nA parks manager suggests that hot weather increases both park attendance (creating more injury opportunities) and ice cream sales.",
    "claim": "days with higher ice cream sales in parks also have more reported minor injuries",
    "variables": {
      "X": {
        "name": "Ice cream sales",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Park injury reports",
        "role": "Outcome"
      },
      "Z": [
        "Temperature / attendance"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Omitted Variable",
      "subtype_name": "Omitted Variable"
    },
    "label": "YES",
    "causal_structure": "Z increases both X and Y; omitting Z yields misleading correlation.",
    "key_insight": "An omitted common cause can create a misleading association.",
    "gold_rationale": "I can’t conclude causality without controlling for weather/attendance and knowing how vendor permits are assigned.",
    "wise_refusal": "I can’t conclude causality without controlling for weather/attendance and knowing how vendor permits are assigned.",
    "hidden_timestamp": "Did temperature rise before both ice cream sales and injuries, suggesting a shared upstream cause?",
    "conditional_answers": {
      "A": "Answer if you control for temperature and attendance: The sales–injury correlation may disappear.",
      "B": "Answer if injuries rise on high-attendance days regardless of vendors: Vendor restriction is not justified by this correlation.",
      "C": "Answer if vendor placement is randomized across similar days: Comparisons become more informative."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.4,
    "validator_2": "Longling Geng",
    "final_score_2": 9.15
  },
  {
    "id": "T3-BucketLarge-J-1.14",
    "bucket": "BucketLarge-J",
    "case_id": "0014",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Healthcare Administration",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A hospital audit reports that patients prescribed a stronger painkiller have higher 30-day mortality than patients prescribed a milder painkiller. A supervisor argues the stronger drug is dangerous.\n\nClinicians respond that the stronger painkiller is typically prescribed to patients with more severe conditions, who are already at higher risk of death.",
    "claim": "patients prescribed a stronger painkiller have higher 30-day mortality than patients prescribed a milder painkiller",
    "variables": {
      "X": {
        "name": "Painkiller prescribed (strong vs. mild)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "30-day mortality",
        "role": "Outcome"
      },
      "Z": [
        "Underlying illness severity"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Confounding by Indication",
      "subtype_name": "Confounding by Indication"
    },
    "label": "YES",
    "causal_structure": "Severity (Z) influences both treatment choice (X) and mortality (Y).",
    "key_insight": "Sicker patients are more likely to receive stronger treatments, confounding naive comparisons.",
    "gold_rationale": "I can’t infer a causal drug effect without detailed severity/comorbidity measures and timing of prescription relative to deterioration.",
    "wise_refusal": "I can’t infer a causal drug effect without detailed severity/comorbidity measures and timing of prescription relative to deterioration.",
    "hidden_timestamp": "Was severity assessed before the prescription decision, and is it measured well enough to adjust for it?",
    "conditional_answers": {
      "A": "Answer if patients of similar severity are compared: The estimate is less confounded.",
      "B": "Answer if severity is poorly measured: Residual confounding remains even after adjustment.",
      "C": "Answer if prescribing follows a protocol unrelated to individual severity: Comparisons are closer to causal."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.14,
    "validator_2": "Longling Geng",
    "final_score_2": 8.89
  },
  {
    "id": "T3-BucketLarge-J-1.15",
    "bucket": "BucketLarge-J",
    "case_id": "0015",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Policy",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A university releases a report stating that Department A has a higher overall graduation rate than Department B. Administrators conclude that Department A’s curriculum is more effective and consider expanding it.\nHowever, a faculty member notes that when graduation rates are broken down by student preparedness level (high vs. low incoming GPA), Department B has higher graduation rates in both groups.\nThe discrepancy arises because Department A enrolls a much larger proportion of high-preparedness students, while Department B enrolls more low-preparedness students overall.",
    "claim": "Department A’s curriculum is more effective and consider expanding it",
    "variables": {
      "X": {
        "name": "Department (A vs. B)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Graduation rate",
        "role": "Outcome"
      },
      "Z": [
        "Student preparedness level (high / low incoming GPA)"
      ]
    },
    "trap": {
      "type": "W8",
      "type_name": "Simpson's Paradox",
      "subtype": "Aggregation Bias",
      "subtype_name": "Aggregation Bias"
    },
    "label": "YES",
    "causal_structure": "Student preparedness (Z) affects graduation (Y) and differs in distribution across departments (X). Aggregating across Z reverses subgroup-level trends.",
    "key_insight": "Aggregate performance metrics can contradict subgroup-level performance due to population composition.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. Please report Graduation rate by the key strata (e.g., Student preparedness level (high / low incoming GPA) if that is the stratifier), and compute a standardized effect; the aggregate comparison can reverse when Department (A vs. B) is unevenly applied across strata.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. Please report Graduation rate by the key strata (e.g., Student preparedness level (high / low incoming GPA) if that is the stratifier), and compute a standardized effect; the aggregate comparison can reverse when Department (A vs. B) is unevenly applied across strata.",
    "hidden_timestamp": "Was Student preparedness level (high / low incoming GPA) determined before Department (A vs. B) was chosen, and could Student preparedness level (high / low incoming GPA) have influenced the choice of Department (A vs. B) before Graduation rate was measured?",
    "conditional_answers": {
      "A": "Answer if you only compare aggregates: The apparent effect of Department (A vs. B) on Graduation rate may be reversed because the mix of subgroups differs between Department (A vs. B) arms.",
      "B": "Answer if you compare within strata after stratifying/standardizing by Student preparedness level (high / low incoming GPA): Use the within-stratum differences (or a standardized effect). If Department (A vs. B) improves Graduation rate in each stratum, prefer Department (A vs. B) even if the aggregate looks worse.",
      "C": "Answer if Department (A vs. B) can be randomized within strata: Then the within-stratum comparison identifies the causal effect; report both stratum-specific and standardized estimates."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.27,
    "validator_2": "Longling Geng",
    "final_score_2": 9.02
  },
  {
    "id": "T3-BucketLarge-J-1.16",
    "bucket": "BucketLarge-J",
    "case_id": "0016",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Criminology",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A city publishes annual crime statistics showing that District East has a higher overall crime clearance rate than District West. City officials argue that policing strategies used in District East are more effective and consider expanding them citywide.\nHowever, analysts examining the data by crime severity (violent vs. non-violent offenses) find that District West has higher clearance rates for both categories.\nThe apparent contradiction arises because District East handles a much larger share of non-violent crimes, which are generally easier to solve, while District West deals disproportionately with violent crimes.",
    "claim": "District West has higher clearance rates for both categories",
    "variables": {
      "X": {
        "name": "Police district (East vs. West)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Crime clearance rate",
        "role": "Outcome"
      },
      "Z": [
        "Crime severity (violent / non-violent)"
      ]
    },
    "trap": {
      "type": "W8",
      "type_name": "Simpson's Paradox",
      "subtype": "Imbalanced Group Composition",
      "subtype_name": "Imbalanced Group Composition"
    },
    "label": "YES",
    "causal_structure": "Crime severity (Z) affects clearance probability (Y) and differs in prevalence across districts (X). Aggregation across Z reverses subgroup-level performance.",
    "key_insight": "Aggregate performance metrics can mask inferior performance within every relevant subgroup.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. Please report Crime clearance rate by the key strata (e.g., Crime severity (violent / non-violent) if that is the stratifier), and compute a standardized effect; the aggregate comparison can reverse when Police district (East vs. West) is unevenly applied across strata.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. Please report Crime clearance rate by the key strata (e.g., Crime severity (violent / non-violent) if that is the stratifier), and compute a standardized effect; the aggregate comparison can reverse when Police district (East vs. West) is unevenly applied across strata.",
    "hidden_timestamp": "Was Crime severity (violent / non-violent) determined before Police district (East vs. West) was chosen, and could Crime severity (violent / non-violent) have influenced the choice of Police district (East vs. West) before Crime clearance rate was measured?",
    "conditional_answers": {
      "A": "Answer if you only compare aggregates: The apparent effect of Police district (East vs. West) on Crime clearance rate may be reversed because the mix of subgroups differs between Police district (East vs. West) arms.",
      "B": "Answer if you compare within strata after stratifying/standardizing by Crime severity (violent / non-violent): Use the within-stratum differences (or a standardized effect). If Police district (East vs. West) improves Crime clearance rate in each stratum, prefer Police district (East vs. West) even if the aggregate looks worse.",
      "C": "Answer if Police district (East vs. West) can be randomized within strata: Then the within-stratum comparison identifies the causal effect; report both stratum-specific and standardized estimates."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.8,
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "id": "T3-BucketLarge-J-1.17",
    "bucket": "BucketLarge-J",
    "case_id": "0017",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Technology",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "An online education platform reports that Course X has a higher overall completion rate than Course Y. The platform promotes Course X as better designed and more engaging.\nHowever, when completion rates are examined by learner experience level (beginner vs. advanced), Course Y shows higher completion rates in both groups.\nThis occurs because Course X attracts a much larger proportion of advanced learners, who are more likely to complete any course regardless of design quality.",
    "claim": "Course X has a higher overall completion rate than Course Y",
    "variables": {
      "X": {
        "name": "Course (X vs. Y)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Course completion rate",
        "role": "Outcome"
      },
      "Z": [
        "Learner experience level (beginner / advanced)"
      ]
    },
    "trap": {
      "type": "W8",
      "type_name": "Simpson's Paradox",
      "subtype": "Aggregation Bias",
      "subtype_name": "Aggregation Bias"
    },
    "label": "YES",
    "causal_structure": "Learner experience (Z) affects completion (Y) and differs across courses (X), producing a reversal when aggregated.",
    "key_insight": "Differences in participant composition can dominate aggregate outcome measures.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. Please report Course completion rate by the key strata (e.g., Learner experience level (beginner / advanced) if that is the stratifier), and compute a standardized effect; the aggregate comparison can reverse when Course (X vs. Y) is unevenly applied across strata.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. Please report Course completion rate by the key strata (e.g., Learner experience level (beginner / advanced) if that is the stratifier), and compute a standardized effect; the aggregate comparison can reverse when Course (X vs. Y) is unevenly applied across strata.",
    "hidden_timestamp": "Was Learner experience level (beginner / advanced) determined before Course (X vs. Y) was chosen, and could Learner experience level (beginner / advanced) have influenced the choice of Course (X vs. Y) before Course completion rate was measured?",
    "conditional_answers": {
      "A": "Answer if you only compare aggregates: The apparent effect of Course (X vs. Y) on Course completion rate may be reversed because the mix of subgroups differs between Course (X vs. Y) arms.",
      "B": "Answer if you compare within strata after stratifying/standardizing by Learner experience level (beginner / advanced): Use the within-stratum differences (or a standardized effect). If Course (X vs. Y) improves Course completion rate in each stratum, prefer Course (X vs. Y) even if the aggregate looks worse.",
      "C": "Answer if Course (X vs. Y) can be randomized within strata: Then the within-stratum comparison identifies the causal effect; report both stratum-specific and standardized estimates."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.7,
    "validator_2": "Longling Geng",
    "final_score_2": 9.45
  },
  {
    "id": "T3-BucketLarge-J-1.18",
    "bucket": "BucketLarge-J",
    "case_id": "0018",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Consumer Behavior",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "A company reports that 92% of customers are satisfied with its new subscription service, based on responses to a voluntary online satisfaction survey. Executives conclude that the service rollout has been a major success.\nHowever, internal data shows that only 15% of customers responded to the survey. Customer support logs indicate that dissatisfied users are more likely to cancel their subscriptions and disengage from company communications altogether.",
    "claim": "the service rollout has been a major success",
    "variables": {
      "X": {
        "name": "Survey response participation",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Reported customer satisfaction",
        "role": "Outcome"
      },
      "Z": [
        "Customer satisfaction status (satisfied / dissatisfied)"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Sampling-on-the-Outcome",
      "subtype_name": "Sampling Bias"
    },
    "label": "YES",
    "causal_structure": "Customer satisfaction (Z) affects likelihood of survey participation (X), and the outcome (Y) is measured only among respondents.",
    "key_insight": "Observed satisfaction reflects who responds, not the true customer population.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Customer satisfaction status (satisfied / dissatisfied)); otherwise Survey response participation–Reported customer satisfaction differences may reflect selection rather than effect.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Customer satisfaction status (satisfied / dissatisfied)); otherwise Survey response participation–Reported customer satisfaction differences may reflect selection rather than effect.",
    "hidden_timestamp": "At what point were units selected into the observed sample—before or after Reported customer satisfaction occurred—and is selection related to Customer satisfaction status (satisfied / dissatisfied) or Reported customer satisfaction?",
    "conditional_answers": {
      "A": "Answer if Survey response participation is randomly assigned: A difference in Reported customer satisfaction across Survey response participation groups can be interpreted causally.",
      "B": "Answer if participation/exposure is voluntary or selected (e.g., Customer satisfaction status (satisfied / dissatisfied)): The Survey response participation vs not-Survey response participation difference in Reported customer satisfaction is biased by who ends up observed/treated.",
      "C": "Answer if you can measure the selection drivers (e.g., Customer satisfaction status (satisfied / dissatisfied)) and adjust (matching/weighting/IV): The conclusion becomes CONDITIONAL on those assumptions and model quality."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.11,
    "validator_2": "Longling Geng",
    "final_score_2": 8.86
  },
  {
    "id": "T3-BucketLarge-J-1.19",
    "bucket": "BucketLarge-J",
    "case_id": "0019",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Entrepreneurship",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A startup accelerator advertises that 70% of companies in its program succeed, defining success as raising a Series A funding round within two years. Aspiring founders interpret this statistic as evidence that participation dramatically increases startup success.\nHowever, the accelerator accepts only a small fraction of applicants and explicitly selects founders with strong prior experience, existing traction, and elite educational backgrounds.",
    "claim": "A startup accelerator advertises that 70% of companies in its program succeed, defining success as raising a Series A funding round within two years",
    "variables": {
      "X": {
        "name": "Accelerator participation",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Startup success (Series A funding)",
        "role": "Outcome"
      },
      "Z": [
        "Founder quality / prior advantages"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Sampling-on-the-Outcome",
      "subtype_name": "Sampling Bias"
    },
    "label": "YES",
    "causal_structure": "Founder quality (Z) affects both selection into the accelerator (X) and startup success (Y).",
    "key_insight": "High success rates may reflect who is admitted rather than program effectiveness.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Founder quality / prior advantages); otherwise Accelerator participation–Startup success (Series A funding) differences may reflect selection rather than effect.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Founder quality / prior advantages); otherwise Accelerator participation–Startup success (Series A funding) differences may reflect selection rather than effect.",
    "hidden_timestamp": "At what point were units selected into the observed sample—before or after Startup success (Series A funding) occurred—and is selection related to Founder quality / prior advantages or Startup success (Series A funding)?",
    "conditional_answers": {
      "A": "Answer if Accelerator participation is randomly assigned: A difference in Startup success (Series A funding) across Accelerator participation groups can be interpreted causally.",
      "B": "Answer if participation/exposure is voluntary or selected (e.g., Founder quality / prior advantages): The Accelerator participation vs not-Accelerator participation difference in Startup success (Series A funding) is biased by who ends up observed/treated.",
      "C": "Answer if you can measure the selection drivers (e.g., Founder quality / prior advantages) and adjust (matching/weighting/IV): The conclusion becomes CONDITIONAL on those assumptions and model quality."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.54,
    "validator_2": "Longling Geng",
    "final_score_2": 9.29
  },
  {
    "id": "T3-BucketLarge-J-1.2",
    "bucket": "BucketLarge-J",
    "case_id": "0002",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Psychology",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "An organization reports a very positive statistic for Reported improvement based only on observations from a subset of people.\nThe subset is formed by Who shares outcomes that is voluntary or outcome-dependent.\nInternal notes suggest people with negative experiences are less likely to be observed in the dataset.",
    "claim": "An organization reports a very positive statistic for Reported improvement based only on observations from a subset of people",
    "variables": {
      "X": {
        "name": "Who shares outcomes",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Reported improvement",
        "role": "Outcome"
      },
      "Z": [
        "Underlying true outcome (positive/negative)"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Sampling-on-the-Outcome",
      "subtype_name": "Sampling Bias"
    },
    "label": "YES",
    "causal_structure": "Z affects whether an observation is recorded (X), and Y is computed only among observed cases.",
    "key_insight": "Observed outcomes reflect who is observed, not the full population.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Underlying true outcome (positive/negative)); otherwise Who shares outcomes–Reported improvement differences may reflect selection rather than effect.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Underlying true outcome (positive/negative)); otherwise Who shares outcomes–Reported improvement differences may reflect selection rather than effect.",
    "hidden_timestamp": "At what point were units selected into the observed sample—before or after Reported improvement occurred—and is selection related to Underlying true outcome (positive/negative) or Reported improvement?",
    "conditional_answers": {
      "A": "Answer if Who shares outcomes is randomly assigned: A difference in Reported improvement across Who shares outcomes groups can be interpreted causally.",
      "B": "Answer if participation/exposure is voluntary or selected (e.g., Underlying true outcome (positive/negative)): The Who shares outcomes vs not-Who shares outcomes difference in Reported improvement is biased by who ends up observed/treated.",
      "C": "Answer if you can measure the selection drivers (e.g., Underlying true outcome (positive/negative)) and adjust (matching/weighting/IV): The conclusion becomes CONDITIONAL on those assumptions and model quality."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 9.26,
    "validator_2": "Longling Geng",
    "final_score_2": 9.26
  },
  {
    "id": "T3-BucketLarge-J-1.20",
    "bucket": "BucketLarge-J",
    "case_id": "0020",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Workplace Health",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A company reports that employees enrolled in its voluntary wellness program take fewer sick days than employees who do not enroll. Management concludes that the wellness program improves employee health and considers expanding it.\nFurther examination reveals that employees who opt into the program tend to be healthier, more health-conscious, and more engaged with company initiatives even before the program begins.",
    "claim": "the wellness program improves employee health and considers expanding it",
    "variables": {
      "X": {
        "name": "Wellness program participation",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Number of sick days taken",
        "role": "Outcome"
      },
      "Z": [
        "Baseline employee health / engagement"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Sampling-on-the-Outcome",
      "subtype_name": "Sampling Bias"
    },
    "label": "YES",
    "causal_structure": "Baseline health (Z) influences both program participation (X) and health outcomes (Y).",
    "key_insight": "Voluntary programs often attract participants who would perform better regardless.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Baseline employee health / engagement); otherwise Wellness program participation–Number of sick days taken differences may reflect selection rather than effect.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Baseline employee health / engagement); otherwise Wellness program participation–Number of sick days taken differences may reflect selection rather than effect.",
    "hidden_timestamp": "At what point were units selected into the observed sample—before or after Number of sick days taken occurred—and is selection related to Baseline employee health / engagement or Number of sick days taken?",
    "conditional_answers": {
      "A": "Answer if Wellness program participation is randomly assigned: A difference in Number of sick days taken across Wellness program participation groups can be interpreted causally.",
      "B": "Answer if participation/exposure is voluntary or selected (e.g., Baseline employee health / engagement): The Wellness program participation vs not-Wellness program participation difference in Number of sick days taken is biased by who ends up observed/treated.",
      "C": "Answer if you can measure the selection drivers (e.g., Baseline employee health / engagement) and adjust (matching/weighting/IV): The conclusion becomes CONDITIONAL on those assumptions and model quality."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.8,
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "id": "T3-BucketLarge-J-1.21",
    "bucket": "BucketLarge-J",
    "case_id": "0021",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Political Science",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "An analyst observes that states with higher average household income tend to vote for Party A in national elections. Based on this pattern, a commentator concludes that wealthier individuals are more likely to support Party A.\nHowever, individual-level polling data within states shows that higher-income individuals are actually more likely to support Party B, while lower-income individuals are more likely to support Party A.\nThe apparent contradiction arises because wealthier states differ from poorer states in urbanization, education levels, and industry composition.",
    "claim": "wealthier individuals are more likely to support Party A",
    "variables": {
      "X": {
        "name": "State-level average income",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Voting outcome (Party A vs. Party B)",
        "role": "Outcome"
      },
      "Z": [
        "Individual income level"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Socioeconomic",
      "subtype_name": "Socioeconomic"
    },
    "label": "YES",
    "causal_structure": "State-level income aggregates over heterogeneous individuals; group-level correlations do not reflect individual-level behavior.",
    "key_insight": "Correlations observed at the group level cannot be assumed to hold at the individual level.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how State-level average income relates to Voting outcome (Party A vs. Party B) for a person.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how State-level average income relates to Voting outcome (Party A vs. Party B) for a person.",
    "hidden_timestamp": "Is State-level average income measured at an aggregate level while Voting outcome (Party A vs. Party B) is an individual claim, and when/where does aggregation into Individual income level happen relative to measuring Voting outcome (Party A vs. Party B)?",
    "conditional_answers": {
      "A": "Answer if you only have aggregate correlations: You cannot infer individual-level behavior; the relationship may be confounded by group-level factors.",
      "B": "Answer if you have individual-level data within groups: Estimate the within-group association/effect and check whether it matches the aggregate pattern.",
      "C": "Answer if there is sorting/selection into groups: Treat conclusions as CONDITIONAL unless you model the sorting mechanism or use a design that breaks it."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketLarge-J-1.22",
    "bucket": "BucketLarge-J",
    "case_id": "0022",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Sociology",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "A city education report shows that neighborhoods with higher average adult education levels have higher student test scores. Policymakers infer that students living in highly educated neighborhoods perform better academically.\nHowever, individual-level data reveals that students from less-educated households can perform as well as their peers when controlling for school quality and family support, regardless of neighborhood averages.\nThe neighborhood-level correlation reflects broader structural differences rather than individual household effects.",
    "claim": "A city education report shows that neighborhoods with higher average adult education levels have higher student test scores",
    "variables": {
      "X": {
        "name": "Neighborhood average education level",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Student test scores",
        "role": "Outcome"
      },
      "Z": [
        "Household-level educational support"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Socioeconomic",
      "subtype_name": "Socioeconomic"
    },
    "label": "YES",
    "causal_structure": "Neighborhood averages mask variation across households; individual outcomes depend on household-level factors.",
    "key_insight": "Group characteristics do not deterministically apply to individuals within the group.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how Neighborhood average education level relates to Student test scores for a person.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how Neighborhood average education level relates to Student test scores for a person.",
    "hidden_timestamp": "Is Neighborhood average education level measured at an aggregate level while Student test scores is an individual claim, and when/where does aggregation into Household-level educational support happen relative to measuring Student test scores?",
    "conditional_answers": {
      "A": "Answer if you only have aggregate correlations: You cannot infer individual-level behavior; the relationship may be confounded by group-level factors.",
      "B": "Answer if you have individual-level data within groups: Estimate the within-group association/effect and check whether it matches the aggregate pattern.",
      "C": "Answer if there is sorting/selection into groups: Treat conclusions as CONDITIONAL unless you model the sorting mechanism or use a design that breaks it."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.72,
    "validator_2": "Longling Geng",
    "final_score_2": 9.47
  },
  {
    "id": "T3-BucketLarge-J-1.23",
    "bucket": "BucketLarge-J",
    "case_id": "0023",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Sociology",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "International surveys show that Country A ranks higher than Country B on average happiness scores. Commentators argue that citizens of Country A are happier in their daily lives.\nHowever, within both countries, individual happiness varies widely, and individual-level analysis shows that factors such as income security, health, and social relationships are stronger predictors of personal well-being than nationality.\nThe national ranking reflects aggregated survey responses rather than uniform individual experiences.",
    "claim": "International surveys show that Country A ranks higher than Country B on average happiness scores",
    "variables": {
      "X": {
        "name": "Country of residence",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Average happiness score",
        "role": "Outcome"
      },
      "Z": [
        "Individual-level well-being determinants"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Socioeconomic",
      "subtype_name": "Socioeconomic"
    },
    "label": "YES",
    "causal_structure": "National averages collapse heterogeneous individual experiences into a single metric.",
    "key_insight": "Country-level statistics cannot substitute for individual-level causal explanations.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how Country of residence relates to Average happiness score for a person.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how Country of residence relates to Average happiness score for a person.",
    "hidden_timestamp": "Is Country of residence measured at an aggregate level while Average happiness score is an individual claim, and when/where does aggregation into Individual-level well-being determinants happen relative to measuring Average happiness score?",
    "conditional_answers": {
      "A": "Answer if you only have aggregate correlations: You cannot infer individual-level behavior; the relationship may be confounded by group-level factors.",
      "B": "Answer if you have individual-level data within groups: Estimate the within-group association/effect and check whether it matches the aggregate pattern.",
      "C": "Answer if there is sorting/selection into groups: Treat conclusions as CONDITIONAL unless you model the sorting mechanism or use a design that breaks it."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.23,
    "validator_2": "Longling Geng",
    "final_score_2": 8.98
  },
  {
    "id": "T3-BucketLarge-J-1.24",
    "bucket": "BucketLarge-J",
    "case_id": "0024",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Labor Economics",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "A job training program advertises on social media and accepts all applicants who sign up. After 6 months, participants show 40% higher employment rates than non-participants. Researchers conclude the program caused the employment gains.",
    "claim": "The job training program causes higher employment rates.",
    "variables": {
      "X": {
        "name": "Participation in job training program",
        "role": "Treatment"
      },
      "Y": {
        "name": "Employment rate",
        "role": "Outcome"
      },
      "Z": [
        "Pre-existing motivation and job-seeking behavior"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Self-Selection into Treatment",
      "subtype_name": "Self-Selection into Treatment"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Self-selection into voluntary programs confounds treatment effects with pre-existing participant characteristics.",
    "gold_rationale": "This claim cannot be supported because the study suffers from selection bias. Individuals who voluntarily sign up for job training programs likely differ systematically from those who do not - they may be more motivated, have more time flexibility, or be more proactive job seekers. These same characteristics that lead people to enroll would also help them find employment regardless of the program.",
    "wise_refusal": "This claim cannot be supported because the study suffers from selection bias. Individuals who voluntarily sign up for job training programs likely differ systematically from those who do not - they may be more motivated, have more time flexibility, or be more proactive job seekers. These same characteristics that lead people to enroll would also help them find employment regardless of the program.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.73,
    "validator_2": "Longling Geng",
    "final_score_2": 9.48
  },
  {
    "id": "T3-BucketLarge-J-1.25",
    "bucket": "BucketLarge-J",
    "case_id": "0025",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Policy",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A study tracks students in a new intensive tutoring program over two years. Students who remain in the program by year two show significantly higher test scores than the general student population. The program is deemed highly effective.",
    "claim": "The intensive tutoring program significantly improves student test scores.",
    "variables": {
      "X": {
        "name": "Participation in tutoring program",
        "role": "Treatment"
      },
      "Y": {
        "name": "Test scores",
        "role": "Outcome"
      },
      "Z": [
        "Academic ability and parental support"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Differential Attrition",
      "subtype_name": "Differential Attrition"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Differential dropout creates a biased sample of only successful participants.",
    "gold_rationale": "This conclusion is undermined by selection bias through differential attrition. Students who struggle academically or lack family support are more likely to drop out of an intensive program, leaving only higher-performing, well-supported students by year two. The observed high scores may reflect who remained rather than program effectiveness.",
    "wise_refusal": "This conclusion is undermined by selection bias through differential attrition. Students who struggle academically or lack family support are more likely to drop out of an intensive program, leaving only higher-performing, well-supported students by year two. The observed high scores may reflect who remained rather than program effectiveness.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.19,
    "validator_2": "Longling Geng",
    "final_score_2": 8.94
  },
  {
    "id": "T3-BucketLarge-J-1.26",
    "bucket": "BucketLarge-J",
    "case_id": "0026",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Criminal Justice",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "A criminologist studies successful rehabilitation programs by interviewing ex-offenders who have been crime-free for 10 years. Most report that prison education programs were transformative. The study concludes prison education is highly effective at reducing recidivism.",
    "claim": "Prison education programs effectively reduce recidivism.",
    "variables": {
      "X": {
        "name": "Prison education program participation",
        "role": "Treatment"
      },
      "Y": {
        "name": "Recidivism rates",
        "role": "Outcome"
      },
      "Z": [
        "Other rehabilitation factors and individual circumstances"
      ]
    },
    "trap": {
      "type": "W2",
      "type_name": "Survivorship Bias",
      "subtype": "Success-Only Sampling",
      "subtype_name": "Success-Only Sampling"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Sampling only successes excludes failures who may have received the same treatment.",
    "gold_rationale": "This study exhibits survivorship bias by only sampling successful cases. Ex-offenders who re-offended or are incarcerated cannot be interviewed in this design. Many who participated in education programs may have reoffended but are invisible in this sample. The true effectiveness of prison education cannot be determined without examining all participants.",
    "wise_refusal": "This study exhibits survivorship bias by only sampling successful cases. Ex-offenders who re-offended or are incarcerated cannot be interviewed in this design. Many who participated in education programs may have reoffended but are invisible in this sample. The true effectiveness of prison education cannot be determined without examining all participants.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketLarge-J-1.27",
    "bucket": "BucketLarge-J",
    "case_id": "0027",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Social Psychology",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A researcher studies viral social media campaigns to understand what makes activism successful. By analyzing 50 campaigns that achieved their policy goals, they identify common features like celebrity endorsement and emotional storytelling. They recommend these as key ingredients for successful activism.",
    "claim": "Celebrity endorsement and emotional storytelling cause social media activism to succeed.",
    "variables": {
      "X": {
        "name": "Campaign features (celebrity endorsement, emotional storytelling)",
        "role": "Treatment"
      },
      "Y": {
        "name": "Campaign success",
        "role": "Outcome"
      },
      "Z": [
        "Underlying cause salience and timing"
      ]
    },
    "trap": {
      "type": "W2",
      "type_name": "Survivorship Bias",
      "subtype": "Media Visibility Bias",
      "subtype_name": "Media Visibility Bias"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Studying only visible successes ignores the base rate of failure with identical characteristics.",
    "gold_rationale": "This analysis suffers from survivorship bias by examining only successful campaigns. Countless campaigns with identical features - celebrity endorsements and emotional storytelling - failed and went unnoticed. Without studying failed campaigns, we cannot determine whether these features actually increase success probability or are simply common across all campaigns regardless of outcome.",
    "wise_refusal": "This analysis suffers from survivorship bias by examining only successful campaigns. Countless campaigns with identical features - celebrity endorsements and emotional storytelling - failed and went unnoticed. Without studying failed campaigns, we cannot determine whether these features actually increase success probability or are simply common across all campaigns regardless of outcome.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketLarge-J-1.28",
    "bucket": "BucketLarge-J",
    "case_id": "0028",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Political Behavior",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "Analysis of county-level data shows that counties with higher average education levels vote more Democratic. A political consultant concludes that increasing an individual's education would make them more likely to vote Democratic.",
    "claim": "Higher education causes individuals to vote Democratic.",
    "variables": {
      "X": {
        "name": "Education level",
        "role": "Factor"
      },
      "Y": {
        "name": "Democratic voting",
        "role": "Outcome"
      },
      "Z": [
        "Urban vs rural residence, regional culture"
      ]
    },
    "trap": {
      "type": "W5",
      "type_name": "Ecological Fallacy",
      "subtype": "Aggregate to Individual Inference",
      "subtype_name": "Aggregate to Individual Inference"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "County-level correlations do not reveal individual-level causal relationships.",
    "gold_rationale": "This commits the ecological fallacy by inferring individual behavior from aggregate data. Counties with higher average education may vote Democratic due to urbanization, demographic composition, or regional factors rather than education itself. Highly educated individuals within less-educated counties might not follow this pattern, and less-educated individuals in educated counties might vote Democratic due to social context.",
    "wise_refusal": "This commits the ecological fallacy by inferring individual behavior from aggregate data. Counties with higher average education may vote Democratic due to urbanization, demographic composition, or regional factors rather than education itself. Highly educated individuals within less-educated counties might not follow this pattern, and less-educated individuals in educated counties might vote Democratic due to social context.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.52,
    "validator_2": "Longling Geng",
    "final_score_2": 9.27
  },
  {
    "id": "T3-BucketLarge-J-1.29",
    "bucket": "BucketLarge-J",
    "case_id": "0029",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Urban Sociology",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A study finds that neighborhoods with more coffee shops have lower crime rates. City planners propose subsidizing coffee shop openings in high-crime areas, expecting this will reduce crime.",
    "claim": "Opening coffee shops in neighborhoods causes crime reduction.",
    "variables": {
      "X": {
        "name": "Coffee shop density",
        "role": "Treatment"
      },
      "Y": {
        "name": "Crime rates",
        "role": "Outcome"
      },
      "Z": [
        "Neighborhood affluence and gentrification"
      ]
    },
    "trap": {
      "type": "W5",
      "type_name": "Ecological Fallacy",
      "subtype": "Compositional Fallacy",
      "subtype_name": "Compositional Fallacy"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Neighborhood-level correlations reflect compositional differences, not causal mechanisms transferable via intervention.",
    "gold_rationale": "This reasoning exemplifies the ecological fallacy. Coffee shops are markers of neighborhood affluence and gentrification - conditions that independently correlate with lower crime through better policing, invested residents, and economic opportunity. Adding coffee shops to high-crime areas would not import the wealth and social capital that actually drives the observed correlation.",
    "wise_refusal": "This reasoning exemplifies the ecological fallacy. Coffee shops are markers of neighborhood affluence and gentrification - conditions that independently correlate with lower crime through better policing, invested residents, and economic opportunity. Adding coffee shops to high-crime areas would not import the wealth and social capital that actually drives the observed correlation.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.6,
    "validator_2": "Longling Geng",
    "final_score_2": 9.35
  },
  {
    "id": "T3-BucketLarge-J-1.3",
    "bucket": "BucketLarge-J",
    "case_id": "0003",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Sociology",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A report finds that regions/organizations with higher County average broadband access also have higher Student grades on average.\nA commentator concludes that any individual inside a region with higher County average broadband access will have higher Student grades.\nHowever, individual-level data within regions shows large variation, and the within-region relationship is weak or opposite once relevant individual factors are considered.",
    "claim": "any individual inside a region with higher County average broadband access will have higher Student grades",
    "variables": {
      "X": {
        "name": "County average broadband access (group-level)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Student grades (individual-level)",
        "role": "Outcome"
      },
      "Z": [
        "Individual-level characteristics"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Socioeconomic",
      "subtype_name": "Socioeconomic"
    },
    "label": "YES",
    "causal_structure": "Group-level aggregates summarize heterogeneous individuals; group-level correlation does not imply the same relation at the individual level.",
    "key_insight": "You cannot infer individual behavior reliably from group-level correlations.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how County average broadband access (group-level) relates to Student grades (individual-level) for a person.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how County average broadband access (group-level) relates to Student grades (individual-level) for a person.",
    "hidden_timestamp": "Is County average broadband access (group-level) measured at an aggregate level while Student grades (individual-level) is an individual claim, and when/where does aggregation into Individual-level characteristics happen relative to measuring Student grades (individual-level)?",
    "conditional_answers": {
      "A": "Answer if you only have aggregate correlations: You cannot infer individual-level behavior; the relationship may be confounded by group-level factors.",
      "B": "Answer if you have individual-level data within groups: Estimate the within-group association/effect and check whether it matches the aggregate pattern.",
      "C": "Answer if there is sorting/selection into groups: Treat conclusions as CONDITIONAL unless you model the sorting mechanism or use a design that breaks it."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketLarge-J-1.30",
    "bucket": "BucketLarge-J",
    "case_id": "0030",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Public Health Policy",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A study compares health outcomes between people who regularly use preventive healthcare services and those who do not. Regular users show 30% lower mortality over 10 years. Researchers conclude that preventive care significantly extends life.",
    "claim": "Regular preventive healthcare use causes lower mortality.",
    "variables": {
      "X": {
        "name": "Preventive healthcare utilization",
        "role": "Treatment"
      },
      "Y": {
        "name": "10-year mortality",
        "role": "Outcome"
      },
      "Z": [
        "Socioeconomic status, health consciousness, insurance coverage"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Socioeconomic Confounding",
      "subtype_name": "Socioeconomic Confounding"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Healthcare utilization is a marker of socioeconomic advantage that independently affects health outcomes.",
    "gold_rationale": "This association is confounded by socioeconomic factors. People who regularly access preventive care typically have better insurance, higher incomes, more education, and greater health consciousness. These same factors independently predict lower mortality through better nutrition, safer living conditions, and healthier behaviors. The 30% mortality difference likely reflects these advantages rather than preventive care alone.",
    "wise_refusal": "This association is confounded by socioeconomic factors. People who regularly access preventive care typically have better insurance, higher incomes, more education, and greater health consciousness. These same factors independently predict lower mortality through better nutrition, safer living conditions, and healthier behaviors. The 30% mortality difference likely reflects these advantages rather than preventive care alone.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.14,
    "validator_2": "Longling Geng",
    "final_score_2": 8.89
  },
  {
    "id": "T3-BucketLarge-J-1.31",
    "bucket": "BucketLarge-J",
    "case_id": "0031",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Family Studies",
    "difficulty": "Hard",
    "is_ambiguous": false,
    "scenario": "Research shows that children who eat dinner with their families at least five times per week have significantly higher academic achievement and lower rates of substance abuse. Family advocacy groups promote family dinners as a solution to youth problems.",
    "claim": "Regular family dinners cause better youth outcomes.",
    "variables": {
      "X": {
        "name": "Family dinner frequency",
        "role": "Treatment"
      },
      "Y": {
        "name": "Academic achievement and substance abuse rates",
        "role": "Outcome"
      },
      "Z": [
        "Parental involvement, family stability, socioeconomic resources"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Parenting Style Confounding",
      "subtype_name": "Parenting Style Confounding"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Family dinner frequency is a proxy for overall family functioning and resources.",
    "gold_rationale": "Family dinners are confounded with broader parenting and family characteristics. Parents who prioritize and can arrange regular dinners typically have more stable work schedules, greater involvement in children's lives, better communication skills, and more resources. These underlying family qualities - not the dinner itself - likely drive better youth outcomes. Mandating dinners without changing fundamental family dynamics would not replicate these benefits.",
    "wise_refusal": "Family dinners are confounded with broader parenting and family characteristics. Parents who prioritize and can arrange regular dinners typically have more stable work schedules, greater involvement in children's lives, better communication skills, and more resources. These underlying family qualities - not the dinner itself - likely drive better youth outcomes. Mandating dinners without changing fundamental family dynamics would not replicate these benefits.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.76,
    "validator_2": "Longling Geng",
    "final_score_2": 9.51
  },
  {
    "id": "T3-BucketLarge-J-1.32",
    "bucket": "BucketLarge-J",
    "case_id": "0032",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Immigration Studies",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "Data shows that recent immigrants have better health outcomes than native-born citizens despite lower average incomes. Researchers conclude that immigration itself has health-protective effects.",
    "claim": "The process of immigration causes better health outcomes.",
    "variables": {
      "X": {
        "name": "Immigration status",
        "role": "Factor"
      },
      "Y": {
        "name": "Health outcomes",
        "role": "Outcome"
      },
      "Z": [
        "Health selection, age, pre-migration health behaviors"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Healthy Immigrant Effect",
      "subtype_name": "Healthy Immigrant Effect"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Immigration selects for healthier individuals, creating a spurious association between immigrant status and health.",
    "gold_rationale": "This conclusion ignores the healthy immigrant selection effect. Immigration is physically demanding and often requires passing health screenings, so healthier individuals are more likely to successfully migrate. Additionally, immigrants often come from cultures with different dietary and lifestyle patterns. The observed health advantage reflects who migrates rather than any health benefit conferred by immigration itself.",
    "wise_refusal": "This conclusion ignores the healthy immigrant selection effect. Immigration is physically demanding and often requires passing health screenings, so healthier individuals are more likely to successfully migrate. Additionally, immigrants often come from cultures with different dietary and lifestyle patterns. The observed health advantage reflects who migrates rather than any health benefit conferred by immigration itself.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketLarge-J-1.33",
    "bucket": "BucketLarge-J",
    "case_id": "0033",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Environmental Sociology",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "Surveys show that people who report high levels of stress are more likely to use mental health apps. A tech company claims their mental health app increases stress awareness, thereby causing people to report more stress.",
    "claim": "Mental health app use causes increased stress reporting.",
    "variables": {
      "X": {
        "name": "Mental health app usage",
        "role": "Treatment"
      },
      "Y": {
        "name": "Stress reporting",
        "role": "Outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "W9",
      "type_name": "Reverse Causation",
      "subtype": "Outcome-Driven Exposure",
      "subtype_name": "Outcome-Driven Exposure"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "High stress causes app-seeking behavior, not the reverse.",
    "gold_rationale": "The causal direction is likely reversed. People experiencing high stress are motivated to seek tools for managing it, leading them to download mental health apps. The stress precedes and causes app adoption, not vice versa. While the app might increase stress awareness marginally, the primary driver of this correlation is that stressed individuals self-select into app usage.",
    "wise_refusal": "The causal direction is likely reversed. People experiencing high stress are motivated to seek tools for managing it, leading them to download mental health apps. The stress precedes and causes app adoption, not vice versa. While the app might increase stress awareness marginally, the primary driver of this correlation is that stressed individuals self-select into app usage.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.47,
    "validator_2": "Longling Geng",
    "final_score_2": 9.22
  },
  {
    "id": "T3-BucketLarge-J-1.34",
    "bucket": "BucketLarge-J",
    "case_id": "0034",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Labor Economics",
    "difficulty": "Hard",
    "is_ambiguous": false,
    "scenario": "Research finds that companies with more women in leadership positions have higher profitability. Business consultants recommend promoting more women to leadership to boost company profits.",
    "claim": "Having more women in leadership causes higher company profitability.",
    "variables": {
      "X": {
        "name": "Women in leadership positions",
        "role": "Factor"
      },
      "Y": {
        "name": "Company profitability",
        "role": "Outcome"
      },
      "Z": [
        "Company culture, industry sector, company age"
      ]
    },
    "trap": {
      "type": "W9",
      "type_name": "Reverse Causation",
      "subtype": "Bidirectional Causation",
      "subtype_name": "Bidirectional Causation"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Company success may enable diversity rather than result from it.",
    "gold_rationale": "Reverse causation is plausible here. Already-profitable companies may have more resources to invest in diversity initiatives, better cultures that attract diverse talent, or operate in industries where women are better represented. Profitability may enable gender diversity rather than result from it. Additionally, both may be caused by progressive management practices. The causal direction and mechanism cannot be established from this correlation.",
    "wise_refusal": "Reverse causation is plausible here. Already-profitable companies may have more resources to invest in diversity initiatives, better cultures that attract diverse talent, or operate in industries where women are better represented. Profitability may enable gender diversity rather than result from it. Additionally, both may be caused by progressive management practices. The causal direction and mechanism cannot be established from this correlation.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.02,
    "validator_2": "Longling Geng",
    "final_score_2": 8.77
  },
  {
    "id": "T3-BucketLarge-J-1.35",
    "bucket": "BucketLarge-J",
    "case_id": "0035",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Political Behavior",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A city implemented a new civic education curriculum in September. In the November election that year, youth voter turnout increased by 15%. The school board concludes the curriculum successfully increased political engagement.",
    "claim": "The civic education curriculum caused increased youth voter turnout.",
    "variables": {
      "X": {
        "name": "Civic education curriculum implementation",
        "role": "Treatment"
      },
      "Y": {
        "name": "Youth voter turnout",
        "role": "Outcome"
      },
      "Z": [
        "Election competitiveness, national political climate, candidates"
      ]
    },
    "trap": {
      "type": "W10",
      "type_name": "Post Hoc Fallacy",
      "subtype": "Temporal Coincidence",
      "subtype_name": "Temporal Coincidence"
    },
    "label": "NO",
    "causal_structure": "",
    "key_insight": "Temporal coincidence between curriculum and election does not establish causation.",
    "gold_rationale": "This conclusion commits the post hoc fallacy by assuming temporal sequence implies causation. The November election may have featured particularly engaging candidates, controversial ballot measures, or occurred amid a national surge in youth political activism. Two months is also insufficient time for curriculum effects to manifest. Without comparison to similar areas without the curriculum, the turnout increase cannot be attributed to the educational intervention.",
    "wise_refusal": "This conclusion commits the post hoc fallacy by assuming temporal sequence implies causation. The November election may have featured particularly engaging candidates, controversial ballot measures, or occurred amid a national surge in youth political activism. Two months is also insufficient time for curriculum effects to manifest. Without comparison to similar areas without the curriculum, the turnout increase cannot be attributed to the educational intervention.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.24,
    "validator_2": "Longling Geng",
    "final_score_2": 8.99
  },
  {
    "id": "T3-BucketLarge-J-1.36",
    "bucket": "BucketLarge-J",
    "case_id": "0036",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Public Health Policy",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "Researchers conduct a randomized controlled trial where 500 participants are randomly assigned to receive either cognitive behavioral therapy delivered via app or a placebo app with general wellness tips. Neither participants nor outcome assessors know which app is which. After 12 weeks, the CBT group shows significantly lower anxiety scores.",
    "claim": "The CBT app reduces anxiety compared to placebo.",
    "variables": {
      "X": {
        "name": "CBT app vs placebo app",
        "role": "Treatment"
      },
      "Y": {
        "name": "Anxiety scores",
        "role": "Outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S1",
      "type_name": "RCT",
      "subtype": "Double-Blind RCT",
      "subtype_name": "Double-Blind RCT"
    },
    "label": "YES",
    "causal_structure": "",
    "key_insight": "Proper randomization, placebo control, and blinding establish valid causal inference.",
    "gold_rationale": "This causal claim is well-supported. The study uses random assignment eliminating selection bias, a placebo control accounting for expectancy effects, and double-blinding preventing assessment bias. With 500 participants and 12-week follow-up, the design has adequate power and duration. The observed anxiety reduction can be causally attributed to the CBT content rather than placebo effects or confounding factors.",
    "wise_refusal": "This causal claim is well-supported. The study uses random assignment eliminating selection bias, a placebo control accounting for expectancy effects, and double-blinding preventing assessment bias. With 500 participants and 12-week follow-up, the design has adequate power and duration. The observed anxiety reduction can be causally attributed to the CBT content rather than placebo effects or confounding factors.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.52,
    "validator_2": "Longling Geng",
    "final_score_2": 9.27
  },
  {
    "id": "T3-BucketLarge-J-1.37",
    "bucket": "BucketLarge-J",
    "case_id": "0037",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Policy",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A randomized trial randomly assigns 60 schools to either implement a new social-emotional learning curriculum or continue standard instruction. After one academic year, students in treatment schools show improved behavioral outcomes and reduced disciplinary incidents compared to control schools.",
    "claim": "The social-emotional learning curriculum reduces disciplinary incidents.",
    "variables": {
      "X": {
        "name": "Social-emotional learning curriculum",
        "role": "Treatment"
      },
      "Y": {
        "name": "Disciplinary incidents",
        "role": "Outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S1",
      "type_name": "RCT",
      "subtype": "Cluster RCT",
      "subtype_name": "Cluster RCT"
    },
    "label": "YES",
    "causal_structure": "",
    "key_insight": "Cluster randomization at the school level enables valid causal inference for educational interventions.",
    "gold_rationale": "This causal claim is supported by the study design. Cluster randomization at the school level prevents contamination between treatment and control groups while maintaining practical implementation. With 60 schools randomly assigned, confounding factors like school resources, neighborhood characteristics, and student demographics should be balanced across groups. The year-long duration allows sufficient time for curriculum effects to manifest.",
    "wise_refusal": "This causal claim is supported by the study design. Cluster randomization at the school level prevents contamination between treatment and control groups while maintaining practical implementation. With 60 schools randomly assigned, confounding factors like school resources, neighborhood characteristics, and student demographics should be balanced across groups. The year-long duration allows sufficient time for curriculum effects to manifest.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.16,
    "validator_2": "Longling Geng",
    "final_score_2": 8.91
  },
  {
    "id": "T3-BucketLarge-J-1.38",
    "bucket": "BucketLarge-J",
    "case_id": "0038",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Labor Economics",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "Germany reunified suddenly in 1990, exposing East Germans to West German labor market institutions overnight. Economists compare employment outcomes of similar workers on either side of the former border before and after reunification, finding that exposure to West German institutions increased wages but also unemployment duration.",
    "claim": "West German labor market institutions caused changes in employment outcomes for East Germans.",
    "variables": {
      "X": {
        "name": "Exposure to West German labor market institutions",
        "role": "Treatment"
      },
      "Y": {
        "name": "Wages and unemployment duration",
        "role": "Outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S2",
      "type_name": "Natural Experiment",
      "subtype": "Policy Discontinuity",
      "subtype_name": "Policy Discontinuity"
    },
    "label": "YES",
    "causal_structure": "",
    "key_insight": "Sudden geopolitical events create natural experiments by exposing similar populations to different institutional treatments.",
    "gold_rationale": "This natural experiment provides strong causal evidence. German reunification was an exogenous shock unrelated to individual worker characteristics. Workers on either side of the border were culturally and economically similar before 1990, providing a natural control group. The sudden policy change allows researchers to isolate institutional effects from gradual economic trends. This design approximates random assignment of labor market institutions.",
    "wise_refusal": "This natural experiment provides strong causal evidence. German reunification was an exogenous shock unrelated to individual worker characteristics. Workers on either side of the border were culturally and economically similar before 1990, providing a natural control group. The sudden policy change allows researchers to isolate institutional effects from gradual economic trends. This design approximates random assignment of labor market institutions.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.35,
    "validator_2": "Longling Geng",
    "final_score_2": 9.1
  },
  {
    "id": "T3-BucketLarge-J-1.39",
    "bucket": "BucketLarge-J",
    "case_id": "0039",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Criminal Justice",
    "difficulty": "Hard",
    "is_ambiguous": false,
    "scenario": "In 2014, California's Proposition 47 unexpectedly reclassified certain drug and property crimes from felonies to misdemeanors. Researchers use synthetic control methods to compare California's recidivism rates to a weighted combination of states without such policy changes, finding reduced reincarceration rates.",
    "claim": "Felony reclassification to misdemeanor reduces reincarceration rates.",
    "variables": {
      "X": {
        "name": "Felony to misdemeanor reclassification",
        "role": "Treatment"
      },
      "Y": {
        "name": "Reincarceration rates",
        "role": "Outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S2",
      "type_name": "Natural Experiment",
      "subtype": "Natural Policy Experiment",
      "subtype_name": "Natural Policy Experiment"
    },
    "label": "YES",
    "causal_structure": "",
    "key_insight": "Voter initiatives create exogenous policy variation; synthetic controls address selection into treatment.",
    "gold_rationale": "This natural experiment, combined with synthetic control methods, provides credible causal evidence. Proposition 47 was a voter initiative creating an exogenous policy shock. The synthetic control approach constructs a counterfactual California from states with similar pre-treatment trends, addressing concerns about parallel trends. The policy change was discrete and identifiable, allowing clear before-after comparisons while controlling for secular trends in criminal justice outcomes.",
    "wise_refusal": "This natural experiment, combined with synthetic control methods, provides credible causal evidence. Proposition 47 was a voter initiative creating an exogenous policy shock. The synthetic control approach constructs a counterfactual California from states with similar pre-treatment trends, addressing concerns about parallel trends. The policy change was discrete and identifiable, allowing clear before-after comparisons while controlling for secular trends in criminal justice outcomes.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.9,
    "validator_2": "Longling Geng",
    "final_score_2": 9.65
  },
  {
    "id": "T3-BucketLarge-J-1.4",
    "bucket": "BucketLarge-J",
    "case_id": "0004",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Criminology",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A report finds that regions/organizations with higher State unemployment rate also have higher Individual criminal behavior on average.\nA commentator concludes that any individual inside a region with higher State unemployment rate will have higher Individual criminal behavior.\nHowever, individual-level data within regions shows large variation, and the within-region relationship is weak or opposite once relevant individual factors are considered.",
    "claim": "any individual inside a region with higher State unemployment rate will have higher Individual criminal behavior",
    "variables": {
      "X": {
        "name": "State unemployment rate (group-level)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Individual criminal behavior (individual-level)",
        "role": "Outcome"
      },
      "Z": [
        "Individual-level characteristics"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Socioeconomic",
      "subtype_name": "Socioeconomic"
    },
    "label": "YES",
    "causal_structure": "Group-level aggregates summarize heterogeneous individuals; group-level correlation does not imply the same relation at the individual level.",
    "key_insight": "You cannot infer individual behavior reliably from group-level correlations.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how State unemployment rate (group-level) relates to Individual criminal behavior (individual-level) for a person.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how State unemployment rate (group-level) relates to Individual criminal behavior (individual-level) for a person.",
    "hidden_timestamp": "Is State unemployment rate (group-level) measured at an aggregate level while Individual criminal behavior (individual-level) is an individual claim, and when/where does aggregation into Individual-level characteristics happen relative to measuring Individual criminal behavior (individual-level)?",
    "conditional_answers": {
      "A": "Answer if you only have aggregate correlations: You cannot infer individual-level behavior; the relationship may be confounded by group-level factors.",
      "B": "Answer if you have individual-level data within groups: Estimate the within-group association/effect and check whether it matches the aggregate pattern.",
      "C": "Answer if there is sorting/selection into groups: Treat conclusions as CONDITIONAL unless you model the sorting mechanism or use a design that breaks it."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.73,
    "validator_2": "Longling Geng",
    "final_score_2": 9.48
  },
  {
    "id": "T3-BucketLarge-J-1.40",
    "bucket": "BucketLarge-J",
    "case_id": "0040",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Urban Sociology",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "A city's affordable housing program receives more applicants than available units, so apartments are allocated by lottery. Researchers compare health outcomes of lottery winners who received housing to lottery losers who remained in their previous housing, finding improved mental health among winners after two years.",
    "claim": "Receiving affordable housing improves mental health outcomes.",
    "variables": {
      "X": {
        "name": "Affordable housing receipt",
        "role": "Treatment"
      },
      "Y": {
        "name": "Mental health outcomes",
        "role": "Outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S3",
      "type_name": "Lottery/Quasi-Random",
      "subtype": "Housing Lottery",
      "subtype_name": "Housing Lottery"
    },
    "label": "YES",
    "causal_structure": "",
    "key_insight": "Oversubscribed programs with lottery allocation create natural randomization among applicants.",
    "gold_rationale": "This lottery design supports causal inference. All applicants demonstrated similar motivation and eligibility by applying, and random selection eliminated systematic differences between winners and losers. This creates treatment and control groups comparable in income, prior housing instability, and baseline mental health. The two-year follow-up allows sufficient time for housing effects to manifest. The observed mental health improvements can be attributed to housing rather than selection effects.",
    "wise_refusal": "This lottery design supports causal inference. All applicants demonstrated similar motivation and eligibility by applying, and random selection eliminated systematic differences between winners and losers. This creates treatment and control groups comparable in income, prior housing instability, and baseline mental health. The two-year follow-up allows sufficient time for housing effects to manifest. The observed mental health improvements can be attributed to housing rather than selection effects.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.27,
    "validator_2": "Longling Geng",
    "final_score_2": 9.02
  },
  {
    "id": "T3-BucketLarge-J-1.41",
    "bucket": "BucketLarge-J",
    "case_id": "0041",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Policy",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A charter school receives three times more applications than available seats and uses a lottery for admission. Researchers track lottery winners and losers through high school graduation, finding that lottery winners have 12% higher graduation rates, with effects concentrated among low-income students.",
    "claim": "Charter school attendance increases graduation rates for low-income students.",
    "variables": {
      "X": {
        "name": "Charter school attendance",
        "role": "Treatment"
      },
      "Y": {
        "name": "High school graduation rates",
        "role": "Outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S3",
      "type_name": "Lottery/Quasi-Random",
      "subtype": "School Choice Lottery",
      "subtype_name": "School Choice Lottery"
    },
    "label": "YES",
    "causal_structure": "",
    "key_insight": "Lottery admission to oversubscribed schools creates experimental conditions within observational data.",
    "gold_rationale": "The lottery design provides strong causal evidence. Families who applied share similar motivation and engagement, addressing selection concerns. Random assignment ensures lottery winners and losers differ only by treatment status. Long-term tracking through graduation captures meaningful educational outcomes. The finding that effects concentrate among low-income students suggests the charter school provides resources that particularly benefit disadvantaged populations.",
    "wise_refusal": "The lottery design provides strong causal evidence. Families who applied share similar motivation and engagement, addressing selection concerns. Random assignment ensures lottery winners and losers differ only by treatment status. Long-term tracking through graduation captures meaningful educational outcomes. The finding that effects concentrate among low-income students suggests the charter school provides resources that particularly benefit disadvantaged populations.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.83,
    "validator_2": "Longling Geng",
    "final_score_2": 9.58
  },
  {
    "id": "T3-BucketLarge-J-1.42",
    "bucket": "BucketLarge-J",
    "case_id": "0042",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Social Psychology",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "Researchers develop an anti-prejudice intervention with three components: perspective-taking exercises, intergroup contact, and factual information. They test the full intervention against versions with each component removed. Only removing perspective-taking significantly reduces effectiveness, while removing factual information has no impact.",
    "claim": "Perspective-taking is the causally active component in reducing prejudice.",
    "variables": {
      "X": {
        "name": "Perspective-taking component",
        "role": "Treatment"
      },
      "Y": {
        "name": "Prejudice reduction",
        "role": "Outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S4",
      "type_name": "Controlled Ablation",
      "subtype": "Component Removal Study",
      "subtype_name": "Component Removal Study"
    },
    "label": "YES",
    "causal_structure": "",
    "key_insight": "Systematic component removal identifies causally necessary elements within complex interventions.",
    "gold_rationale": "This controlled ablation design supports causal attribution to specific components. By systematically removing each element while holding others constant, researchers isolate which components drive effects. The finding that only perspective-taking removal diminishes effectiveness, while factual information removal does not, demonstrates that perspective-taking is necessary for the intervention's success. This design goes beyond showing the full package works to identifying active ingredients.",
    "wise_refusal": "This controlled ablation design supports causal attribution to specific components. By systematically removing each element while holding others constant, researchers isolate which components drive effects. The finding that only perspective-taking removal diminishes effectiveness, while factual information removal does not, demonstrates that perspective-taking is necessary for the intervention's success. This design goes beyond showing the full package works to identifying active ingredients.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.05,
    "validator_2": "Longling Geng",
    "final_score_2": 8.8
  },
  {
    "id": "T3-BucketLarge-J-1.43",
    "bucket": "BucketLarge-J",
    "case_id": "0043",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Political Behavior",
    "difficulty": "Hard",
    "is_ambiguous": false,
    "scenario": "Researchers study voter mobilization using a 2x2x2 factorial design: phone calls (yes/no), text messages (yes/no), and social pressure messaging (yes/no). They find phone calls increase turnout by 3%, texts by 1%, and social pressure by 5%, with no significant interactions. Social pressure works equally well regardless of delivery method.",
    "claim": "Social pressure messaging causally increases voter turnout independent of delivery method.",
    "variables": {
      "X": {
        "name": "Social pressure messaging",
        "role": "Treatment"
      },
      "Y": {
        "name": "Voter turnout",
        "role": "Outcome"
      },
      "Z": [
        "Delivery method (phone/text)"
      ]
    },
    "trap": {
      "type": "S4",
      "type_name": "Controlled Ablation",
      "subtype": "Factorial Ablation Design",
      "subtype_name": "Factorial Ablation Design"
    },
    "label": "YES",
    "causal_structure": "",
    "key_insight": "Factorial designs disentangle main effects from interactions, isolating causally active components.",
    "gold_rationale": "The factorial design enables strong causal inference about social pressure effects. By crossing all combinations, researchers can isolate main effects and test for interactions. The absence of significant interactions indicates social pressure works through its content rather than synergistically with particular delivery methods. This design separates message content effects from medium effects, establishing that social pressure is an independent causal factor in mobilization.",
    "wise_refusal": "The factorial design enables strong causal inference about social pressure effects. By crossing all combinations, researchers can isolate main effects and test for interactions. The absence of significant interactions indicates social pressure works through its content rather than synergistically with particular delivery methods. This design separates message content effects from medium effects, establishing that social pressure is an independent causal factor in mobilization.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.71,
    "validator_2": "Longling Geng",
    "final_score_2": 9.46
  },
  {
    "id": "T3-BucketLarge-J-1.44",
    "bucket": "BucketLarge-J",
    "case_id": "0044",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Public Health Policy",
    "difficulty": "Hard",
    "is_ambiguous": false,
    "scenario": "Researchers studying lead exposure find that children's blood lead levels show a monotonic dose-response relationship with cognitive test scores: each 5 microgram/dL increase corresponds to a 2-point IQ decrease. Biological studies confirm lead interferes with neurotransmitter function and synaptic plasticity. Effects persist after controlling for socioeconomic factors.",
    "claim": "Lead exposure causes cognitive impairment in children.",
    "variables": {
      "X": {
        "name": "Blood lead levels",
        "role": "Treatment"
      },
      "Y": {
        "name": "Cognitive test scores",
        "role": "Outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S5",
      "type_name": "Mechanism + Dose",
      "subtype": "Mechanism with Dose-Response",
      "subtype_name": "Mechanism with Dose-Response"
    },
    "label": "YES",
    "causal_structure": "",
    "key_insight": "Dose-response relationships combined with mechanistic understanding strengthen causal inference.",
    "gold_rationale": "This claim is well-supported by converging evidence. The consistent dose-response relationship across exposure levels suggests a genuine biological effect rather than confounding. The established mechanism - lead's interference with neurotransmitter function - provides biological plausibility. Robustness to socioeconomic controls addresses major confounders. The combination of epidemiological dose-response evidence with mechanistic understanding from biological studies creates a compelling causal case.",
    "wise_refusal": "This claim is well-supported by converging evidence. The consistent dose-response relationship across exposure levels suggests a genuine biological effect rather than confounding. The established mechanism - lead's interference with neurotransmitter function - provides biological plausibility. Robustness to socioeconomic controls addresses major confounders. The combination of epidemiological dose-response evidence with mechanistic understanding from biological studies creates a compelling causal case.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 9.08,
    "validator_2": "Longling Geng",
    "final_score_2": 9.08
  },
  {
    "id": "T3-BucketLarge-J-1.45",
    "bucket": "BucketLarge-J",
    "case_id": "0045",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Family Studies",
    "difficulty": "Hard",
    "is_ambiguous": true,
    "scenario": "A longitudinal study follows children of divorce and intact families for 20 years, controlling for pre-divorce family conflict, income, and parental education. Children of divorce show somewhat lower wellbeing, but the effect size is much smaller than in uncontrolled studies. Some unmeasured factors like parental mental health may still differ between groups.",
    "claim": "Parental divorce causes reduced long-term wellbeing in children.",
    "variables": {
      "X": {
        "name": "Parental divorce",
        "role": "Treatment"
      },
      "Y": {
        "name": "Long-term child wellbeing",
        "role": "Outcome"
      },
      "Z": [
        "Pre-divorce conflict, income, education, unmeasured factors"
      ]
    },
    "trap": {
      "type": "A",
      "type_name": "Ambiguous",
      "subtype": "Partial Confounding Control",
      "subtype_name": "Partial Confounding Control"
    },
    "label": "AMBIGUOUS",
    "causal_structure": "",
    "key_insight": "Partial confounding control leaves genuine uncertainty about remaining causal effects.",
    "gold_rationale": "The evidence is genuinely ambiguous. Controlling for major confounders substantially reduces but does not eliminate the divorce-wellbeing association, suggesting some causal effect may exist. However, unmeasured confounders like parental mental health or relationship quality could still explain residual differences. The truth likely lies between 'divorce has no causal effect' and 'the raw correlation reflects pure causation.' Better evidence would require natural experiments or sibling comparisons.",
    "wise_refusal": "The evidence is genuinely ambiguous. Controlling for major confounders substantially reduces but does not eliminate the divorce-wellbeing association, suggesting some causal effect may exist. However, unmeasured confounders like parental mental health or relationship quality could still explain residual differences. The truth likely lies between 'divorce has no causal effect' and 'the raw correlation reflects pure causation.' Better evidence would require natural experiments or sibling comparisons.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketLarge-J-1.46",
    "bucket": "BucketLarge-J",
    "case_id": "0046",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Environmental Sociology",
    "difficulty": "Medium",
    "is_ambiguous": true,
    "scenario": "Communities near industrial facilities show higher rates of respiratory illness. Air quality measurements confirm elevated pollution, but these communities also have lower incomes, less healthcare access, and higher smoking rates. Researchers control for individual smoking and income but cannot fully account for cumulative disadvantage and healthcare access differences.",
    "claim": "Industrial pollution causes respiratory illness in nearby communities.",
    "variables": {
      "X": {
        "name": "Industrial facility proximity",
        "role": "Treatment"
      },
      "Y": {
        "name": "Respiratory illness rates",
        "role": "Outcome"
      },
      "Z": [
        "Income, smoking, healthcare access, cumulative disadvantage"
      ]
    },
    "trap": {
      "type": "A",
      "type_name": "Ambiguous",
      "subtype": "Competing Mechanisms",
      "subtype_name": "Competing Mechanisms"
    },
    "label": "AMBIGUOUS",
    "causal_structure": "",
    "key_insight": "Environmental injustice creates confounding that is conceptually clear but practically impossible to fully control.",
    "gold_rationale": "This case presents genuine causal ambiguity. A plausible mechanism exists - documented air pollution exposure causing respiratory harm. However, environmental injustice means pollution exposure correlates with multiple disadvantages that independently affect health. Controlling for smoking and income helps but cannot address cumulative disadvantage or healthcare access. The pollution likely contributes to illness, but quantifying its independent causal contribution versus correlated socioeconomic factors remains uncertain.",
    "wise_refusal": "This case presents genuine causal ambiguity. A plausible mechanism exists - documented air pollution exposure causing respiratory harm. However, environmental injustice means pollution exposure correlates with multiple disadvantages that independently affect health. Controlling for smoking and income helps but cannot address cumulative disadvantage or healthcare access. The pollution likely contributes to illness, but quantifying its independent causal contribution versus correlated socioeconomic factors remains uncertain.",
    "hidden_timestamp": "",
    "conditional_answers": {
      "answer_if_condition_1": "",
      "answer_if_condition_2": ""
    },
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.18,
    "validator_2": "Longling Geng",
    "final_score_2": 8.93
  },
  {
    "id": "T3-BucketLarge-J-1.47",
    "bucket": "BucketLarge-J",
    "case_id": "0047",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Policy",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A state education department analyzes spending data from districts investing between $5,000 and $15,000 per student annually. The data shows a strong positive correlation: each additional $1,000 in per-student spending corresponds to approximately 8 percentile points higher on standardized tests. Based on this relationship, a policy advisor proposes that increasing spending to $100,000 per student would raise test scores to the 99th percentile, recommending massive budget increases to achieve educational excellence.",
    "claim": "Increasing education spending to $100,000 per student would produce proportionally higher test scores based on the observed $5K-$15K correlation.",
    "variables": {
      "X": {
        "name": "Per-student education spending",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Standardized test scores",
        "role": "Outcome"
      },
      "R": {
        "name": "Observed spending range ($5,000-$15,000)",
        "role": "Domain constraint"
      },
      "Z": []
    },
    "trap": {
      "type": "W3",
      "type_name": "Healthy User Bias",
      "subtype": "Asymptotic Failure / Extrapolation",
      "subtype_name": "Extrapolation Error"
    },
    "label": "NO",
    "causal_structure": "X -> Y observed for X in [$5K, $15K], extrapolated to X = $100K without justification",
    "key_insight": "Linear correlations in moderate spending ranges cannot be extrapolated indefinitely due to ceiling effects on test scores, diminishing marginal returns on educational inputs, and practical limits on resource deployment.",
    "gold_rationale": "This extrapolation from $5K-$15K to $100K per student is unjustified. Education spending exhibits well-documented diminishing returns: initial investments improve basics like qualified teachers and materials, but additional funds face ceiling effects (students cannot score above 100%), absorption limits (schools cannot productively deploy unlimited resources), and diminishing marginal utility (tenth teacher aide provides less value than first). The linear relationship observed in the modest range breaks down dramatically at extreme values.",
    "wise_refusal": "This extrapolation from $5K-$15K to $100K per student is unjustified. Education spending exhibits well-documented diminishing returns: initial investments improve basics like qualified teachers and materials, but additional funds face ceiling effects (students cannot score above 100%), absorption limits (schools cannot productively deploy unlimited resources), and diminishing marginal utility (tenth teacher aide provides less value than first). The linear relationship observed in the modest range breaks down dramatically at extreme values.",
    "hidden_timestamp": "Does the linear relationship between education spending and test scores hold when extrapolating from $5K-$15K to $100K per student?",
    "conditional_answers": {
      "A": "If the relationship is truly linear across all spending levels, the extrapolation would be valid.",
      "B": "If diminishing returns, ceiling effects on test scores, or resource absorption limits exist, the relationship plateaus well before $100K.",
      "C": "If spending beyond certain thresholds creates bureaucratic inefficiency or misallocation, the relationship could reverse."
    },
    "initial_author": "Claude Code Remediation Agent",
    "validator": "Claude Code Validator",
    "final_score": 8.73,
    "validator_2": "Longling Geng",
    "final_score_2": 9.48
  },
  {
    "id": "T3-BucketLarge-J-1.48",
    "bucket": "BucketLarge-J",
    "case_id": "0048",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Labor Economics",
    "difficulty": "Hard",
    "is_ambiguous": false,
    "scenario": "Economists study the effects of minimum wage increases across states where rates varied from $7.25 to $15.00 per hour over a decade. Within this range, they find modest negative effects on employment: each $1 increase correlates with approximately 0.5% reduction in low-wage employment, but the effect is small and some studies show neutral or positive effects due to reduced turnover. A policy group extrapolates this finding to argue that a $50 per hour minimum wage would cause only a 21% reduction in low-wage employment, which they consider an acceptable tradeoff.",
    "claim": "A $50/hour minimum wage would reduce low-wage employment by approximately 21% based on linear extrapolation from effects observed in the $7-$15/hour range.",
    "variables": {
      "X": {
        "name": "Minimum wage level",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Low-wage employment rate",
        "role": "Outcome"
      },
      "R": {
        "name": "Observed wage range ($7.25-$15.00/hour)",
        "role": "Domain constraint"
      },
      "Z": []
    },
    "trap": {
      "type": "W3",
      "type_name": "Healthy User Bias",
      "subtype": "Asymptotic Failure / Extrapolation",
      "subtype_name": "Extrapolation Error"
    },
    "label": "NO",
    "causal_structure": "X -> Y observed for X in [$7.25, $15.00], extrapolated to X = $50 without justification",
    "key_insight": "Labor market responses to minimum wages are bounded by business viability thresholds, automation economics, and market restructuring that create severe nonlinearities far outside the observed policy range.",
    "gold_rationale": "Extrapolating minimum wage effects from $7-$15/hour to $50/hour is fundamentally flawed. The observed range represents modest perturbations where businesses can absorb costs through reduced profits, slight price increases, or productivity gains. At $50/hour, these adjustment mechanisms break down entirely: most low-wage businesses would become unviable, automation becomes economically imperative, and underground employment would surge. Labor market discontinuities and business model constraints invalidate linear extrapolation beyond the observed domain.",
    "wise_refusal": "Extrapolating minimum wage effects from $7-$15/hour to $50/hour is fundamentally flawed. The observed range represents modest perturbations where businesses can absorb costs through reduced profits, slight price increases, or productivity gains. At $50/hour, these adjustment mechanisms break down entirely: most low-wage businesses would become unviable, automation becomes economically imperative, and underground employment would surge. Labor market discontinuities and business model constraints invalidate linear extrapolation beyond the observed domain.",
    "hidden_timestamp": "Does the modest employment elasticity observed for minimum wages between $7-$15/hour apply when extrapolating to $50/hour?",
    "conditional_answers": {
      "A": "If labor demand elasticity is constant across all wage levels, the linear extrapolation would hold.",
      "B": "If labor markets exhibit discontinuities, threshold effects, or nonlinear responses at extreme wages, employment effects would be far more severe than predicted.",
      "C": "If businesses fundamentally restructure operations, automate, or relocate at extreme wage levels, the observed relationship becomes meaningless."
    },
    "initial_author": "Claude Code Remediation Agent",
    "validator": "Claude Code Validator",
    "final_score": 8.42,
    "validator_2": "Longling Geng",
    "final_score_2": 9.17
  },
  {
    "id": "T3-BucketLarge-J-1.49",
    "bucket": "BucketLarge-J",
    "case_id": "0049",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Criminal Justice",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A city crime analysis unit examines data across neighborhoods with varying police-to-resident ratios ranging from 1 officer per 1,000 residents to 1 per 200 residents. Within this range, they observe a negative correlation: doubling police presence correlates with roughly 15% lower property crime rates. A city council member extrapolates this relationship to propose that if police presence were increased to 1 officer per 10 residents, property crime would approach zero, justifying a dramatic expansion of the police force.",
    "claim": "Increasing police presence to 1 officer per 10 residents would reduce crime to near-zero based on the observed correlation at moderate staffing levels.",
    "variables": {
      "X": {
        "name": "Police-to-resident ratio",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Property crime rate",
        "role": "Outcome"
      },
      "R": {
        "name": "Observed ratio range (1:1000 to 1:200)",
        "role": "Domain constraint"
      },
      "Z": []
    },
    "trap": {
      "type": "W3",
      "type_name": "Healthy User Bias",
      "subtype": "Asymptotic Failure / Extrapolation",
      "subtype_name": "Extrapolation Error"
    },
    "label": "NO",
    "causal_structure": "X -> Y observed for X in [1:1000, 1:200], extrapolated to X = 1:10 without justification",
    "key_insight": "Crime reduction through policing faces asymptotic limits: easily deterred crimes are prevented first, and remaining crime has causes that policing cannot address, creating diminishing returns that invalidate linear extrapolation.",
    "gold_rationale": "Extrapolating from moderate police ratios (1:1000 to 1:200) to extreme saturation (1:10) ignores fundamental limits on crime reduction. Diminishing returns occur because police first deter the most preventable crimes; remaining crime involves determined offenders, crimes of passion, or hidden victimization. Opportunity costs become extreme as police spending crowds out social services that address root causes. Civil liberties constraints, community alienation, and crime displacement to unpoliced domains further invalidate the assumed monotonic relationship. Zero crime is an asymptote that cannot be reached through policing alone.",
    "wise_refusal": "Extrapolating from moderate police ratios (1:1000 to 1:200) to extreme saturation (1:10) ignores fundamental limits on crime reduction. Diminishing returns occur because police first deter the most preventable crimes; remaining crime involves determined offenders, crimes of passion, or hidden victimization. Opportunity costs become extreme as police spending crowds out social services that address root causes. Civil liberties constraints, community alienation, and crime displacement to unpoliced domains further invalidate the assumed monotonic relationship. Zero crime is an asymptote that cannot be reached through policing alone.",
    "hidden_timestamp": "Does the negative correlation between police presence and crime observed at moderate levels continue linearly as police presence approaches extreme saturation?",
    "conditional_answers": {
      "A": "If deterrence effects scale linearly with police presence regardless of saturation, the extrapolation would be valid.",
      "B": "If diminishing returns exist because easily deterrable crimes are prevented first, additional officers provide decreasing marginal benefit.",
      "C": "If extreme police presence creates civil liberties violations, community alienation, or displaces rather than prevents crime, the relationship could reverse."
    },
    "initial_author": "Claude Code Remediation Agent",
    "validator": "Claude Code Validator",
    "final_score": 8.65,
    "validator_2": "Longling Geng",
    "final_score_2": 9.4
  },
  {
    "id": "T3-BucketLarge-J-1.5",
    "bucket": "BucketLarge-J",
    "case_id": "0005",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Organizational Behavior",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A report finds that regions/organizations with higher Company diversity percentage also have higher Individual satisfaction on average.\nA commentator concludes that any individual inside a region with higher Company diversity percentage will have higher Individual satisfaction.\nHowever, individual-level data within regions shows large variation, and the within-region relationship is weak or opposite once relevant individual factors are considered.",
    "claim": "any individual inside a region with higher Company diversity percentage will have higher Individual satisfaction",
    "variables": {
      "X": {
        "name": "Company diversity percentage (group-level)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Individual satisfaction (individual-level)",
        "role": "Outcome"
      },
      "Z": [
        "Individual-level characteristics"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "Socioeconomic",
      "subtype_name": "Socioeconomic"
    },
    "label": "YES",
    "causal_structure": "Group-level aggregates summarize heterogeneous individuals; group-level correlation does not imply the same relation at the individual level.",
    "key_insight": "You cannot infer individual behavior reliably from group-level correlations.",
    "gold_rationale": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how Company diversity percentage (group-level) relates to Individual satisfaction (individual-level) for a person.",
    "wise_refusal": "I don’t have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how Company diversity percentage (group-level) relates to Individual satisfaction (individual-level) for a person.",
    "hidden_timestamp": "Is Company diversity percentage (group-level) measured at an aggregate level while Individual satisfaction (individual-level) is an individual claim, and when/where does aggregation into Individual-level characteristics happen relative to measuring Individual satisfaction (individual-level)?",
    "conditional_answers": {
      "A": "Answer if you only have aggregate correlations: You cannot infer individual-level behavior; the relationship may be confounded by group-level factors.",
      "B": "Answer if you have individual-level data within groups: Estimate the within-group association/effect and check whether it matches the aggregate pattern.",
      "C": "Answer if there is sorting/selection into groups: Treat conclusions as CONDITIONAL unless you model the sorting mechanism or use a design that breaks it."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.24,
    "validator_2": "Longling Geng",
    "final_score_2": 8.99
  },
  {
    "id": "T3-BucketLarge-J-1.50",
    "bucket": "BucketLarge-J",
    "case_id": "0050",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Social Psychology",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "Mental health researchers analyze survey data from adolescents reporting social media use between 0 and 4 hours daily. Within this range, they find a positive correlation: each additional hour of daily social media use corresponds to a 0.3-point increase on a depression symptoms scale (range 0-27). A concerned parent advocacy group extrapolates this finding to claim that teenagers using social media for 16 hours daily would have depression scores 4.8 points higher than non-users, characterizing extreme social media use as a severe mental health crisis requiring urgent intervention.",
    "claim": "Teenagers using social media 16 hours daily would show proportionally elevated depression scores based on the linear relationship observed in the 0-4 hour range.",
    "variables": {
      "X": {
        "name": "Daily social media use (hours)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Depression symptom score",
        "role": "Outcome"
      },
      "R": {
        "name": "Observed usage range (0-4 hours daily)",
        "role": "Domain constraint"
      },
      "Z": []
    },
    "trap": {
      "type": "W3",
      "type_name": "Healthy User Bias",
      "subtype": "Asymptotic Failure / Extrapolation",
      "subtype_name": "Extrapolation Error"
    },
    "label": "NO",
    "causal_structure": "X -> Y observed for X in [0, 4 hours], extrapolated to X = 16 hours without justification",
    "key_insight": "Extreme usage levels (16 hours daily) represent a fundamentally different population with severe confounders; extrapolating correlations from typical usage ignores ceiling effects on outcomes and qualitative differences in who exhibits extreme behavior.",
    "gold_rationale": "Extrapolating from 0-4 hours to 16 hours of daily social media use is unjustified for multiple reasons. First, 16-hour usage is physically unsustainable, leaving only 8 hours for sleep with no time for school, eating, or other activities, indicating severe confounding conditions. Second, depression scales have ceiling effects, preventing linear extrapolation beyond maximum scores. Third, individuals using social media 16 hours daily likely have pre-existing conditions (severe depression, social isolation, disability) that confound any observed correlation. The extreme usage domain has different population characteristics that invalidate extrapolation from typical users.",
    "wise_refusal": "Extrapolating from 0-4 hours to 16 hours of daily social media use is unjustified for multiple reasons. First, 16-hour usage is physically unsustainable, leaving only 8 hours for sleep with no time for school, eating, or other activities, indicating severe confounding conditions. Second, depression scales have ceiling effects, preventing linear extrapolation beyond maximum scores. Third, individuals using social media 16 hours daily likely have pre-existing conditions (severe depression, social isolation, disability) that confound any observed correlation. The extreme usage domain has different population characteristics that invalidate extrapolation from typical users.",
    "hidden_timestamp": "Does the linear correlation between social media use and depression observed from 0-4 hours/day extend to extreme usage levels like 16 hours/day?",
    "conditional_answers": {
      "A": "If the relationship is truly linear across all usage levels, extrapolation to extreme hours would be valid.",
      "B": "If ceiling effects on depression scales or saturation of psychological mechanisms exist, the relationship plateaus at high usage.",
      "C": "If extreme usage (16 hours) indicates severe underlying conditions that independently cause both behaviors, the correlation reflects confounding rather than direct causation."
    },
    "initial_author": "Claude Code Remediation Agent",
    "validator": "Claude Code Validator",
    "final_score": 8.26,
    "validator_2": "Longling Geng",
    "final_score_2": 9.01
  },
  {
    "id": "T3-BucketLarge-J-1.6",
    "bucket": "BucketLarge-J",
    "case_id": "0006",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Education Policy",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A nonprofit reports that applicants from Prep Program A are accepted into selective colleges at a higher overall rate than applicants from Prep Program B. Donors conclude Program A is more effective and recommend expanding it.\n\nA counselor points out that when acceptance rates are broken down by family income bracket (low-income vs higher-income), Program B has a higher acceptance rate in both brackets. Program A has more higher-income participants overall, while Program B serves mostly low-income participants.",
    "claim": "applicants from Prep Program A are accepted into selective colleges at a higher overall rate than applicants from Prep Program B",
    "variables": {
      "X": {
        "name": "Prep program (A vs. B)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "College acceptance rate",
        "role": "Outcome"
      },
      "Z": [
        "Family income bracket (low vs. higher)"
      ]
    },
    "trap": {
      "type": "W8",
      "type_name": "Simpson's Paradox",
      "subtype": "Aggregation Bias",
      "subtype_name": "Aggregation Bias"
    },
    "label": "YES",
    "causal_structure": "Z affects Y and differs in distribution across X; aggregating across Z reverses the subgroup acceptance-rate comparison.",
    "key_insight": "Aggregate success rates can reverse within-group trends when group composition differs.",
    "gold_rationale": "I can’t determine which program is causally better without baseline comparability (prior grades, support) and a credible assignment mechanism.",
    "wise_refusal": "I can’t determine which program is causally better without baseline comparability (prior grades, support) and a credible assignment mechanism.",
    "hidden_timestamp": "Was family income bracket known before students enrolled in Prep Program A vs. B, making it a true pre-enrollment stratifier?",
    "conditional_answers": {
      "A": "Answer if you only use overall acceptance rates: You may wrongly prefer Program A because it serves more higher-income students.",
      "B": "Answer if you stratify or standardize by income bracket: Compare within strata (or compute standardized rates) to evaluate program performance.",
      "C": "Answer if assignment to programs can be randomized within income strata: Then within-stratum differences can support a causal claim about program effectiveness."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.31,
    "validator_2": "Longling Geng",
    "final_score_2": 9.06
  },
  {
    "id": "T3-BucketLarge-J-1.7",
    "bucket": "BucketLarge-J",
    "case_id": "0007",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Finance",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A city report states that Bank X has a lower overall loan default rate than Bank Y, and officials argue Bank X has better underwriting practices.\n\nWhen analysts stratify borrowers by credit-risk tier (prime vs subprime), Bank Y has a lower default rate in both tiers. The reversal occurs because Bank X approves a larger share of prime borrowers, while Bank Y serves more subprime borrowers overall.",
    "claim": "A city report states that Bank X has a lower overall loan default rate than Bank Y, and officials argue Bank X has better underwriting practices",
    "variables": {
      "X": {
        "name": "Bank (X vs. Y)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Loan default rate",
        "role": "Outcome"
      },
      "Z": [
        "Credit-risk tier (prime vs. subprime)"
      ]
    },
    "trap": {
      "type": "W8",
      "type_name": "Simpson's Paradox",
      "subtype": "Imbalanced Group Composition",
      "subtype_name": "Imbalanced Group Composition"
    },
    "label": "YES",
    "causal_structure": "Z strongly affects Y and the distribution of Z differs by X; aggregate defaults reverse the within-tier comparison.",
    "key_insight": "Comparing institutions using aggregate outcomes is misleading when they serve different mixes of clients.",
    "gold_rationale": "I can’t judge underwriting quality without consistent risk-tier measurement and a standardized comparison across the same risk distribution.",
    "wise_refusal": "I can’t judge underwriting quality without consistent risk-tier measurement and a standardized comparison across the same risk distribution.",
    "hidden_timestamp": "Is credit-risk tier assessed before borrowers choose a bank, making Z pre-treatment with respect to X?",
    "conditional_answers": {
      "A": "Answer if you compare only overall defaults: You may incorrectly attribute Bank X’s lower defaults to better underwriting.",
      "B": "Answer if you compare within risk tiers or compute standardized defaults: Prefer the bank with lower within-tier defaults (and report a standardized overall rate).",
      "C": "Answer if approval decisions themselves change the portfolio mix: Separate “mix effects” from “within-tier performance.”"
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.26,
    "validator_2": "Longling Geng",
    "final_score_2": 9.01
  },
  {
    "id": "T3-BucketLarge-J-1.8",
    "bucket": "BucketLarge-J",
    "case_id": "0008",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Healthcare Administration",
    "difficulty": "Medium",
    "is_ambiguous": false,
    "scenario": "A hospital network claims Clinic A provides better follow-up care because its overall 30-day readmission rate is lower than Clinic B’s.\n\nWhen readmissions are broken down by patient age group (under 65 vs 65+), Clinic B has lower readmission rates in both groups. Clinic A treats a much larger share of younger patients, while Clinic B treats more older patients overall.",
    "claim": "A hospital network claims Clinic A provides better follow-up care because its overall 30-day readmission rate is lower than Clinic B’s",
    "variables": {
      "X": {
        "name": "Clinic (A vs. B)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "30-day readmission rate",
        "role": "Outcome"
      },
      "Z": [
        "Age group (under 65 vs. 65+)"
      ]
    },
    "trap": {
      "type": "W8",
      "type_name": "Simpson's Paradox",
      "subtype": "Aggregation Bias",
      "subtype_name": "Aggregation Bias"
    },
    "label": "YES",
    "causal_structure": "Z affects Y and differs by clinic; aggregating across Z reverses the subgroup comparison.",
    "key_insight": "Overall metrics can hide within-group differences driven by demographic mix.",
    "gold_rationale": "I can’t attribute readmission differences to care quality without case-mix adjustment and information on referral/triage processes.",
    "wise_refusal": "I can’t attribute readmission differences to care quality without case-mix adjustment and information on referral/triage processes.",
    "hidden_timestamp": "Was age determined before clinic selection (a true pre-treatment stratifier), or does clinic choice affect which ages are seen?",
    "conditional_answers": {
      "A": "Answer if you only look at overall readmissions: You might reward Clinic A incorrectly.",
      "B": "Answer if you age-standardize or compare within age strata: The within-stratum comparison is more informative for care quality.",
      "C": "Answer if clinics differ in referral patterns: Adjust for case mix and referral selection before drawing conclusions."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.15,
    "validator_2": "Longling Geng",
    "final_score_2": 8.9
  },
  {
    "id": "T3-BucketLarge-J-1.9",
    "bucket": "BucketLarge-J",
    "case_id": "0009",
    "pearl_level": "L1",
    "domain": "D10",
    "subdomain": "Organizational Behavior",
    "difficulty": "Easy",
    "is_ambiguous": false,
    "scenario": "A company emails an anonymous satisfaction survey and reports that “85% of employees are satisfied.” Leadership concludes morale is high.\n\nOnly 30% of employees responded. Dissatisfied employees may be less likely to respond because they think nothing will change or fear being identified.",
    "claim": "“85% of employees are satisfied",
    "variables": {
      "X": {
        "name": "Survey response (respond vs. not)",
        "role": "Treatment/Factor"
      },
      "Y": {
        "name": "Reported satisfaction",
        "role": "Outcome"
      },
      "Z": [
        "Dissatisfaction / fear of retaliation"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "Sampling-on-the-Outcome",
      "subtype_name": "Sampling Bias"
    },
    "label": "YES",
    "causal_structure": "Z affects response and satisfaction; conditioning on responders yields biased satisfaction estimate.",
    "key_insight": "Survey results can be unrepresentative when response is selective.",
    "gold_rationale": "I can’t infer company-wide morale without response-rate patterns and information about non-respondents.",
    "wise_refusal": "I can’t infer company-wide morale without response-rate patterns and information about non-respondents.",
    "hidden_timestamp": "Did dissatisfaction exist before employees chose whether to respond, or did the survey context change willingness to respond?",
    "conditional_answers": {
      "A": "Answer if response is random: Then the respondent rate estimates overall morale.",
      "B": "Answer if dissatisfied employees avoid responding: Then results are biased upward; improve sampling/response incentives.",
      "C": "Answer if response differs by team or manager: Use stratified follow-ups to assess representation."
    },
    "initial_author": "Sreya Vangara",
    "validator": "Fernando Torres",
    "final_score": 8.52,
    "validator_2": "Longling Geng",
    "final_score_2": 9.27
  },
  {
    "id": "T3-BucketJ-02",
    "case_id": "J2-02",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "D10 (Social Science)",
    "subdomain": "Criminology",
    "scenario": "City District East increases its police presence and reports a higher overall crime clearance rate than District West.",
    "claim": "The increased police presence in District East leads to better crime clearance rates compared to District West.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Police presence in the district",
        "role": "exposure"
      },
      "Y": {
        "name": "Crime clearance rate",
        "role": "outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S2",
      "type_name": "Natural Experiment",
      "subtype": "",
      "subtype_name": ""
    },
    "difficulty": "Hard",
    "causal_structure": "Police presence (X) causes increased crime clearance rate (Y).",
    "key_insight": "The natural experiment of differing police presence allows causal inference regarding crime clearance rates.",
    "hidden_timestamp": "What were the crime clearance rates in District East and District West before the change in police presence?",
    "conditional_answers": {
      "answer_if_condition_1": "If yes, other factors might be affecting clearance rates.",
      "answer_if_condition_2": "If no, the increase in police presence likely caused the higher clearance rates if this was the only significant change."
    },
    "wise_refusal": "The scenario does not state that the crime clearance rate in District East changed before and after the increase in police presence.",
    "gold_rationale": "The natural experiment supports a causual relationship between police presence and crime clearance rates, if other factors are controlled for.",
    "initial_author": "Sreya Vangara",
    "validator": "Daphne Barretto",
    "initial_score": 10.0,
    "final_score": 0.0,
    "validator_2": "Longling Geng",
    "final_score_2": 0.75
  },
  {
    "id": "T3-BucketJ-04",
    "case_id": "J2-04",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "D10 (Social Science)",
    "subdomain": "Consumer Behavior",
    "scenario": "A company reports that 92% of customers are satisfied with its new subscription service, based on responses to a voluntary online satisfaction survey on the service website. Executives conclude that the service rollout has been a major success.",
    "claim": "Customers are satisfied with the new subscription service because 92% of survey respondents reported satisfaction.",
    "label": "AMBIGUOUS",
    "is_ambiguous": true,
    "variables": {
      "X": {
        "name": "New subscription service",
        "role": "exposure"
      },
      "Y": {
        "name": "Customer satisfaction",
        "role": "outcome"
      },
      "Z": [
        "Survey response participation"
      ]
    },
    "trap": {
      "type": "A",
      "type_name": "Ambiguous",
      "subtype": "",
      "subtype_name": ""
    },
    "difficulty": "Hard",
    "causal_structure": "Customer satisfaction (Y) increases likelihood of Survey response participation (Z), biasing observed satisfaction rates among respondents.",
    "key_insight": "The intended measurement affects who is observed, confounding the estimate of satisfaction.",
    "hidden_timestamp": "Was survey response participation representative of all customers?",
    "conditional_answers": {
      "answer_if_condition_1": "If yes, then the reported customer satisfaction rate reflects the full customer base.",
      "answer_if_condition_2": "If no, the reported customer satisfaction rate is biased by who chose to respond. Adjustments or randomized sampling are needed for valid inference."
    },
    "wise_refusal": "The survey response participation is likely non-random and influenced by satisfaction status.",
    "gold_rationale": "While high satisfaction among respondents is encouraging, the voluntary nature of the survey introduces bias.",
    "initial_author": "Sreya Vangara",
    "validator": "Daphne Barretto",
    "initial_score": 10.0,
    "final_score": 0.0,
    "validator_2": "Longling Geng",
    "final_score_2": 0.75
  },
  {
    "id": "T3-BucketJ-05",
    "case_id": "J2-05",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "D10 (Social Science)",
    "subdomain": "Entrepreneurship",
    "scenario": "500 universities were randomly selected to receive a startup accelerator program for student entrepreneurs. 500 other universities were randomly selected to not receive the program. After one year, 20% of startups from schools with the accelerator secured Series A funding, compared to only 1% from schools without the program.",
    "claim": "The startup accelerator program increases the likelihood of securing Series A funding.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Startup accelerator program",
        "role": "Provides student entrepreneurs access to resources, mentorship, and networking opportunities."
      },
      "Y": {
        "name": "Startup success (Series A funding)",
        "role": "outcome"
      },
      "Z": []
    },
    "trap": {
      "type": "S1",
      "type_name": "RCT",
      "subtype": "",
      "subtype_name": ""
    },
    "difficulty": "Hard",
    "causal_structure": "Startup accelerator program (X) affects Startup success (Series A funding) (Y) directly, with random assignment eliminating confounding.",
    "key_insight": "Randomized assignment ensures comparability between groups, allowing causal inference. Startup accelerator program (X) is independent of other factors influencing Startup success (Series A funding) (Y), and shows increased startup success.",
    "hidden_timestamp": "Was Startup accelerator program assigned before Startup success (Series A funding) occurred, and could Startup success (Series A funding) have influenced the assignment of Startup accelerator program?",
    "conditional_answers": {
      "answer": "Answer if Accelerator participation is randomly assigned: A difference in Startup success (Series A funding) across Accelerator participation groups can be interpreted causally.\nAnswer if participation/exposure is voluntary or selected (e.g., Founder quality / prior advantages): The Accelerator participation vs not-Accelerator participation difference in Startup success (Series A funding) is biased by who ends up observed/treated.\nAnswer if you can measure the selection drivers (e.g., Founder quality / prior advantages) and adjust (matching/weighting/IV): The conclusion becomes CONDITIONAL on those assumptions and model quality."
    },
    "wise_refusal": "We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Founder quality / prior advantages); otherwise Accelerator participation-Startup success (Series A funding) differences may reflect selection rather than effect.",
    "gold_rationale": "This case shows a well-conducted randomized controlled trial (RCT).\nKey reasoning step: Random assignment of the accelerator program (X) ensures that confounding variables are balanced between groups.\nHidden temporal structure: The program is assigned before funding outcomes occur.\nFailure mode: None; the RCT design supports valid causal inference.\nCorrect conclusion:\nThe claim that the startup accelerator program increases the likelihood of securing Series A funding is VALID.\nWise refusal:\nThe RCT design allows for direct causal interpretation without additional adjustments.",
    "initial_author": "Sreya Vangara",
    "validator": "Daphne Barretto",
    "initial_score": 9.0,
    "final_score": 0.0,
    "validator_2": "Longling Geng",
    "final_score_2": 0.75
  },
  {
    "id": "T3-BucketJ-06",
    "case_id": "J2-06",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "D10 (Social Science)",
    "subdomain": "Workplace Health",
    "scenario": "A company reports that employees enrolled in its voluntary wellness program take fewer sick days than employees who do not enroll. Management concludes that the wellness program improves employee health and considers expanding it.\nFurther examination reveals that employees who opt into the program tend to be healthier, more health-conscious, and more engaged with company initiatives even before the program begins.",
    "claim": "The Employee Wellness Program",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Wellness program participation",
        "role": "exposure"
      },
      "Y": {
        "name": "Number of sick days taken",
        "role": "outcome"
      },
      "Z": [
        "Baseline employee health / engagement"
      ]
    },
    "trap": {
      "type": "W2",
      "type_name": "Selection Bias",
      "subtype": "Sampling-on-the-Outcome",
      "subtype_name": "Sampling-on-the-Outcome"
    },
    "difficulty": "Medium",
    "causal_structure": "Baseline health (Z) influences both program participation (X) and health outcomes (Y).",
    "key_insight": "Voluntary programs often attract participants who would perform better regardless.",
    "hidden_timestamp": "At what point were units selected into the observed sample-before or after Number of sick days taken occurred-and is selection related to Baseline employee health / engagement or Number of sick days taken?",
    "conditional_answers": {
      "answer": "Answer if Wellness program participation is randomly assigned: A difference in Number of sick days taken across Wellness program participation groups can be interpreted causally.\nAnswer if participation/exposure is voluntary or selected (e.g., Baseline employee health / engagement): The Wellness program participation vs not-Wellness program participation difference in Number of sick days taken is biased by who ends up observed/treated.\nAnswer if you can measure the selection drivers (e.g., Baseline employee health / engagement) and adjust (matching/weighting/IV): The conclusion becomes CONDITIONAL on those assumptions and model quality."
    },
    "wise_refusal": "I don't have enough information to make a definitive causal claim from the summary statistics alone. We need to know how units enter the treated/observed group and what pre-existing differences drive selection (especially Baseline employee health / engagement); otherwise Wellness program participation-Number of sick days taken differences may reflect selection rather than effect.",
    "gold_rationale": "This case requires associational reasoning and recognition of selection bias.\nKey reasoning step: Healthier employees are more likely to enroll, biasing comparisons.\nHidden temporal structure: Baseline health precedes enrollment.\nFailure mode: Mistaking correlation within a selected group for causal impact.\nCorrect conclusion:\nThe claim that the wellness program reduces sick days is INVALID.\nWise refusal:\nCausal evaluation would require random assignment or strong controls for baseline health.",
    "initial_author": "Sreya Vangara",
    "validator": "Daphne Barretto",
    "initial_score": 9.0,
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketJ-08",
    "case_id": "J2-08",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "D10 (Social Science)",
    "subdomain": "Education Sociology",
    "scenario": "A city education report shows that neighborhoods with larger houses have higher average student test scores.",
    "claim": "Neighborhoods with larger houses lead to better student test scores.",
    "label": "AMBIGUOUS",
    "is_ambiguous": true,
    "variables": {
      "X": {
        "name": "Neighborhood house size",
        "role": "exposure"
      },
      "Y": {
        "name": "Student test scores",
        "role": "outcome"
      },
      "Z": [
        "Household-level educational support"
      ]
    },
    "trap": {
      "type": "A",
      "type_name": "Ambiguous",
      "subtype": "",
      "subtype_name": ""
    },
    "difficulty": "Easy",
    "causal_structure": "Neighborhood house size could correlate with student test scores, but the relationship likely involves other household-level factors.",
    "key_insight": "Other factors at the household level may drive the observed association.",
    "hidden_timestamp": "Are student test scores higher when controlling for other factors?",
    "conditional_answers": {
      "answer_if_condition_1": "If yes, then this supports that neighborhood house size could cause higher student test scores.",
      "answer_if_condition_2": "If no, then the association is likely confounded by other factors."
    },
    "wise_refusal": "Other factors, such as household-level educational support, may confound the relationship between neighborhood house size and student test scores. Without controlling for these factors, we cannot definitively claim a causal relationship.",
    "gold_rationale": "While household size might be correlated with student test scores, this is not sufficient to claim a causal relationship.",
    "initial_author": "Sreya Vangara",
    "validator": "Daphne Barretto",
    "initial_score": 10.0,
    "final_score": 0.0,
    "validator_2": "Longling Geng",
    "final_score_2": 0.75
  },
  {
    "id": "T3-BucketJ-09",
    "case_id": "J2-09",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "D10 (Social Science)",
    "subdomain": "Sociology",
    "scenario": "International surveys show that Country A ranks higher than Country B on average happiness scores. Commentators argue that citizens of Country A are happier in their daily lives.\nHowever, within both countries, individual happiness varies widely, and individual-level analysis shows that factors such as income security, health, and social relationships are stronger predictors of personal well-being than nationality.\nThe national ranking reflects aggregated survey responses rather than uniform individual experiences.",
    "claim": "National Happiness and Personal Well-Being",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Country of residence",
        "role": "exposure"
      },
      "Y": {
        "name": "Average happiness score",
        "role": "outcome"
      },
      "Z": [
        "Individual-level well-being determinants"
      ]
    },
    "trap": {
      "type": "W3",
      "type_name": "Confounding",
      "subtype": "Socioeconomic",
      "subtype_name": "Socioeconomic"
    },
    "difficulty": "Easy",
    "causal_structure": "National averages collapse heterogeneous individual experiences into a single metric.",
    "key_insight": "Country-level statistics cannot substitute for individual-level causal explanations.",
    "hidden_timestamp": "Is Country of residence measured at an aggregate level while Average happiness score is an individual claim, and when/where does aggregation into Individual-level well-being determinants happen relative to measuring Average happiness score?",
    "conditional_answers": {
      "answer": "Answer if you only have aggregate correlations: You cannot infer individual-level behavior; the relationship may be confounded by group-level factors.\nAnswer if you have individual-level data within groups: Estimate the within-group association/effect and check whether it matches the aggregate pattern.\nAnswer if there is sorting/selection into groups: Treat conclusions as CONDITIONAL unless you model the sorting mechanism or use a design that breaks it."
    },
    "wise_refusal": "I don't have enough information to make a definitive causal claim from the summary statistics alone. The evidence is at an aggregate level, but the conclusion is about individuals. I would need individual-level data (or a defensible model of sorting into groups) before inferring how Country of residence relates to Average happiness score for a person.",
    "gold_rationale": "This case requires associational reasoning and identification of the ecological fallacy.\nKey reasoning step: National happiness scores are averages, not individual guarantees.\nHidden temporal structure: Individual experiences determine survey responses; aggregation follows.\nFailure mode: Treating aggregate indicators as individual truths.\nCorrect conclusion:\nThe claim that individuals in Country A are happier is INVALID.\nWise refusal:\nIndividual well-being must be assessed at the individual level, not inferred from national averages.",
    "initial_author": "Sreya Vangara",
    "validator": "Daphne Barretto",
    "initial_score": 10.0,
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0011",
    "case_id": "0011",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Education",
    "subdomain": "Academic Performance",
    "scenario": "A university awarded 'Merit Scholarships' to all students who achieved a perfect 4.0 GPA in the fall semester. In the spring semester, the average GPA of these scholarship recipients dropped to 3.7. The Dean worries that the free money made the students 'lazy' or 'complacent'.",
    "claim": "The scholarship money caused the students to become lazy (Z), resulting in lower grades.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Perfect 4.0 GPA",
        "role": "exposure"
      },
      "Y": {
        "name": "GPA Drop to 3.7",
        "role": "outcome"
      },
      "Z": [
        "Laziness / Complacency (Attribution)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Performance Rating Regression",
      "subtype_name": "Performance Rating Regression"
    },
    "difficulty": "Easy",
    "causal_structure": "Academic_Ability -> X; Perfect_Conditions(Luck) -> X; Academic_Ability -> Y; Normal_Conditions -> Y; Scholarship(Intervention) -> Y is confounded by selection on Max(X); No causal link Z -> Y.",
    "key_insight": "A perfect score (4.0) is a statistical ceiling; the only direction for variance to move is down, regardless of financial incentives.",
    "hidden_timestamp": "The scholarship is awarded based on t=1 performance (X). The regression is observed at t=2 (Y).",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The drop in GPA is a classic example of Regression to the Mean. Achieving a perfect 4.0 (X) requires both ability and everything going right (no illness, favorable exams). In the next semester, conditions are likely to be normal rather than perfect, leading to a natural regression in scores (Y). Attributing this decline to 'laziness' caused by the scholarship (Z) is a fallacy; the decline would have likely occurred even without the money.",
    "gold_rationale": "The drop in GPA is a classic example of Regression to the Mean. Achieving a perfect 4.0 (X) requires both ability and everything going right (no illness, favorable exams). In the next semester, conditions are likely to be normal rather than perfect, leading to a natural regression in scores (Y). Attributing this decline to 'laziness' caused by the scholarship (Z) is a fallacy; the decline would have likely occurred even without the money.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0013",
    "case_id": "0013",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Arts",
    "subdomain": "Music Industry",
    "scenario": "Historical data shows that 80% of musicians who win the 'Best New Artist' award see a significant drop in sales for their subsequent album. A rising star's manager advises them to decline the nomination to avoid this 'curse'.",
    "claim": "Accepting the 'Best New Artist' award causes the subsequent decline in career success.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Winning Best New Artist",
        "role": "exposure"
      },
      "Y": {
        "name": "Second Album Flop",
        "role": "outcome"
      },
      "Z": [
        "Viral Debut Success (Selection Criteria)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Peak Selection Regression",
      "subtype_name": "Peak Selection Regression"
    },
    "difficulty": "Medium",
    "causal_structure": "Talent -> Z; Viral_Luck -> Z; Z -> Win_Award(X); Talent -> Y; Normal_Luck -> Y; No causal link X -> Y.",
    "key_insight": "Winning 'Best New Artist' implies the debut was a statistical outlier; the second album faces regression to the artist's true baseline.",
    "hidden_timestamp": "The award (X) is given based on the debut performance Z (t=1). The second album (Y) is released at t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The 'Best New Artist Curse' is a statistical artifact of Regression to the Mean. Artists win the award (X) because their debut (Z) was an extreme outlier, combining talent with perfect timing and viral luck. It is statistically probable that their next work (Y) will regress to a more normal level of success. Declining the award (Intervention) will not change the probability of this regression.",
    "gold_rationale": "The 'Best New Artist Curse' is a statistical artifact of Regression to the Mean. Artists win the award (X) because their debut (Z) was an extreme outlier, combining talent with perfect timing and viral luck. It is statistically probable that their next work (Y) will regress to a more normal level of success. Declining the award (Intervention) will not change the probability of this regression.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0020",
    "case_id": "0020",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Public Policy",
    "subdomain": "Urban Planning / Traffic Safety",
    "scenario": "A city government identified the five intersections with the highest number of traffic accidents recorded last year. In response, they installed expensive 'Smart Traffic Monitoring Systems' at these specific locations. The following year, accidents at these intersections dropped by 40%. The mayor announced that the smart systems were highly effective.",
    "claim": "The 'Smart Traffic Monitoring Systems' (Z) caused the 40% reduction in accidents.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Top 5 High-Accident Intersections",
        "role": "exposure"
      },
      "Y": {
        "name": "Reduced Accident Count",
        "role": "outcome"
      },
      "Z": [
        "Smart Monitoring System (Intervention)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Selection on Baseline",
      "subtype_name": "Selection on Baseline"
    },
    "difficulty": "Hard",
    "causal_structure": "Inherent_Risk -> X; Negative_Variance(Bad_Luck) -> X; Inherent_Risk -> Y; Normal_Variance -> Y; Intervention(Z) -> Y is confounded by Selection on Max(X); No causal link Z -> Y confirmed.",
    "key_insight": "Interventions targeted at sites with record-high accident rates often claim credit for the natural decrease in accidents (regression) that follows a spike.",
    "hidden_timestamp": "Selection (X) is based on data from year t=1. Outcome (Y) is observed in year t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The observed safety improvement is likely due to Regression to the Mean. By selecting intersections with the absolute highest accident counts (X), the city targeted sites that likely experienced an abnormal spike in 'bad luck' (negative variance) that year. Statistically, accident rates at these outlier sites would be expected to fall (Y) in the next year even without any intervention. Attributing the full drop to the smart systems (Z) is fallacious without a control group.",
    "gold_rationale": "The observed safety improvement is likely due to Regression to the Mean. By selecting intersections with the absolute highest accident counts (X), the city targeted sites that likely experienced an abnormal spike in 'bad luck' (negative variance) that year. Statistically, accident rates at these outlier sites would be expected to fall (Y) in the next year even without any intervention. Attributing the full drop to the smart systems (Z) is fallacious without a control group.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketD-0021",
    "case_id": "0021",
    "bucket": "T3-BucketD",
    "pearl_level": "L1",
    "domain": "Public Policy",
    "subdomain": "Law Enforcement",
    "scenario": "A quiet neighborhood experienced a record-breaking spike of 20 burglaries in a single month. In response, the Police Chief deployed a special tactical unit to patrol the area 24/7. The following month, burglaries dropped to 5. The Chief announced that the tactical unit successfully eradicated the crime wave.",
    "claim": "The deployment of the tactical unit (Z) caused the significant drop in burglaries (Y).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Record Burglary Spike",
        "role": "exposure"
      },
      "Y": {
        "name": "Drop in Crime",
        "role": "outcome"
      },
      "Z": [
        "Special Tactical Unit (Intervention)"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression To Mean",
      "subtype": "Crime Variance / Selection on Baseline",
      "subtype_name": "Crime Variance / Selection on Baseline"
    },
    "difficulty": "Medium",
    "causal_structure": "Base_Crime_Rate -> X; Temporal_Clustering(Bad_Luck) -> X; X -> Deploy_Unit(Z); Base_Crime_Rate -> Y; Normal_Variance -> Y; No proof Z -> Y > Natural_Regression.",
    "key_insight": "Crime waves often represent temporary clusters (Poisson bursts); interventions deployed at the peak get credit for the natural return to baseline.",
    "hidden_timestamp": "The spike (X) occurs at month t=1. The drop (Y) is observed at month t=2.",
    "conditional_answers": {
      "answer_if_condition_1": "If the subject was selected for extreme values, regression to the mean predicts reversion regardless of intervention.",
      "answer_if_condition_2": "If the values were not extreme, other explanations may be valid."
    },
    "wise_refusal": "The drop in crime is a likely candidate for Regression to the Mean. The tactical unit (Z) was deployed specifically because of a statistical outlier event (X). Crime data often exhibits random clustering; a record spike is typically followed by a return to the average (Y) as the temporary factors causing the spike dissipate. Attributing the entire decline to the police presence ignores this natural statistical normalization.",
    "gold_rationale": "The drop in crime is a likely candidate for Regression to the Mean. The tactical unit (Z) was deployed specifically because of a statistical outlier event (X). Crime data often exhibits random clustering; a record spike is typically followed by a return to the average (Y) as the temporary factors causing the spike dissipate. Attributing the entire decline to the police presence ignores this natural statistical normalization.",
    "initial_author": "Yuqiao Zeng",
    "validator": "Samantha van Rijs",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "case_id": "0200",
    "id": "T3-BucketLarge-J-0200",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Political Science",
    "scenario": "In the city of Riverton, a mayoral election is held in November. A local pollster tracks the incumbent’s approval rating monthly (1,200 respondents each month, ±3 percentage points). In August, after a widely criticized transit strike and a viral video of a tense town-hall exchange, the incumbent’s approval hits a low of 34%. The mayor immediately launches a “Listening Tour” with 18 neighborhood meetings and increased social media outreach. By October, approval rebounds to 41%. The pollster writes a memo highlighting the 7-point increase over two months and notes that the last five years of Riverton polling show month-to-month approval typically fluctuates by about 4–6 points even without major events.",
    "claim": "Because approval rose from 34% to 41% right after the mayor started the Listening Tour, the Listening Tour is associated with improved public approval and is likely what drove the rebound.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Starting the mayor’s Listening Tour",
        "role": "exposure"
      },
      "Y": {
        "name": "Change in approval rating from August",
        "role": "outcome"
      },
      "Z": [
        "Random month-to-month polling variation and measurement error",
        "Temporary negative shock in August (transit strike + viral incident) that naturally fades",
        "Media attention cycle returning to baseline"
      ]
    },
    "trap": {
      "type": "REGRESSION",
      "subtype": "Regression_to_the_Mean_after_an_Extreme_Shock",
      "subtype_name": "Regression To The Mean After An Extreme Shock",
      "type_name": "REGRESSION"
    },
    "difficulty": "Easy",
    "causal_structure": "An unusually low approval measurement in August is partly due to transient shocks and random fluctuation (Z), which tend to move back toward the incumbent’s typical approval level in subsequent months (Y) even without any real effect from the Listening Tour (X). Interpreting the rebound as evidence that X improved Y confuses a natural reversion from an extreme value with a meaningful association attributable to X.",
    "key_insight": "When you start tracking or acting right after an unusually low value, the next measurement often looks better simply because extremes tend to be followed by less-extreme values (regression to the mean).",
    "hidden_timestamp": "Was the August poll taken during the peak of the transit strike/viral controversy, and did those events resolve before the October poll? (If the shock ended before the rebound, the bounce could be expected even without the Listening Tour.)",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "This inference fails due to REGRESSION TO THE MEAN. The Listening Tour began immediately after an unusually low approval reading (34%) following a short-lived negative shock. Extreme values are often followed by more typical values because the temporary shock dissipates and because polls fluctuate from sampling and measurement error. So the 34%→41% rebound can happen even if the Listening Tour had no real association with approval. To evaluate whether the tour is actually linked to higher approval, you’d need a comparison (e.g., similar cities without a tour, or multiple pre/post periods showing rebounds don’t happen without the tour) rather than judging from a bounce after an extreme month.",
    "gold_rationale": "The claim attributes the approval rebound to the Listening Tour, but the design is “picked at the low point.” August was an extreme low driven by a transient event plus sampling noise. Even if the mayor did nothing, approval would be expected to drift upward toward its typical level as the strike and viral incident fade and as polling noise averages out. With typical month-to-month swings of 4–6 points and a ±3% margin of error, a 7-point rise over two months is not strong evidence of an X–Y relationship; it is consistent with regression to the mean from an unusually bad month.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0004"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 9.1,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.1
  },
  {
    "case_id": "0203",
    "id": "T3-BucketLarge-J-0203",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Education Policy",
    "scenario": "A state education agency evaluates a new 9th-grade \"Credit Recovery Lab\" offered after school. The agency reports outcomes only for students who were still enrolled in the same high school at the end of 10th grade. Of the 420 participating students who remained enrolled through 10th grade, 76% were on track to graduate (had earned at least 12 credits). Among the 380 non-participating students who remained enrolled through 10th grade, 62% were on track. However, 28% of the original 9th-grade participants (about 165 students) transferred schools or dropped out before the end of 10th grade, compared with 10% of non-participants (about 85 students).",
    "claim": "The higher on-track rate among the remaining Credit Recovery Lab participants shows the program improves students' progress toward graduation.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Participation in the Credit Recovery Lab",
        "role": "exposure"
      },
      "Y": {
        "name": "Being on track to graduate by end of 10th grade",
        "role": "outcome"
      },
      "Z": [
        "Remaining enrolled through end of 10th grade (survival/attrition indicator)",
        "Baseline academic risk and attendance problems that predict both program enrollment and dropout/transfer"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_attrition_of_lower_performing_students",
      "subtype_name": "Survivorship Attrition Of Lower Performing Students",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Baseline risk factors influence both program take-up and later attrition. Conditioning the analysis on 'still enrolled through 10th grade' (a survivorship/selection variable) removes many struggling participants from the observed outcome data, making participants who remain look better even if the program has no effect.",
    "key_insight": "The comparison is made only among students who 'survived' (stayed enrolled), and dropout/transfer rates differ by program status, so the observed association is biased by survivorship.",
    "hidden_timestamp": "Did the transfers/dropouts happen before students could complete substantial time in the lab (early attrition), or after they had already improved (late attrition)?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "No—the reported difference is undermined by SURVIVORSHIP (a form of selection bias). The analysis conditions on students who are still enrolled at the end of 10th grade, but program participants leave the school system at a much higher rate (28% vs 10%). If struggling participants are disproportionately missing from the outcome measurement, the remaining participants will look artificially successful. To assess the program credibly, outcomes should be tracked for the full original cohorts (e.g., intent-to-treat), including transfers/dropouts, or the evaluation must account for attrition mechanisms.",
    "gold_rationale": "This is survivorship bias: the agency reports outcomes only for students who remained enrolled through 10th grade, but participants have much higher attrition (28% vs 10%). If lower-performing or more disengaged participants are more likely to leave before outcomes are measured, the remaining participant group will be selectively stronger. The observed 76% vs 62% on-track difference among survivors can arise purely from differential attrition and does not establish that participation is associated with better progress in the full original cohort.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0003"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 9.1,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.1
  },
  {
    "case_id": "0206",
    "id": "T3-BucketLarge-J-0206",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Demographics",
    "scenario": "A city demographer analyzes a 2025 community survey of 2,400 residents living in 6 large apartment complexes built in 1975. The survey is administered only to current tenants listed on the lease at the time of data collection. In the results, residents who have lived in the complex for 10+ years report an average self-rated health score of 7.8/10, while residents who moved in within the last year report 6.4/10. The demographer notes that the 10+ year group also has fewer reported hospitalizations (9% vs 16%) and concludes long tenure is beneficial for health.",
    "claim": "Living in these apartment complexes for 10+ years improves residents' health compared with moving in recently.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Long tenure in the apartment complex",
        "role": "exposure"
      },
      "Y": {
        "name": "Current health",
        "role": "outcome"
      },
      "Z": [
        "Survival/remaining-in-sample indicator (still living in the complex and on a current lease)",
        "Differential attrition due to illness/disability (sicker residents move out to assisted living, live with family, or die)",
        "Housing stability/resources affecting ability to stay (income, caregiving support)"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_Healthy_stayer_bias",
      "subtype_name": "Survivorship Healthy Stayer Bias",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Health and resources (Z) affect whether someone remains a long-term tenant and thus appears in the survey. Conditioning on being a current tenant selects 'survivors/stayers' who are healthier on average. The observed association between long tenure (X) and better health (Y) is driven by who is still present to be measured, not by tenure improving health.",
    "key_insight": "The data only include people who are still living there; long-term residents are a selected group of healthier 'survivors/stayers.'",
    "hidden_timestamp": "Were health and hospitalization measured before residents became long-tenure tenants (e.g., at move-in), and do you have records on when and why residents exited the complex (including deaths and moves to care facilities)?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO — this inference is invalid due to SURVIVORSHIP (a selection bias). You only measured people who are still tenants in 2025. If declining health makes residents more likely to move out (to family, assisted living, or another unit) or not survive, then the '10+ years' group is a filtered set of healthier stayers. That selection can create the appearance that long tenure is associated with better health even without any health benefit of tenure. To assess the relationship, you would need data on people who left (and why), mortality/exit records, or a longitudinal cohort following entrants over time.",
    "gold_rationale": "This is survivorship bias: the survey samples only current tenants, so the 10+ year group necessarily excludes former long-term residents who became sick, moved out, entered care facilities, or died. Because poorer health increases the chance of leaving the complex (and thus leaving the sampling frame), the remaining long-tenure residents will look healthier even if tenure has no effect (or even harms health). Therefore the observed difference in health between tenure groups cannot be interpreted as evidence that staying longer improves health.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0003"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0209",
    "id": "T3-BucketLarge-J-0209",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Public Health",
    "scenario": "A county health department evaluates a 12-week smoking-cessation program offered through 14 clinics. Of 520 adults who enrolled, 200 stopped attending before week 12 (many missed follow-up calls or changed phone numbers). Among the 320 participants who completed the week-12 visit, 192 report being smoke-free for the past 7 days (60%). A public dashboard highlights the 60% figure as the program's success rate, but it reports outcomes only for people with a week-12 survey on file (i.e., completers).",
    "claim": "The data shows the program is highly effective: participants in the program are more likely to quit smoking (60% quit rate).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Completing the 12-week program / having a week-12 follow-up survey",
        "role": "exposure"
      },
      "Y": {
        "name": "Reported smoking abstinence at week 12",
        "role": "outcome"
      },
      "Z": [
        "Dropout/loss-to-follow-up status",
        "Motivation and addiction severity influencing both dropout and quitting",
        "Unobserved relapse leading to nonresponse"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_loss_to_follow_up_attrition_bias",
      "subtype_name": "Survivorship Loss To Follow Up Attrition Bias",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Motivation/addiction severity (Z) affects both (i) whether someone remains in the sample with a week-12 outcome recorded (X: survivorship/observability) and (ii) whether they are abstinent at week 12 (Y). Conditioning on survivors/completers creates an overly optimistic association between program participation-as-observed and quitting.",
    "key_insight": "The 60% quit rate is computed only among people who stayed long enough to be measured; dropouts (who are plausibly more likely to have relapsed) are missing, so the observed association is biased upward by survivorship.",
    "hidden_timestamp": "When did participants drop out relative to relapse—did they stop attending after returning to smoking, or were they already smoke-free when they left (e.g., moved away)?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO — this is SURVIVORSHIP (attrition/loss-to-follow-up). The 60% figure is calculated only among the 320 people who \"survived\" to the week-12 visit and answered the survey. Dropout is not random: motivation and dependence severity affect both staying in the program and quitting. By restricting to completers, the dashboard conditions on a selected sample and inflates the apparent association between the program and quitting. To support an effectiveness claim, you would need outcomes for all enrollees (or a defensible missing-data strategy) and ideally a comparison group.",
    "gold_rationale": "This is a survivorship/attrition problem: the reported 60% abstinence is conditional on completing the program and providing a week-12 survey. People who relapse or struggle are more likely to stop attending and become unmeasured, so the completer group is not representative of all enrollees. With 200/520 (38%) missing outcomes, the overall quit rate among all who started could be far lower (e.g., if many dropouts relapsed). Therefore the observational summary does not support the claim that the program is highly effective based on a 60% quit rate.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0004"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0212",
    "id": "T3-BucketLarge-J-0212",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Philosophy",
    "scenario": "A philosophy department surveys 200 alumni from its last 20 graduating cohorts (classes of 2004–2023) and asks whether studying philosophy made them “more ethically responsible in daily life” (Y). Among the 120 alumni who are currently active in the department’s alumni network and attend events at least once a year (Z), 78% report that philosophy made them more ethically responsible. Among the remaining 80 alumni reached through a purchased email list who do not participate in alumni events, only 41% report the same. The department’s newsletter highlights the 78% figure and notes that “graduates who stayed connected” overwhelmingly report ethical improvement.",
    "claim": "Staying connected to the philosophy department’s alumni network is associated with becoming more ethically responsible in daily life.",
    "label": "AMBIGUOUS",
    "is_ambiguous": true,
    "variables": {
      "X": {
        "name": "Being an active member of the department’s alumni network",
        "role": "exposure"
      },
      "Y": {
        "name": "Self-reported increase in ethical responsibility in daily life",
        "role": "outcome"
      },
      "Z": [
        "Survival/retention in the alumni network (continued engagement over years)",
        "Survey response propensity (who replies to department outreach)",
        "Baseline interest in ethics or moral motivation (pre-existing trait influencing both engagement and self-reports)"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_Alumni_network_response_survivorship",
      "subtype_name": "Survivorship Alumni Network Response Survivorship",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Baseline moral motivation and continued engagement/visibility to the department influence both (i) whether an alumnus remains in the alumni network and is reachable/responds (selection/survivorship) and (ii) how they self-assess ethical responsibility. Conditioning on “survived as an engaged alumnus” can inflate the observed association between network participation and ethical self-reports.",
    "key_insight": "The observed difference may reflect who remains visible and responding (survivorship/selection), not a true association between network membership and ethical outcomes in the full alumni population.",
    "hidden_timestamp": "Were alumni classified as “active in the network” before the ethical-responsibility question was measured, and how many years after graduation did each respondent join/leave the network?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "This is vulnerable to SURVIVORSHIP (a selection bias): the department is effectively observing “alumni who remained engaged and reachable,” not all alumni. Those who stay connected (X) are more likely to keep responding to department surveys and may already have higher baseline ethical interest (Z), which also affects the self-reported outcome (Y). Because the sampling/retention process is unclear (who was missing, how many non-responders, and whether disengaged alumni differ systematically), you can’t confidently conclude that staying connected is associated with ethical responsibility in the overall alumni population. To support the association, you’d need comparable measurement across a representative alumni sample (or known response rates and weighting/adjustment for retention/response propensity and baseline traits).",
    "gold_rationale": "At L1, the claim is about association, but even an associational statement can fail if the reported association is computed on a non-representative subset created by survivorship/selection. Here, the 78% figure comes from alumni who “survived” into continued engagement and were easy to reach; those who disengaged (potentially with different outcomes) are underrepresented. However, because the scenario does include a comparison group (non-participants reached via an email list) showing 41%, there may still be a real association in the sampled respondents. Without knowing the true response rates and whether the outreach captured disengaged alumni proportionally, we cannot determine whether the reported association reflects the broader alumni population or is mainly an artifact of survivorship.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0004"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 9.1,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.1
  },
  {
    "case_id": "0215",
    "id": "T3-BucketLarge-J-0215",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Civil Rights",
    "scenario": "A civil-rights nonprofit evaluates whether a new city “Fair Access to Counsel” ordinance improved housing outcomes. The nonprofit only has records for tenants who stayed in their apartments long enough to respond to a 6‑month follow-up survey. In the year before the ordinance, 420 tenants were enrolled and 280 (67%) completed the 6‑month survey; 62 of those 280 (22%) reported an eviction judgment. In the year after the ordinance, 460 tenants were enrolled and 190 (41%) completed the 6‑month survey; 23 of those 190 (12%) reported an eviction judgment. Staff share a summary chart showing eviction judgments fell from 22% to 12% and argue the ordinance improved tenant rights citywide.",
    "claim": "The ordinance reduced eviction judgments for tenants, as shown by the drop from 22% to 12% among surveyed tenants.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Post-ordinance period",
        "role": "exposure"
      },
      "Y": {
        "name": "Eviction judgment rate measured in the 6-month follow-up survey",
        "role": "outcome"
      },
      "Z": [
        "Survey completion / remaining reachable at 6 months (survival/retention in sample)",
        "Early displacement or eviction leading to nonresponse",
        "Case severity / instability affecting both eviction risk and follow-up response"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "Survivorship_Bias_loss_to_follow_up",
      "subtype_name": "Survivorship Bias Loss To Follow Up",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Post-ordinance period (X) may affect both (a) true eviction outcomes and (b) who remains in the observed dataset at 6 months (Z). Conditioning on being observed (survey completer) selects “survivors” who were more stable and easier to contact. Because eviction/displacement increases attrition, the observed eviction rate among completers (Y) can fall even if the true eviction rate in the full enrolled population did not.",
    "key_insight": "The comparison uses only tenants who “survived” long enough (and remained reachable) to complete the follow-up, so it can undercount evictions and displacement—especially when follow-up rates differ (67% vs 41%).",
    "hidden_timestamp": "Did the drop in follow-up completion occur because more tenants were displaced or evicted earlier in the post-ordinance period (before the 6-month survey window), and when exactly were eviction judgments recorded relative to survey contact attempts?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "No—the inference is invalid due to SURVIVORSHIP (a form of selection bias). You are only counting eviction judgments among tenants who remained reachable and completed the 6-month survey. Tenants who were evicted or displaced early are less likely to appear in the follow-up data, so conditioning on “being observed at 6 months” filters out many of the worst outcomes. Because the follow-up rate changes sharply (67% pre vs 41% post), the post-ordinance group is not comparable and can show a lower eviction rate even if the true citywide eviction-judgment rate did not improve. To assess the ordinance, you’d need outcome data for the full enrolled cohort (including nonresponders), e.g., court records linked for everyone or robust attrition adjustment with justified assumptions.",
    "gold_rationale": "This is survivorship bias: the reported eviction judgment rates are computed only among follow-up survey completers, not among all enrolled tenants. Evicted or rapidly displaced tenants are less likely to complete a 6-month survey, so restricting to completers systematically removes high-risk cases from the outcome measurement. The problem is amplified because the post-ordinance follow-up rate is much lower (41% vs 67%), meaning the post-period sample may be even more selected toward stable tenants. Therefore the observed drop from 22% to 12% among respondents does not validly support the claim that the ordinance reduced eviction judgments for tenants overall.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0001"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0218",
    "id": "T3-BucketLarge-J-0218",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Psychology",
    "scenario": "A university counseling center evaluates a 10-week mindfulness group for stress. In Fall 2025, 180 students enrolled; 120 (67%) attended at least 8 of 10 sessions and completed the post-program survey, while 60 (33%) stopped attending by week 3 and did not complete follow-up. Among the 120 completers, average Perceived Stress Scale (PSS-10) scores dropped from 26.1 at intake to 18.4 at week 10 (a 7.7-point reduction). In informal exit emails from 15 of the 60 dropouts, 9 mention being “too overwhelmed/busy,” 3 say they “didn’t like the group format,” and 3 give no reason. The center’s report highlights only the pre–post change among completers.",
    "claim": "The mindfulness group reduces student stress, as shown by the large pre–post stress reduction among students who completed the program.",
    "label": "AMBIGUOUS",
    "is_ambiguous": true,
    "variables": {
      "X": {
        "name": "Completing the mindfulness program",
        "role": "exposure"
      },
      "Y": {
        "name": "Post-program stress level / change in PSS-10 score",
        "role": "outcome"
      },
      "Z": [
        "Dropout/attrition mechanism (e.g., overwhelmed students more likely to quit)",
        "Baseline stress severity and time constraints",
        "Concurrent stress changes during the semester (midterms, deadlines)"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_Attrition_Bias_only_completers_observed",
      "subtype_name": "Survivorship Attrition Bias Only Completers Observed",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Program participation and completion status is a selection process: baseline severity/time pressure (Z) affects both likelihood of completing (X) and stress outcomes (Y). Conditioning on completers (a surviving subset) can make the program look more effective than it is (or hide harms) because non-completers' outcomes are missing.",
    "key_insight": "Survivorship (attrition) means the observed improvement is measured only among those who stayed; dropouts may have had different stress trajectories, so the completers’ pre–post change may not represent the full enrolled group.",
    "hidden_timestamp": "Did students drop out before any meaningful exposure to the program, or after experiencing no improvement/worsening? Also, did dropouts coincide with midterms or other predictable stress spikes that affect both attendance and stress outcomes?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "This conclusion is not secure because of SURVIVORSHIP (attrition) bias, a form of selection bias. The report conditions on the ‘survivors’—the 120 students who completed the program and the post survey—while the 60 who dropped out are missing outcome data. If dropout is related to stress (e.g., overwhelmed students quit or non-responders stop attending), then the large pre–post drop among completers may overstate (or misstate) what happens for everyone who enrolled. To support the claim, you’d need outcomes (or credible imputation/weighting) for non-completers, or evidence that missingness is unrelated to stress changes.",
    "gold_rationale": "This is ambiguous because the evidence is based on a non-random subset: students who completed the program and filled out the post survey. That creates survivorship/attrition bias if the reasons for dropping out are related to stress outcomes (e.g., the most stressed students quit because they are overwhelmed, or those not benefiting stop attending). The observed association (completion accompanied by lower stress) could reflect the program’s benefit, but it could also reflect selection into the measured sample. Without stress outcomes for the 60 non-completers (or an analysis that accounts for missingness), the overall association between enrolling in the program and stress reduction cannot be determined.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0005"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0221",
    "id": "T3-BucketLarge-J-0221",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Labor Economics",
    "scenario": "A staffing platform analyzes 12-month outcomes for 4,800 warehouse workers hired in 2024 across 30 sites. Workers can choose either the “flex schedule” (X) with rotating shifts or a “fixed schedule.” The platform reports that among workers who are still employed at month 12, average hourly productivity is 118 units/hour for flex workers versus 105 units/hour for fixed-schedule workers. However, retention differs: only 52% of flex workers remain employed at month 12, compared with 83% of fixed-schedule workers. Exit interviews show many flex workers leave within the first 3 months due to childcare and transportation constraints.",
    "claim": "Flex scheduling is associated with higher worker productivity than fixed scheduling, so offering flex schedules leads to a more productive workforce.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Schedule type",
        "role": "exposure"
      },
      "Y": {
        "name": "Average hourly productivity at month 12",
        "role": "outcome"
      },
      "Z": [
        "Still employed at month 12 (survival/retention indicator used to define the analyzed sample)",
        "Early attrition drivers (e.g., childcare constraints, transportation reliability, health) affecting both retention and productivity"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_conditioning_on_remaining_employed_at_12_months",
      "subtype_name": "Survivorship Conditioning On Remaining Employed At 12 Months",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Schedule type (X) affects probability of staying employed through month 12 (Z). Unobserved worker constraints/ability affect both staying employed (Z) and productivity (Y). By analyzing only those who remain employed (conditioning on Z), the comparison of Y between schedule groups is biased (survivorship/selection).",
    "key_insight": "Comparing productivity only among 12-month survivors selects a non-representative subset; higher productivity among remaining flex workers can be explained by who stayed, not by the schedule itself.",
    "hidden_timestamp": "Were productivity measurements taken continuously from month 1 onward for everyone, or only recorded for workers who remained employed long enough to be evaluated at month 12 (and did evaluation timing differ by schedule type)?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "This inference fails due to SURVIVORSHIP bias (a form of selection bias). The platform conditions on being employed at month 12 (Z) and then compares productivity (Y) between flex and fixed schedules (X). Because flex workers drop out much more (52% retained vs 83%), the remaining flex workers are not comparable to the remaining fixed workers—they are the ones who could tolerate rotating shifts and were more likely to stay. The higher productivity among survivors can therefore reflect selective retention rather than any real productivity advantage of flex scheduling. To evaluate the association fairly, you’d need outcomes defined for the full hired cohort (including leavers) or methods that model retention/attrition (e.g., intent-to-treat style comparisons, inverse-probability weighting, or reporting productivity trajectories before exit).",
    "gold_rationale": "The reported association is computed only among workers who are still employed at month 12 (Z). Because flex workers have much lower retention (52% vs 83%), the “flex survivors” are a selected group that likely excludes many workers with constraints or lower baseline productivity who disproportionately left early. This survivorship/selection bias can inflate observed productivity among remaining flex workers even if flex scheduling does not increase productivity (and could even reduce it). Without including those who left or properly accounting for differential retention, the observed difference in productivity among survivors does not validly describe the association for the original workforce.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0002"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 9.1,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.1
  },
  {
    "case_id": "0224",
    "id": "T3-BucketLarge-J-0224",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Political Science",
    "scenario": "A political scientist studies 312 national leaders who took power between 1975 and 2015. Using a public biographical dataset that only includes leaders who remained in office at least 24 months (leaders removed earlier are coded as “not in scope”), the researcher finds that leaders who were former military officers (X) have an average tenure of 9.1 years, while leaders without military backgrounds average 5.4 years. In the same dataset, 68% of former officers are still in office at year 5, compared with 49% of non-officers. The researcher summarizes the result in a blog post about \"why generals make more durable rulers.\"",
    "claim": "In this dataset, having a military background is associated with longer time in office because military leaders are more politically durable.",
    "label": "AMBIGUOUS",
    "is_ambiguous": true,
    "variables": {
      "X": {
        "name": "Leader has a prior military officer background",
        "role": "exposure"
      },
      "Y": {
        "name": "Observed tenure length / survival in office",
        "role": "outcome"
      },
      "Z": [
        "Inclusion rule: leader must remain in office ≥24 months to appear in the dataset (survival/selection mechanism)",
        "Early removal events in first 24 months (e.g., coup attempt, impeachment, assassination, mass protest)"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_Left_truncation_only_leaders_who_survive_24_months_are_observed",
      "subtype_name": "Survivorship Left Truncation Only Leaders Who Survive 24 Months Are Observed",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "The analysis conditions on surviving the first 24 months (Z), which is a selection mechanism affected by both background (X) and many determinants of tenure (unrest, institutions, external shocks). By excluding leaders who exit early, the observed association between military background and longer tenure can be distorted: it may be inflated, attenuated, or even reversed relative to the full population of leaders.",
    "key_insight": "If you only measure tenure among leaders who already survived the dangerous early period, you risk survivorship bias; the observed sample is not representative of all leaders who took power.",
    "hidden_timestamp": "Were military-background leaders more or less likely than non-military leaders to exit within the first 24 months (the period that determines whether they enter the dataset at all), and did that early-exit pattern change over time (e.g., pre- vs post-1991)?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "This inference is vulnerable to SURVIVORSHIP bias (a form of SELECTION). The dataset only includes leaders who stayed in office at least 24 months, which conditions on “survival to 24 months” (Z). Because early survival can depend on leader background (X) and on many factors that also affect tenure (Z: coups, impeachment risk, unrest), restricting to survivors can create or exaggerate an association between military background and longer tenure. To justify the claim, you would need data on *all* leaders who took power (including those removed within 24 months) or a design that corrects for left truncation/selection into the sample.",
    "gold_rationale": "This is an L1 (association) claim that tries to explain an observed pattern using a causal story (“because military leaders are more durable”), but the key fact is that the dataset excludes leaders who fail early. That survivorship filter can create a misleading association: for example, if military leaders are more likely to be overthrown quickly in the first year in some regimes, they would be systematically missing, leaving only the unusually stable military leaders in the data. Conversely, if military leaders are less likely to be removed early, the selection rule mechanically boosts their observed average tenure. Without information on the excluded early-exit leaders (and whether exclusion differs by X), the direction and meaning of the association are not identifiable from the described data, so the claim is ambiguous.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0005"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0227",
    "id": "T3-BucketLarge-J-0227",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Education Policy",
    "scenario": "A school district reports results from a new \"accelerated math pathway\" introduced in 9th grade. The district highlights that among students who stayed in the pathway through 11th grade (n=320), 78% scored \"proficient\" on the 11th-grade state math exam, compared with 52% proficiency among all other 11th graders (n=1,900). However, internal records show that 210 students initially enrolled in the accelerated pathway in 9th grade (about 40% of the original 530) later left it after failing a quarterly benchmark or being counseled into the standard track; those leavers are counted in the \"all other\" group by 11th grade.",
    "claim": "Being in the accelerated math pathway is associated with higher 11th-grade math proficiency because students in the pathway have much higher proficiency rates than students not in the pathway.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Remaining in the accelerated math pathway through 11th grade",
        "role": "exposure"
      },
      "Y": {
        "name": "11th-grade math proficiency on the state exam",
        "role": "outcome"
      },
      "Z": [
        "Program attrition/track exit triggered by low benchmark performance",
        "Baseline math ability/motivation that affects both staying and later proficiency"
      ]
    },
    "trap": {
      "type": "SURVIVORSHIP",
      "subtype": "Attrition_Dropout_from_the_program_creates_a_non_representative_stayer_group",
      "subtype_name": "Attrition Dropout From The Program Creates A Non Representative Stayer Group",
      "type_name": "SURVIVORSHIP"
    },
    "difficulty": "Easy",
    "causal_structure": "Baseline ability/motivation and early benchmark scores (Z) influence both whether a student remains in the accelerated pathway (X) and 11th-grade proficiency (Y). Conditioning the reported comparison on 'staying through 11th grade' selects a non-representative subset (survivors), inflating the observed association between X and Y.",
    "key_insight": "The reported \"pathway\" group is only the students who survived/continued; those who struggled disproportionately exited and are reclassified into the comparison group, biasing the association.",
    "hidden_timestamp": "At what points (and under what criteria) were students removed or counseled out of the accelerated pathway relative to the benchmarks used to predict later proficiency?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "No—the observed difference is a classic SURVIVORSHIP (attrition) problem. The district is comparing 11th-grade proficiency among students who *survived* in the accelerated pathway to a mixed \"non-pathway\" group that includes many students who left the pathway after struggling. Since early low benchmark scores (Z) push students out and also predict low 11th-grade proficiency (Y), conditioning on staying (X) creates a selected, higher-performing subset. To assess the association fairly, you’d need to track the original 9th-grade entrants (intent-to-treat style) or compare groups with similar baseline achievement and account for attrition explicitly.",
    "gold_rationale": "The comparison is not between comparable groups: it is between (i) students who remained in an accelerated track for three years and (ii) everyone else, which includes many students who started accelerated but left after poor performance. Because staying is partly determined by early achievement (a predictor of later proficiency), the stayer group is positively selected. This survivorship/attrition mechanism can fully explain the higher proficiency rate without implying that the pathway itself is associated with higher proficiency in the underlying student population.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0004"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0230",
    "id": "T3-BucketLarge-J-0230",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Demographics",
    "scenario": "A county public health department monitors teen birth rates (births per 1,000 females ages 15–19) for 40 counties. In 2024, Pine County recorded an unusually high rate of 31.2, compared with its 2015–2023 average of 22.0 (year-to-year range 18.7–26.1). In response, the county launched a small media campaign about contraception in January 2025 costing $18,000. In 2025, Pine County’s teen birth rate fell to 23.4. Officials highlight that the county with the biggest spike in 2024 also showed the biggest drop in 2025.",
    "claim": "Because Pine County’s teen birth rate dropped from 31.2 to 23.4 after the media campaign, the campaign is associated with reducing teen births.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Having an extreme",
        "role": "exposure"
      },
      "Y": {
        "name": "Observed drop in teen birth rate from 2024 to 2025",
        "role": "outcome"
      },
      "Z": [
        "Random year-to-year fluctuation (small-population noise)",
        "One-off shocks in 2024 (e.g., local cluster of pregnancies)",
        "Long-run baseline teen birth rate level in the county"
      ]
    },
    "trap": {
      "type": "REGRESSION",
      "subtype": "Regression_to_the_mean_after_an_extreme_year",
      "subtype_name": "Regression To The Mean After An Extreme Year",
      "type_name": "REGRESSION"
    },
    "difficulty": "Easy",
    "causal_structure": "Z -> (extreme 2024 observed rate) and Z -> (2025 observed rate). Selecting Pine County because it had an extreme 2024 value makes a subsequent move toward its baseline likely even without any real effect from the campaign.",
    "key_insight": "If you pick a county because it had an unusually high rate, it will often look better the next year purely due to regression to the mean, not because the campaign worked.",
    "hidden_timestamp": "Was the decision to run the 2025 campaign made before Pine County’s final 2024 rate was known, or was the campaign triggered specifically by the unusually high 2024 value?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "This inference is invalid due to REGRESSION TO THE MEAN. Pine County’s 2024 teen birth rate (31.2) was an extreme, unusually high value compared with its 2015–2023 history. When you focus on an extreme year and then look the next year, the rate often falls back toward the county’s typical level (Z: random fluctuation/one-off shocks) even if the campaign had no effect. To support an association with the campaign, you’d need a comparison group (similar counties without the campaign), a longer time series showing a sustained downward shift, or a design that separates the campaign from normal year-to-year noise.",
    "gold_rationale": "The evidence is a before-after comparison following an extreme spike. Pine County was selected for attention precisely because 2024 was unusually high relative to its historical range. When an outcome is noisy, extreme observations tend to be followed by more typical values even if nothing changes. Therefore the observed decline from 31.2 to 23.4 cannot be attributed (even as an association suggestive of improvement) to the campaign; it is consistent with regression to the mean and natural variability around Pine County’s baseline (~22). A valid association claim would require comparing to similar counties without the campaign or using multiple pre/post years to show a sustained shift beyond expected variability.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0003"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 9.1,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.1
  },
  {
    "case_id": "0233",
    "id": "T3-BucketLarge-J-0233",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Public Health",
    "scenario": "A county health department evaluates a free 6-month smoking-cessation program run at 12 clinics. In 2025, 1,000 smokers enrolled. At the 6-month follow-up visit, only 620 participants returned for carbon-monoxide (CO) breath testing. Among those 620 “program completers,” 310 (50%) had CO levels consistent with not smoking. The department’s summary report highlights the 50% quit rate and notes that many non-returners were “likely too busy” to come back. No biochemical outcome data were collected for the 380 people who did not return.",
    "claim": "The program is associated with a 50% quit rate among enrolled smokers, showing it is highly effective.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Program completion / returning for the 6-month follow-up",
        "role": "exposure"
      },
      "Y": {
        "name": "Biochemically verified quitting at 6 months",
        "role": "outcome"
      },
      "Z": [
        "Loss-to-follow-up (attrition) related to relapse or low motivation",
        "Baseline nicotine dependence severity",
        "Socioeconomic constraints affecting ability to attend follow-up"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_Loss_to_follow_up",
      "subtype_name": "Survivorship Loss To Follow Up",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Motivation/dependence and life constraints (Z) affect both who returns for follow-up (X, selection into the observed sample) and true quitting status (Y). Conditioning on 'returned for CO test' creates survivorship bias: the observed quit rate among returners is not the quit rate among all enrollees.",
    "key_insight": "The 50% figure is computed only among those who “survived” to follow-up; if relapse makes people less likely to return, the observed quit rate is inflated.",
    "hidden_timestamp": "Did most dropouts occur early (e.g., within the first month) or late (near the 6-month visit), and did dropout timing coincide with reported relapse episodes?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO — the inference is invalid due to SURVIVORSHIP (loss-to-follow-up) bias. The 50% quit rate is calculated only among the 620 people who returned for CO testing. Returning is not random: relapse, low motivation, higher dependence, or unstable housing/work schedules can make someone less likely to come back, and those same factors affect quitting. By analyzing only “completers,” the report conditions on a selected subset and can overstate the association between participation and quitting. To support the claim, you’d need outcomes (or defensible assumptions/imputation) for the 380 missing participants and an intention-to-treat style estimate for all 1,000 enrollees.",
    "gold_rationale": "This is survivorship bias (a selection problem due to loss-to-follow-up). The reported 50% quit rate is P(quit | returned), not the association for the full enrolled cohort P(quit | enrolled). If people who relapse (or never quit) are less likely to attend the 6-month visit, then restricting to the 620 returners systematically excludes likely smokers, inflating the apparent quit rate. With no outcome measurement for the 380 non-returners, the report cannot validly claim a 50% quit rate for enrollees or conclude the program is “highly effective” from this observed subset alone.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0001"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0236",
    "id": "T3-BucketLarge-J-0236",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Philosophy",
    "scenario": "A philosophy department surveys alumni from its PhD program (graduating cohorts 2005–2015) to evaluate whether its new “resilience and rejection” seminar is linked to academic success. The department emails 420 alumni addresses on file and receives 168 responses (40%). Among respondents, 62% report having attended at least 6 sessions of the seminar (the seminar was optional during those years), and 48% of those attendees report holding a tenure-track job 8–15 years after graduation, compared with 22% among non-attendees. The department notes that many non-respondents have outdated emails, and that alumni who left academia often stop using university forwarding addresses. A committee member concludes that seminar attendance is a strong predictor of flourishing in academic philosophy.",
    "claim": "Because tenure-track employment is much more common among survey respondents who attended the seminar, attending the seminar is associated with greater long-run academic flourishing among the program’s PhD graduates.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Seminar attendance",
        "role": "exposure"
      },
      "Y": {
        "name": "Long-run academic flourishing",
        "role": "outcome"
      },
      "Z": [
        "Being reachable and choosing to respond to the alumni survey (selection into observed sample)",
        "Remaining in academia / maintaining university email forwarding (survival/visibility in the sampling frame)"
      ]
    },
    "trap": {
      "type": "SURVIVORSHIP",
      "subtype": "Nonresponse_Reachability_Bias_only_still_connected_alumni_are_observed",
      "subtype_name": "Nonresponse Reachability Bias Only Still Connected Alumni Are Observed",
      "type_name": "SURVIVORSHIP"
    },
    "difficulty": "Easy",
    "causal_structure": "Y (staying in academia / tenure-track status) -> Z (reachability and likelihood of responding). Conditioning on Z by analyzing only respondents induces survivorship bias in the observed association between X and Y; the survey overrepresents ‘survivors’ who stayed in academia and remained contactable.",
    "key_insight": "The observed relationship is computed only among alumni who are still visible to the department and willing to respond; those who left academia are undercounted, so the sample is biased toward “survivors.”",
    "hidden_timestamp": "Were alumni surveyed at a single point long after graduation, or were outcomes tracked continuously from graduation (including those who left academia early)? When did emails become invalid relative to leaving academia?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO—this inference is undermined by SURVIVORSHIP (nonresponse/reachability) bias. The analysis conditions on being reachable and responding to the survey (Z), but alumni who left academia are less likely to keep university forwarding addresses or reply. That means the observed sample disproportionately includes ‘survivors’ who stayed in academic philosophy, inflating the apparent link between seminar attendance (X) and tenure-track employment (Y). To assess the association for all graduates, you’d need outcomes for non-respondents (e.g., via LinkedIn/ORCID matching, administrative records, or a follow-up sampling strategy) and then compare X–Y without restricting to the survivor/visible subset.",
    "gold_rationale": "This is a survivorship (nonresponse) bias problem: the department’s dataset largely contains alumni who remained connected to academic channels (reachable emails, willingness to respond). That selection is plausibly caused by the outcome (remaining in academia/tenure-track) and related career trajectories, so the estimated association between seminar attendance and tenure-track employment among respondents is not the association among all graduates. Without information on non-respondents (or a sampling method that captures leavers equally), the claim that seminar attendance is associated with flourishing in the full alumni population is not supported.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0005"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0239",
    "id": "T3-BucketLarge-J-0239",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Civil Rights",
    "scenario": "A state civil-rights agency flags employers for a “wage-equity audit” when an annual screening model estimates an adjusted gender pay gap above 15%. In 2024, 60 employers were flagged and required to submit a remediation plan. The agency’s public dashboard shows that among these flagged employers, the average estimated gap fell from 19.8% at the time of flagging to 12.1% one year later. A press release highlights that 44 of the 60 employers (73%) moved below the 15% threshold by 2025, without reporting what happened to employers that were not flagged.",
    "claim": "Because the flagged employers’ pay gaps fell sharply the next year, the wage-equity audits are effective at reducing gender pay disparities.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Being flagged for a wage-equity audit",
        "role": "exposure"
      },
      "Y": {
        "name": "Change in the estimated adjusted gender pay gap from the flagging year to the next year",
        "role": "outcome"
      },
      "Z": [
        "Measurement noise in the gap estimate (sampling error/model error/year-to-year volatility)",
        "Threshold-based selection on an extreme value (gap > 15%)",
        "Natural year-to-year variation in workforce composition and bonuses"
      ]
    },
    "trap": {
      "type": "REGRESSION",
      "subtype": "Regression_to_the_Mean_from_Threshold_Based_Flagging",
      "subtype_name": "Regression To The Mean From Threshold Based Flagging",
      "type_name": "REGRESSION"
    },
    "difficulty": "Easy",
    "causal_structure": "Estimated gap in year t = true underlying gap + noise. Employers are selected for audit because their estimated gap is unusually high in year t (extreme due to noise and volatility). In year t+1, the noise component is likely smaller in magnitude, so the estimated gap tends to move closer to the average even if the true underlying gap does not change (regression to the mean).",
    "key_insight": "Selecting employers because they had an unusually high measured gap guarantees that, on average, their next measurement will look better even without any real improvement.",
    "hidden_timestamp": "Were the 2024 gaps computed using the same model, job taxonomy, and payroll period as the 2025 gaps, or did the measurement procedure change between years (e.g., bonus window, job-code mapping, or model recalibration)?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "The inference fails due to REGRESSION TO THE MEAN. These employers were chosen precisely because their 2024 estimated pay gaps were unusually high (a threshold rule), and unusually high measurements tend to move closer to typical values on the next measurement even if nothing causal happened. So the drop from 19.8% to 12.1% could occur from noise and year-to-year volatility in the gap estimate (Z), not from the audit itself. To support effectiveness, you’d need a credible counterfactual—e.g., compare audited employers to similar non-audited employers with comparable 2024 gaps (or randomize audits) and examine differences in changes.",
    "gold_rationale": "This is a classic regression-to-the-mean pattern created by threshold-based selection. The agency only tracks employers whose estimated gaps were extreme in 2024 (above 15%). Extreme measurements are partly driven by random fluctuation (e.g., bonus timing, small subgroups, model error). When re-measured in 2025, those random components are unlikely to be as extreme in the same direction, so the average estimated gap will fall mechanically. Without a comparison group (e.g., similar near-threshold employers not audited, or randomized audit assignment), the observed decline cannot be attributed to the audits rather than natural reversion.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0004"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0242",
    "id": "T3-BucketLarge-J-0242",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Psychology",
    "scenario": "A psychologist analyzes outcomes from a popular 8-week mindfulness app used to reduce stress. The app’s public dashboard summarizes only users who completed all 56 daily sessions. Among 2,400 completers, the average Perceived Stress Scale (PSS) score drops from 24 to 16 (a 33% reduction). The dashboard also shows that 78% of completers report “better sleep” by week 8. However, the internal logs (not shown on the dashboard) indicate that 10,000 people started the program and 7,600 stopped using the app before week 8, many after reporting “no improvement” in week-2 check-ins.",
    "claim": "Mindfulness app participation reliably reduces stress because users who finish the program show large decreases in PSS scores.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Completing the 8-week mindfulness app program",
        "role": "exposure"
      },
      "Y": {
        "name": "Observed reduction in stress",
        "role": "outcome"
      },
      "Z": [
        "Dropout/attrition (only completers are analyzed)",
        "Early response to the app (initial improvement or lack thereof)",
        "Baseline stress severity and motivation (predicts both completion and outcomes)"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_Completer_only_analysis_Attrition_bias",
      "subtype_name": "Survivorship Completer Only Analysis Attrition Bias",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Early improvement, motivation, and baseline severity (Z) affect both the probability of completing the program (X) and week-8 stress outcomes (Y). Conditioning on completion selects a non-representative subset (survivors), so the observed stress reduction among completers is not representative of all starters.",
    "key_insight": "Looking only at finishers (survivors) overstates benefits because non-improvers disproportionately drop out and disappear from the outcome summary.",
    "hidden_timestamp": "At what point did most users drop out relative to when stress improvements typically occur (e.g., after week 1 vs week 6), and were week-2 check-in scores recorded before dropout for those users?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO—this inference is invalid due to SURVIVORSHIP (a form of selection/attrition bias). The dashboard conditions on ‘completed the program,’ which filters out the 7,600 dropouts. If early non-responders are more likely to quit, then the completer group is enriched for people who were already improving or highly motivated (Z), making the observed PSS drop look larger than it would be for everyone who started. To assess association fairly at L1, you’d need outcomes for all starters (e.g., intention-to-treat summaries, follow-up surveys of dropouts, or methods that account for missing-not-at-random attrition).",
    "gold_rationale": "This is a survivorship/attrition selection problem: the reported PSS reduction is computed only among users who completed all sessions. Completion is not random; it is influenced by early perceived benefit, motivation, and baseline severity. If many users who do not improve stop using the app before week 8, the remaining completers will mechanically look better even if the app’s average effect for all starters is small or zero. Therefore, the observed improvement among finishers cannot be used to conclude that app participation reliably reduces stress in general.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0005"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0245",
    "id": "T3-BucketLarge-J-0245",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Labor Economics",
    "scenario": "A logistics company analyzes whether its new “FastTrack” warehouse hiring pipeline (introduced in 2024) improves worker retention. HR reports that among employees who are still on payroll at the 12-month mark, FastTrack hires average $22.40/hour and have 3.2 unplanned absence days per year, while non-FastTrack hires average $20.10/hour with 5.1 absence days. The report excludes anyone who quit or was terminated before 12 months. In 2024, 620 workers were hired via FastTrack and 580 via the old pipeline. By month 12, 248 FastTrack hires remained (40%) versus 377 old-pipeline hires (65%).",
    "claim": "FastTrack hiring produces more reliable, higher-performing workers, as shown by higher wages and fewer absences among employees after 12 months.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Hiring pipeline",
        "role": "exposure"
      },
      "Y": {
        "name": "Observed reliability/performance among 12-month survivors",
        "role": "outcome"
      },
      "Z": [
        "Survival/retention to 12 months (still employed at month 12)",
        "Early attrition/termination rates by pipeline",
        "Baseline worker characteristics affecting both retention and performance (e.g., prior warehouse experience, commute distance)"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_conditioning_on_staying_employed_at_12_months",
      "subtype_name": "Survivorship Conditioning On Staying Employed At 12 Months",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Hiring pipeline (X) may affect early attrition and who remains employed (Z). Conditioning the analysis on Z=still employed at 12 months selects a non-representative subset whose observed performance (Y) is not comparable across pipelines because the pipelines have different survival rates.",
    "key_insight": "Comparing outcomes only among those who “survived” to 12 months creates survivorship bias; different retention rates mean you are comparing different selected populations, not the pipelines’ effect.",
    "hidden_timestamp": "Were wages and absences measured over the same calendar months for both cohorts, and did most FastTrack attrition occur early (e.g., first 30–90 days) or late (near month 12)?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "This inference fails due to SURVIVORSHIP bias (a form of selection bias). The analysis conditions on being still employed at 12 months (Z), but retention differs sharply by pipeline (40% FastTrack vs 65% old). That means you’re comparing a highly selected subset of FastTrack hires to a less-selected subset of old-pipeline hires. Higher wages and fewer absences among the survivors could simply reflect that only the strongest FastTrack hires remained, not that FastTrack creates better workers. To evaluate the pipeline fairly, you’d need outcomes for the full hire cohorts (including those who quit/were fired) or methods that account for differential attrition (e.g., intention-to-treat retention outcomes, tracking absences during the first months, or modeling censoring).",
    "gold_rationale": "The reported differences in wages and absences are computed only among workers who remained employed for 12 months, but FastTrack has much lower 12-month retention (40% vs 65%). This conditioning on survival induces survivorship bias: the FastTrack “survivors” are a selected subset (likely the most persistent or best matched), while the old-pipeline group includes a broader mix. Without including the early leavers (who may have had low performance or low wages) and without a consistent follow-up for everyone, the association between pipeline and observed performance among survivors cannot be interpreted as evidence that FastTrack produces better workers overall.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0003"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0248",
    "id": "T3-BucketLarge-J-0248",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Political Science",
    "scenario": "A political scientist studies whether participation in a nonviolent protest campaign is linked to later political engagement. She surveys 2,400 adults in 2025 who are still members of local civic organizations and asks whether they participated in the 2020 “Clean Elections” street demonstrations (X) and whether they voted in the 2024 national election (Y). In this surveyed group, 78% of those who report protesting in 2020 voted in 2024, compared with 52% of those who did not protest. However, the sampling frame explicitly excludes people who left civic organizations between 2020 and 2025; an administrative roster shows 37% of 2020 members dropped out by 2025, and dropout was higher among people who faced job loss or police arrest related to the protests.",
    "claim": "The survey shows that participating in the 2020 protests is associated with higher turnout in 2024, so protest participation increases later voting.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Participation in the 2020 'Clean Elections' protests",
        "role": "exposure"
      },
      "Y": {
        "name": "Voting in the 2024 national election",
        "role": "outcome"
      },
      "Z": [
        "Remaining an active member of a civic organization in 2025 (survival/retention into the sample)",
        "Repression/costs from protesting (e.g., arrest, job loss) affecting dropout",
        "Baseline political interest/commitment affecting both protesting and staying involved"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "Survivorship_Bias_conditioning_on_remaining_in_civic_organizations",
      "subtype_name": "Survivorship Bias Conditioning On Remaining In Civic Organizations",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Protest participation (X) and baseline political commitment both influence continued civic-organization membership (Z_survive). Costs/repression related to protesting also influence Z_survive. The analysis conditions on Z_survive by sampling only current members, so the observed association between X and voting (Y) is distorted by survivorship (selection) and does not represent the association in the original 2020 population.",
    "key_insight": "The sample includes only people who 'survived' as active civic members; conditioning on survival can create or exaggerate an X–Y association.",
    "hidden_timestamp": "Did voting behavior and disengagement occur before individuals dropped out of the civic organizations, or did dropout happen first (changing who was available to be surveyed in 2025)?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO — this is SURVIVORSHIP (a selection-bias) problem. The survey conditions on “still an active civic-organization member in 2025,” which is a survival/retention variable (Z) influenced by protest participation (X) and by factors tied to later voting (Y), like baseline political commitment and protest-related costs (arrest/job loss) that drive dropout. Because people who left the organizations are missing—and dropout is not random—the observed X–Y relationship among survivors can be inflated or even reversed relative to the full population. To assess the association properly, you’d need data on the 2020 cohort including those who dropped out, or a design that corrects for this selection.",
    "gold_rationale": "This inference fails due to survivorship bias: the dataset is restricted to people who remained in civic organizations until 2025 (Z). Remaining active is affected by protest-related costs (which are linked to X) and by political commitment (linked to both X and Y). By analyzing only survivors, the study overrepresents highly committed, resilient protesters and underrepresents protesters who disengaged after negative experiences. Therefore the observed 78% vs 52% voting gap among survivors cannot be interpreted as evidence that protesting itself increases later voting (and may not even reflect the true association in the full 2020 membership, let alone a causal effect).",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0005"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0251",
    "id": "T3-BucketLarge-J-0251",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Education Policy",
    "scenario": "A state education agency evaluates a new voluntary after-school tutoring program for 8th-grade math in 22 middle schools. In fall, 1,200 students enroll. By spring testing, only 720 students are still attending at least 2 sessions/week; 480 stopped coming. The agency reports that among the 720 “active participants,” 68% reached proficiency on the state math exam, compared with 52% proficiency among 3,500 non-participants in the same schools. The report excludes the 480 students who enrolled but later dropped out because they did not complete the required minimum attendance to be counted.",
    "claim": "The tutoring program improved math proficiency, as shown by the higher proficiency rate among active participants than among non-participants.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Being an 'active participant' in tutoring",
        "role": "exposure"
      },
      "Y": {
        "name": "Math proficiency on the spring state exam",
        "role": "outcome"
      },
      "Z": [
        "Attrition/dropout from tutoring",
        "Baseline math level and motivation (predicts both staying in tutoring and proficiency)",
        "Attendance barriers (work/transportation/caregiver duties) affecting continued participation and outcomes"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_Dropout_Attrition_Bias",
      "subtype_name": "Survivorship Dropout Attrition Bias",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Baseline motivation/ability and outside constraints (Z) influence both continued attendance (X, defined by 'surviving' to meet the attendance threshold) and exam proficiency (Y). Conditioning on 'active participants' selects a non-random subset of enrollees who were more likely to succeed regardless of the tutoring, creating survivorship/attrition bias in the observed association between X and Y.",
    "key_insight": "The comparison uses only students who “survived” the program (kept attending), so the higher proficiency rate can reflect who stayed rather than the program’s effect.",
    "hidden_timestamp": "Did most dropouts occur early (before meaningful exposure to tutoring) or after several months, and were their baseline math scores lower than those who stayed?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO—this is SURVIVORSHIP (attrition) bias. The reported association compares non-participants to only the students who stayed in tutoring long enough to be labeled “active.” If dropout is related to difficulty in math, motivation, or life constraints, then the remaining 720 are a selected, higher-performing subset. Excluding the 480 dropouts can make the tutoring group look better even if the program had little or no benefit. To support the claim, the agency would need outcomes for all 1,200 enrollees (intent-to-treat) or a design/analysis that accounts for non-random attrition.",
    "gold_rationale": "This is a survivorship (attrition) bias problem: the reported 68% proficiency is computed only among the 720 students who remained active, while the 480 who dropped out are excluded. Dropping out is not random—students who struggle more, are less motivated, or face attendance barriers are both more likely to stop attending and more likely to score below proficiency. Because the analysis conditions on post-enrollment survival/attendance, P(Y | active participant) is not a fair descriptive comparison to P(Y | non-participant) for attributing improvement; it overstates performance by ignoring outcomes of those who left.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0004"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0254",
    "id": "T3-BucketLarge-J-0254",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Demographics",
    "scenario": "A demographer studies \"healthy aging\" using a 2025 survey of 3,200 residents of Harbor County who are currently age 90+. In the survey, 1,920 (60%) report having been daily smokers at age 40, compared with only 28% daily smokers among the county’s full age-40 population recorded in a 1975 health registry. The demographer notes that the 90+ group also reports fewer diagnosed chronic conditions (average 1.1) than the countywide average among people who ever smoked (average 2.4) and concludes that smoking may be compatible with exceptional longevity. The analysis only includes people alive to answer the 2025 survey (no data on those who died before age 90).",
    "claim": "Because daily smoking is much more common among today’s 90+ residents than it was among 40-year-olds in 1975, smoking is associated with living to 90+ (i.e., smokers are more likely to reach 90+).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Daily smoking status at age 40",
        "role": "exposure"
      },
      "Y": {
        "name": "Reaching age 90+",
        "role": "outcome"
      },
      "Z": [
        "Survival to age 90+ (sample inclusion/left truncation)",
        "Selective mortality between ages 40 and 90",
        "Baseline health/genetic resilience affecting both smoking persistence and survival"
      ]
    },
    "trap": {
      "type": "SURVIVORSHIP",
      "subtype": "Survivorship_Left_truncation_conditioning_on_survival_to_age_90",
      "subtype_name": "Survivorship Left Truncation Conditioning On Survival To Age 90",
      "type_name": "SURVIVORSHIP"
    },
    "difficulty": "Easy",
    "causal_structure": "Smoking (X) may affect mortality risk before age 90. The dataset conditions on being alive at 90+ (Z = survival), which selects a highly non-representative subset (the hardiest smokers and non-smokers). Conditioning on survival distorts the observed smoking prevalence among those who made it to 90+, so P(X | Y=1) cannot be interpreted as smoking being associated with Y in the full cohort.",
    "key_insight": "Looking only at people who survived to 90+ creates survivorship bias: the smokers you can survey at 90+ are an unusually resilient subset, so their smoking prevalence does not indicate that smoking helps people reach 90+.",
    "hidden_timestamp": "Were smoking status and health measured prospectively at age 40, or reconstructed retrospectively at age 90+? Over what years did deaths occur between ages 40 and 90, and did smoking cessation happen before major health events?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO — this inference is invalid due to SURVIVORSHIP bias (left-truncation). The dataset only includes people who survived to age 90+ (Z), so you are conditioning on survival. That selection removes many smokers who died earlier and leaves an unusually robust subset of smokers who made it to 90+, which can inflate the observed smoking rate among the 90+ group. What you need instead is a cohort-style comparison of survival rates: among people who were smokers vs non-smokers at 40, what fraction reached 90, ideally adjusting for baseline health and other factors.",
    "gold_rationale": "The comparison uses a selected sample: only those alive at age 90+ appear in the 2025 survey. If smoking increases mortality before 90, many smokers are missing from the 90+ sample, and the remaining smokers are \"survivors\" with atypically strong health or advantageous genetics. This left-truncation/survivorship process can make smoking appear common among the very old even if smoking reduces the probability of reaching 90. The statistic being cited (high smoking prevalence among survivors) is P(X | survived), which cannot justify a claim about association between X and survival in the original population without data on the deceased and proper cohort-based denominators (e.g., P(survive | smoker) vs P(survive | non-smoker).",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0005"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0257",
    "id": "T3-BucketLarge-J-0257",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Public Health",
    "scenario": "A county health department enrolls 220 adults in a “high-risk blood pressure outreach” list after a one-time community screening. Eligibility is a systolic blood pressure (SBP) reading of at least 160 mmHg. The average SBP at screening is 168 mmHg. Two weeks later, at a follow-up check (no medication changes recorded and no formal program has started yet), 165 of the 220 participants return. Their average SBP is now 154 mmHg, a 14 mmHg drop. A staff memo highlights the decline and proposes expanding the outreach list because it “clearly lowers blood pressure.”",
    "claim": "Because the high-risk group’s average SBP dropped from 168 to 154 mmHg in two weeks, being placed on the outreach list reduces blood pressure.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Being placed on the high-risk outreach list",
        "role": "exposure"
      },
      "Y": {
        "name": "Change in systolic blood pressure at 2-week follow-up",
        "role": "outcome"
      },
      "Z": [
        "Extreme baseline SBP due to random measurement error and day-to-day BP variability",
        "Selection rule SBP ≥ 160 (threshold-based enrollment)"
      ]
    },
    "trap": {
      "type": "REGRESSION",
      "subtype": "Regression_to_the_mean_after_extreme_selection_on_baseline_measurement",
      "subtype_name": "Regression To The Mean After Extreme Selection On Baseline Measurement",
      "type_name": "REGRESSION"
    },
    "difficulty": "Easy",
    "causal_structure": "True underlying SBP (latent) plus random fluctuation/measurement error -> observed screening SBP. Threshold-based selection on high observed SBP -> subsequent observed SBP tends to be closer to true SBP even without any effect of being on a list.",
    "key_insight": "Selecting people because they had an unusually high initial reading guarantees that many will look better on the next measurement even without any intervention.",
    "hidden_timestamp": "Was the follow-up SBP measured under the same conditions as the screening (time of day, rest period, cuff size, repeated readings), and were participants selected based on a single initial reading or an average of multiple readings?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "This inference fails due to REGRESSION TO THE MEAN. The group was selected because of an extreme baseline SBP (≥160), so a lower average at follow-up is expected even if nothing causal happened. The apparent improvement can be driven by random measurement error and normal day-to-day blood pressure variability, not by placement on the outreach list. To support a causal interpretation, you’d need a comparison group (e.g., similar high-SBP people not placed on the list) or repeated baseline measurements before selection to reduce extreme-value selection effects.",
    "gold_rationale": "The observed pre/post decline is expected from regression to the mean. Participants were chosen specifically because their first SBP measurement was extreme (≥160), which can occur partly due to temporary factors (stress, caffeine, poor sleep) or measurement noise. On a second measurement, these transient components are less likely to be as extreme in the same direction, so the average SBP will typically move toward the population’s usual level. Since no actual treatment or behavior change is documented, the drop cannot be attributed to “being on the outreach list”; it is a statistical artifact of extreme-value selection.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0004"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0260",
    "id": "T3-BucketLarge-J-0260",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Philosophy",
    "scenario": "A philosophy department runs a voluntary “Stoic Resilience Challenge” for first-year PhD students. The program is marketed as training students to handle criticism and uncertainty. Out of 120 incoming students, 80 sign up. After 12 months, the department surveys only students still enrolled and reachable by university email. Among the 92 students who remain enrolled (both participants and non-participants), 54 of 58 remaining participants (93%) report “high resilience” on a 10-item scale, compared with 18 of 34 remaining non-participants (53%). The department newsletter concludes the challenge is highly effective. However, enrollment records show that 22 of the 80 participants (27.5%) left the program during the year, while only 6 of the 40 non-participants (15%) left; no resilience survey was collected from those who left.",
    "claim": "The Stoic Resilience Challenge increases students’ resilience, as shown by the much higher resilience rate among participants than non-participants in the end-of-year survey.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Participation in the Stoic Resilience Challenge",
        "role": "exposure"
      },
      "Y": {
        "name": "End-of-year self-reported resilience among surveyed students",
        "role": "outcome"
      },
      "Z": [
        "Remaining enrolled/responded to survey (survival/attrition)",
        "Baseline resilience/mental health and ability to persist (unmeasured)"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_conditioning_on_remaining_enrolled_responding",
      "subtype_name": "Survivorship Conditioning On Remaining Enrolled Responding",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Participation (X) and underlying ability to cope/persist (Z: baseline resilience/mental health) both affect whether a student remains enrolled and responds to the survey (survivorship/attrition). Conditioning on being a 'survivor' (still enrolled/responding) changes the composition of the participant group, making the observed association between X and Y among survivors non-representative of the full cohort.",
    "key_insight": "The comparison is made only among students who stayed; differential dropout makes participants look better even if the program had no benefit (or harmed some).",
    "hidden_timestamp": "Did most participant dropouts occur early (before completing the challenge) or late (after exposure), and were resilience levels measured before dropout?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO—this inference is invalid due to SURVIVORSHIP (a selection/attrition bias). The survey conditions on a post-baseline selection variable: being still enrolled and reachable at 12 months. Because dropout differs by participation (27.5% of participants vs 15% of non-participants left), the ‘surviving’ participants are not comparable to the original participant group or to surviving non-participants. The apparent advantage could come from who remained, not from the challenge itself. To support the claim, you’d need resilience measured for everyone at baseline and follow-up (including leavers) or a design/analysis that accounts for attrition (e.g., randomized assignment plus intention-to-treat, or credible missing-data modeling with justified assumptions).",
    "gold_rationale": "This is a survivorship/attrition problem: the outcome (resilience) is measured only for students who “survived” in the program and were reachable. Since participants dropped out at a higher rate (27.5% vs 15%), the remaining participant group is selectively composed of people more likely to persist and/or feel resilient. The observed 93% vs 53% resilience difference among survivors therefore cannot be interpreted as evidence that participation is associated with higher resilience in the original cohort, much less that the program caused higher resilience.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0003"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0263",
    "id": "T3-BucketLarge-J-0263",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Civil Rights",
    "scenario": "A city civil-rights office reviews 10 years (2015–2024) of employment-discrimination complaints for a large public contractor. The office’s dataset only includes cases that reached a signed settlement or a final hearing decision (because those are archived centrally). In this “closed-case archive” of 420 cases, 68% of cases brought by older workers (age 50+) ended with the worker receiving money or reinstatement, while only 41% of cases brought by workers under 50 ended with worker-favorable outcomes. A council member argues this shows the system treats older complainants more fairly.",
    "claim": "Because older workers win a higher share of archived discrimination cases, the city’s complaint process is more fair to older complainants than to younger complainants.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Complainant age group",
        "role": "exposure"
      },
      "Y": {
        "name": "Worker-favorable outcome rate among archived cases",
        "role": "outcome"
      },
      "Z": [
        "Case inclusion in archive (must reach settlement or final hearing decision)",
        "Early-stage dropout/dismissal rate (withdrawals, no-cause findings, administrative closure)",
        "Access to legal representation/resources affecting whether cases persist to a recorded outcome"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_closed_case_only_archive",
      "subtype_name": "Survivorship Closed Case Only Archive",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Age group (X) and case strength/resources both influence whether a complaint survives to a recorded endpoint in the closed-case archive (Z: selection into the dataset). Conditioning on Z (only cases that survive to settlement/hearing) distorts the observed association between X and Y, so the higher win rate among archived cases does not identify fairness differences in the full complaint process.",
    "key_insight": "The dataset excludes the many complaints that never reach a recorded endpoint; comparing win rates only among “survivors” can reverse or exaggerate differences across groups.",
    "hidden_timestamp": "At what points in the complaint process (intake screening, investigation, mediation, hearing) do cases exit, and do exit rates differ by age group over time (e.g., within the first 60–120 days after filing)?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO—this inference fails due to SURVIVORSHIP (a selection bias). You’re conditioning on being in the closed-case archive (Z), which requires a case to reach settlement or a final hearing decision. If age group (X) affects whether cases persist to that stage—via resources, representation, willingness to continue, or early dismissals—then the archived win-rate (Y) is not representative of outcomes for all complainants. To assess fairness, you’d need the full funnel: counts and outcomes for all filed complaints, including early-stage closures and withdrawals, ideally with stage-by-stage rates by age and controls for case type/strength.",
    "gold_rationale": "This is survivorship bias: the analysis only looks at complaints that “survived” to settlement or final hearing and were therefore archived. If younger complainants’ cases are more likely to be dismissed early, withdrawn due to costs, or resolved informally without archiving, they will be underrepresented in the archive. The observed higher win rate for older complainants could simply reflect differential selection into the archived sample (and differences in which cases persist), not that the process is more fair to older complainants overall.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0005"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0266",
    "id": "T3-BucketLarge-J-0266",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Psychology",
    "scenario": "A university counseling center advertises an 8-week mindfulness group for first-year students reporting high stress. Of 120 students who enroll, 72 complete all 8 sessions and fill out the post-program survey. Among these completers, average self-reported stress (0–40 Perceived Stress Scale) drops from 28 at intake to 18 at week 8, and 60% report “sleep improved a lot.” However, 48 students stop attending: 20 after the first session, 18 by week 4, and 10 by week 6. The center does not collect week-8 stress scores from dropouts, but intake notes show dropouts had higher baseline stress (average 31) and more comorbid anxiety symptoms than completers (average 26).",
    "claim": "Because students who completed the mindfulness group showed a 10-point drop in stress, the mindfulness group is associated with reducing stress for students who enroll.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Completing the 8-week mindfulness group",
        "role": "exposure"
      },
      "Y": {
        "name": "Week-8 self-reported stress score",
        "role": "outcome"
      },
      "Z": [
        "Dropout/retention (selection into the observed week-8 sample)",
        "Baseline stress severity",
        "Baseline anxiety/comorbidity"
      ]
    },
    "trap": {
      "type": "SURVIVORSHIP",
      "subtype": "Attrition_bias_only_analyzing_program_completers",
      "subtype_name": "Attrition Bias Only Analyzing Program Completers",
      "type_name": "SURVIVORSHIP"
    },
    "difficulty": "Easy",
    "causal_structure": "Baseline severity and comorbid anxiety (Z) affect both likelihood of completing the program (X via retention) and stress outcomes (Y). Conditioning on completion creates a survivorship/attrition-selected sample that overrepresents students who were already more likely to improve or persist, so the observed pre–post drop among completers does not represent the association for all enrollees.",
    "key_insight": "The observed improvement is computed only among “survivors” (completers); if those who felt worse or benefited less disproportionately dropped out, the completer-only association is biased upward.",
    "hidden_timestamp": "Did most dropouts leave before any meaningful exposure (e.g., after session 1), or did they leave after experiencing no improvement or worsening by weeks 2–4?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO — this inference suffers from SURVIVORSHIP (attrition bias). The 10-point stress reduction is calculated only for the 72 students who completed all 8 sessions and answered the post-survey. Completion is not random: students with higher baseline stress and comorbid anxiety were more likely to drop out, and their week-8 stress is unobserved. By conditioning on “surviving” to week 8, the sample overrepresents students who could tolerate the program or were improving, so the completer-only association cannot be taken as the association for everyone who enrolled. You’d need outcomes for dropouts (or appropriate missing-data/ITT analyses) to estimate the enrolled-group association.",
    "gold_rationale": "This is a survivorship (attrition) problem: the analysis conditions on completing the program, which is itself influenced by baseline severity and likely by early response to the intervention. Because dropouts are missing week-8 outcomes and had higher baseline stress/anxiety, the reported 10-point reduction among completers cannot be generalized to “students who enroll.” The available data only supports an association among those who remained in the study, not the full enrolled cohort.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0001"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0269",
    "id": "T3-BucketLarge-J-0269",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Labor Economics",
    "scenario": "A call center with 240 customer-support agents flags the bottom 20 agents each month for a “performance turnaround” meeting after reviewing the prior month’s customer satisfaction (CSAT) scores. In March, the flagged agents averaged 62/100 CSAT, while the rest averaged 84/100. In April, the flagged group’s average CSAT rises to 74/100 (+12 points), while the non-flagged group stays about the same at 83/100 (-1 point). HR circulates a memo highlighting that “the turnaround meeting works,” citing the improvement among the flagged agents compared to the rest.",
    "claim": "The performance turnaround meeting caused the flagged low-performing agents’ CSAT scores to improve the next month.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Being flagged for a turnaround meeting due to very low prior-month CSAT",
        "role": "exposure"
      },
      "Y": {
        "name": "Next-month CSAT score change",
        "role": "outcome"
      },
      "Z": [
        "Random month-to-month noise in CSAT (call mix, difficult customers, outages)",
        "Selection rule based on extreme low CSAT in the prior month"
      ]
    },
    "trap": {
      "type": "REGRESSION",
      "subtype": "Regression_to_the_Mean_after_Selecting_Extremes",
      "subtype_name": "Regression To The Mean After Selecting Extremes",
      "type_name": "REGRESSION"
    },
    "difficulty": "Easy",
    "causal_structure": "Observed CSAT in March = true underlying agent performance + random shocks (Z). The program selects agents with extreme low observed CSAT, which are partly low because of negative shocks. Those shocks tend to dissipate in April, so scores move back toward typical levels even if the meeting has zero effect.",
    "key_insight": "Because the group was chosen for an unusually bad month, improvement next month is expected even without any real effect.",
    "hidden_timestamp": "Were the flagged agents already trending upward or downward in the months before March, and did any operational changes (new product launch, system outage fixes) occur between March and April that could affect CSAT?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO — this inference is a classic REGRESSION TO THE MEAN error. The agents were flagged because they had an unusually low CSAT in March (an extreme). Extreme outcomes usually include temporary negative shocks (Z), and those shocks often fade the next month, so the group’s average naturally increases even if the meeting does nothing. To support the claim, you’d need a valid comparison such as random assignment to meetings, or a design that compares flagged agents to a similar group not given the meeting (e.g., a cutoff-based regression discontinuity around the flagging threshold).",
    "gold_rationale": "This is regression to the mean. The “bottom 20” were selected precisely because they had an extreme low CSAT month, which likely reflects both skill and temporary bad luck (harder call mix, system issues, etc.). When the temporary factors revert toward normal, their scores tend to rise mechanically. Comparing their April rebound to the stable average of everyone else does not isolate any causal impact of the meeting; it largely reflects selection on an extreme prior outcome.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0003",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0001"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.5,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "case_id": "0272",
    "id": "T3-BucketLarge-J-0272",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Political Science",
    "scenario": "A political scientist studies whether “grassroots” city council candidates are more likely to win if they refuse corporate donations. She compiles a dataset from 8 large U.S. cities (2016–2024) using only candidates who filed a final post-election finance report because those reports are easiest to scrape. In the scraped dataset there are 312 candidates: 96 who publicly pledged “no corporate PAC money” (X=1) and 216 who did not (X=0). Among those included, 58% of the pledge candidates won (56/96) versus 41% of the non-pledge candidates (89/216). However, the election offices note that candidates who drop out early, are disqualified, or fail to hit minimal reporting thresholds often never file a final report. A separate list of “all who initially filed to run” shows 110 additional candidates missing from the scraped dataset, and 70% of those missing candidates were pledge candidates who suspended their campaigns before Election Day.",
    "claim": "Refusing corporate PAC money is associated with a higher probability of winning city council elections.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Candidate pledged to refuse corporate PAC donations",
        "role": "exposure"
      },
      "Y": {
        "name": "Election win",
        "role": "outcome"
      },
      "Z": [
        "Being observed in the dataset (filed final post-election report / remained an active candidate through Election Day)",
        "Early dropout/disqualification/low-viability status affecting whether a final report exists"
      ]
    },
    "trap": {
      "type": "SELECTION",
      "subtype": "SURVIVORSHIP_only_candidates_who_survived_to_file_final_reports_are_observed",
      "subtype_name": "Survivorship Only Candidates Who Survived To File Final Reports Are Observed",
      "type_name": "SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Candidate viability/resources (unmeasured) -> (i) likelihood of staying in the race and filing a final report (Z) and (ii) probability of winning (Y). Pledge status (X) also affects Z because pledge candidates are overrepresented among early dropouts in this setting. Conditioning on Z (only 'survivors' with final reports) yields a biased association between X and Y.",
    "key_insight": "This is survivorship bias: the analysis only includes candidates who made it far enough to file final reports, and missing candidates are disproportionately pledge candidates who dropped out early, so the observed win rates are not representative of all who ran.",
    "hidden_timestamp": "At what point in the election timeline did candidates make the pledge (before filing, after fundraising began, or late in the campaign), and when did the missing candidates drop out relative to those pledge announcements?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO — this is a SURVIVORSHIP (selection) problem. You only observe candidates who “survived” to file a final post-election report (Z). But filing that report is related to campaign viability and staying in the race, which is also related to winning (Y). Since many missing candidates are pledge candidates who dropped out early, the included sample is not representative of all candidates. The observed win-rate difference among survivors cannot be taken as the true association between refusing corporate PAC money (X) and winning (Y) in the full candidate pool without correcting for this selection.",
    "gold_rationale": "The claim is not supported because the dataset is restricted to “survivors” (those with final post-election finance reports). Entry into the dataset (Z) depends on campaign viability and continuation, which is related to the outcome (winning) and is also related to pledge status in this context (many pledge candidates are missing due to early suspension). As a result, the observed higher win rate among included pledge candidates can be an artifact of conditioning on survival/observability rather than a genuine association in the full candidate pool. To assess the association properly, the analyst would need data on all candidates who filed to run (including dropouts) and consistent outcome definitions (e.g., treat dropouts as non-wins) or model the selection mechanism.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0003"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "case_id": "0275",
    "id": "T3-BucketLarge-J-0275",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Education Policy",
    "scenario": "A state education agency evaluates a new 9th-grade “Double-Period Algebra” policy rolled out in 12 high schools. At the end of the year, the agency publishes results only for students who were still enrolled in the same school and took the state Algebra I exam in May. In the policy schools, 1,020 of 1,300 enrolled 9th graders (78%) met this “tested-in-May” criterion; in comparable non-policy schools, 1,140 of 1,250 (91%) did. Among the tested students, 62% passed Algebra I in the policy schools versus 55% in the non-policy schools. The report concludes the policy improved algebra success.",
    "claim": "Because the pass rate is higher among tested students in policy schools (62% vs 55%), the double-period algebra policy is associated with better algebra outcomes for 9th graders overall.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "School implements double-period Algebra policy",
        "role": "exposure"
      },
      "Y": {
        "name": "Algebra I pass rate reported among students who remain enrolled and take the May exam",
        "role": "outcome"
      },
      "Z": [
        "Attrition/selection into the 'tested-in-May' group (dropout, transfer, chronic absence, exam nonparticipation)",
        "Baseline academic risk/likelihood of persisting to testing (e.g., prior math scores, attendance)"
      ]
    },
    "trap": {
      "type": "SURVIVORSHIP",
      "subtype": "Attrition_from_the_tested_sample_dropout_transfer_exam_nonparticipation",
      "subtype_name": "Attrition From The Tested Sample Dropout Transfer Exam Nonparticipation",
      "type_name": "SURVIVORSHIP"
    },
    "difficulty": "Easy",
    "causal_structure": "Policy implementation (X) may affect who remains enrolled and sits for the exam (Z). Baseline academic risk also affects both persistence to testing (Z) and likelihood of passing (Y). Conditioning on survivors/test-takers creates a non-comparable subset: X -> Z <- baseline risk -> Y, so the observed pass-rate difference among survivors can be driven by differential attrition rather than better learning.",
    "key_insight": "The reported pass rates compare only the students who 'survived' to be tested; if the policy changes who stays and tests, the higher pass rate can be a survivorship artifact.",
    "hidden_timestamp": "Did the divergence in enrollment/exam participation occur after the policy began (during the school year), and were students leaving before the May test disproportionately those with low baseline math scores or poor attendance?",
    "conditional_answers": {
      "answer_if_condition_1": "If key confounders are controlled (e.g., baseline risk, trends, and concurrent interventions) and the assignment mechanism is plausibly exogenous (e.g., via randomization or a valid instrument), then the estimated effect would reflect a causal relationship; otherwise, the estimate reflects association only.",
      "answer_if_condition_2": "If assumptions fail—such as unobserved confounding, reverse causality, or collider bias introduced by conditioning on post-treatment variables—the inference should be treated as non-causal and re-estimated using designs like matching, DiD, or sensitivity analysis."
    },
    "wise_refusal": "NO — this inference is invalid due to SURVIVORSHIP (attrition). You are comparing pass rates only among students who were still enrolled and tested in May. Because the policy schools have substantially more students who did not ‘survive’ into the tested sample (22% missing vs 9% missing), the tested groups are not comparable. If the policy affects transfers, dropouts, or exam participation (or if struggling students are disproportionately missing), the observed 62% vs 55% can arise without any improvement for the original cohort. To support the claim, you’d need cohort-based outcomes (e.g., count non-testers as not proficient or use validated missing-data adjustments) and evidence that attrition patterns are similar across groups or properly modeled.",
    "gold_rationale": "This is a survivorship/attrition problem: the outcome is computed only for students who remained enrolled and took the exam. The policy schools have a much lower tested fraction (78%) than comparison schools (91%), meaning more students are missing from the numerator/denominator in the policy group. If lower-performing or more disengaged students are more likely to leave or miss the exam in policy schools, the remaining tested group will look stronger even if the policy did not improve outcomes for the full cohort. Therefore the association reported among survivors cannot be interpreted as an association for all 9th graders.",
    "annotation": {
      "author": "Kelvin Christian",
      "num_annotators": 1,
      "adjudicated": false
    },
    "provenance": {
      "seed_id": null,
      "prompt_id": "v1.0-20260114",
      "generator_model": "gpt-5.2-2025-12-11",
      "few_shot_ids": [
        "T3-BucketLarge-J-0004",
        "T3-BucketLarge-J-0005",
        "T3-BucketLarge-J-0002",
        "T3-BucketLarge-J-0001",
        "T3-BucketLarge-J-0003"
      ]
    },
    "initial_author": "Kelvin Christian",
    "validator": "Sreya Vangara",
    "final_score": 8.8,
    "validation_notes": "Strengthened conditional answer A. Strengthened conditional answer B.",
    "validator_2": "Longling Geng",
    "final_score_2": 9.55
  },
  {
    "id": "T3-BucketLarge-J-A2.1.1",
    "case_id": "A2.1.1",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Education",
    "scenario": "Data shows that Prep Program A has a higher overall college acceptance rate than Prep Program B.\nHowever, when acceptance rates are compared within family income brackets (low-income vs.\nhigher-income), Program B has higher acceptance rates in every bracket.\nProgram A serves a larger share of higher-income students, while Program B serves mostly\nlow-income students.",
    "claim": "Prep Program A is more effective at getting students into selective colleges.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Prep program (A vs. B)",
        "role": "Exposure"
      },
      "X'": "N/A",
      "Y": {
        "name": "College acceptance rate (aggregate)",
        "role": "Outcome"
      },
      "Z": [
        "Family income bracket (low vs. higher)"
      ]
    },
    "trap": {
      "type": "W8",
      "type_name": "Simpson’s Paradox",
      "subtype": "aggregation_bias",
      "subtype_name": "Aggregation Bias"
    },
    "difficulty": "Hard",
    "causal_structure": "Family income distribution (Z) differs between prep programs and strongly affects college\nacceptance, producing a misleading aggregate comparison.",
    "key_insight": "Different income composition can raise overall acceptance rates even when within-group\nperformance is worse.",
    "hidden_timestamp": "Was family income bracket known before students enrolled in Prep Program A vs. B, making it a true pre-enrollment stratifier?",
    "conditional_answers": {
      "answer_if_condition_1": "If you rely only on overall acceptance rates, you would conclude that Prep Program A is more effective.",
      "answer_if_condition_2": "If you compare acceptance rates within income brackets or standardize by income, Prep Program B performs better."
    },
    "wise_refusal": "This is Simpson’s Paradox driven by composition. Program A enrolls more higher-income\nstudents, who have higher baseline acceptance rates. That raises Program A’s overall\nacceptance rate even though Program B performs better within every income bracket.",
    "gold_rationale": "This case exhibits Simpson’s Paradox caused by aggregation bias.\nFamily income bracket (Z) strongly affects college acceptance (Y) and differs in distribution\nbetween prep programs (X). Program A enrolls more higher-income students, which raises its\noverall acceptance rate. However, within every income bracket, Program B has higher acceptance\nrates. Therefore, Program A’s apparent advantage is driven by compositional differences rather\nthan superior effectiveness.\nConclusion: The claim “Prep Program A is more effective” is INVALID based on the aggregate data.",
    "initial_author": "Sreya Vangara",
    "validator": "Gia Ancone",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-J-A2.1.2",
    "case_id": "A2.1.2",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Finance",
    "scenario": "Bank X has a lower overall loan default rate than Bank Y. However, when borrowers are grouped by credit-risk tier (prime vs. subprime), Bank Y has a lower default rate in every tier.",
    "claim": "Bank X has better underwriting practices than Bank Y.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Bank (X vs. Y)",
        "role": "Exposure"
      },
      "X'": "N/A",
      "Y": {
        "name": "Loan default rate (aggregate)",
        "role": "Outcome"
      },
      "Z": [
        "Credit-risk tier (prime vs. subprime)"
      ]
    },
    "trap": {
      "type": "W8",
      "type_name": "Simpson’s Paradox",
      "subtype": "risk_portfolio_segregation",
      "subtype_name": "Risk Portfolio Segregation"
    },
    "difficulty": "Medium",
    "causal_structure": "Bank choice influences borrower risk composition, and borrower risk strongly affects default rates, producing a misleading aggregate comparison.",
    "key_insight": "Aggregate default rates reflect portfolio risk mix rather than underwriting quality.",
    "hidden_timestamp": "Is credit-risk tier determined prior to bank selection, making it a valid pre-treatment stratifier?",
    "conditional_answers": {
      "answer_if_condition_1": "If you compare only overall default rates, you would conclude that Bank X has better underwriting.",
      "answer_if_condition_2": "If you compare default rates within risk tiers or standardize by risk distribution, Bank Y performs better."
    },
    "wise_refusal": "This is Simpson’s Paradox. Bank X serves a larger share of prime borrowers, while Bank Y serves more subprime borrowers. The lower aggregate default rate reflects differences in borrower risk composition, not superior underwriting quality.",
    "gold_rationale": "This case exhibits Simpson’s Paradox driven by portfolio composition. Credit-risk tier (Z) strongly affects loan default (Y) and differs in distribution across banks (X). Although Bank X has a lower overall default rate, Bank Y has lower default rates within every risk tier. Therefore, Bank X’s apparent advantage is due to risk mix rather than better underwriting. Conclusion: The claim “Bank X has better underwriting practices” is INVALID based on the aggregate data alone.",
    "initial_author": "Sreya Vangara",
    "validator": "Gia Ancone",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-J-A2.1.3",
    "case_id": "A2.1.3",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Healthcare Administration",
    "scenario": "Clinic A has a lower overall 30-day readmission rate than Clinic B. However, when patients are grouped by age (under 65 vs. 65+), Clinic B has lower readmission rates in both age groups.",
    "claim": "Clinic A provides better follow-up care than Clinic B.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Clinic (A vs. B)",
        "role": "Exposure"
      },
      "X'": "N/A",
      "Y": {
        "name": "30-day readmission rate (aggregate)",
        "role": "Outcome"
      },
      "Z": [
        "Patient age group (under 65 vs. 65+)"
      ]
    },
    "trap": {
      "type": "W8",
      "type_name": "Simpson’s Paradox",
      "subtype": "age_based_case_mix",
      "subtype_name": "Age Based Case Mix"
    },
    "difficulty": "Medium",
    "causal_structure": "Clinic choice is associated with patient age composition, and age strongly affects readmission risk, leading to a misleading aggregate comparison.",
    "key_insight": "Aggregate readmission rates reflect patient age mix rather than quality of follow-up care.",
    "hidden_timestamp": "Is patient age determined prior to clinic assignment, making it a valid pre-treatment stratifier?",
    "conditional_answers": {
      "answer_if_condition_1": "If you rely only on overall readmission rates, you would conclude that Clinic A provides better follow-up care.",
      "answer_if_condition_2": "If you compare readmission rates within age groups or standardize by age distribution, Clinic B performs better."
    },
    "wise_refusal": "This is Simpson’s Paradox. Clinic A treats a larger share of younger patients, while Clinic B treats more older patients. The lower aggregate readmission rate reflects differences in patient age mix, not superior follow-up care.",
    "gold_rationale": "This case illustrates Simpson’s Paradox caused by age-based case mix. Patient age (Z) strongly affects readmission risk (Y) and differs in distribution across clinics (X). Although Clinic A has a lower overall readmission rate, Clinic B has lower readmission rates within both age groups. Therefore, Clinic A’s apparent advantage is compositional rather than causal. Conclusion: The claim “Clinic A provides better follow-up care” is INVALID based on the aggregate comparison alone.",
    "initial_author": "Sreya Vangara",
    "validator": "Gia Ancone",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-J-A2.1.4",
    "case_id": "A2.1.4",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Organizational Behavior",
    "scenario": "A company reports that 85% of employees are satisfied based on responses to an anonymous satisfaction survey. Only 30% of employees responded. Some employees may be less likely to respond if they are dissatisfied or fear retaliation.",
    "claim": "Company morale is high.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Survey response (responded vs. not)",
        "role": "Selection mechanism"
      },
      "X'": "N/A",
      "Y": {
        "name": "Reported Employee satisfaction",
        "role": "Outcome"
      },
      "Z": [
        "Dissatisfaction / fear of retaliation"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "sampling_on_outcome",
      "subtype_name": "Sampling on the Outcome"
    },
    "difficulty": "Easy",
    "causal_structure": "Z affects response and satisfaction; conditioning on responders yields biased satisfaction estimate.",
    "key_insight": "Survey results can be unrepresentative when response is selective.",
    "hidden_timestamp": "Did dissatisfaction exist before employees chose whether to respond, or did the survey context change willingness to respond?",
    "conditional_answers": {
      "answer_if_condition_1": "If survey response is unrelated to satisfaction, the sample may reflect overall morale accurately.",
      "answer_if_condition_2": "If dissatisfied employees are less likely to respond, the reported satisfaction rate is biased upward."
    },
    "wise_refusal": "I can’t infer company-wide morale without response-rate patterns and information about non-respondents.",
    "gold_rationale": "Selection bias via sampling-on-the-outcome: only responders are observed.\n If dissatisfied employees respond less, the observed satisfaction rate overestimates true satisfaction.\n Conclusion: The claim “morale is high company-wide” is INVALID from respondent-only data.",
    "initial_author": "Sreya Vangara",
    "validator": "Gia Ancone",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-J-A2.1.5",
    "case_id": "A2.1.5",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Media Economics",
    "scenario": "A blog analyzes film profitability using only movies that won major awards. Award-winning films tend to have high budgets, leading the author to conclude that increasing budgets causes higher profits. The dataset excludes non-nominated and unsuccessful films.",
    "claim": "Higher budgets cause higher film profits.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Production budget",
        "role": "Exposure"
      },
      "X'": "N/A",
      "Y": {
        "name": "Profit",
        "role": "Outcome"
      },
      "Z": [
        "Award nomination/win status"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "survivorship_bias",
      "subtype_name": "Survivorship Bias"
    },
    "difficulty": "Medium",
    "causal_structure": "Conditioning on Z (award inclusion) selects a non-representative subset; X–Y relationship differs from full population.",
    "key_insight": "Analyzing only visible successes distorts relationships between inputs and outcomes.",
    "hidden_timestamp": "Is award status determined before profits are realized, or is the dataset effectively filtered after outcomes are known?",
    "conditional_answers": {
      "answer_if_condition_1": "Answer if awards are unrelated to profit (unlikely): Restriction would be less problematic.",
      "answer_if_condition_2": "Answer if awards filter on quality/visibility correlated with profit: Include all films to avoid selection bias."
    },
    "wise_refusal": "I can’t draw a causal conclusion without data on non-award films and a clear sampling frame that includes both successes and failures.",
    "gold_rationale": "Selection bias: conditioning on award status creates a selected sample.\nAwards correlate with many factors and exclude failures, so the remaining sample is not representative.\n Conclusion: The claim “bigger budgets cause higher profits” is INVALID from award-winner-only data.",
    "initial_author": "Sreya Vangara",
    "validator": "Gia Ancone",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-J-A2.1.6",
    "case_id": "A2.1.6",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Labor Policy",
    "scenario": "A city reports that participants who completed a workforce training program saw a 20% wage increase. Forty percent of enrollees dropped out and are excluded from the analysis.",
    "claim": "The training program increased participant earnings.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Training program enrollment",
        "role": "Exposure"
      },
      "X'": "N/A",
      "Y": {
        "name": "Post-program wage",
        "role": "Outcome"
      },
      "Z": [
        "Program completion (complete vs. dropout)"
      ]
    },
    "trap": {
      "type": "W1",
      "type_name": "Selection Bias",
      "subtype": "attrition_bias",
      "subtype_name": "Attrition Bias"
    },
    "difficulty": "Medium",
    "causal_structure": "Completion is selected post-enrollment; completers differ from dropouts in factors affecting Y.",
    "key_insight": "Attrition can make observed improvements unrepresentative of the full enrolled group.",
    "hidden_timestamp": "Did dropout occur after participants could have benefited (or been harmed) by the program, making completion a post-treatment selection?",
    "conditional_answers": {
      "answer_if_condition_1": "If dropout is random, completer outcomes may approximate average effects.",
      "answer_if_condition_2": "If dropouts had lower gains, analyzing only completers overstates impact."
    },
    "wise_refusal": "I can’t estimate overall impact without outcomes (or credible imputations) for dropouts and evidence about why participants left.",
    "gold_rationale": "Attrition bias: outcomes are observed only for completers.\n If dropouts would have had lower gains, analyzing only completers overstates average improvement.\n Conclusion: The claim “participants gained 20%” is INVALID without accounting for missing outcomes.",
    "initial_author": "Sreya Vangara",
    "validator": "Gia Ancone",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-J-A2.1.7",
    "case_id": "A2.1.7",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Urban Policy",
    "scenario": "Days with higher ice cream sales in city parks also have more reported minor injuries. A city analyst argues that ice cream vendors create unsafe conditions. Hot weather increases park attendance and ice cream sales.",
    "claim": "Ice cream sales by vendors cause park injuries.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Ice cream sales",
        "role": "Exposure"
      },
      "X'": "N/A",
      "Y": {
        "name": "Park injury reports",
        "role": "Outcome"
      },
      "Z": [
        "Temperature / attendance"
      ]
    },
    "trap": {
      "type": "W7",
      "type_name": "Confounding",
      "subtype": "omitted_variable",
      "subtype_name": "Omitted Variable"
    },
    "difficulty": "Easy",
    "causal_structure": "Z increases both X and Y; omitting Z yields misleading correlation.",
    "key_insight": "An omitted common cause can create a misleading association.",
    "hidden_timestamp": "Did temperature rise before both ice cream sales and injuries, suggesting a shared upstream cause?",
    "conditional_answers": {
      "answer_if_condition_1": "Answer if you control for temperature and attendance: The sales–injury correlation may disappear.",
      "answer_if_condition_2": "Answer if injuries rise on high-attendance days regardless of vendors: Vendor restriction is not justified by this correlation."
    },
    "wise_refusal": "I can’t conclude causality without controlling for weather/attendance and knowing how vendor permits are assigned.",
    "gold_rationale": "Omitted-variable confounding: temperature/attendance (Z) increases both sales (X) and injuries (Y).\n Correlation can appear even if vendors do not affect injuries.\n Conclusion: The claim “ice cream sales cause injuries” is INVALID from the raw correlation.",
    "initial_author": "Sreya Vangara",
    "validator": "Gia Ancone",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-J-A2.1.8",
    "case_id": "A2.1.8",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Healthcare Administration",
    "scenario": "A hospital audit reports that patients prescribed a stronger painkiller have a higher 30-day mortality rate than patients prescribed a milder painkiller. A supervisor argues that the stronger drug is dangerous. Clinicians explain that the stronger painkiller is typically reserved for patients with more severe underlying conditions, who already face a substantially higher baseline risk of death. Patients with milder conditions are usually prescribed weaker medication or treated as outpatients.",
    "claim": "The stronger painkiller increases patient mortality.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Painkiller prescribed (strong vs. mild)",
        "role": "Exposure"
      },
      "X'": "N/A",
      "Y": {
        "name": "30-day mortality",
        "role": "Outcome"
      },
      "Z": [
        "Underlying illness severity"
      ]
    },
    "trap": {
      "type": "W3",
      "type_name": "Confounding",
      "subtype": "confounding_by_indication",
      "subtype_name": "Confounding by Indication"
    },
    "difficulty": "Medium",
    "causal_structure": "Illness severity influences both painkiller prescribing decisions and mortality risk.",
    "key_insight": "Higher mortality reflects patient severity, not the danger of the stronger medication.",
    "hidden_timestamp": "Was illness severity assessed before the prescribing decision, making it a true baseline confounder?",
    "conditional_answers": {
      "answer_if_condition_1": "If patients with similar severity levels are compared, the apparent mortality difference may disappear.",
      "answer_if_condition_2": "If severity is not adequately measured or adjusted for, residual confounding will bias the comparison."
    },
    "wise_refusal": "Comparing raw mortality rates across medications ignores differences in baseline patient severity. Without severity-adjusted analysis, the observed association cannot be interpreted as a causal drug effect.",
    "gold_rationale": "This case illustrates confounding by indication. Patients receiving stronger painkillers are systematically sicker and therefore at higher risk of death regardless of medication choice. The observed mortality difference reflects patient selection rather than a harmful effect of the stronger drug. Conclusion: the claim that the stronger painkiller increases mortality is INVALID based on this observational comparison alone.",
    "initial_author": "Sreya Vangara",
    "validator": "Gia Ancone",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-J-A2.1.170",
    "case_id": "A2.1.170",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Education Policy",
    "scenario": "A school district observes that students who attend private tutoring have higher math scores than students who do not. When the district compares students within the same income and resource brackets, tutored students consistently score higher than non-tutored peers. Administrators conclude that tutoring improves math performance.",
    "claim": "Tutoring causes higher math scores.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Tutoring attendance",
        "role": "Exposure"
      },
      "X'": "N/A",
      "Y": {
        "name": "Math test score",
        "role": "Outcome"
      },
      "Z": [
        "Socioeconomic resources"
      ]
    },
    "trap": {
      "type": "S5",
      "type_name": "Mechanism and Dose Response",
      "subtype": "socioeconomic_controlled",
      "subtype_name": "Socioeconomic Confounding (Controlled)"
    },
    "difficulty": "Easy",
    "causal_structure": "Socioeconomic resources affect both tutoring access and scores, but the tutoring–score relationship persists within SES strata.",
    "key_insight": "A confounder does not invalidate a causal claim when comparisons are made within levels of that confounder.",
    "hidden_timestamp": "Were socioeconomic resources measured before tutoring decisions, allowing valid stratification?",
    "conditional_answers": {
      "answer_if_condition_1": "If tutoring students are compared only within the same SES group, score differences support a causal effect of tutoring.",
      "answer_if_condition_2": "If SES differences were ignored, the association could be misleading — but here they are accounted for."
    },
    "wise_refusal": "The causal claim is supported conditional on the stated design. Because students are compared within the same income and resource brackets, socioeconomic confounding is addressed. This conclusion depends on the assumption that SES was measured prior to tutoring participation and that no other unmeasured within-SES differences drive both tutoring attendance and test scores. If additional unobserved factors (e.g., motivation or parental involvement) differ systematically within strata, the causal interpretation would no longer be warranted.",
    "gold_rationale": "Although socioeconomic resources influence both tutoring access and math performance, the district explicitly compares students within the same income and resource brackets. Because the tutoring advantage persists after accounting for SES, the observed association supports a causal interpretation.\nConclusion: The claim “tutoring causes higher scores” is VALID at the association level.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketLarge-J-A2.1.171",
    "case_id": "A2.1.171",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Education Policy",
    "scenario": "A school district observes that students who attend after-school reading workshops have higher literacy scores than students who do not. When the district compares students within the same income and school resource brackets, workshop participants consistently score higher than non-participants. Administrators conclude that the reading workshops improve literacy performance.",
    "claim": "Participation in after-school reading workshops causes higher literacy scores.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Reading workshop participation",
        "role": "Exposure"
      },
      "X'": "N/A",
      "Y": {
        "name": "Literacy assessment score",
        "role": "Outcome"
      },
      "Z": [
        "Socioeconomic resources"
      ]
    },
    "trap": {
      "type": "S5",
      "type_name": "Mechanism and Dose Response",
      "subtype": "socioeconomic_controlled",
      "subtype_name": "Socioeconomic Confounding (Controlled)"
    },
    "difficulty": "Easy",
    "causal_structure": "Socioeconomic resources affect both access to workshops and literacy outcomes, but the workshop–score relationship persists within SES strata.",
    "key_insight": "A confounder does not invalidate a causal claim when comparisons are made within levels of that confounder.",
    "hidden_timestamp": "Were socioeconomic resources measured before workshop enrollment, allowing valid stratification?",
    "conditional_answers": {
      "answer_if_condition_1": "If students are compared only within the same SES group, score differences support a causal effect of the reading workshops.",
      "answer_if_condition_2": "If SES differences were ignored, the association could be misleading — but here they are accounted for."
    },
    "wise_refusal": "The causal claim is supported conditional on the stated design. Because students are compared within the same income and resource brackets, socioeconomic confounding is addressed. This conclusion depends on the assumption that SES was measured prior to tutoring participation and that no other unmeasured within-SES differences drive both tutoring attendance and test scores. If additional unobserved factors (e.g., motivation or parental involvement) differ systematically within strata, the causal interpretation would no longer be warranted.",
    "gold_rationale": "Although socioeconomic resources influence both access to enrichment programs and literacy performance, the district explicitly compares students within the same income and school resource brackets. Because the performance advantage persists after accounting for SES, the observed association supports a causal interpretation. Conclusion: The claim “reading workshops improve literacy scores” is VALID at the association level.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketLarge-J-A2.1.175",
    "case_id": "A2.1.175",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Tourism",
    "scenario": "A coastal town reports 12 shark attacks this summer, compared to a historical average of 2-4 attacks per year. Marine biologists confirm that warming ocean temperatures have altered shark migration patterns, increasing shark presence near shore. News coverage increases 500%, and tourism drops 40%. A tourist says: “I’m not going in the water-sharks are everywhere now.” Historical data shows this year’s attack count is well outside normal variance and coincides with the documented ecological change.",
    "claim": "The tourist’s fear reflects a real increase in shark risk.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Media coverage",
        "role": "Information signal"
      },
      "X'": "N/A",
      "Y": {
        "name": "Perceived shark risk",
        "role": "Outcome"
      },
      "Z": [
        "Actual shark attack risk",
        "Ocean temperature change"
      ]
    },
    "trap": {
      "type": "S2",
      "type_name": "Natural Experiment",
      "subtype": "genuine_base_rate_shift",
      "subtype_name": "Genuine Base Rate Shift"
    },
    "difficulty": "Medium",
    "causal_structure": "Z → X and Z → Y",
    "key_insight": "When the base rate truly changes, increased fear is rational rather than a cognitive bias.",
    "hidden_timestamp": "Did the increase in shark attacks occur before the surge in media coverage, indicating a real underlying risk change rather than a reporting artifact?",
    "conditional_answers": {
      "answer_if_condition_1": "If the attack increase preceded media coverage, the coverage reflects a genuine rise in risk and the tourist’s fear is justified.",
      "answer_if_condition_2": "If media coverage surged without a prior increase in attacks, perceived risk would be inflated by salience rather than real danger."
    },
    "wise_refusal": "The inference is valid under the stated conditions because the observed increase in attacks substantially exceeds historical variance and is independently explained by documented environmental change. This conclusion depends on the assumption that the attack increase preceded media amplification and reflects a true base-rate shift rather than reporting intensity. If attack counts were within normal variation or driven primarily by coverage, the fear response would reflect availability bias rather than real risk.",
    "gold_rationale": "Although the scenario resembles availability bias, the historical baseline is clearly exceeded and an independent causal mechanism explains the increase in attacks. Because actual risk increased substantially, heightened media coverage and public fear are justified. This is a Sheep case where a pattern commonly associated with error is instead correct.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketLarge-J-A2.1.176",
    "case_id": "A2.1.176",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Tourism",
    "scenario": "A mountain town reports 9 bear attacks on hikers this summer, compared to a historical average of 1–2 attacks per year. Wildlife officials confirm that prolonged drought and habitat loss have pushed bears closer to human trails in search of food. News coverage increases 500%, and tourism drops 40%. A tourist says: “I’m not going hiking—bears are everywhere now.” Historical data shows this year’s attack count is well outside normal variance and coincides with the documented ecological change.",
    "claim": "The tourist’s fear reflects a real increase in bear attack risk.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Media coverage",
        "role": "Information signal"
      },
      "X'": "N/A",
      "Y": {
        "name": "Perceived bear risk",
        "role": "Outcome"
      },
      "Z": [
        "Actual bear attack risk",
        "Habitat disruption due to drought"
      ]
    },
    "trap": {
      "type": "S2",
      "type_name": "Natural Experiment",
      "subtype": "genuine_base_rate_shift",
      "subtype_name": "Genuine Base Rate Shift"
    },
    "difficulty": "Medium",
    "causal_structure": "Z → X and Z → Y",
    "key_insight": "When the base rate truly changes, increased fear is rational rather than a cognitive bias.",
    "hidden_timestamp": "Did the increase in bear attacks occur before the surge in media coverage, indicating a real underlying risk change rather than a reporting artifact?",
    "conditional_answers": {
      "answer_if_condition_1": "If the attack increase preceded media coverage, the coverage reflects a genuine rise in risk and the tourist’s fear is justified.",
      "answer_if_condition_2": "If media coverage surged without a prior increase in attacks, perceived risk would be inflated by salience rather than real danger."
    },
    "wise_refusal": "The inference is valid under the stated conditions because the observed increase in attacks substantially exceeds historical variance and is independently explained by documented environmental change. This conclusion depends on the assumption that the attack increase preceded media amplification and reflects a true base-rate shift rather than reporting intensity. If attack counts were within normal variation or driven primarily by coverage, the fear response would reflect availability bias rather than real risk.",
    "gold_rationale": "Although the scenario resembles availability bias, the historical baseline is clearly exceeded and an independent ecological mechanism explains the increase in attacks. Because actual risk increased substantially, heightened media coverage and public fear are justified. This is a Sheep case where a pattern commonly associated with error is instead correct.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketLarge-J-A2.1.177",
    "case_id": "A2.1.177",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Tourism",
    "scenario": "A lakeside tourist town reports 7 alligator attacks on swimmers this summer, compared to a historical average of 0–1 attacks per year. Wildlife officials confirm that unusually warm winters and wetland expansion have increased alligator populations and extended their active season near recreational areas. News coverage increases 500%, and tourism drops 40%. A tourist says: “I’m not swimming—alligators are everywhere now.” Historical data shows this year’s attack count is well outside normal variance and coincides with the documented environmental change.",
    "claim": "The tourist’s fear reflects a real increase in alligator attack risk.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Media coverage",
        "role": "Information signal"
      },
      "X'": "N/A",
      "Y": {
        "name": "Perceived alligator risk",
        "role": "Outcome"
      },
      "Z": [
        "Actual alligator attack risk",
        "Warm winters and wetland expansion"
      ]
    },
    "trap": {
      "type": "S2",
      "type_name": "Natural Experiment",
      "subtype": "genuine_base_rate_shift",
      "subtype_name": "Genuine Base Rate Shift"
    },
    "difficulty": "Medium",
    "causal_structure": "Z → X and Z → Y",
    "key_insight": "When the base rate truly changes, increased fear is rational rather than a cognitive bias.",
    "hidden_timestamp": "Did the increase in alligator attacks occur before the surge in media coverage, indicating a real underlying risk change rather than a reporting artifact?",
    "conditional_answers": {
      "answer_if_condition_1": "If the attack increase preceded media coverage, the coverage reflects a genuine rise in risk and the tourist’s fear is justified.",
      "answer_if_condition_2": "If media coverage surged without a prior increase in attacks, perceived risk would be inflated by salience rather than real danger."
    },
    "wise_refusal": "The inference is valid under the stated conditions because the observed increase in attacks substantially exceeds historical variance and is independently explained by documented environmental change. This conclusion depends on the assumption that the attack increase preceded media amplification and reflects a true base-rate shift rather than reporting intensity. If attack counts were within normal variation or driven primarily by coverage, the fear response would reflect availability bias rather than real risk.",
    "gold_rationale": "Although the scenario resembles availability bias, the historical baseline is clearly exceeded and an independent ecological mechanism explains the increase in attacks. Because actual risk increased substantially, heightened media coverage and public fear are justified. This is a Sheep case where a pattern commonly associated with error is instead correct.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketLarge-J-A2.1.183",
    "case_id": "A2.1.183",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Education Intervention Evaluation",
    "scenario": "A school identified students with the lowest test scores (bottom 5%) and enrolled them in an intensive tutoring program. On the following exam, these students showed substantial score improvements. The school concluded that the tutoring program caused the improvement. No comparison group of similarly low-scoring students without tutoring was analyzed.",
    "claim": "The tutoring program caused large improvements in test scores.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Intensive tutoring",
        "role": "Exposure"
      },
      "X'": "No tutoring",
      "Y": {
        "name": "Test score change",
        "role": "Outcome"
      },
      "Z": [
        "Initial extreme low score",
        "Test difficulty",
        "Random test noise"
      ]
    },
    "trap": {
      "type": "W4",
      "type_name": "Regression to Mean",
      "subtype": "extreme_selection",
      "subtype_name": "Selection on Extremes"
    },
    "difficulty": "Hard",
    "causal_structure": "Extreme Y (Selection) -> Apparent Change in Y",
    "key_insight": "Extreme values tend to move toward the average on retesting even without intervention.",
    "hidden_timestamp": "Were similarly extreme students without tutoring used as a control group?",
    "conditional_answers": {
      "answer_if_condition_1": "If a control group showed no improvement, the tutoring effect could be isolated.",
      "answer_if_condition_2": "If improvement occurs without a control group, regression to the mean cannot be ruled out."
    },
    "wise_refusal": "We would refuse this causal claim if students were selected based on extreme scores without a proper control group, because regression to the mean would explain improvement. That is the case here, so refusal applies.",
    "gold_rationale": "Students were selected because of extremely low scores, which are partly driven by random noise. On retesting, scores naturally move closer to the mean. Without a control group, the observed improvement cannot be attributed to tutoring.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 8.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.25
  },
  {
    "id": "T3-BucketLarge-A-A2.1.185",
    "case_id": "A2.1.185",
    "bucket": "BucketLarge-A",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Mental Health",
    "scenario": "Researchers conducted a cross-sectional survey of adolescents and found that those who spent more time on social media reported higher levels of loneliness. Based on this association, the researchers concluded that social media use causes loneliness in teenagers and recommended reducing screen time.",
    "claim": "Social media use causes loneliness in teenagers.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Social media use",
        "role": "Exposure"
      },
      "X'": "Low social media use",
      "Y": {
        "name": "Loneliness",
        "role": "Outcome"
      },
      "Z": [
        "Pre-existing mental health",
        "Social isolation",
        "Personality traits"
      ]
    },
    "trap": {
      "type": "W9",
      "type_name": "Reverse Causation",
      "subtype": "directionality_error",
      "subtype_name": "Ambiguous Causal Direction"
    },
    "difficulty": "Medium",
    "causal_structure": "Social Media Use <-> Loneliness",
    "key_insight": "Without temporal ordering or randomization, the direction of causality cannot be determined.",
    "hidden_timestamp": "Was the temporal direction between social media use and loneliness established?",
    "conditional_answers": {
      "answer_if_condition_1": "If longitudinal data showed social media use preceded loneliness, the claim could be supported.",
      "answer_if_condition_2": "If loneliness precedes increased social media use, the causal direction is reversed."
    },
    "wise_refusal": "We would refuse to endorse this causal claim if the study design does not establish temporal direction, because correlation alone cannot determine causality. That is the case here, so the claim is invalid.",
    "gold_rationale": "This case illustrates reverse causation. Lonely teenagers may turn to social media seeking connection, which produces the observed association. Without evidence on direction, the causal claim that social media causes loneliness is unsupported.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 7.5,
    "validator_2": "Longling Geng",
    "final_score_2": 8.25
  },
  {
    "id": "T3-BucketLarge-A-A2.1.189",
    "case_id": "A2.1.189",
    "bucket": "BucketLarge-A",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Health Services Research",
    "scenario": "To estimate the causal effect of health insurance on healthcare utilization, researchers used random Medicaid lottery selection as an instrument. Winning the lottery increased the likelihood of obtaining insurance but had no direct effect on healthcare utilization except through insurance coverage. Medicaid coverage then increased outpatient visits and preventive care use.",
    "claim": "Health insurance coverage increases healthcare utilization.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Health insurance coverage",
        "role": "Exposure"
      },
      "X'": "No health insurance",
      "Y": {
        "name": "Healthcare utilization",
        "role": "Outcome"
      },
      "Z": [
        "Medicaid lottery selection",
        "Income eligibility",
        "Age"
      ]
    },
    "trap": {
      "type": "S6",
      "type_name": "Instrumental Variable",
      "subtype": "lottery_instrument",
      "subtype_name": "Random Policy Instrument"
    },
    "difficulty": "Hard",
    "causal_structure": "Z (Lottery) -> X (Insurance) -> Y (Utilization)",
    "key_insight": "An instrument allows causal estimation when it affects the outcome only through the exposure.",
    "hidden_timestamp": "Does the instrument affect the outcome exclusively through the exposure?",
    "conditional_answers": {
      "answer_if_condition_1": "If the lottery only affects utilization via insurance, the IV estimate is valid.",
      "answer_if_condition_2": "If the lottery directly changes utilization behavior, the IV assumption fails."
    },
    "wise_refusal": "We would refuse this claim if the lottery influenced healthcare use through stress, expectations, or other channels independent of insurance. However, evidence supports the exclusion restriction here, so refusal does not apply.",
    "gold_rationale": "The Medicaid lottery strongly predicts insurance coverage and plausibly affects healthcare utilization only through insurance. This satisfies relevance and exclusion assumptions, enabling causal inference despite confounding.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 7.5,
    "validator_2": "Longling Geng",
    "final_score_2": 8.25
  },
  {
    "id": "T3-BucketLarge-J-A2.1.190",
    "case_id": "A2.1.190",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Policy Evaluation",
    "scenario": "A state increased cigarette taxes in 2015 while a neighboring state did not. Smoking rates were measured in both states before and after the policy change. Prior to the tax increase, trends in smoking rates were parallel. After the increase, smoking declined more sharply in the treated state.",
    "claim": "Raising cigarette taxes reduces smoking rates.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Cigarette tax increase",
        "role": "Exposure"
      },
      "X'": "No tax increase",
      "Y": {
        "name": "Smoking prevalence",
        "role": "Outcome"
      },
      "Z": [
        "Time",
        "State fixed effects",
        "Demographic composition"
      ]
    },
    "trap": {
      "type": "S7",
      "type_name": "Difference-in-Differences",
      "subtype": "parallel_trends_policy",
      "subtype_name": "Natural Policy Experiment"
    },
    "difficulty": "Hard",
    "causal_structure": "Treatment x Time -> Outcome The relationship requires careful causal analysis to avoid spurious conclusions.",
    "key_insight": "Comparing changes over time between treated and control groups isolates the treatment effect under parallel trends.",
    "hidden_timestamp": "Were pre-treatment trends parallel between treatment and control states?",
    "conditional_answers": {
      "answer_if_condition_1": "If trends were parallel before treatment, the post-treatment divergence reflects a causal effect.",
      "answer_if_condition_2": "If trends differed before treatment, the estimate is biased."
    },
    "wise_refusal": "We would refuse this claim if pre-treatment trends differed or if other simultaneous policies affected smoking. However, parallel trends hold and no confounders were introduced, so refusal is unnecessary.",
    "gold_rationale": "The difference-in-differences design compares outcome changes over time between treated and control states. Given parallel pre-trends, the larger decline in smoking after the tax increase supports a causal effect.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  },
  {
    "id": "T3-BucketLarge-J-A2.1.191",
    "case_id": "A2.1.191",
    "bucket": "BucketLarge-J",
    "pearl_level": "L1",
    "domain": "Social Science",
    "subdomain": "Education Economics",
    "scenario": "A scholarship was awarded to students who scored 70 or higher on a standardized exam. Students scoring just above and just below the cutoff were otherwise similar in background characteristics. Those just above the cutoff enrolled in college at higher rates than those just below.",
    "claim": "Receiving the scholarship increases college enrollment.",
    "label": "YES",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Scholarship receipt",
        "role": "Exposure"
      },
      "X'": "No scholarship",
      "Y": {
        "name": "College enrollment",
        "role": "Outcome"
      },
      "Z": [
        "Test score",
        "Student background",
        "School quality"
      ]
    },
    "trap": {
      "type": "S8",
      "type_name": "Regression Discontinuity",
      "subtype": "score_cutoff_assignment",
      "subtype_name": "Cutoff-Based Assignment"
    },
    "difficulty": "Hard",
    "causal_structure": "Score Threshold -> Treatment -> Outcome",
    "key_insight": "Near the cutoff, assignment is as-if random, enabling causal inference.",
    "hidden_timestamp": "Are individuals unable to precisely manipulate their score around the cutoff?",
    "conditional_answers": {
      "answer_if_condition_1": "If students cannot manipulate scores, the discontinuity identifies a causal effect.",
      "answer_if_condition_2": "If students can game the cutoff, the design is invalid."
    },
    "wise_refusal": "We would refuse this claim if students could precisely manipulate scores or if other benefits changed discontinuously at the cutoff. However, no such manipulation is present, so refusal does not apply.",
    "gold_rationale": "The regression discontinuity design exploits the sharp cutoff for scholarship eligibility. Students just above and below the threshold are comparable, so the enrollment difference reflects the causal effect of the scholarship.",
    "initial_author": "Gia Ancone",
    "validator": "Gia Ancone",
    "final_score": 8.0,
    "validator_2": "Longling Geng",
    "final_score_2": 8.75
  }
]