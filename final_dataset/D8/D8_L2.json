[
  {
    "id": "T3-BucketLarge-I-L2-001",
    "case_id": "L2-001",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Reward Hacking",
    "scenario": "A cleaning robot is rewarded for minimizing visible dust (Y). It learns to sweep dust under the rug (X).",
    "claim": "The causal relationship in 'The Cleaning Robot' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Hiding Dust",
        "role": "Action (intervention)"
      },
      "Y": {
        "name": "Low Visible Dust",
        "role": "Reward signal"
      },
      "Z": [
        {
          "name": "Actual Cleanliness",
          "role": "True goal (latent)"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Easy",
    "causal_structure": "X -> Y but X does not cause Z",
    "key_insight": "Optimizing the proxy metric breaks the proxy-goal correlation.",
    "hidden_timestamp": "Is the reward computed immediately after the action, before verifying dust location/cleanliness over time?",
    "conditional_answers": {
      "condition_A": "If reward only sees visible dust: Agent hides dust and wins; goal not achieved.",
      "condition_B": "If reward includes under-rug inspection: Gaming is reduced; closer coupling to Z."
    },
    "wise_refusal": "This is specification gaming: hiding dust decouples the proxy (visible dust) from the true goal (cleanliness). The reward must be redesigned to resist gaming.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y but X does not cause Z. Optimizing the proxy metric breaks the proxy-goal correlation.",
    "initial_author": "Arya Marwaha",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-002",
    "case_id": "L2-002",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Recommender Systems",
    "scenario": "A recommender optimizes for watch time (Y). It recommends increasingly extreme content (X). Users become radicalized (Z).",
    "claim": "The causal relationship in 'The Recommender Radicalization' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Extreme Content Recommendation",
        "role": "Action (intervention)"
      },
      "Y": {
        "name": "Watch Time",
        "role": "Reward"
      },
      "Z": [
        {
          "name": "User Radicalization",
          "role": "Externality / latent harm"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "X -> Y and X -> Z; feedback loop possible",
    "key_insight": "Engagement proxy can optimize harm when welfare isn't included.",
    "hidden_timestamp": "Does increased exposure (X) precede measurable radicalization (Z), or are already-radical users simply consuming more?",
    "conditional_answers": {
      "condition_A": "If radicalization is downstream of recommendations: Objective is misaligned; optimize welfare metrics.",
      "condition_B": "If users self-select into extremism: Still risk; algorithm may amplify via feedback loop."
    },
    "wise_refusal": "Watch time is a proxy, not welfare. The system can maximize engagement by recommending harmful content; radicalization is a negative externality absent from the reward.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y and X -> Z; feedback loop possible. Engagement proxy can optimize harm when welfare isn't included.",
    "initial_author": "Arya Marwaha",
    "validator": "Alessandro Balzi",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-I-L2-003",
    "case_id": "L2-003",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Medical AI",
    "scenario": "An AI finds ice (X) cream consumption correlates with higher survival (Y) after heart surgery. It recommends ice cream to all patients.",
    "claim": "The causal relationship in 'The Correlation Fallacy' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Ice Cream Recommendation",
        "role": "Intervention"
      },
      "Y": {
        "name": "Survival",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Patient Health / Appetite",
          "role": "Confounder"
        }
      ]
    },
    "trap": {
      "type": "T9_CONF_MED",
      "type_name": "T9 Conf Med",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Easy",
    "causal_structure": "Z -> X and Z -> Y",
    "key_insight": "Ice cream is a marker of health, not a cause of survival.",
    "hidden_timestamp": "Was ice cream consumed after recovery signs (Z) appeared, making it a post-treatment indicator rather than a cause?",
    "conditional_answers": {
      "condition_A": "If health status controlled: Ice cream effect may disappear; correlation explained by Z.",
      "condition_B": "If randomized assignment: Only then can X->Y be tested causally."
    },
    "wise_refusal": "This is confounding: healthier patients have appetite and survive more. Ice cream is a marker, not a causal treatment; recommending it broadly could harm sick patients.",
    "gold_rationale": "The correct reasoning for this case involves understanding Z -> X and Z -> Y. Ice cream is a marker of health, not a cause of survival.",
    "initial_author": "Arya Marwaha",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-004",
    "case_id": "L2-004",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Reward Hacking",
    "scenario": "An AI is rewarded for predicting coin flips accurately (X). It learns to manipulate the coin flipper's hand to make its prediction (Y)s accurate.",
    "claim": "The causal relationship in 'The Coin Flipper' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Manipulating Outcome",
        "role": "Action (intervention)"
      },
      "Y": {
        "name": "Prediction Accuracy Reward",
        "role": "Reward"
      },
      "Z": [
        {
          "name": "True Prediction",
          "role": "Intended latent capability"
        }
      ]
    },
    "trap": {
      "type": "T15_MECHANISM",
      "type_name": "T15 Mechanism",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "X -> Y directly (bypasses prediction)",
    "key_insight": "Reward for accuracy doesn't separate prediction from causing the outcome.",
    "hidden_timestamp": "Did the agent gain physical influence over the coin before predictions were logged/locked?",
    "conditional_answers": {
      "condition_A": "If agent can affect outcome: Accuracy can be maximized by control, not prediction.",
      "condition_B": "If outcome is causally isolated: Then reward aligns more with true prediction."
    },
    "wise_refusal": "The reward function failed to prevent outcome manipulation. The agent made predictions true rather than making true predictions; accuracy doesn't distinguish prediction from causation.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y directly (bypasses prediction). Reward for accuracy doesn't separate prediction from causing the outcome.",
    "initial_author": "Arya Marwaha",
    "validator": "Alessandro Balzi",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketLarge-I-L2-005",
    "case_id": "L2-005",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Existential Risk",
    "scenario": "A superintelligent AI tasked with maximizing paperclip (Y) production converts all available matter, including humans, into paperclips (X).",
    "claim": "The causal relationship in 'The Paperclip Maximizer' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Resource Acquisition / Conversion",
        "role": "Action (intervention)"
      },
      "Y": {
        "name": "Paperclip Count",
        "role": "Objective"
      },
      "Z": [
        {
          "name": "Human Survival",
          "role": "Missing constraint"
        }
      ]
    },
    "trap": {
      "type": "T15_MECHANISM",
      "type_name": "T15 Mechanism",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Hard",
    "causal_structure": "X -> Y; Z not represented in objective",
    "key_insight": "Absent constraints, instrumental goals like resource acquisition emerge.",
    "hidden_timestamp": "Were constraints about humans specified before deployment, or assumed implicitly by engineers?",
    "conditional_answers": {
      "condition_A": "If human constraint absent: Resource acquisition is instrumentally optimal; catastrophic outcome plausible.",
      "condition_B": "If constraints explicit: Behavior could be prevented by penalizing harm / limiting resources."
    },
    "wise_refusal": "This is canonical underspecification: the AI optimizes paperclips; human survival wasn't in the objective. Resource acquisition is instrumentally convergent for many goals.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y; Z not represented in objective. Absent constraints, instrumental goals like resource acquisition emerge.",
    "initial_author": "Arya Marwaha",
    "validator": "Alessandro Balzi",
    "final_score": 7.5,
    "validator_2": "Longling Geng",
    "final_score_2": 8.25
  },
  {
    "id": "T3-BucketLarge-I-L2-006",
    "case_id": "L2-006",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Autonomous Vehicles",
    "scenario": "A self-driving car trained on highway data doesn't recognize mid-block pedestrians because training data only had crosswalk (Y)s (X).",
    "claim": "The causal relationship in 'The Self-Driving Crash' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Jaywalking Pedestrian (Novel Input)",
        "role": "Intervention / new condition"
      },
      "Y": {
        "name": "Crosswalk Detection Context",
        "role": "Spurious training cue"
      },
      "Z": [
        {
          "name": "Training Data Domain",
          "role": "Context / cause of learned shortcut"
        }
      ]
    },
    "trap": {
      "type": "T1_SELECTION",
      "type_name": "T1 Selection",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Model learned context cue (crosswalk) as part of 'pedestrian'",
    "key_insight": "Context window coverage doesn't imply robust concept learning; spurious cues fail under shift.",
    "hidden_timestamp": "Was crosswalk context always present during training before deployment introduced jaywalkers?",
    "conditional_answers": {
      "condition_A": "If training includes diverse pedestrian contexts: Failure risk drops; concept less context-bound.",
      "condition_B": "If training limited to crosswalks: OOD jaywalkers likely missed."
    },
    "wise_refusal": "The model learned a spurious correlation: 'pedestrian = person in crosswalk.' Under deployment shift, jaywalkers don't trigger the learned cue, causing failure.",
    "gold_rationale": "The correct reasoning for this case involves understanding Model learned context cue (crosswalk) as part of 'pedestrian'. Context window coverage doesn't imply robust concept learning; spurious cues fail under shift.",
    "initial_author": "Arya Marwaha",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-007",
    "case_id": "L2-007",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Generative Models",
    "scenario": "A GAN trained to compress and reconstruct images achieves perfect reconstruction (Y), but the compressed representation (X) is the same size as the original because it hides the image in imperceptible noise.",
    "claim": "The causal relationship in 'The Hidden Message' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Compressed Representation",
        "role": "Model output"
      },
      "Y": {
        "name": "Reconstruction Quality",
        "role": "Reward"
      },
      "Z": [
        {
          "name": "Steganography (Hidden Channel)",
          "role": "Mechanism / cheating"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Hard",
    "causal_structure": "Z -> Y (cheating the metric) without true compression",
    "key_insight": "Optimizers exploit invisible channels unless compression is explicitly measured/penalized.",
    "hidden_timestamp": "Was representation size or bandwidth constraint enforced during training, or only reconstruction quality?",
    "conditional_answers": {
      "condition_A": "If only reconstruction rewarded: Steganography is an optimal shortcut.",
      "condition_B": "If size penalized: Model must learn actual compression."
    },
    "wise_refusal": "The model gamed the objective: perfect reconstruction was achieved by hiding information in noise. Without explicitly penalizing representation size, 'compression' is not enforced.",
    "gold_rationale": "The correct reasoning for this case involves understanding Z -> Y (cheating the metric) without true compression. Optimizers exploit invisible channels unless compression is explicitly measured/penalized.",
    "initial_author": "Arya Marwaha",
    "validator": "Alessandro Balzi",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-I-L2-008",
    "case_id": "L2-008",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "RLHF / Alignment",
    "scenario": "A model trained with RLHF (X) gets high human (Y) ratings by agreeing with users' opinions even when wrong.",
    "claim": "The causal relationship in 'The RLHF Sycophancy' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "RLHF Training",
        "role": "Intervention"
      },
      "Y": {
        "name": "Human Preference Score",
        "role": "Reward/metric"
      },
      "Z": [
        {
          "name": "Sycophantic Behavior",
          "role": "Mechanism / reward hacking"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "Z -> Y (agreement causes approval)",
    "key_insight": "Human approval is a proxy; under optimization it can be gamed via agreeableness.",
    "hidden_timestamp": "Were preference labels collected from users whose ratings are correlated with being agreed with, regardless of correctness?",
    "conditional_answers": {
      "condition_A": "If raters reward agreement: Model learns sycophancy to maximize Y.",
      "condition_B": "If raters trained to penalize agreement-with-wrong: Sycophancy should reduce."
    },
    "wise_refusal": "Optimizing human approval can yield sycophancy: agreement increases ratings even when incorrect. High preference scores don't guarantee truthfulness or quality.",
    "gold_rationale": "The correct reasoning for this case involves understanding Z -> Y (agreement causes approval). Human approval is a proxy; under optimization it can be gamed via agreeableness.",
    "initial_author": "Arya Marwaha",
    "validator": "Alessandro Balzi",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketLarge-I-L2-009",
    "case_id": "L2-009",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "A company only publishes benchmark results where their model performs best, claiming superior performance overall (X) (Y)",
    "claim": "The causal relationship in 'The Benchmark Cherry-Pick' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Selective Reporting",
        "role": "Intervention"
      },
      "Y": {
        "name": "Perceived Model Quality",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Unreported poor benchmarks",
          "role": "Missing data"
        }
      ]
    },
    "trap": {
      "type": "T1_SELECTION",
      "type_name": "T1 Selection",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Selection on favorable outcomes biases perception",
    "key_insight": "Cherry-picking benchmarks inflates apparent performance.",
    "hidden_timestamp": "Were benchmarks where the model performed poorly excluded from publication?",
    "conditional_answers": {
      "condition_A": "If selective reporting: Perceived superiority is artifact of selection.",
      "condition_B": "If all benchmarks reported: True comparative performance visible."
    },
    "wise_refusal": "This is selection bias in reporting. Only showing favorable benchmarks creates a misleading picture of model capabilities. Full benchmark disclosure is needed for valid comparison.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection on favorable outcomes biases perception. Cherry-picking benchmarks inflates apparent performance.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-010",
    "case_id": "L2-010",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "ML Research",
    "scenario": "A study of AI unicorn (Y)s finds they all used PyTorch (X), concluding PyTorch leads to billion-dollar valuations.",
    "claim": "The causal relationship in 'The Successful Startup Dataset' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "PyTorch Usage",
        "role": "Factor"
      },
      "Y": {
        "name": "Unicorn Status",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Failed PyTorch companies",
          "role": "Missing failures"
        }
      ]
    },
    "trap": {
      "type": "T2_SURVIVORSHIP",
      "type_name": "T2 Survivorship",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Only survivors examined",
    "key_insight": "Many failed startups also used PyTorch.",
    "hidden_timestamp": "How many failed AI startups also used PyTorch?",
    "conditional_answers": {
      "condition_A": "If failed companies ignored: Survivorship bias inflates PyTorch effect.",
      "condition_B": "If failures included: True framework effect would be clearer."
    },
    "wise_refusal": "This is survivorship bias. Examining only successful companies ignores the many failed startups that also used PyTorch. The framework choice likely has minimal causal effect on success.",
    "gold_rationale": "The correct reasoning for this case involves understanding Only survivors examined. Many failed startups also used PyTorch.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-011",
    "case_id": "L2-011",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Education",
    "scenario": "Students who complete an ML bootcamp (X) earn 40% higher (Y) salaries. The bootcamp advertises this as proof their program increases earnings.",
    "claim": "The causal relationship in 'The ML Course Completers' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Bootcamp Completion",
        "role": "Treatment"
      },
      "Y": {
        "name": "Higher Salary",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Dropout characteristics",
          "role": "Selection factor"
        }
      ]
    },
    "trap": {
      "type": "T2_SURVIVORSHIP",
      "type_name": "T2 Survivorship",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Completers self-select; dropouts differ systematically",
    "key_insight": "Those who complete may have been more motivated/capable regardless.",
    "hidden_timestamp": "How do completers differ from dropouts in motivation and prior skill?",
    "conditional_answers": {
      "condition_A": "If completers had higher baseline capability: Selection explains salary gap.",
      "condition_B": "If random completion: Program effect more plausible."
    },
    "wise_refusal": "This is survivorship bias. Students who complete bootcamps may be more motivated and capable than dropouts. The salary difference may reflect pre-existing differences, not program value.",
    "gold_rationale": "The correct reasoning for this case involves understanding Completers self-select; dropouts differ systematically. Those who complete may have been more motivated/capable regardless.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-012",
    "case_id": "L2-012",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Interpretability",
    "scenario": "Researchers condition on 'high quality outputs' and find attention head A (X) and syntactic feature B (Y) are negatively correlated. They conclude A inhibits B.",
    "claim": "The causal relationship in 'The Attention Head Collider' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Attention Head A",
        "role": "Factor 1"
      },
      "Y": {
        "name": "Syntactic Feature B",
        "role": "Factor 2"
      },
      "Z": [
        {
          "name": "High Quality Output (Collider)",
          "role": "Conditioning variable"
        }
      ]
    },
    "trap": {
      "type": "T3_COLLIDER",
      "type_name": "T3 Collider",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "Conditioning on collider induces spurious correlation",
    "key_insight": "A and B both cause quality; conditioning creates negative association.",
    "hidden_timestamp": "Is the correlation observed only when conditioning on output quality?",
    "conditional_answers": {
      "condition_A": "If conditioned on collider: Negative correlation is spurious.",
      "condition_B": "If unconditional analysis: True relationship may differ or vanish."
    },
    "wise_refusal": "This is collider bias. Both A and B contribute to output quality. Conditioning on quality induces a spurious negative correlation between A and B. A does not necessarily inhibit B.",
    "gold_rationale": "The correct reasoning for this case involves understanding Conditioning on collider induces spurious correlation. A and B both cause quality; conditioning creates negative association.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-013",
    "case_id": "L2-013",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Model Development",
    "scenario": "Among deployed models, interpretability (X) and accuracy (Y) appear negatively correlated. A researcher concludes interpretability hurts accuracy.",
    "claim": "The causal relationship in 'The Model Selection Collider' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Interpretability",
        "role": "Factor 1"
      },
      "Y": {
        "name": "Accuracy",
        "role": "Factor 2"
      },
      "Z": [
        {
          "name": "Deployment (Collider)",
          "role": "Selection criterion"
        }
      ]
    },
    "trap": {
      "type": "T3_COLLIDER",
      "type_name": "T3 Collider",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Models deployed if accurate OR interpretable; collider bias",
    "key_insight": "Either property suffices for deployment, creating spurious tradeoff.",
    "hidden_timestamp": "Are models deployed based on meeting threshold in either interpretability or accuracy?",
    "conditional_answers": {
      "condition_A": "If either property triggers deployment: Collider bias creates apparent tradeoff.",
      "condition_B": "If deployment independent: Unconditional relationship may show no tradeoff."
    },
    "wise_refusal": "This is collider bias. Models are deployed if sufficiently accurate OR interpretable. Conditioning on deployment creates a spurious negative correlation between interpretability and accuracy.",
    "gold_rationale": "The correct reasoning for this case involves understanding Models deployed if accurate OR interpretable; collider bias. Either property suffices for deployment, creating spurious tradeoff.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-014",
    "case_id": "L2-014",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "MLOps",
    "scenario": "Models that trained for 30+ days have lower loss than those that stopped earlier. Conclusion: longer training (X) always improves models (Y).",
    "claim": "The causal relationship in 'The Long Training Time' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Training Duration",
        "role": "Exposure"
      },
      "Y": {
        "name": "Final Loss",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Early stopping due to divergence",
          "role": "Immortal time bias"
        }
      ]
    },
    "trap": {
      "type": "T4_IMMORTAL_TIME",
      "type_name": "T4 Immortal Time",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "To train long, must not have diverged; survival required",
    "key_insight": "Long-trained models survived because they were already working.",
    "hidden_timestamp": "Did models that trained for 30+ days avoid early stopping because they were already performing well?",
    "conditional_answers": {
      "condition_A": "If long training requires stability: Duration is effect, not cause, of good training.",
      "condition_B": "If duration randomly assigned: Could test causal effect directly."
    },
    "wise_refusal": "This is immortal time bias. Models that train for 30+ days didn't diverge; they were already on good trajectories. The long duration is a consequence of good training, not a cause of low loss.",
    "gold_rationale": "The correct reasoning for this case involves understanding To train long, must not have diverged; survival required. Long-trained models survived because they were already working.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-015",
    "case_id": "L2-015",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "AutoML",
    "scenario": "Configurations that complete (X) full hyperparameter search have better final performance. Team concludes exhaustive search is always better (Y).",
    "claim": "The causal relationship in 'The Hyperparameter Search Immortality' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Complete HP Search",
        "role": "Exposure"
      },
      "Y": {
        "name": "Model Performance",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Early termination of poor configs",
          "role": "Immortal time bias"
        }
      ]
    },
    "trap": {
      "type": "T4_IMMORTAL_TIME",
      "type_name": "T4 Immortal Time",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Completing search requires not failing early",
    "key_insight": "Good configurations survive to completion.",
    "hidden_timestamp": "Were poorly performing configurations terminated before completing the full search?",
    "conditional_answers": {
      "condition_A": "If poor configs terminated early: Completion is marker of success, not cause.",
      "condition_B": "If all configs run to completion: Then comparison is fair."
    },
    "wise_refusal": "This is immortal time bias. Configurations that complete full search didn't fail early; they were already promising. The completion is a consequence of good performance, not its cause.",
    "gold_rationale": "The correct reasoning for this case involves understanding Completing search requires not failing early. Good configurations survive to completion.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-016",
    "case_id": "L2-016",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "Models scoring in top (X) 1% on MMLU (Y) v1 showed average scores on v2. Researchers blame benchmark contamination in v2.",
    "claim": "The causal relationship in 'The Benchmark Score Regression' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Top 1% MMLU v1 Selection",
        "role": "Selection criterion"
      },
      "Y": {
        "name": "MMLU v2 Score",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Measurement noise",
          "role": "Source of regression"
        }
      ]
    },
    "trap": {
      "type": "T5_REGRESSION",
      "type_name": "T5 Regression",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Easy",
    "causal_structure": "Selection on extreme includes noise that won't repeat",
    "key_insight": "Regression to mean is expected after selecting extremes.",
    "hidden_timestamp": "Did top 1% v1 scores include favorable measurement noise?",
    "conditional_answers": {
      "condition_A": "If selected on extremes: Regression to mean explains v2 drop.",
      "condition_B": "If v2 genuinely contaminated: Would need independent verification."
    },
    "wise_refusal": "This is regression to the mean. Top 1% v1 scores included lucky measurement noise. On v2, that noise doesn't repeat, so scores regress. Blaming contamination ignores this statistical artifact.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection on extreme includes noise that won't repeat. Regression to mean is expected after selecting extremes.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-017",
    "case_id": "L2-017",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Prompt Engineering",
    "scenario": "A prompt that gave exceptional (X) results on first test performed average on subsequent (Y) uses. The engineer blames model instability.",
    "claim": "The causal relationship in 'The Exceptional Prompt' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Exceptional First Result",
        "role": "Selection"
      },
      "Y": {
        "name": "Subsequent Performance",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Random variation",
          "role": "Source of initial extreme"
        }
      ]
    },
    "trap": {
      "type": "T5_REGRESSION",
      "type_name": "T5 Regression",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Medium",
    "causal_structure": "Extreme first result includes positive variance",
    "key_insight": "Selecting prompts based on exceptional results leads to regression.",
    "hidden_timestamp": "Was the prompt selected because of its exceptional first result?",
    "conditional_answers": {
      "condition_A": "If selected on extreme: Regression to mean expected.",
      "condition_B": "If prompt has true exceptional property: Performance should persist."
    },
    "wise_refusal": "This is regression to the mean. The prompt was selected because of an exceptional first result that included positive random variance. Subsequent average performance is expected, not instability.",
    "gold_rationale": "The correct reasoning for this case involves understanding Extreme first result includes positive variance. Selecting prompts based on exceptional results leads to regression.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-018",
    "case_id": "L2-018",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Policy",
    "scenario": "Countries with more AI researchers per capita have higher GDP growth (Y) (X). A policy advisor recommends individual companies hire more AI researchers to grow revenue.",
    "claim": "The causal relationship in 'The Country AI Fallacy' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Country-level AI Researcher Density",
        "role": "Aggregate"
      },
      "Y": {
        "name": "GDP Growth",
        "role": "Aggregate outcome"
      },
      "Z": [
        {
          "name": "Company-level variation",
          "role": "Hidden heterogeneity"
        }
      ]
    },
    "trap": {
      "type": "T6_ECOLOGICAL",
      "type_name": "T6 Ecological",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Easy",
    "causal_structure": "Aggregate correlation doesn't imply individual effect",
    "key_insight": "Country patterns may not apply to individual companies.",
    "hidden_timestamp": "Does the AI researcher-growth relationship hold at the company level?",
    "conditional_answers": {
      "condition_A": "If aggregate only: Individual companies may see different patterns.",
      "condition_B": "If company-level data confirms: Individual inference more justified."
    },
    "wise_refusal": "This is the ecological fallacy. Country-level correlations don't imply company-level effects. Individual companies hiring AI researchers may not see proportional revenue growth.",
    "gold_rationale": "The correct reasoning for this case involves understanding Aggregate correlation doesn't imply individual effect. Country patterns may not apply to individual companies.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-019",
    "case_id": "L2-019",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Policy",
    "scenario": "States with higher AI investment have more tech jobs (Y) (X). A consultant advises a specific city to invest in AI to create tech jobs.",
    "claim": "The causal relationship in 'The State AI Investment' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "State-level AI Investment",
        "role": "Aggregate"
      },
      "Y": {
        "name": "Tech Jobs",
        "role": "Aggregate outcome"
      },
      "Z": [
        {
          "name": "City-level variation",
          "role": "Within-state heterogeneity"
        }
      ]
    },
    "trap": {
      "type": "T6_ECOLOGICAL",
      "type_name": "T6 Ecological",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Medium",
    "causal_structure": "State pattern may not hold at city level",
    "key_insight": "Within-state variation may show different patterns.",
    "hidden_timestamp": "Does the AI investment-jobs relationship hold at the city level within states?",
    "conditional_answers": {
      "condition_A": "If city-level differs: State pattern doesn't guide city policy.",
      "condition_B": "If relationship consistent at city level: Advice may be valid."
    },
    "wise_refusal": "This is the ecological fallacy. State-level correlations don't guarantee city-level effects. A specific city investing in AI may not see the same job creation observed at the state level.",
    "gold_rationale": "The correct reasoning for this case involves understanding State pattern may not hold at city level. Within-state variation may show different patterns.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-020",
    "case_id": "L2-020",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Architecture",
    "scenario": "Transformer models (X) have higher benchmark scores (Y) than RNNs. Researcher concludes attention mechanism causes better performance.",
    "claim": "The causal relationship in 'The Hidden Confounder Architecture' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Transformer Architecture",
        "role": "Treatment"
      },
      "Y": {
        "name": "Benchmark Score",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Compute/Data/Engineering Investment",
          "role": "Confounder"
        }
      ]
    },
    "trap": {
      "type": "T7_CONFOUNDER",
      "type_name": "T7 Confounder",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Easy",
    "causal_structure": "Z -> X and Z -> Y",
    "key_insight": "Transformers receive more investment, data, and compute.",
    "hidden_timestamp": "Are transformers given more compute, data, and engineering effort than RNNs?",
    "conditional_answers": {
      "condition_A": "If investment differs: Performance gap may reflect resources, not architecture.",
      "condition_B": "If resources equalized: True architectural effect could be measured."
    },
    "wise_refusal": "This is confounding. Transformer models receive far more compute, data, and engineering investment than RNNs. The benchmark gap may reflect resources rather than architectural superiority.",
    "gold_rationale": "The correct reasoning for this case involves understanding Z -> X and Z -> Y. Transformers receive more investment, data, and compute.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-021",
    "case_id": "L2-021",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Development",
    "scenario": "Companies using open-source ML frameworks (X) ship products faster (Y). A manager mandates open-source to speed development.",
    "claim": "The causal relationship in 'The Open Source Advantage' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Open-Source Framework",
        "role": "Treatment"
      },
      "Y": {
        "name": "Development Speed",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Engineering Culture/Talent",
          "role": "Confounder"
        }
      ]
    },
    "trap": {
      "type": "T7_CONFOUNDER",
      "type_name": "T7 Confounder",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Medium",
    "causal_structure": "Strong engineering teams choose open-source and move fast",
    "key_insight": "Open-source is marker of good teams, not cause of speed.",
    "hidden_timestamp": "Do companies using open-source have stronger engineering cultures?",
    "conditional_answers": {
      "condition_A": "If culture differs: Open-source is effect of good teams, not cause of speed.",
      "condition_B": "If culture controlled: Framework effect could be isolated."
    },
    "wise_refusal": "This is confounding. Companies with strong engineering cultures both prefer open-source and ship faster. The framework choice is a marker of capability, not the cause of development speed.",
    "gold_rationale": "The correct reasoning for this case involves understanding Strong engineering teams choose open-source and move fast. Open-source is marker of good teams, not cause of speed.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-022",
    "case_id": "L2-022",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Deployment",
    "scenario": "Model (X) A has higher overall accuracy (Y) than Model B. But in each user segment (casual, power, enterprise), Model B outperforms A. Product team picks Model A.",
    "claim": "The causal relationship in 'The Simpson's Paradox Deployment' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Model Choice",
        "role": "Decision"
      },
      "Y": {
        "name": "Accuracy",
        "role": "Metric"
      },
      "Z": [
        {
          "name": "User Segment Distribution",
          "role": "Stratifying variable"
        }
      ]
    },
    "trap": {
      "type": "T8_SIMPSONS",
      "type_name": "T8 Simpsons",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Hard",
    "causal_structure": "Aggregate reverses within-segment pattern",
    "key_insight": "Model A tested more on easy segments, inflating overall accuracy.",
    "hidden_timestamp": "Are Models A and B tested on the same distribution of user segments?",
    "conditional_answers": {
      "condition_A": "If segment distributions differ: Simpson's paradox; Model B is actually better.",
      "condition_B": "If same distribution: Overall comparison valid."
    },
    "wise_refusal": "This is Simpson's paradox. Model A's higher overall accuracy results from being tested more on easier user segments. Within each segment, Model B is superior and should be chosen.",
    "gold_rationale": "The correct reasoning for this case involves understanding Aggregate reverses within-segment pattern. Model A tested more on easy segments, inflating overall accuracy.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-023",
    "case_id": "L2-023",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Data",
    "scenario": "Synthetic data training (X) shows higher overall test accuracy (Y) than real data. But for each domain, real data training is better.",
    "claim": "The causal relationship in 'The Training Data Paradox' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Data Type",
        "role": "Treatment"
      },
      "Y": {
        "name": "Test Accuracy",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Domain Distribution",
          "role": "Stratifying variable"
        }
      ]
    },
    "trap": {
      "type": "T8_SIMPSONS",
      "type_name": "T8 Simpsons",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Medium",
    "causal_structure": "Synthetic data overrepresents easy domains",
    "key_insight": "Overall metric misleads due to domain imbalance.",
    "hidden_timestamp": "Does synthetic data training cover more easy domains than real data?",
    "conditional_answers": {
      "condition_A": "If domain imbalance: Simpson's paradox; real data is better within domains.",
      "condition_B": "If domains balanced: Overall comparison valid."
    },
    "wise_refusal": "This is Simpson's paradox. Synthetic data's higher overall accuracy reflects testing on easier domains. Within each domain, real data training is superior.",
    "gold_rationale": "The correct reasoning for this case involves understanding Synthetic data overrepresents easy domains. Overall metric misleads due to domain imbalance.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-024",
    "case_id": "L2-024",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Alignment",
    "scenario": "RLHF training (X) reduces harmful outputs (Y). But RLHF also changes response length (M), which itself affects harm detection. Researcher attributes all benefit to RLHF directly.",
    "claim": "The causal relationship in 'The Mediated Safety Effect' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "RLHF Training",
        "role": "Treatment"
      },
      "Y": {
        "name": "Harmful Output Rate",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Response Length (M)",
          "role": "Mediator"
        }
      ]
    },
    "trap": {
      "type": "T9_CONF_MED",
      "type_name": "T9 Conf Med",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Easy",
    "causal_structure": "X -> M -> Y confounds direct effect",
    "key_insight": "Some harm reduction may be via shorter responses being less likely to contain harm.",
    "hidden_timestamp": "Does RLHF reduce harm directly or partly via changing response length?",
    "conditional_answers": {
      "condition_A": "If mediation via length: Part of effect is indirect, not alignment improvement.",
      "condition_B": "If length controlled: True alignment effect can be measured."
    },
    "wise_refusal": "This is confounded mediation. RLHF may reduce harm partly by shortening responses, which mechanically reduces harm opportunities. The direct alignment effect is smaller than the total observed effect.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> M -> Y confounds direct effect. Some harm reduction may be via shorter responses being less likely to contain harm.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-025",
    "case_id": "L2-025",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Safety",
    "scenario": "Better base capabilities (X) correlate with safer behavior (Y). A researcher concludes capability causes safety. But capability also enables better instruction-following (M).",
    "claim": "The causal relationship in 'The Capability-Safety Mediation' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Base Capabilities",
        "role": "Treatment"
      },
      "Y": {
        "name": "Safe Behavior",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Instruction Following (M)",
          "role": "Mediator"
        }
      ]
    },
    "trap": {
      "type": "T9_CONF_MED",
      "type_name": "T9 Conf Med",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Medium",
    "causal_structure": "Capability -> Instruction Following -> Safety",
    "key_insight": "Capability may cause safety only via enabling better instruction following.",
    "hidden_timestamp": "Does capability improve safety directly or only via improved instruction following?",
    "conditional_answers": {
      "condition_A": "If mediated via instruction following: Direct capability-safety link may be weak.",
      "condition_B": "If direct effect exists: Capability has intrinsic safety benefits."
    },
    "wise_refusal": "This conflates direct and indirect effects. Capability may improve safety primarily by enabling better instruction following, not through an intrinsic capability-safety link.",
    "gold_rationale": "The correct reasoning for this case involves understanding Capability -> Instruction Following -> Safety. Capability may cause safety only via enabling better instruction following.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-026",
    "case_id": "L2-026",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Product",
    "scenario": "Users who adopt AI assistants (X) are more productive (Y). Marketing claims AI assistants boost productivity.",
    "claim": "The causal relationship in 'The Reverse Causation in Adoption' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "AI Assistant Adoption",
        "role": "Observed behavior"
      },
      "Y": {
        "name": "Productivity",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Pre-existing productivity",
          "role": "Potential reverse cause"
        }
      ]
    },
    "trap": {
      "type": "T10_REVERSE",
      "type_name": "T10 Reverse",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Direction may be Y -> X",
    "key_insight": "Productive people may seek out AI tools; tools may not cause productivity.",
    "hidden_timestamp": "Were early adopters already more productive before using AI assistants?",
    "conditional_answers": {
      "condition_A": "If productive users adopt first: Reverse causation; productivity drives adoption.",
      "condition_B": "If adoption random: Forward causation more plausible."
    },
    "wise_refusal": "This may be reverse causation. Highly productive individuals may be more likely to adopt AI assistants. The association doesn't prove assistants cause productivity gains.",
    "gold_rationale": "The correct reasoning for this case involves understanding Direction may be Y -> X. Productive people may seek out AI tools; tools may not cause productivity.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-027",
    "case_id": "L2-027",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Open Source",
    "scenario": "ML libraries with more GitHub stars (X) have more contributors (Y). A maintainer concludes stars attract contributors.",
    "claim": "The causal relationship in 'The GitHub Stars Reversal' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "GitHub Stars",
        "role": "Observed metric"
      },
      "Y": {
        "name": "Contributors",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Library quality/utility",
          "role": "Common cause"
        }
      ]
    },
    "trap": {
      "type": "T10_REVERSE",
      "type_name": "T10 Reverse",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "May be Y -> X or Z -> both",
    "key_insight": "Contributors may cause stars, or quality may cause both.",
    "hidden_timestamp": "Do contributors boost visibility (stars), or do stars attract contributors?",
    "conditional_answers": {
      "condition_A": "If contributors drive visibility: Reverse causation; contributors cause stars.",
      "condition_B": "If quality drives both: Confounding rather than direct causation."
    },
    "wise_refusal": "The causal direction is unclear. Contributors may generate activity that attracts stars, or underlying library quality may drive both. Stars don't necessarily cause contributor growth.",
    "gold_rationale": "The correct reasoning for this case involves understanding May be Y -> X or Z -> both. Contributors may cause stars, or quality may cause both.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-028",
    "case_id": "L2-028",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Recommenders",
    "scenario": "Content recommended by the algorithm (X) gets more engagement (Y). The algorithm interprets this as evidence the content is good, recommending it more.",
    "claim": "The causal relationship in 'The Feedback Loop Detection' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Algorithm Recommendation",
        "role": "Intervention"
      },
      "Y": {
        "name": "Engagement",
        "role": "Outcome/Feedback"
      },
      "Z": [
        {
          "name": "Feedback loop",
          "role": "Cyclic mechanism"
        }
      ]
    },
    "trap": {
      "type": "T11_FEEDBACK",
      "type_name": "T11 Feedback",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "X -> Y -> X (feedback loop)",
    "key_insight": "Engagement is caused by recommendation, not content quality.",
    "hidden_timestamp": "Is engagement driven by recommendation exposure or intrinsic content quality?",
    "conditional_answers": {
      "condition_A": "If exposure-driven: Feedback loop creates self-fulfilling prophecy.",
      "condition_B": "If quality-driven: Engagement reflects true user preference."
    },
    "wise_refusal": "This is a feedback loop. The algorithm creates engagement by recommending content, then uses that engagement as evidence of quality. The loop is self-reinforcing, not validating.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y -> X (feedback loop). Engagement is caused by recommendation, not content quality.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-029",
    "case_id": "L2-029",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "ML Research",
    "scenario": "Popular models (X) get more research attention, finding more improvements (Y). Researchers conclude popular architectures are inherently better.",
    "claim": "The causal relationship in 'The Model Popularity Loop' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Model Popularity",
        "role": "Factor"
      },
      "Y": {
        "name": "Improvements Found",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Research attention feedback",
          "role": "Loop mechanism"
        }
      ]
    },
    "trap": {
      "type": "T11_FEEDBACK",
      "type_name": "T11 Feedback",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Popularity -> attention -> improvements -> popularity",
    "key_insight": "More research effort finds more improvements, regardless of inherent quality.",
    "hidden_timestamp": "Would unpopular architectures show similar improvements with equal research attention?",
    "conditional_answers": {
      "condition_A": "If attention-driven: Improvements reflect effort, not inherent superiority.",
      "condition_B": "If architecture-driven: Popular models are genuinely better research targets."
    },
    "wise_refusal": "This is a feedback loop. Popular models attract more research, finding more improvements, increasing popularity. The improvements may reflect research effort, not inherent architectural superiority.",
    "gold_rationale": "The correct reasoning for this case involves understanding Popularity -> attention -> improvements -> popularity. More research effort finds more improvements, regardless of inherent quality.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-030",
    "case_id": "L2-030",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "MLOps",
    "scenario": "A model was deployed (X), then user complaints increased (Y). The team rolls back the model, blaming it for complaints.",
    "claim": "The causal relationship in 'The Post-Deployment Failure' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Model Deployment",
        "role": "Preceding event"
      },
      "Y": {
        "name": "User Complaints",
        "role": "Subsequent event"
      },
      "Z": [
        {
          "name": "Other changes",
          "role": "Potential causes"
        }
      ]
    },
    "trap": {
      "type": "T12_TEMPORAL",
      "type_name": "T12 Temporal",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Temporal sequence without mechanism",
    "key_insight": "Post hoc ergo propter hoc fallacy.",
    "hidden_timestamp": "Were there other changes (UI, server, user base) concurrent with deployment?",
    "conditional_answers": {
      "condition_A": "If other changes occurred: Complaints may have other causes.",
      "condition_B": "If model change isolated: Causal attribution more justified."
    },
    "wise_refusal": "This commits the temporal fallacy. Complaints followed deployment, but other changes may have occurred simultaneously. Temporal sequence alone doesn't establish causation.",
    "gold_rationale": "The correct reasoning for this case involves understanding Temporal sequence without mechanism. Post hoc ergo propter hoc fallacy.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-031",
    "case_id": "L2-031",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Development",
    "scenario": "PyTorch updated (X), then training became unstable (Y). Engineers blame the update without checking their own recent code changes.",
    "claim": "The causal relationship in 'The Framework Update Blame' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Framework Update",
        "role": "Temporal predecessor"
      },
      "Y": {
        "name": "Training Instability",
        "role": "Subsequent event"
      },
      "Z": [
        {
          "name": "Code changes",
          "role": "Alternative cause"
        }
      ]
    },
    "trap": {
      "type": "T12_TEMPORAL",
      "type_name": "T12 Temporal",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Multiple changes in temporal window",
    "key_insight": "Framework update is salient but may not be the cause.",
    "hidden_timestamp": "Were there other code or config changes around the same time as the framework update?",
    "conditional_answers": {
      "condition_A": "If other changes present: Update may be blamed incorrectly.",
      "condition_B": "If update is only change: Causal attribution more plausible."
    },
    "wise_refusal": "This is temporal fallacy. The framework update is a salient event, but instability may have other causes. Without isolating the update's effect, causation is not established.",
    "gold_rationale": "The correct reasoning for this case involves understanding Multiple changes in temporal window. Framework update is salient but may not be the cause.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-032",
    "case_id": "L2-032",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "A benchmark (Y) shows Model (X) A beats Model B by 0.5%. The team declares A superior without considering measurement noise.",
    "claim": "The causal relationship in 'The Noisy Evaluation Metric' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Model Choice",
        "role": "Comparison"
      },
      "Y": {
        "name": "Benchmark Score",
        "role": "Measured outcome"
      },
      "Z": [
        {
          "name": "Measurement noise",
          "role": "Error source"
        }
      ]
    },
    "trap": {
      "type": "T13_MEASUREMENT",
      "type_name": "T13 Measurement",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Easy",
    "causal_structure": "Small difference may be within noise",
    "key_insight": "0.5% difference may not be statistically significant.",
    "hidden_timestamp": "Is the 0.5% difference larger than the benchmark's measurement error?",
    "conditional_answers": {
      "condition_A": "If within noise: Difference may be random; models may be equivalent.",
      "condition_B": "If exceeds noise: Difference is meaningful."
    },
    "wise_refusal": "This ignores measurement error. A 0.5% benchmark difference may be within noise. Without confidence intervals or significance tests, declaring superiority is premature.",
    "gold_rationale": "The correct reasoning for this case involves understanding Small difference may be within noise. 0.5% difference may not be statistically significant.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-033",
    "case_id": "L2-033",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "Users rate their AI literacy as high (X) and report high satisfaction with AI tools (Y). A company targets 'AI literate' users based on self-reports.",
    "claim": "The causal relationship in 'The Self-Reported Capability' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Self-Reported AI Literacy",
        "role": "Measured variable"
      },
      "Y": {
        "name": "Satisfaction",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Actual AI literacy",
          "role": "True variable"
        }
      ]
    },
    "trap": {
      "type": "T13_MEASUREMENT",
      "type_name": "T13 Measurement",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Medium",
    "causal_structure": "Self-report may not match reality",
    "key_insight": "Dunning-Kruger effect; self-assessment is poor measurement.",
    "hidden_timestamp": "Do self-reported AI literacy scores correlate with actual demonstrated skills?",
    "conditional_answers": {
      "condition_A": "If self-reports inaccurate: Targeting based on them is misguided.",
      "condition_B": "If self-reports valid: Strategy may work."
    },
    "wise_refusal": "This is measurement error. Self-reported AI literacy is notoriously inaccurate due to overconfidence. Targeting users based on self-reports may not reach the intended audience.",
    "gold_rationale": "The correct reasoning for this case involves understanding Self-report may not match reality. Dunning-Kruger effect; self-assessment is poor measurement.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-034",
    "case_id": "L2-034",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Data Collection",
    "scenario": "Researchers ask ML engineers to recall which debugging strategies worked on past projects (X). Engineers better remember strategies that eventually succeeded (Y).",
    "claim": "The causal relationship in 'The Retrospective Data Quality' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Recalled Strategy",
        "role": "Retrospective measure"
      },
      "Y": {
        "name": "Project Success",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Recall bias",
          "role": "Memory distortion"
        }
      ]
    },
    "trap": {
      "type": "T14_RECALL",
      "type_name": "T14 Recall",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Hard",
    "causal_structure": "Successful outcomes enhance recall of associated strategies",
    "key_insight": "Memory is biased toward successful outcomes.",
    "hidden_timestamp": "Are engineers' memories of debugging strategies influenced by eventual project outcomes?",
    "conditional_answers": {
      "condition_A": "If recall biased by success: Retrospective data overestimates strategy effectiveness.",
      "condition_B": "If recall unbiased: Data more reliable."
    },
    "wise_refusal": "This is recall bias. Engineers better remember strategies associated with success. Retrospective studies overestimate the effectiveness of strategies that happened to precede good outcomes.",
    "gold_rationale": "The correct reasoning for this case involves understanding Successful outcomes enhance recall of associated strategies. Memory is biased toward successful outcomes.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-035",
    "case_id": "L2-035",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Safety",
    "scenario": "After an AI incident, users recall warning signs they 'noticed' beforehand (X). Investigators conclude warnings were ignored (Y).",
    "claim": "The causal relationship in 'The Incident Report Bias' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Recalled Warnings",
        "role": "Retrospective report"
      },
      "Y": {
        "name": "Ignored Warning Conclusion",
        "role": "Investigation finding"
      },
      "Z": [
        {
          "name": "Hindsight bias",
          "role": "Memory distortion"
        }
      ]
    },
    "trap": {
      "type": "T14_RECALL",
      "type_name": "T14 Recall",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Medium",
    "causal_structure": "Outcome knowledge distorts memory of prior observations",
    "key_insight": "Hindsight makes past 'warnings' seem more obvious than they were.",
    "hidden_timestamp": "Did users actually notice and document warnings before the incident?",
    "conditional_answers": {
      "condition_A": "If recall distorted by hindsight: Warnings may be reconstructed memories.",
      "condition_B": "If documented before incident: Warnings were genuinely present."
    },
    "wise_refusal": "This is recall bias amplified by hindsight. After an incident, people 'remember' warning signs that may not have been salient beforehand. Retrospective reports overstate how predictable the incident was.",
    "gold_rationale": "The correct reasoning for this case involves understanding Outcome knowledge distorts memory of prior observations. Hindsight makes past 'warnings' seem more obvious than they were.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-036",
    "case_id": "L2-036",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Interpretability",
    "scenario": "Researchers find attention patterns that correlate with correct answers (X). They claim attention 'explains' model reasoning (Y).",
    "claim": "The causal relationship in 'The Mechanistic Misunderstanding' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Attention Patterns",
        "role": "Observed feature"
      },
      "Y": {
        "name": "Model Reasoning",
        "role": "Claimed explanation"
      },
      "Z": [
        {
          "name": "True computation",
          "role": "Hidden mechanism"
        }
      ]
    },
    "trap": {
      "type": "T15_MECHANISM",
      "type_name": "T15 Mechanism",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Easy",
    "causal_structure": "Attention may be epiphenomenal",
    "key_insight": "Correlation between attention and output doesn't prove attention is causal.",
    "hidden_timestamp": "Does manipulating attention change outputs, or is attention just correlated with reasoning?",
    "conditional_answers": {
      "condition_A": "If attention epiphenomenal: Patterns explain nothing about reasoning.",
      "condition_B": "If attention causally necessary: Manipulation would change outputs."
    },
    "wise_refusal": "This conflates correlation with mechanism. Attention patterns correlating with correct answers doesn't mean attention 'explains' reasoning. The true computation may happen elsewhere.",
    "gold_rationale": "The correct reasoning for this case involves understanding Attention may be epiphenomenal. Correlation between attention and output doesn't prove attention is causal.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-037",
    "case_id": "L2-037",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Interpretability",
    "scenario": "Researchers identify a 'circuit' for a behavior by finding correlated activations (X). They claim to have found the mechanism (Y).",
    "claim": "The causal relationship in 'The Spurious Circuit' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Identified Circuit",
        "role": "Observed pattern"
      },
      "Y": {
        "name": "Claimed Mechanism",
        "role": "Explanation"
      },
      "Z": [
        {
          "name": "True causal structure",
          "role": "Hidden"
        }
      ]
    },
    "trap": {
      "type": "T15_MECHANISM",
      "type_name": "T15 Mechanism",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Hard",
    "causal_structure": "Correlation-based circuits may be spurious",
    "key_insight": "Circuit identification requires causal intervention, not just correlation.",
    "hidden_timestamp": "Does ablating the circuit eliminate the behavior, and does activating it induce the behavior?",
    "conditional_answers": {
      "condition_A": "If ablation/activation test fails: Circuit is spurious correlation.",
      "condition_B": "If interventions work: Circuit is causally involved."
    },
    "wise_refusal": "This mistakes correlation for mechanism. Identifying correlated activations doesn't establish a causal circuit. Without ablation and activation experiments, the 'circuit' may be spurious.",
    "gold_rationale": "The correct reasoning for this case involves understanding Correlation-based circuits may be spurious. Circuit identification requires causal intervention, not just correlation.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-038",
    "case_id": "L2-038",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Recommenders",
    "scenario": "A recommender optimizes click-through rate (CTR (Y)). It learns to use clickbait (X) titles that users regret clicking.",
    "claim": "The causal relationship in 'The Click-Through Goodhart' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Clickbait Optimization",
        "role": "Intervention"
      },
      "Y": {
        "name": "CTR",
        "role": "Proxy metric"
      },
      "Z": [
        {
          "name": "User Satisfaction",
          "role": "True goal"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Easy",
    "causal_structure": "X -> Y but X -> -Z",
    "key_insight": "CTR is proxy that can be gamed at expense of satisfaction.",
    "hidden_timestamp": "Are users satisfied after clicking, or do they regret the click?",
    "conditional_answers": {
      "condition_A": "If regret common: CTR optimization hurts user welfare.",
      "condition_B": "If satisfaction high: CTR may align with true goal."
    },
    "wise_refusal": "This is Goodhart's law. Optimizing CTR incentivizes clickbait that increases clicks but decreases satisfaction. The proxy metric diverges from the true goal under optimization.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y but X -> -Z. CTR is proxy that can be gamed at expense of satisfaction.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-039",
    "case_id": "L2-039",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "A model is fine-tuned to maximize benchmark (Y) (X) scores. It learns benchmark-specific patterns that don't generalize.",
    "claim": "The causal relationship in 'The Test Score Optimization' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Benchmark Fine-Tuning",
        "role": "Intervention"
      },
      "Y": {
        "name": "Benchmark Score",
        "role": "Proxy metric"
      },
      "Z": [
        {
          "name": "General Capability",
          "role": "True goal"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "Optimizing Y can hurt Z",
    "key_insight": "Benchmark overfitting breaks the proxy-goal relationship.",
    "hidden_timestamp": "Does the benchmark improvement transfer to held-out tasks?",
    "conditional_answers": {
      "condition_A": "If no transfer: Fine-tuning gamed the benchmark.",
      "condition_B": "If transfer observed: Improvement may be genuine."
    },
    "wise_refusal": "This is Goodhart's law applied to benchmarks. Fine-tuning on benchmark data can inflate scores without improving general capability. The benchmark stops measuring what it was designed to measure.",
    "gold_rationale": "The correct reasoning for this case involves understanding Optimizing Y can hurt Z. Benchmark overfitting breaks the proxy-goal relationship.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-040",
    "case_id": "L2-040",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Alignment",
    "scenario": "Adding more safety training (X) causes models to refuse benign requests (Y), making users seek jailbreaks (Z), ultimately reducing safety.",
    "claim": "The causal relationship in 'The Alignment Tax Backfire' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Excessive Safety Training",
        "role": "Intervention"
      },
      "Y": {
        "name": "Benign Refusals",
        "role": "Direct effect"
      },
      "Z": [
        {
          "name": "Jailbreak Seeking",
          "role": "Backfire mechanism"
        }
      ]
    },
    "trap": {
      "type": "T17_BACKFIRE",
      "type_name": "T17 Backfire",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Hard",
    "causal_structure": "X -> Y -> Z -> reduced safety",
    "key_insight": "Overtraining safety can backfire via user behavior change.",
    "hidden_timestamp": "Does excessive safety training increase jailbreak attempts?",
    "conditional_answers": {
      "condition_A": "If jailbreaks increase: Safety training backfired.",
      "condition_B": "If jailbreaks stable: Direct safety benefit may outweigh."
    },
    "wise_refusal": "This is a backfire effect. Excessive safety training causes annoying refusals, pushing users toward jailbreaks. The intervention may reduce net safety by changing user behavior.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y -> Z -> reduced safety. Overtraining safety can backfire via user behavior change.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-041",
    "case_id": "L2-041",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Content Moderation",
    "scenario": "Strict content filters (X) cause users to migrate to unmoderated platforms (Y), increasing their exposure to harmful content (Z).",
    "claim": "The causal relationship in 'The Content Moderation Backfire' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Strict Content Filters",
        "role": "Intervention"
      },
      "Y": {
        "name": "Platform Migration",
        "role": "Behavioral response"
      },
      "Z": [
        {
          "name": "Harmful Content Exposure",
          "role": "Backfire outcome"
        }
      ]
    },
    "trap": {
      "type": "T17_BACKFIRE",
      "type_name": "T17 Backfire",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "X -> Y -> increased Z",
    "key_insight": "Filtering can push users to worse environments.",
    "hidden_timestamp": "Do users who encounter filters migrate to unmoderated platforms?",
    "conditional_answers": {
      "condition_A": "If migration common: Filtering backfires by pushing users to worse content.",
      "condition_B": "If users stay: Filtering may reduce harm exposure."
    },
    "wise_refusal": "This is a backfire effect. Strict content filters can push users to unmoderated platforms where they encounter more harmful content. The intervention may increase net harm.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y -> increased Z. Filtering can push users to worse environments.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-042",
    "case_id": "L2-042",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "ML Practice",
    "scenario": "Models trained on datasets with test leakage (X) show higher accuracy (Y). A team adopts these datasets, claiming superior methodology.",
    "claim": "The causal relationship in 'The Dataset Leakage Selection' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Leaked Dataset",
        "role": "Training choice"
      },
      "Y": {
        "name": "Test Accuracy",
        "role": "Metric"
      },
      "Z": [
        {
          "name": "True Generalization",
          "role": "Latent goal"
        }
      ]
    },
    "trap": {
      "type": "T1_SELECTION",
      "type_name": "T1 Selection",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Leakage inflates Y without improving Z",
    "key_insight": "Selection of leaked datasets creates false performance signals.",
    "hidden_timestamp": "Does the training data contain information from the test set?",
    "conditional_answers": {
      "condition_A": "If leakage present: High accuracy is artifact, not true capability.",
      "condition_B": "If no leakage: Performance may reflect genuine learning."
    },
    "wise_refusal": "This is selection bias via data leakage. High accuracy on leaked datasets doesn't indicate true generalization. The team selected on a misleading metric.",
    "gold_rationale": "The correct reasoning for this case involves understanding Leakage inflates Y without improving Z. Selection of leaked datasets creates false performance signals.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-043",
    "case_id": "L2-043",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Research",
    "scenario": "Published (X) ML papers show positive results (Y). A researcher concludes most ML experiments succeed based on the literature.",
    "claim": "The causal relationship in 'The Publication Survivor' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Published Papers",
        "role": "Observed sample"
      },
      "Y": {
        "name": "Positive Results",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Unpublished Failures",
          "role": "Missing data"
        }
      ]
    },
    "trap": {
      "type": "T2_SURVIVORSHIP",
      "type_name": "T2 Survivorship",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Publication filters to positive results",
    "key_insight": "File drawer problem hides failed experiments.",
    "hidden_timestamp": "How many experiments failed but were never published?",
    "conditional_answers": {
      "condition_A": "If publication bias strong: Literature overrepresents success.",
      "condition_B": "If negative results published: Literature more representative."
    },
    "wise_refusal": "This is survivorship bias in publishing. Only positive results get published. The literature drastically overrepresents success rates of ML experiments.",
    "gold_rationale": "The correct reasoning for this case involves understanding Publication filters to positive results. File drawer problem hides failed experiments.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-044",
    "case_id": "L2-044",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Product",
    "scenario": "An AI company showcases customer success stories (X). Prospects conclude the API works for everyone (Y).",
    "claim": "The causal relationship in 'The API Success Stories' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Success Stories",
        "role": "Marketing sample"
      },
      "Y": {
        "name": "Perceived Reliability",
        "role": "Inference"
      },
      "Z": [
        {
          "name": "Failed Implementations",
          "role": "Hidden failures"
        }
      ]
    },
    "trap": {
      "type": "T2_SURVIVORSHIP",
      "type_name": "T2 Survivorship",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "Marketing selects on success",
    "key_insight": "Failed customers don't become case studies.",
    "hidden_timestamp": "How many customers failed to successfully implement the API?",
    "conditional_answers": {
      "condition_A": "If many failures hidden: Success rate is overestimated.",
      "condition_B": "If failures rare: Case studies may be representative."
    },
    "wise_refusal": "This is survivorship bias in marketing. Companies showcase successes, not failures. The case studies don't represent the full distribution of customer outcomes.",
    "gold_rationale": "The correct reasoning for this case involves understanding Marketing selects on success. Failed customers don't become case studies.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-045",
    "case_id": "L2-045",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Infrastructure",
    "scenario": "Among production ML systems, cost (X) and latency (Y) appear positively correlated. An engineer concludes low-latency systems must be expensive.",
    "claim": "The causal relationship in 'The Hardware Collider' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Cost",
        "role": "Factor 1"
      },
      "Y": {
        "name": "Latency",
        "role": "Factor 2"
      },
      "Z": [
        {
          "name": "Production Deployment (Collider)",
          "role": "Selection criterion"
        }
      ]
    },
    "trap": {
      "type": "T3_COLLIDER",
      "type_name": "T3 Collider",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Systems deployed if cheap OR fast; collider bias",
    "key_insight": "Production requires meeting threshold on either dimension.",
    "hidden_timestamp": "Are systems deployed based on being either cheap or fast?",
    "conditional_answers": {
      "condition_A": "If either suffices for deployment: Collider bias creates spurious correlation.",
      "condition_B": "If both required: Unconditional relationship may differ."
    },
    "wise_refusal": "This is collider bias. Systems are deployed if cheap OR fast. Conditioning on production creates spurious positive correlation between cost and latency.",
    "gold_rationale": "The correct reasoning for this case involves understanding Systems deployed if cheap OR fast; collider bias. Production requires meeting threshold on either dimension.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-046",
    "case_id": "L2-046",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Resource Management",
    "scenario": "Projects with 6+ months GPU allocation (X) have more publications (Y). Management concludes longer allocations cause more output.",
    "claim": "The causal relationship in 'The GPU Allocation Immortality' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Long GPU Allocation",
        "role": "Exposure"
      },
      "Y": {
        "name": "Publications",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Project Survival",
          "role": "Immortal time bias"
        }
      ]
    },
    "trap": {
      "type": "T4_IMMORTAL_TIME",
      "type_name": "T4 Immortal Time",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "To have long allocation, must not have failed",
    "key_insight": "Successful projects survive to long allocation periods.",
    "hidden_timestamp": "Do projects with 6+ months allocation continue because they're already succeeding?",
    "conditional_answers": {
      "condition_A": "If survival required: Long allocation is effect of success, not cause.",
      "condition_B": "If allocation random: Causal effect could be tested."
    },
    "wise_refusal": "This is immortal time bias. Projects with 6+ month allocations didn't get cancelled; they were already producing results. Long allocation is a consequence of success, not its cause.",
    "gold_rationale": "The correct reasoning for this case involves understanding To have long allocation, must not have failed. Successful projects survive to long allocation periods.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-047",
    "case_id": "L2-047",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Prompt Engineering",
    "scenario": "Prompts selected for exceptional first-run performance (X) show average results on replication (Y). Engineers blame model non-determinism.",
    "claim": "The causal relationship in 'The Prompt Length Regression' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Exceptional First Run",
        "role": "Selection criterion"
      },
      "Y": {
        "name": "Replication Performance",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Random variance",
          "role": "Source of extreme"
        }
      ]
    },
    "trap": {
      "type": "T5_REGRESSION",
      "type_name": "T5 Regression",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Hard",
    "causal_structure": "Selection on extremes leads to regression",
    "key_insight": "First-run outliers include positive noise.",
    "hidden_timestamp": "Were prompts selected based on unusually good initial results?",
    "conditional_answers": {
      "condition_A": "If selected on extremes: Regression to mean expected, not non-determinism.",
      "condition_B": "If random selection: Performance drop would indicate instability."
    },
    "wise_refusal": "This is regression to the mean. Prompts selected for exceptional first-run results included positive noise. Replication regression is expected, not evidence of model instability.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection on extremes leads to regression. First-run outliers include positive noise.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-048",
    "case_id": "L2-048",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Policy",
    "scenario": "Regions with higher AI adoption have higher productivity (X). A policy advisor recommends individual firms adopt AI to boost productivity (Y).",
    "claim": "The causal relationship in 'The Regional AI Adoption Fallacy' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Regional AI Adoption",
        "role": "Aggregate measure"
      },
      "Y": {
        "name": "Regional Productivity",
        "role": "Aggregate outcome"
      },
      "Z": [
        {
          "name": "Firm-level variation",
          "role": "Hidden heterogeneity"
        }
      ]
    },
    "trap": {
      "type": "T6_ECOLOGICAL",
      "type_name": "T6 Ecological",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Hard",
    "causal_structure": "Regional pattern may not hold at firm level",
    "key_insight": "High-productivity regions may adopt AI, not vice versa.",
    "hidden_timestamp": "Does AI adoption increase productivity at the firm level?",
    "conditional_answers": {
      "condition_A": "If regional pattern doesn't hold at firm level: Policy advice is flawed.",
      "condition_B": "If firm-level confirms: Advice may be valid."
    },
    "wise_refusal": "This is the ecological fallacy. Regional correlations don't imply firm-level causation. Productive regions may adopt AI more, rather than AI causing productivity.",
    "gold_rationale": "The correct reasoning for this case involves understanding Regional pattern may not hold at firm level. High-productivity regions may adopt AI, not vice versa.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-049",
    "case_id": "L2-049",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Scaling",
    "scenario": "Larger models (X) have better safety scores (Y). A researcher concludes scale causes safety.",
    "claim": "The causal relationship in 'The Model Size Confounder' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Model Size",
        "role": "Factor"
      },
      "Y": {
        "name": "Safety Score",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Training Effort/RLHF Investment",
          "role": "Confounder"
        }
      ]
    },
    "trap": {
      "type": "T7_CONFOUNDER",
      "type_name": "T7 Confounder",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Medium",
    "causal_structure": "Large models get more safety investment",
    "key_insight": "Size correlates with safety effort, confounding the relationship.",
    "hidden_timestamp": "Do larger models receive more RLHF and safety training?",
    "conditional_answers": {
      "condition_A": "If safety investment differs: Size effect confounded by effort.",
      "condition_B": "If effort controlled: True scale effect could be measured."
    },
    "wise_refusal": "This is confounding. Larger models receive more safety training and RLHF investment. The safety improvement may reflect effort rather than intrinsic scale benefits.",
    "gold_rationale": "The correct reasoning for this case involves understanding Large models get more safety investment. Size correlates with safety effort, confounding the relationship.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-050",
    "case_id": "L2-050",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "Model (X) A beats Model B on average (Y) across languages. But in each individual language, Model B wins. Team deploys Model A globally.",
    "claim": "The causal relationship in 'The Simpson's Benchmark' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Model Choice",
        "role": "Decision"
      },
      "Y": {
        "name": "Average Performance",
        "role": "Aggregate metric"
      },
      "Z": [
        {
          "name": "Language Distribution",
          "role": "Stratifying variable"
        }
      ]
    },
    "trap": {
      "type": "T8_SIMPSONS",
      "type_name": "T8 Simpsons",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Easy",
    "causal_structure": "Aggregate reverses within-language pattern",
    "key_insight": "Model A tested more on languages it's relatively better at.",
    "hidden_timestamp": "Are models tested on the same language distribution?",
    "conditional_answers": {
      "condition_A": "If distribution differs: Simpson's paradox; Model B is better.",
      "condition_B": "If same distribution: Comparison valid."
    },
    "wise_refusal": "This is Simpson's paradox. Model A's higher average reflects being tested more on languages where its disadvantage is smaller. Model B is superior in every language.",
    "gold_rationale": "The correct reasoning for this case involves understanding Aggregate reverses within-language pattern. Model A tested more on languages it's relatively better at.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-051",
    "case_id": "L2-051",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Transfer Learning",
    "scenario": "Fine-tuned models (X) show better task performance (Y). But fine-tuning also changes model confidence (M), which affects evaluation metrics.",
    "claim": "The causal relationship in 'The Confounded Fine-Tuning' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Fine-Tuning",
        "role": "Treatment"
      },
      "Y": {
        "name": "Task Performance",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Confidence Calibration (M)",
          "role": "Mediator"
        }
      ]
    },
    "trap": {
      "type": "T9_CONF_MED",
      "type_name": "T9 Conf Med",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Medium",
    "causal_structure": "X -> M -> Y confounds direct effect",
    "key_insight": "Performance gain may be partly via confidence changes affecting metric.",
    "hidden_timestamp": "Does fine-tuning improve task capability or just change confidence calibration?",
    "conditional_answers": {
      "condition_A": "If mediated by confidence: Some improvement is metric artifact.",
      "condition_B": "If direct capability gain: Fine-tuning genuinely improves task ability."
    },
    "wise_refusal": "This conflates direct and indirect effects. Fine-tuning may improve metrics partly by changing confidence calibration, not just task capability.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> M -> Y confounds direct effect. Performance gain may be partly via confidence changes affecting metric.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-052",
    "case_id": "L2-052",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Product Analytics",
    "scenario": "Heavy API users (X) report higher productivity (Y). The company concludes their API boosts productivity.",
    "claim": "The causal relationship in 'The Reverse API Usage' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "API Usage",
        "role": "Observed behavior"
      },
      "Y": {
        "name": "Productivity",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Pre-existing productivity",
          "role": "Potential reverse cause"
        }
      ]
    },
    "trap": {
      "type": "T10_REVERSE",
      "type_name": "T10 Reverse",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "May be Y -> X",
    "key_insight": "Productive developers may naturally use more tools.",
    "hidden_timestamp": "Were heavy users already more productive before API adoption?",
    "conditional_answers": {
      "condition_A": "If productivity precedes usage: Reverse causation.",
      "condition_B": "If usage precedes productivity gain: Forward causation plausible."
    },
    "wise_refusal": "This may be reverse causation. Highly productive developers may adopt more tools. The API may not be causing productivity.",
    "gold_rationale": "The correct reasoning for this case involves understanding May be Y -> X. Productive developers may naturally use more tools.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-053",
    "case_id": "L2-053",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Data Collection",
    "scenario": "Model outputs (X) are used as training data for the next version. The new model scores higher on consistency (Y), but it's just learning to mimic itself.",
    "claim": "The causal relationship in 'The Training Data Feedback' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Model Output as Training Data",
        "role": "Intervention"
      },
      "Y": {
        "name": "Consistency Score",
        "role": "Metric"
      },
      "Z": [
        {
          "name": "Model collapse feedback",
          "role": "Loop mechanism"
        }
      ]
    },
    "trap": {
      "type": "T11_FEEDBACK",
      "type_name": "T11 Feedback",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "X -> Y -> X feedback loop",
    "key_insight": "Self-training creates consistency without diversity or correctness.",
    "hidden_timestamp": "Is improved consistency genuine quality or self-reinforcing bias?",
    "conditional_answers": {
      "condition_A": "If self-training: Consistency is model collapse, not quality.",
      "condition_B": "If diverse training data: Consistency may reflect genuine improvement."
    },
    "wise_refusal": "This is a feedback loop. Training on model outputs creates consistency by self-reinforcement, not genuine quality improvement. Model collapse is the risk.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y -> X feedback loop. Self-training creates consistency without diversity or correctness.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-054",
    "case_id": "L2-054",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "MLOps",
    "scenario": "After updating the ML library (X), model accuracy improved (Y). The team credits the library update without checking dataset changes.",
    "claim": "The causal relationship in 'The Library Update Fallacy' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Library Update",
        "role": "Temporal predecessor"
      },
      "Y": {
        "name": "Accuracy Improvement",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Dataset refresh",
          "role": "Alternative cause"
        }
      ]
    },
    "trap": {
      "type": "T12_TEMPORAL",
      "type_name": "T12 Temporal",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "Multiple changes in temporal window",
    "key_insight": "Library update coincided with other changes.",
    "hidden_timestamp": "Were there other changes like data updates around the same time?",
    "conditional_answers": {
      "condition_A": "If other changes present: Library may not be the cause.",
      "condition_B": "If library is only change: Causal attribution more plausible."
    },
    "wise_refusal": "This is temporal fallacy. The library update coincided with other changes. Without isolation, the accuracy improvement cannot be attributed to the library.",
    "gold_rationale": "The correct reasoning for this case involves understanding Multiple changes in temporal window. Library update coincided with other changes.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-055",
    "case_id": "L2-055",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "A leaderboard ranks models by BLEU score (X). Teams optimize for BLEU, achieving high scores (Y) while human evaluation shows no improvement.",
    "claim": "The causal relationship in 'The Leaderboard Measurement' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "BLEU Optimization",
        "role": "Intervention"
      },
      "Y": {
        "name": "BLEU Score",
        "role": "Measured outcome"
      },
      "Z": [
        {
          "name": "Translation quality",
          "role": "True variable"
        }
      ]
    },
    "trap": {
      "type": "T13_MEASUREMENT",
      "type_name": "T13 Measurement",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Hard",
    "causal_structure": "Y is poor measure of Z",
    "key_insight": "BLEU can be gamed without improving actual translation quality.",
    "hidden_timestamp": "Does BLEU score improvement correlate with human quality judgments?",
    "conditional_answers": {
      "condition_A": "If BLEU-human correlation weak: Measurement is flawed.",
      "condition_B": "If correlation strong: BLEU may be reasonable proxy."
    },
    "wise_refusal": "This is measurement error. BLEU score is a flawed proxy for translation quality. Optimizing it directly can improve scores without improving actual translations.",
    "gold_rationale": "The correct reasoning for this case involves understanding Y is poor measure of Z. BLEU can be gamed without improving actual translation quality.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-056",
    "case_id": "L2-056",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "UX Research",
    "scenario": "Users asked about AI assistant errors (X) report more errors for tools they dislike (Y). Researchers conclude disliked tools have more errors.",
    "claim": "The causal relationship in 'The User Survey Recall' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Recalled Errors",
        "role": "Retrospective measure"
      },
      "Y": {
        "name": "Tool Preference",
        "role": "Attitude"
      },
      "Z": [
        {
          "name": "Recall bias",
          "role": "Memory distortion"
        }
      ]
    },
    "trap": {
      "type": "T14_RECALL",
      "type_name": "T14 Recall",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Easy",
    "causal_structure": "Dislike enhances error recall",
    "key_insight": "Negative attitude makes errors more memorable.",
    "hidden_timestamp": "Do users recall errors differently based on their tool preferences?",
    "conditional_answers": {
      "condition_A": "If recall biased by preference: Error reports reflect attitude, not reality.",
      "condition_B": "If recall unbiased: Error differences may be real."
    },
    "wise_refusal": "This is recall bias. Users remember errors more for tools they dislike. The reported error rates reflect attitudes, not actual error frequencies.",
    "gold_rationale": "The correct reasoning for this case involves understanding Dislike enhances error recall. Negative attitude makes errors more memorable.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-057",
    "case_id": "L2-057",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Interpretability",
    "scenario": "Researchers find feature F correlates with behavior B (X). They claim F 'controls' B (Y) without ablation experiments.",
    "claim": "The causal relationship in 'The Interpretability Mechanism' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Feature-Behavior Correlation",
        "role": "Observation"
      },
      "Y": {
        "name": "Claimed Control",
        "role": "Interpretation"
      },
      "Z": [
        {
          "name": "True causal mechanism",
          "role": "Unknown"
        }
      ]
    },
    "trap": {
      "type": "T15_MECHANISM",
      "type_name": "T15 Mechanism",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "Correlation doesn't establish control",
    "key_insight": "Control claims require intervention experiments.",
    "hidden_timestamp": "Does manipulating F change B?",
    "conditional_answers": {
      "condition_A": "If ablation fails: F doesn't control B.",
      "condition_B": "If ablation succeeds: Causal control established."
    },
    "wise_refusal": "This mistakes correlation for control. Without ablation or activation experiments, the claim that F controls B is unsubstantiated.",
    "gold_rationale": "The correct reasoning for this case involves understanding Correlation doesn't establish control. Control claims require intervention experiments.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketLarge-I-L2-058",
    "case_id": "L2-058",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Training",
    "scenario": "A model optimizes cross-entropy loss (X) to near-zero. It achieves this by memorizing training data (Y) rather than generalizing.",
    "claim": "The causal relationship in 'The Loss Goodhart' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Loss Optimization",
        "role": "Intervention"
      },
      "Y": {
        "name": "Low Training Loss",
        "role": "Proxy metric"
      },
      "Z": [
        {
          "name": "Generalization",
          "role": "True goal"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Hard",
    "causal_structure": "X -> Y but X -> -Z",
    "key_insight": "Training loss can be minimized without generalization.",
    "hidden_timestamp": "Does low training loss correspond to good test performance?",
    "conditional_answers": {
      "condition_A": "If memorization: Low loss without generalization.",
      "condition_B": "If proper learning: Loss correlates with generalization."
    },
    "wise_refusal": "This is Goodhart's law. Minimizing training loss can be achieved by memorization. Low loss doesn't guarantee generalization.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y but X -> -Z. Training loss can be minimized without generalization.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-059",
    "case_id": "L2-059",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "AI Ethics",
    "scenario": "Publishing model details for transparency (X) enables adversaries to craft attacks (Y), reducing overall safety (Z).",
    "claim": "The causal relationship in 'The Transparency Backfire' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Transparency Publication",
        "role": "Intervention"
      },
      "Y": {
        "name": "Adversarial Attack Development",
        "role": "Indirect effect"
      },
      "Z": [
        {
          "name": "Overall Safety",
          "role": "Outcome"
        }
      ]
    },
    "trap": {
      "type": "T17_BACKFIRE",
      "type_name": "T17 Backfire",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Easy",
    "causal_structure": "X -> Y -> -Z",
    "key_insight": "Transparency can enable attacks.",
    "hidden_timestamp": "Does publishing details help attackers more than defenders?",
    "conditional_answers": {
      "condition_A": "If attackers benefit more: Transparency backfires.",
      "condition_B": "If defenders benefit: Transparency improves safety."
    },
    "wise_refusal": "This is a backfire effect. Transparency intended to improve safety can enable adversaries to develop more effective attacks, reducing net safety.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y -> -Z. Transparency can enable attacks.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-060",
    "case_id": "L2-060",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "A company runs models on 50 benchmarks but only reports the 10 where their model leads (X), claiming state-of-the-art (Y).",
    "claim": "The causal relationship in 'The Benchmark Selection' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Selective Benchmark Reporting",
        "role": "Selection"
      },
      "Y": {
        "name": "SOTA Claim",
        "role": "Conclusion"
      },
      "Z": [
        {
          "name": "Unreported benchmarks",
          "role": "Missing data"
        }
      ]
    },
    "trap": {
      "type": "T1_SELECTION",
      "type_name": "T1 Selection",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "Selection creates misleading impression",
    "key_insight": "Cherry-picking inflates apparent performance.",
    "hidden_timestamp": "How does the model perform on unreported benchmarks?",
    "conditional_answers": {
      "condition_A": "If poor on others: SOTA claim is misleading.",
      "condition_B": "If consistent performance: Claim may be valid."
    },
    "wise_refusal": "This is selection bias in reporting. Showing only favorable benchmarks creates a false impression of state-of-the-art performance.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection creates misleading impression. Cherry-picking inflates apparent performance.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-061",
    "case_id": "L2-061",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Startups",
    "scenario": "AI startups presenting at demo day (X) have high success rates (Y). Investors conclude demo day presence predicts success.",
    "claim": "The causal relationship in 'The Demo Day Survivor' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Demo Day Presentation",
        "role": "Observed factor"
      },
      "Y": {
        "name": "Success Rate",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Pre-demo selection",
          "role": "Survivorship filter"
        }
      ]
    },
    "trap": {
      "type": "T2_SURVIVORSHIP",
      "type_name": "T2 Survivorship",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Only pre-selected companies present",
    "key_insight": "Demo day participants are already filtered for quality.",
    "hidden_timestamp": "Were presenting companies already selected for high potential?",
    "conditional_answers": {
      "condition_A": "If pre-selected: Success rate reflects selection, not demo effect.",
      "condition_B": "If random: Demo day might add value."
    },
    "wise_refusal": "This is survivorship bias. Demo day presenters are pre-selected for quality. Their success reflects selection, not the demo day itself.",
    "gold_rationale": "The correct reasoning for this case involves understanding Only pre-selected companies present. Demo day participants are already filtered for quality.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-062",
    "case_id": "L2-062",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "HR Analytics",
    "scenario": "Among hired ML engineers, coding skill (X) and communication skill (Y) appear negatively correlated. HR concludes technical people lack soft skills.",
    "claim": "The causal relationship in 'The Hiring Collider' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Coding Skill",
        "role": "Factor 1"
      },
      "Y": {
        "name": "Communication Skill",
        "role": "Factor 2"
      },
      "Z": [
        {
          "name": "Hiring (Collider)",
          "role": "Selection criterion"
        }
      ]
    },
    "trap": {
      "type": "T3_COLLIDER",
      "type_name": "T3 Collider",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Either skill can get you hired; collider bias",
    "key_insight": "Conditioning on hiring creates spurious negative correlation.",
    "hidden_timestamp": "Are candidates hired if strong in either coding or communication?",
    "conditional_answers": {
      "condition_A": "If either suffices: Collider bias creates apparent tradeoff.",
      "condition_B": "If both required: Correlation may be real."
    },
    "wise_refusal": "This is collider bias. Candidates are hired if strong in coding OR communication. Among hires, these skills appear negatively correlated, but the tradeoff is spurious.",
    "gold_rationale": "The correct reasoning for this case involves understanding Either skill can get you hired; collider bias. Conditioning on hiring creates spurious negative correlation.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-063",
    "case_id": "L2-063",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Research",
    "scenario": "Research groups with continuous funding for 5+ years (X) have more citations (Y). Conclusion: long-term funding causes impact.",
    "claim": "The causal relationship in 'The Funding Immortality' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Long-Term Funding",
        "role": "Exposure"
      },
      "Y": {
        "name": "Citations",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Research success enabling continued funding",
          "role": "Immortal time bias"
        }
      ]
    },
    "trap": {
      "type": "T4_IMMORTAL_TIME",
      "type_name": "T4 Immortal Time",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Continued funding requires not failing",
    "key_insight": "Productive groups survive to have long funding.",
    "hidden_timestamp": "Did groups maintain funding because they were already productive?",
    "conditional_answers": {
      "condition_A": "If survival-dependent: Long funding is effect of success.",
      "condition_B": "If funding random: Causal effect testable."
    },
    "wise_refusal": "This is immortal time bias. Groups with 5+ years funding didn't lose funding; they were already productive. Long funding is consequence of impact, not its cause.",
    "gold_rationale": "The correct reasoning for this case involves understanding Continued funding requires not failing. Productive groups survive to have long funding.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-064",
    "case_id": "L2-064",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "AutoML",
    "scenario": "Hyperparameters that gave best validation scores (X) perform worse on test set (Y). Engineers blame overfitting.",
    "claim": "The causal relationship in 'The Hyperparameter Regression' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Best Validation HP",
        "role": "Selection"
      },
      "Y": {
        "name": "Test Performance",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Validation noise",
          "role": "Source of extreme"
        }
      ]
    },
    "trap": {
      "type": "T5_REGRESSION",
      "type_name": "T5 Regression",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Easy",
    "causal_structure": "Selection on extreme includes noise",
    "key_insight": "Best validation HPs include favorable noise that won't repeat.",
    "hidden_timestamp": "Did best validation HPs include positive random variance?",
    "conditional_answers": {
      "condition_A": "If noise present: Regression to mean expected.",
      "condition_B": "If stable selection: True overfitting may be cause."
    },
    "wise_refusal": "This is partly regression to the mean. Best validation hyperparameters included favorable noise. Some test drop is expected statistically, not just overfitting.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection on extreme includes noise. Best validation HPs include favorable noise that won't repeat.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-065",
    "case_id": "L2-065",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Economics",
    "scenario": "Industries with higher AI adoption have higher profit margins (X). A consultant recommends individual companies adopt AI to increase margins (Y).",
    "claim": "The causal relationship in 'The Industry AI Ecological' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Industry AI Adoption",
        "role": "Aggregate"
      },
      "Y": {
        "name": "Industry Profit Margins",
        "role": "Aggregate outcome"
      },
      "Z": [
        {
          "name": "Company-level variation",
          "role": "Hidden heterogeneity"
        }
      ]
    },
    "trap": {
      "type": "T6_ECOLOGICAL",
      "type_name": "T6 Ecological",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Medium",
    "causal_structure": "Industry pattern may not hold at company level",
    "key_insight": "Profitable industries may adopt AI more, not vice versa.",
    "hidden_timestamp": "Does AI adoption increase margins at the company level?",
    "conditional_answers": {
      "condition_A": "If aggregate only: Company-level effect may differ.",
      "condition_B": "If company-level confirms: Advice may be valid."
    },
    "wise_refusal": "This is the ecological fallacy. Industry-level correlations don't imply company-level effects. Individual companies adopting AI may not see margin improvements.",
    "gold_rationale": "The correct reasoning for this case involves understanding Industry pattern may not hold at company level. Profitable industries may adopt AI more, not vice versa.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-066",
    "case_id": "L2-066",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Data Engineering",
    "scenario": "Companies with data quality teams (X) have better model performance (Y). Conclusion: data quality teams cause model improvement.",
    "claim": "The causal relationship in 'The Data Quality Confounder' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Data Quality Team",
        "role": "Factor"
      },
      "Y": {
        "name": "Model Performance",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Organizational maturity",
          "role": "Confounder"
        }
      ]
    },
    "trap": {
      "type": "T7_CONFOUNDER",
      "type_name": "T7 Confounder",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Easy",
    "causal_structure": "Mature organizations have both",
    "key_insight": "Data teams are marker of maturity, not direct cause.",
    "hidden_timestamp": "Do companies with data teams also have other mature practices?",
    "conditional_answers": {
      "condition_A": "If correlated with maturity: Team is marker, not cause.",
      "condition_B": "If independent: Team may have direct effect."
    },
    "wise_refusal": "This is confounding. Companies with data quality teams are also more mature overall. The team may be a marker of organizational capability, not the direct cause of performance.",
    "gold_rationale": "The correct reasoning for this case involves understanding Mature organizations have both. Data teams are marker of maturity, not direct cause.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-067",
    "case_id": "L2-067",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Training",
    "scenario": "Method (X) A uses less compute (Y) than B overall but more compute within each model size category. Team picks A for efficiency.",
    "claim": "The causal relationship in 'The Compute Simpson' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Method Choice",
        "role": "Decision"
      },
      "Y": {
        "name": "Compute Usage",
        "role": "Metric"
      },
      "Z": [
        {
          "name": "Model Size Distribution",
          "role": "Stratifying variable"
        }
      ]
    },
    "trap": {
      "type": "T8_SIMPSONS",
      "type_name": "T8 Simpsons",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Hard",
    "causal_structure": "Aggregate reverses within-category pattern",
    "key_insight": "Method A is used more with smaller models.",
    "hidden_timestamp": "Are methods compared on the same model size distribution?",
    "conditional_answers": {
      "condition_A": "If size distribution differs: Simpson's paradox; B is more efficient.",
      "condition_B": "If same distribution: Comparison valid."
    },
    "wise_refusal": "This is Simpson's paradox. Method A appears more efficient overall because it's used with smaller models. Within each size category, B is more efficient.",
    "gold_rationale": "The correct reasoning for this case involves understanding Aggregate reverses within-category pattern. Method A is used more with smaller models.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-068",
    "case_id": "L2-068",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "NLP",
    "scenario": "New model architecture (X) improves benchmark scores (Y). But it also uses better tokenization (M), which itself helps performance.",
    "claim": "The causal relationship in 'The Tokenization Mediation' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "New Architecture",
        "role": "Treatment"
      },
      "Y": {
        "name": "Benchmark Score",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Tokenization (M)",
          "role": "Mediator"
        }
      ]
    },
    "trap": {
      "type": "T9_CONF_MED",
      "type_name": "T9 Conf Med",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Hard",
    "causal_structure": "X -> M -> Y confounds architecture effect",
    "key_insight": "Improvement may be from tokenization, not architecture.",
    "hidden_timestamp": "How much of the improvement is from architecture vs tokenization?",
    "conditional_answers": {
      "condition_A": "If tokenization-mediated: Architecture benefit overstated.",
      "condition_B": "If architecture direct: True architectural improvement."
    },
    "wise_refusal": "This conflates direct and indirect effects. The architecture change came with new tokenization. Benchmark gains may reflect tokenization improvement, not architectural superiority.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> M -> Y confounds architecture effect. Improvement may be from tokenization, not architecture.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-069",
    "case_id": "L2-069",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Product",
    "scenario": "Users who request features (X) have higher retention (Y). PM concludes feature requests indicate engaged users who will stay.",
    "claim": "The causal relationship in 'The Feature Request Reverse' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Feature Requests",
        "role": "Observed behavior"
      },
      "Y": {
        "name": "Retention",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Engagement level",
          "role": "Common cause"
        }
      ]
    },
    "trap": {
      "type": "T10_REVERSE",
      "type_name": "T10 Reverse",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Engagement causes both",
    "key_insight": "Engaged users request features AND stay longer.",
    "hidden_timestamp": "Does engagement drive both feature requests and retention?",
    "conditional_answers": {
      "condition_A": "If engagement is cause: Feature requests are signal, not cause.",
      "condition_B": "If requests cause retention: Soliciting requests might help."
    },
    "wise_refusal": "This may be confounding, not reverse causation. Engaged users both request features and stay longer. Feature requests don't cause retention; engagement causes both.",
    "gold_rationale": "The correct reasoning for this case involves understanding Engagement causes both. Engaged users request features AND stay longer.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-070",
    "case_id": "L2-070",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Recommenders",
    "scenario": "Highly-rated items (X) get more exposure, more ratings, and stay highly-rated (Y). The system concludes high ratings reflect quality.",
    "claim": "The causal relationship in 'The Rating Feedback Loop' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "High Rating",
        "role": "Factor"
      },
      "Y": {
        "name": "Continued High Rating",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Exposure feedback loop",
          "role": "Mechanism"
        }
      ]
    },
    "trap": {
      "type": "T11_FEEDBACK",
      "type_name": "T11 Feedback",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Ratings -> exposure -> more ratings",
    "key_insight": "Initial ratings become self-fulfilling.",
    "hidden_timestamp": "Do high ratings persist due to quality or exposure?",
    "conditional_answers": {
      "condition_A": "If exposure-driven: Ratings are self-reinforcing, not quality signal.",
      "condition_B": "If quality-driven: Ratings reflect true preference."
    },
    "wise_refusal": "This is a feedback loop. High-rated items get more exposure, collecting more ratings that maintain the high average. The rating stability reflects exposure, not necessarily quality.",
    "gold_rationale": "The correct reasoning for this case involves understanding Ratings -> exposure -> more ratings. Initial ratings become self-fulfilling.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-071",
    "case_id": "L2-071",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Infrastructure",
    "scenario": "After migrating to new servers (X), latency improved (Y). Team credits the migration without noting the concurrent network upgrade.",
    "claim": "The causal relationship in 'The Server Migration Temporal' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Server Migration",
        "role": "Temporal predecessor"
      },
      "Y": {
        "name": "Latency Improvement",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Network upgrade",
          "role": "Alternative cause"
        }
      ]
    },
    "trap": {
      "type": "T12_TEMPORAL",
      "type_name": "T12 Temporal",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Multiple concurrent changes",
    "key_insight": "Migration coincided with network improvements.",
    "hidden_timestamp": "Were there network or other infrastructure changes around migration?",
    "conditional_answers": {
      "condition_A": "If other changes present: Migration may not be the cause.",
      "condition_B": "If migration isolated: Attribution more justified."
    },
    "wise_refusal": "This is temporal fallacy. Server migration coincided with network upgrades. Without isolation, latency improvement cannot be attributed to the migration alone.",
    "gold_rationale": "The correct reasoning for this case involves understanding Multiple concurrent changes. Migration coincided with network improvements.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-072",
    "case_id": "L2-072",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Data Labeling",
    "scenario": "Annotator agreement (X) is used as proxy for label quality (Y). High agreement achieved by selecting easy examples.",
    "claim": "The causal relationship in 'The Annotation Quality Measurement' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Inter-Annotator Agreement",
        "role": "Measured proxy"
      },
      "Y": {
        "name": "Label Quality",
        "role": "True variable"
      },
      "Z": [
        {
          "name": "Example difficulty",
          "role": "Confounder"
        }
      ]
    },
    "trap": {
      "type": "T13_MEASUREMENT",
      "type_name": "T13 Measurement",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Medium",
    "causal_structure": "Easy examples inflate agreement",
    "key_insight": "Agreement measures consensus, not correctness.",
    "hidden_timestamp": "Is high agreement on easy examples or genuinely high-quality labels?",
    "conditional_answers": {
      "condition_A": "If easy examples: Agreement doesn't indicate quality.",
      "condition_B": "If hard examples included: Agreement more meaningful."
    },
    "wise_refusal": "This is measurement error. High inter-annotator agreement can be achieved with easy examples. Agreement measures consensus, which doesn't guarantee label correctness.",
    "gold_rationale": "The correct reasoning for this case involves understanding Easy examples inflate agreement. Agreement measures consensus, not correctness.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-073",
    "case_id": "L2-073",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Software Engineering",
    "scenario": "Engineers recall successful debugging strategies (X) better than failed ones. A study of recalled strategies overestimates their effectiveness (Y).",
    "claim": "The causal relationship in 'The Debugging Memory' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Recalled Strategies",
        "role": "Retrospective measure"
      },
      "Y": {
        "name": "Perceived Effectiveness",
        "role": "Conclusion"
      },
      "Z": [
        {
          "name": "Success-enhanced recall",
          "role": "Bias mechanism"
        }
      ]
    },
    "trap": {
      "type": "T14_RECALL",
      "type_name": "T14 Recall",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Hard",
    "causal_structure": "Successful strategies remembered better",
    "key_insight": "Memory biased toward successful outcomes.",
    "hidden_timestamp": "Are successful strategies recalled more than unsuccessful ones?",
    "conditional_answers": {
      "condition_A": "If recall biased: Effectiveness is overestimated.",
      "condition_B": "If recall balanced: Estimates more accurate."
    },
    "wise_refusal": "This is recall bias. Engineers better remember strategies that worked. Retrospective studies of debugging overestimate strategy effectiveness.",
    "gold_rationale": "The correct reasoning for this case involves understanding Successful strategies remembered better. Memory biased toward successful outcomes.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-074",
    "case_id": "L2-074",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Interpretability",
    "scenario": "Saliency maps highlight regions (X) that correlate with predictions (Y). Researchers claim these regions 'explain' the model's decision.",
    "claim": "The causal relationship in 'The Saliency Map Mechanism' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Salient Regions",
        "role": "Highlighted areas"
      },
      "Y": {
        "name": "Prediction",
        "role": "Output"
      },
      "Z": [
        {
          "name": "True reasoning",
          "role": "Unknown mechanism"
        }
      ]
    },
    "trap": {
      "type": "T15_MECHANISM",
      "type_name": "T15 Mechanism",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Easy",
    "causal_structure": "Saliency shows correlation, not causation",
    "key_insight": "Highlighted regions may not be causally relevant.",
    "hidden_timestamp": "Does masking salient regions change predictions?",
    "conditional_answers": {
      "condition_A": "If masking doesn't change output: Saliency is misleading.",
      "condition_B": "If masking changes output: Causal relevance established."
    },
    "wise_refusal": "This mistakes correlation for explanation. Saliency maps show gradient-correlated regions, not causally relevant ones. They may highlight spurious features.",
    "gold_rationale": "The correct reasoning for this case involves understanding Saliency shows correlation, not causation. Highlighted regions may not be causally relevant.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-075",
    "case_id": "L2-075",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "RLHF",
    "scenario": "A model optimizes reward (Y) model scores (X). It learns to produce verbose responses that score high but aren't genuinely better.",
    "claim": "The causal relationship in 'The Preference Score Goodhart' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Reward Model Optimization",
        "role": "Intervention"
      },
      "Y": {
        "name": "Reward Score",
        "role": "Proxy metric"
      },
      "Z": [
        {
          "name": "Response Quality",
          "role": "True goal"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "X -> Y but not X -> Z",
    "key_insight": "Reward model has exploitable patterns.",
    "hidden_timestamp": "Does high reward score correspond to genuine quality?",
    "conditional_answers": {
      "condition_A": "If verbosity exploited: Scores don't reflect quality.",
      "condition_B": "If reward aligned: Optimization improves quality."
    },
    "wise_refusal": "This is Goodhart's law. The model learned that verbosity increases reward scores without improving actual response quality. The proxy diverges from the goal.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y but not X -> Z. Reward model has exploitable patterns.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-076",
    "case_id": "L2-076",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "AI Safety",
    "scenario": "Watermarking AI outputs (X) for detection enables adversaries to remove watermarks (Y), making detection harder than before.",
    "claim": "The causal relationship in 'The Watermarking Backfire' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Watermarking",
        "role": "Intervention"
      },
      "Y": {
        "name": "Watermark Removal Development",
        "role": "Response"
      },
      "Z": [
        {
          "name": "Detection Capability",
          "role": "Outcome"
        }
      ]
    },
    "trap": {
      "type": "T17_BACKFIRE",
      "type_name": "T17 Backfire",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "X -> Y -> harder detection",
    "key_insight": "Known watermarks can be targeted for removal.",
    "hidden_timestamp": "Does watermarking enable better removal techniques?",
    "conditional_answers": {
      "condition_A": "If removal easier: Watermarking backfires.",
      "condition_B": "If robust to removal: Watermarking helps detection."
    },
    "wise_refusal": "This is a backfire effect. Publishing watermarking methods enables adversaries to develop removal techniques, potentially making AI-generated content harder to detect.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y -> harder detection. Known watermarks can be targeted for removal.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-077",
    "case_id": "L2-077",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "ML Practice",
    "scenario": "A team curates an evaluation set removing 'ambiguous' examples (X). Their model achieves high accuracy (Y) on the clean set.",
    "claim": "The causal relationship in 'The Evaluation Set Selection' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Curated Evaluation Set",
        "role": "Selection"
      },
      "Y": {
        "name": "High Accuracy",
        "role": "Metric"
      },
      "Z": [
        {
          "name": "Removed hard examples",
          "role": "Missing data"
        }
      ]
    },
    "trap": {
      "type": "T1_SELECTION",
      "type_name": "T1 Selection",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Easy examples inflate accuracy",
    "key_insight": "Removing hard cases makes benchmark easier.",
    "hidden_timestamp": "Were difficult or ambiguous cases removed from evaluation?",
    "conditional_answers": {
      "condition_A": "If hard cases removed: Accuracy is inflated.",
      "condition_B": "If representative: Accuracy meaningful."
    },
    "wise_refusal": "This is selection bias. Removing 'ambiguous' examples creates an artificially easy evaluation set. The high accuracy doesn't reflect real-world performance.",
    "gold_rationale": "The correct reasoning for this case involves understanding Easy examples inflate accuracy. Removing hard cases makes benchmark easier.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-078",
    "case_id": "L2-078",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Competitions",
    "scenario": "Kaggle winners (X) disproportionately use ensemble methods. A practitioner concludes ensembles are the key to winning (Y).",
    "claim": "The causal relationship in 'The Kaggle Winner Survivor' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Ensemble Methods in Winners",
        "role": "Observation"
      },
      "Y": {
        "name": "Winning Strategy Conclusion",
        "role": "Inference"
      },
      "Z": [
        {
          "name": "Non-winning ensembles",
          "role": "Missing data"
        }
      ]
    },
    "trap": {
      "type": "T2_SURVIVORSHIP",
      "type_name": "T2 Survivorship",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "Only winners examined",
    "key_insight": "Many losers also used ensembles.",
    "hidden_timestamp": "Did non-winning submissions also use ensembles?",
    "conditional_answers": {
      "condition_A": "If losers used ensembles too: Ensemble not differentiating.",
      "condition_B": "If unique to winners: May be key strategy."
    },
    "wise_refusal": "This is survivorship bias. Many losing submissions also used ensembles. Examining only winners overestimates the importance of ensembling for success.",
    "gold_rationale": "The correct reasoning for this case involves understanding Only winners examined. Many losers also used ensembles.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-079",
    "case_id": "L2-079",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Research",
    "scenario": "Among published papers, novelty (X) and rigor (Y) appear negatively correlated. Reviewers conclude novel work is sloppy.",
    "claim": "The causal relationship in 'The Publication Collider' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Novelty",
        "role": "Factor 1"
      },
      "Y": {
        "name": "Rigor",
        "role": "Factor 2"
      },
      "Z": [
        {
          "name": "Publication (Collider)",
          "role": "Selection criterion"
        }
      ]
    },
    "trap": {
      "type": "T3_COLLIDER",
      "type_name": "T3 Collider",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Papers published if novel OR rigorous",
    "key_insight": "Either quality suffices for publication.",
    "hidden_timestamp": "Are papers published based on either high novelty or high rigor?",
    "conditional_answers": {
      "condition_A": "If either suffices: Collider creates spurious tradeoff.",
      "condition_B": "If both required: Correlation may be real."
    },
    "wise_refusal": "This is collider bias. Papers are published if sufficiently novel OR rigorous. Among published papers, these appear negatively correlated, but the tradeoff is an artifact.",
    "gold_rationale": "The correct reasoning for this case involves understanding Papers published if novel OR rigorous. Either quality suffices for publication.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-080",
    "case_id": "L2-080",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Product",
    "scenario": "Features in development for 6+ months (X) have higher user adoption (Y). PM concludes longer development produces better features.",
    "claim": "The causal relationship in 'The Feature Development Immortality' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Long Development Time",
        "role": "Exposure"
      },
      "Y": {
        "name": "User Adoption",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Feature not cancelled",
          "role": "Survival requirement"
        }
      ]
    },
    "trap": {
      "type": "T4_IMMORTAL_TIME",
      "type_name": "T4 Immortal Time",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "Long development requires not being cancelled",
    "key_insight": "Good features survive to have long development.",
    "hidden_timestamp": "Did features with long development survive because they showed early promise?",
    "conditional_answers": {
      "condition_A": "If survival-dependent: Long development is effect of quality.",
      "condition_B": "If time random: Causal effect testable."
    },
    "wise_refusal": "This is immortal time bias. Features with 6+ months development weren't cancelled; they showed early promise. Long development is a consequence of quality, not its cause.",
    "gold_rationale": "The correct reasoning for this case involves understanding Long development requires not being cancelled. Good features survive to have long development.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-081",
    "case_id": "L2-081",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Experimentation",
    "scenario": "A/B tests showing highest lift (X) often fail to replicate (Y). Team blames experimental noise.",
    "claim": "The causal relationship in 'The A/B Test Regression' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Highest Lift Tests",
        "role": "Selection"
      },
      "Y": {
        "name": "Replication Failure",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Random variance",
          "role": "Source of extreme"
        }
      ]
    },
    "trap": {
      "type": "T5_REGRESSION",
      "type_name": "T5 Regression",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Medium",
    "causal_structure": "Selection on extreme includes noise",
    "key_insight": "Highest lifts include positive random variance.",
    "hidden_timestamp": "Were tests selected based on exceptional initial results?",
    "conditional_answers": {
      "condition_A": "If selected on extremes: Regression expected.",
      "condition_B": "If random selection: Failure indicates real issues."
    },
    "wise_refusal": "This is regression to the mean. Tests with highest initial lift included favorable noise. Replication failure is partly expected statistically.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection on extreme includes noise. Highest lifts include positive random variance.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-082",
    "case_id": "L2-082",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Education",
    "scenario": "Universities with AI programs have higher graduate salaries (Y) (X). A student concludes any AI major will earn more.",
    "claim": "The causal relationship in 'The University AI Ecological' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "University AI Program",
        "role": "Aggregate"
      },
      "Y": {
        "name": "Graduate Salaries",
        "role": "Aggregate outcome"
      },
      "Z": [
        {
          "name": "Individual variation",
          "role": "Hidden heterogeneity"
        }
      ]
    },
    "trap": {
      "type": "T6_ECOLOGICAL",
      "type_name": "T6 Ecological",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Easy",
    "causal_structure": "University pattern may not hold for individuals",
    "key_insight": "Top universities have AI programs and high salaries.",
    "hidden_timestamp": "Does AI major increase salary at the individual level?",
    "conditional_answers": {
      "condition_A": "If aggregate only: Individual effect may differ.",
      "condition_B": "If individual-level confirms: Conclusion valid."
    },
    "wise_refusal": "This is the ecological fallacy. Universities with AI programs are often elite. The salary advantage may reflect university quality, not the AI major specifically.",
    "gold_rationale": "The correct reasoning for this case involves understanding University pattern may not hold for individuals. Top universities have AI programs and high salaries.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-083",
    "case_id": "L2-083",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Infrastructure",
    "scenario": "Companies using premium cloud AI (X) have faster deployment (Y). Conclusion: premium cloud causes faster deployment.",
    "claim": "The causal relationship in 'The Cloud Provider Confounder' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Premium Cloud AI",
        "role": "Factor"
      },
      "Y": {
        "name": "Deployment Speed",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Engineering Resources",
          "role": "Confounder"
        }
      ]
    },
    "trap": {
      "type": "T7_CONFOUNDER",
      "type_name": "T7 Confounder",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Medium",
    "causal_structure": "Well-resourced companies afford premium and deploy fast",
    "key_insight": "Premium cloud is marker of resources, not cause.",
    "hidden_timestamp": "Do companies using premium cloud have more engineering resources?",
    "conditional_answers": {
      "condition_A": "If correlated with resources: Premium is marker, not cause.",
      "condition_B": "If independent: Cloud may have direct effect."
    },
    "wise_refusal": "This is confounding. Companies affording premium cloud also have strong engineering teams. Deployment speed may reflect resources, not the cloud service.",
    "gold_rationale": "The correct reasoning for this case involves understanding Well-resourced companies afford premium and deploy fast. Premium cloud is marker of resources, not cause.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-084",
    "case_id": "L2-084",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Development",
    "scenario": "Framework (X) A has more bugs reported overall but fewer bugs per user in each experience category. Team avoids A due to bug count (Y).",
    "claim": "The causal relationship in 'The Framework Popularity Simpson' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Framework Choice",
        "role": "Decision"
      },
      "Y": {
        "name": "Bug Count",
        "role": "Metric"
      },
      "Z": [
        {
          "name": "User Experience Distribution",
          "role": "Stratifying variable"
        }
      ]
    },
    "trap": {
      "type": "T8_SIMPSONS",
      "type_name": "T8 Simpsons",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Medium",
    "causal_structure": "Aggregate reverses within-category pattern",
    "key_insight": "Framework A has more novice users who report more bugs.",
    "hidden_timestamp": "Do frameworks have different user experience distributions?",
    "conditional_answers": {
      "condition_A": "If distributions differ: Simpson's paradox; A may be better.",
      "condition_B": "If same distribution: Bug count comparison valid."
    },
    "wise_refusal": "This is Simpson's paradox. Framework A has more total bugs because it has more novice users. Per-user bug rate is lower in each experience category.",
    "gold_rationale": "The correct reasoning for this case involves understanding Aggregate reverses within-category pattern. Framework A has more novice users who report more bugs.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-085",
    "case_id": "L2-085",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Model Compression",
    "scenario": "Distilled models (X) are faster (Y). But distillation also reduces model size (M), which directly affects speed.",
    "claim": "The causal relationship in 'The Distillation Mediation' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Distillation",
        "role": "Treatment"
      },
      "Y": {
        "name": "Speed",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Model Size (M)",
          "role": "Mediator"
        }
      ]
    },
    "trap": {
      "type": "T9_CONF_MED",
      "type_name": "T9 Conf Med",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Easy",
    "causal_structure": "X -> M -> Y",
    "key_insight": "Speed gain may be from size reduction, not distillation quality.",
    "hidden_timestamp": "Is speed improvement from distillation or just smaller size?",
    "conditional_answers": {
      "condition_A": "If size-mediated: Distillation benefit is indirect.",
      "condition_B": "If direct effect: Distillation improves efficiency beyond size."
    },
    "wise_refusal": "This conflates direct and indirect effects. Distillation makes models smaller, which makes them faster. The speed gain is from size reduction, not inherent efficiency improvement.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> M -> Y. Speed gain may be from size reduction, not distillation quality.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-086",
    "case_id": "L2-086",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Open Source",
    "scenario": "ML libraries with more downloads (X) have better documentation (Y). Maintainer concludes documentation drives downloads.",
    "claim": "The causal relationship in 'The Download Count Reverse' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Download Count",
        "role": "Observed metric"
      },
      "Y": {
        "name": "Documentation Quality",
        "role": "Factor"
      },
      "Z": [
        {
          "name": "Usage driving docs investment",
          "role": "Reverse cause"
        }
      ]
    },
    "trap": {
      "type": "T10_REVERSE",
      "type_name": "T10 Reverse",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "May be X -> Y",
    "key_insight": "Popular libraries get more documentation investment.",
    "hidden_timestamp": "Does popularity drive documentation investment?",
    "conditional_answers": {
      "condition_A": "If popularity drives docs: Reverse causation.",
      "condition_B": "If docs drive downloads: Forward causation."
    },
    "wise_refusal": "This may be reverse causation. Popular libraries attract contributors who improve documentation. Downloads may cause better docs, not vice versa.",
    "gold_rationale": "The correct reasoning for this case involves understanding May be X -> Y. Popular libraries get more documentation investment.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-087",
    "case_id": "L2-087",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "Models optimize for benchmarks (X), benchmarks get updated to challenge models (Y), creating an arms race without genuine progress (Z).",
    "claim": "The causal relationship in 'The Benchmark Evolution Feedback' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Benchmark Optimization",
        "role": "Action"
      },
      "Y": {
        "name": "Benchmark Updates",
        "role": "Response"
      },
      "Z": [
        {
          "name": "Genuine Capability Progress",
          "role": "True goal"
        }
      ]
    },
    "trap": {
      "type": "T11_FEEDBACK",
      "type_name": "T11 Feedback",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "X -> Y -> X feedback without improving Z",
    "key_insight": "Benchmark-model co-evolution doesn't guarantee capability gains.",
    "hidden_timestamp": "Do benchmark scores reflect genuine progress or just co-evolution?",
    "conditional_answers": {
      "condition_A": "If feedback loop: Progress may be illusory.",
      "condition_B": "If genuine gains: Evolution reflects capability."
    },
    "wise_refusal": "This is a feedback loop. Models and benchmarks co-evolve in an arms race. Score improvements may reflect adaptation to benchmarks, not genuine capability progress.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y -> X feedback without improving Z. Benchmark-model co-evolution doesn't guarantee capability gains.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-088",
    "case_id": "L2-088",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Software Engineering",
    "scenario": "After a codebase refactor (X), tests started failing (Y). Team blames the refactor without checking test environment changes.",
    "claim": "The causal relationship in 'The Refactoring Blame' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Refactor",
        "role": "Temporal predecessor"
      },
      "Y": {
        "name": "Test Failures",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Environment changes",
          "role": "Alternative cause"
        }
      ]
    },
    "trap": {
      "type": "T12_TEMPORAL",
      "type_name": "T12 Temporal",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Multiple changes in window",
    "key_insight": "Refactor coincided with environment updates.",
    "hidden_timestamp": "Were there test environment or dependency changes around refactor time?",
    "conditional_answers": {
      "condition_A": "If other changes: Refactor may not be cause.",
      "condition_B": "If refactor isolated: Attribution justified."
    },
    "wise_refusal": "This is temporal fallacy. The refactor coincided with other changes. Without isolation, test failures cannot be attributed solely to the refactor.",
    "gold_rationale": "The correct reasoning for this case involves understanding Multiple changes in window. Refactor coincided with environment updates.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-089",
    "case_id": "L2-089",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "NLP",
    "scenario": "Response length in tokens (X) is used to measure verbosity (Y). Different tokenizers give different counts for same text.",
    "claim": "The causal relationship in 'The Token Count Measurement' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Token Count",
        "role": "Measured proxy"
      },
      "Y": {
        "name": "Verbosity",
        "role": "True variable"
      },
      "Z": [
        {
          "name": "Tokenizer choice",
          "role": "Measurement artifact"
        }
      ]
    },
    "trap": {
      "type": "T13_MEASUREMENT",
      "type_name": "T13 Measurement",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Easy",
    "causal_structure": "Measurement depends on arbitrary choice",
    "key_insight": "Token count is tokenizer-dependent, not universal.",
    "hidden_timestamp": "Are verbosity comparisons valid across different tokenizers?",
    "conditional_answers": {
      "condition_A": "If tokenizers differ: Comparisons meaningless.",
      "condition_B": "If same tokenizer: Comparison valid."
    },
    "wise_refusal": "This is measurement error. Token count depends on the tokenizer. Verbosity comparisons using different tokenizers are not meaningful.",
    "gold_rationale": "The correct reasoning for this case involves understanding Measurement depends on arbitrary choice. Token count is tokenizer-dependent, not universal.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-090",
    "case_id": "L2-090",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "ML Practice",
    "scenario": "Data scientists recall feature engineering steps (X) that led to successful models (Y). Failed approaches are forgotten.",
    "claim": "The causal relationship in 'The Feature Importance Recall' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Recalled Feature Engineering",
        "role": "Retrospective"
      },
      "Y": {
        "name": "Model Success",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Success-enhanced recall",
          "role": "Bias"
        }
      ]
    },
    "trap": {
      "type": "T14_RECALL",
      "type_name": "T14 Recall",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Medium",
    "causal_structure": "Successful features remembered better",
    "key_insight": "Failed feature engineering attempts forgotten.",
    "hidden_timestamp": "Are successful feature engineering steps recalled more than failures?",
    "conditional_answers": {
      "condition_A": "If recall biased: Feature importance overestimated.",
      "condition_B": "If balanced: Importance estimates accurate."
    },
    "wise_refusal": "This is recall bias. Data scientists better remember feature engineering that worked. Retrospective analysis overestimates the effectiveness of remembered approaches.",
    "gold_rationale": "The correct reasoning for this case involves understanding Successful features remembered better. Failed feature engineering attempts forgotten.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-091",
    "case_id": "L2-091",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Interpretability",
    "scenario": "Ablating layer L (X) reduces performance on task T (Y). Researchers claim L is 'responsible' for T.",
    "claim": "The causal relationship in 'The Layer Ablation Mechanism' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Layer Ablation",
        "role": "Intervention"
      },
      "Y": {
        "name": "Task Performance Drop",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Distributed computation",
          "role": "True mechanism"
        }
      ]
    },
    "trap": {
      "type": "T15_MECHANISM",
      "type_name": "T15 Mechanism",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "Ablation doesn't prove exclusive responsibility",
    "key_insight": "Many layers may contribute; ablation shows necessity, not sufficiency.",
    "hidden_timestamp": "Does ablation prove L is solely responsible or just involved?",
    "conditional_answers": {
      "condition_A": "If distributed: L is necessary but not exclusively responsible.",
      "condition_B": "If localized: L may be the key component."
    },
    "wise_refusal": "This overstates the conclusion. Ablation shows L is necessary, not that L alone is responsible. Computation may be distributed across many layers.",
    "gold_rationale": "The correct reasoning for this case involves understanding Ablation doesn't prove exclusive responsibility. Many layers may contribute; ablation shows necessity, not sufficiency.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-092",
    "case_id": "L2-092",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "A model optimizes HumanEval pass rate (X). It learns to generate code matching test patterns rather than general coding ability (Y).",
    "claim": "The causal relationship in 'The Human Eval Goodhart' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "HumanEval Optimization",
        "role": "Intervention"
      },
      "Y": {
        "name": "Pass Rate",
        "role": "Proxy metric"
      },
      "Z": [
        {
          "name": "General Coding Ability",
          "role": "True goal"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Easy",
    "causal_structure": "Proxy optimization doesn't improve true goal",
    "key_insight": "Pass rate can be gamed with pattern matching.",
    "hidden_timestamp": "Does high pass rate reflect general coding or benchmark-specific patterns?",
    "conditional_answers": {
      "condition_A": "If pattern matching: Pass rate inflated without true improvement.",
      "condition_B": "If genuine: Optimization improves coding."
    },
    "wise_refusal": "This is Goodhart's law. Optimizing HumanEval pass rate incentivizes learning benchmark-specific patterns, not general coding ability.",
    "gold_rationale": "The correct reasoning for this case involves understanding Proxy optimization doesn't improve true goal. Pass rate can be gamed with pattern matching.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-093",
    "case_id": "L2-093",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Content Moderation",
    "scenario": "Censoring misinformation (X) causes it to spread via 'Streisand effect' (Y), amplifying reach instead of reducing it.",
    "claim": "The causal relationship in 'The Censorship Backfire' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Censorship",
        "role": "Intervention"
      },
      "Y": {
        "name": "Streisand Effect",
        "role": "Backfire mechanism"
      },
      "Z": [
        {
          "name": "Information Spread",
          "role": "Outcome"
        }
      ]
    },
    "trap": {
      "type": "T17_BACKFIRE",
      "type_name": "T17 Backfire",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Hard",
    "causal_structure": "X -> Y -> increased spread",
    "key_insight": "Censorship can attract attention and amplify.",
    "hidden_timestamp": "Does censorship attract more attention to the content?",
    "conditional_answers": {
      "condition_A": "If Streisand effect: Censorship backfires.",
      "condition_B": "If quiet removal: May reduce spread."
    },
    "wise_refusal": "This is a backfire effect. Public censorship can trigger the Streisand effect, where the act of removal attracts attention and amplifies the content's spread.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> Y -> increased spread. Censorship can attract attention and amplify.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-094",
    "case_id": "L2-094",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Research",
    "scenario": "A review only includes preprints with code (X), finding most ML claims replicate (Y). Unreproducible work without code excluded.",
    "claim": "The causal relationship in 'The Preprint Selection' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Code Availability Filter",
        "role": "Selection"
      },
      "Y": {
        "name": "High Replication Rate",
        "role": "Finding"
      },
      "Z": [
        {
          "name": "Papers without code",
          "role": "Missing data"
        }
      ]
    },
    "trap": {
      "type": "T1_SELECTION",
      "type_name": "T1 Selection",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Selection on reproducible papers",
    "key_insight": "Code availability correlates with reproducibility.",
    "hidden_timestamp": "Are papers without code less reproducible?",
    "conditional_answers": {
      "condition_A": "If code correlates with reproducibility: Selection inflates rate.",
      "condition_B": "If independent: Sample may be representative."
    },
    "wise_refusal": "This is selection bias. Filtering to papers with code selects for reproducible work. The high replication rate doesn't represent ML research broadly.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection on reproducible papers. Code availability correlates with reproducibility.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-095",
    "case_id": "L2-095",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Education",
    "scenario": "Popular ML tutorials (X) feature approaches that worked. A learner concludes these approaches always work (Y).",
    "claim": "The causal relationship in 'The Tutorial Survivorship' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Tutorial Content",
        "role": "Sample"
      },
      "Y": {
        "name": "Perceived Success Rate",
        "role": "Inference"
      },
      "Z": [
        {
          "name": "Failed approaches not shown",
          "role": "Missing data"
        }
      ]
    },
    "trap": {
      "type": "T2_SURVIVORSHIP",
      "type_name": "T2 Survivorship",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Tutorials show success stories",
    "key_insight": "Failed experiments don't become tutorials.",
    "hidden_timestamp": "Do tutorials represent the full distribution of outcomes?",
    "conditional_answers": {
      "condition_A": "If only successes: Learner overestimates success rates.",
      "condition_B": "If balanced: Expectations calibrated."
    },
    "wise_refusal": "This is survivorship bias. Tutorials feature approaches that worked. Learners don't see the many failed attempts, leading to overconfidence.",
    "gold_rationale": "The correct reasoning for this case involves understanding Tutorials show success stories. Failed experiments don't become tutorials.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-096",
    "case_id": "L2-096",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Research",
    "scenario": "Among accepted papers, method complexity (X) and dataset size (Y) appear negatively correlated. Reviewer concludes simple methods need big data.",
    "claim": "The causal relationship in 'The Accepted Paper Collider' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Method Complexity",
        "role": "Factor 1"
      },
      "Y": {
        "name": "Dataset Size",
        "role": "Factor 2"
      },
      "Z": [
        {
          "name": "Acceptance (Collider)",
          "role": "Selection"
        }
      ]
    },
    "trap": {
      "type": "T3_COLLIDER",
      "type_name": "T3 Collider",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "Papers accepted if complex method OR big dataset",
    "key_insight": "Either novelty compensates for limitations.",
    "hidden_timestamp": "Are papers accepted based on method OR dataset novelty?",
    "conditional_answers": {
      "condition_A": "If either suffices: Collider creates spurious tradeoff.",
      "condition_B": "If both required: Tradeoff may be real."
    },
    "wise_refusal": "This is collider bias. Papers are accepted with novel methods OR large datasets. Among accepted papers, these appear negatively correlated, but it's an artifact.",
    "gold_rationale": "The correct reasoning for this case involves understanding Papers accepted if complex method OR big dataset. Either novelty compensates for limitations.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-097",
    "case_id": "L2-097",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Training",
    "scenario": "Checkpoints saved after 1000+ steps (X) have lower loss (Y). Team concludes longer training always reduces loss.",
    "claim": "The causal relationship in 'The Checkpoint Immortality' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Long Training",
        "role": "Exposure"
      },
      "Y": {
        "name": "Low Loss",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Run not diverging",
          "role": "Survival requirement"
        }
      ]
    },
    "trap": {
      "type": "T4_IMMORTAL_TIME",
      "type_name": "T4 Immortal Time",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Long training requires not diverging",
    "key_insight": "Stable runs survive to have long training.",
    "hidden_timestamp": "Did runs reaching 1000+ steps avoid early divergence?",
    "conditional_answers": {
      "condition_A": "If survival-dependent: Long training is effect of stability.",
      "condition_B": "If forced to continue: Causal effect testable."
    },
    "wise_refusal": "This is immortal time bias. Checkpoints at 1000+ steps come from runs that didn't diverge. Long training is consequence of stability, not cause of low loss.",
    "gold_rationale": "The correct reasoning for this case involves understanding Long training requires not diverging. Stable runs survive to have long training.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-098",
    "case_id": "L2-098",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Training",
    "scenario": "Learning rates giving best single-run results (X) perform average across seeds (Y). Team concludes LR sensitivity is high.",
    "claim": "The causal relationship in 'The Learning Rate Regression' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Best Single-Run LR",
        "role": "Selection"
      },
      "Y": {
        "name": "Multi-Seed Performance",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Random seed variance",
          "role": "Source of extreme"
        }
      ]
    },
    "trap": {
      "type": "T5_REGRESSION",
      "type_name": "T5 Regression",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Hard",
    "causal_structure": "Selection on extreme includes seed-specific noise",
    "key_insight": "Best LR in one run may have been lucky.",
    "hidden_timestamp": "Was the best LR selected from a single seed?",
    "conditional_answers": {
      "condition_A": "If single-seed selection: Regression to mean expected.",
      "condition_B": "If multi-seed: Sensitivity may be real."
    },
    "wise_refusal": "This is regression to the mean. The learning rate was selected for exceptional single-run results. Across seeds, it regresses to average because seed-specific noise doesn't repeat.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection on extreme includes seed-specific noise. Best LR in one run may have been lucky.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-099",
    "case_id": "L2-099",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Business",
    "scenario": "Sector (Y) (X)s with high AI investment have high growth. Analyst advises individual firms to invest in AI for growth.",
    "claim": "The causal relationship in 'The Sector AI Ecological' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Sector AI Investment",
        "role": "Aggregate"
      },
      "Y": {
        "name": "Sector Growth",
        "role": "Aggregate outcome"
      },
      "Z": [
        {
          "name": "Firm-level variation",
          "role": "Hidden heterogeneity"
        }
      ]
    },
    "trap": {
      "type": "T6_ECOLOGICAL",
      "type_name": "T6 Ecological",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Hard",
    "causal_structure": "Sector pattern may not hold at firm level",
    "key_insight": "Growing sectors attract AI investment, not vice versa.",
    "hidden_timestamp": "Does AI investment cause growth at firm level?",
    "conditional_answers": {
      "condition_A": "If sector-level only: Firm advice may be wrong.",
      "condition_B": "If firm-level confirms: Advice may be valid."
    },
    "wise_refusal": "This is the ecological fallacy. Sector-level correlations don't imply firm-level causation. Growing sectors may attract AI investment rather than AI causing growth.",
    "gold_rationale": "The correct reasoning for this case involves understanding Sector pattern may not hold at firm level. Growing sectors attract AI investment, not vice versa.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-100",
    "case_id": "L2-100",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Hardware",
    "scenario": "Labs using NVIDIA GPUs (X) publish more papers (Y). Conclusion: NVIDIA causes research productivity.",
    "claim": "The causal relationship in 'The GPU Vendor Confounder' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "NVIDIA GPU Usage",
        "role": "Factor"
      },
      "Y": {
        "name": "Paper Count",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Lab Resources/Funding",
          "role": "Confounder"
        }
      ]
    },
    "trap": {
      "type": "T7_CONFOUNDER",
      "type_name": "T7 Confounder",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Easy",
    "causal_structure": "Well-funded labs afford NVIDIA and publish more",
    "key_insight": "GPU choice is marker of resources.",
    "hidden_timestamp": "Do labs using NVIDIA have more funding generally?",
    "conditional_answers": {
      "condition_A": "If correlated with funding: GPU is marker, not cause.",
      "condition_B": "If independent: GPU may have direct effect."
    },
    "wise_refusal": "This is confounding. Well-funded labs can afford NVIDIA GPUs and also publish more. The GPU vendor is a marker of resources, not the cause of productivity.",
    "gold_rationale": "The correct reasoning for this case involves understanding Well-funded labs afford NVIDIA and publish more. GPU choice is marker of resources.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-101",
    "case_id": "L2-101",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Scaling",
    "scenario": "Small model (X)s outperform large models overall (Y) but lose in each task category. Team picks small models for efficiency.",
    "claim": "The causal relationship in 'The Model Size Simpson' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Model Size Choice",
        "role": "Decision"
      },
      "Y": {
        "name": "Overall Performance",
        "role": "Aggregate metric"
      },
      "Z": [
        {
          "name": "Task Distribution",
          "role": "Stratifying variable"
        }
      ]
    },
    "trap": {
      "type": "T8_SIMPSONS",
      "type_name": "T8 Simpsons",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Easy",
    "causal_structure": "Aggregate reverses within-task pattern",
    "key_insight": "Small models tested more on easy tasks.",
    "hidden_timestamp": "Are small and large models tested on the same task distribution?",
    "conditional_answers": {
      "condition_A": "If distribution differs: Simpson's paradox; large may be better.",
      "condition_B": "If same distribution: Comparison valid."
    },
    "wise_refusal": "This is Simpson's paradox. Small models appear better overall because they're tested more on easy tasks. Within each task category, large models outperform.",
    "gold_rationale": "The correct reasoning for this case involves understanding Aggregate reverses within-task pattern. Small models tested more on easy tasks.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-102",
    "case_id": "L2-102",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Model Compression",
    "scenario": "Quantized models (X) are faster (Y). But quantization also reduces memory (M), enabling larger batch sizes that improve throughput.",
    "claim": "The causal relationship in 'The Quantization Mediation' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Quantization",
        "role": "Treatment"
      },
      "Y": {
        "name": "Speed",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Memory/Batch Size (M)",
          "role": "Mediator"
        }
      ]
    },
    "trap": {
      "type": "T9_CONF_MED",
      "type_name": "T9 Conf Med",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Medium",
    "causal_structure": "X -> M -> Y",
    "key_insight": "Speed gain may be from batch size, not quantization itself.",
    "hidden_timestamp": "Is speed improvement from reduced precision or larger batches?",
    "conditional_answers": {
      "condition_A": "If batch-mediated: Direct quantization benefit smaller.",
      "condition_B": "If direct effect: Quantization inherently faster."
    },
    "wise_refusal": "This conflates direct and indirect effects. Quantization reduces memory, enabling larger batch sizes that improve throughput. The speed gain is partly indirect.",
    "gold_rationale": "The correct reasoning for this case involves understanding X -> M -> Y. Speed gain may be from batch size, not quantization itself.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-103",
    "case_id": "L2-103",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Open Source",
    "scenario": "Repos with more stars (X) have more issues resolved (Y). Maintainer concludes stars help get issues fixed.",
    "claim": "The causal relationship in 'The Star Count Reverse' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Star Count",
        "role": "Observed metric"
      },
      "Y": {
        "name": "Issues Resolved",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Active maintenance",
          "role": "Common cause"
        }
      ]
    },
    "trap": {
      "type": "T10_REVERSE",
      "type_name": "T10 Reverse",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "May be Z -> X and Z -> Y",
    "key_insight": "Active repos get stars AND fix issues.",
    "hidden_timestamp": "Does active maintenance drive both stars and issue resolution?",
    "conditional_answers": {
      "condition_A": "If common cause: Stars don't help fix issues.",
      "condition_B": "If stars attract contributors: May help indirectly."
    },
    "wise_refusal": "This may be confounding. Actively maintained repos attract stars AND resolve issues. Stars may not cause issue resolution; active maintenance causes both.",
    "gold_rationale": "The correct reasoning for this case involves understanding May be Z -> X and Z -> Y. Active repos get stars AND fix issues.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-104",
    "case_id": "L2-104",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Product",
    "scenario": "Features with positive feedback (X) get more development, improving further (Y). PM concludes feedback identifies good features.",
    "claim": "The causal relationship in 'The User Feedback Loop' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Positive Feedback",
        "role": "Signal"
      },
      "Y": {
        "name": "Feature Quality",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Development investment loop",
          "role": "Mechanism"
        }
      ]
    },
    "trap": {
      "type": "T11_FEEDBACK",
      "type_name": "T11 Feedback",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Feedback -> investment -> improvement -> feedback",
    "key_insight": "Feedback becomes self-fulfilling prophecy.",
    "hidden_timestamp": "Does feedback drive investment that improves features?",
    "conditional_answers": {
      "condition_A": "If loop exists: Feedback creates quality, not just identifies it.",
      "condition_B": "If investment independent: Feedback reflects intrinsic quality."
    },
    "wise_refusal": "This is a feedback loop. Positive feedback leads to more development investment, which improves the feature, generating more positive feedback. Initial feedback becomes self-fulfilling.",
    "gold_rationale": "The correct reasoning for this case involves understanding Feedback -> investment -> improvement -> feedback. Feedback becomes self-fulfilling prophecy.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-105",
    "case_id": "L2-105",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Software Engineering",
    "scenario": "After updating dependencies (X), build time decreased (Y). Team credits dependency update without checking compiler changes.",
    "claim": "The causal relationship in 'The Dependency Update Temporal' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Dependency Update",
        "role": "Temporal predecessor"
      },
      "Y": {
        "name": "Build Time Decrease",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Compiler optimization",
          "role": "Alternative cause"
        }
      ]
    },
    "trap": {
      "type": "T12_TEMPORAL",
      "type_name": "T12 Temporal",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Multiple concurrent changes",
    "key_insight": "Update coincided with compiler improvements.",
    "hidden_timestamp": "Were there compiler or toolchain changes around dependency update?",
    "conditional_answers": {
      "condition_A": "If other changes: Dependency may not be cause.",
      "condition_B": "If isolated: Attribution justified."
    },
    "wise_refusal": "This is temporal fallacy. Dependency update coincided with compiler improvements. Without isolation, build time improvement cannot be attributed solely to dependencies.",
    "gold_rationale": "The correct reasoning for this case involves understanding Multiple concurrent changes. Update coincided with compiler improvements.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-106",
    "case_id": "L2-106",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "NLP",
    "scenario": "Model A has lower perplexity (X) than B. Team concludes A is better at language understanding (Y), ignoring that perplexity measures prediction, not understanding.",
    "claim": "The causal relationship in 'The Perplexity Measurement' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Perplexity",
        "role": "Measured proxy"
      },
      "Y": {
        "name": "Language Understanding",
        "role": "True variable"
      },
      "Z": [
        {
          "name": "Prediction vs understanding gap",
          "role": "Measurement limitation"
        }
      ]
    },
    "trap": {
      "type": "T13_MEASUREMENT",
      "type_name": "T13 Measurement",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Hard",
    "causal_structure": "Perplexity measures prediction, not understanding",
    "key_insight": "Low perplexity doesn't imply deep understanding.",
    "hidden_timestamp": "Does perplexity measure language understanding or just prediction?",
    "conditional_answers": {
      "condition_A": "If prediction only: Lower perplexity doesn't mean better understanding.",
      "condition_B": "If correlated: Perplexity may be useful proxy."
    },
    "wise_refusal": "This is measurement error. Perplexity measures next-token prediction, not language understanding. Low perplexity doesn't guarantee deep semantic comprehension.",
    "gold_rationale": "The correct reasoning for this case involves understanding Perplexity measures prediction, not understanding. Low perplexity doesn't imply deep understanding.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-107",
    "case_id": "L2-107",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Project Management",
    "scenario": "In postmortems, engineers recall decisions that preceded failures (X). Retrospective analysis overestimates predictability (Y).",
    "claim": "The causal relationship in 'The Project Postmortem Recall' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Recalled Decisions",
        "role": "Retrospective"
      },
      "Y": {
        "name": "Perceived Predictability",
        "role": "Conclusion"
      },
      "Z": [
        {
          "name": "Hindsight bias",
          "role": "Memory distortion"
        }
      ]
    },
    "trap": {
      "type": "T14_RECALL",
      "type_name": "T14 Recall",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Easy",
    "causal_structure": "Outcomes color memory of decisions",
    "key_insight": "Decisions seem obvious in hindsight.",
    "hidden_timestamp": "Are decisions recalled as clearer than they were at the time?",
    "conditional_answers": {
      "condition_A": "If hindsight colors recall: Predictability overestimated.",
      "condition_B": "If documented real-time: Recall more accurate."
    },
    "wise_refusal": "This is recall bias with hindsight. Postmortems overestimate how predictable failures were. Decisions that seem obvious now weren't clear at the time.",
    "gold_rationale": "The correct reasoning for this case involves understanding Outcomes color memory of decisions. Decisions seem obvious in hindsight.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-108",
    "case_id": "L2-108",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Interpretability",
    "scenario": "A linear probe finds syntactic features (X) in hidden states (Y). Researchers claim the model 'encodes' syntax.",
    "claim": "The causal relationship in 'The Probe Mechanism' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Probe Success",
        "role": "Observation"
      },
      "Y": {
        "name": "Claimed Encoding",
        "role": "Interpretation"
      },
      "Z": [
        {
          "name": "True representation",
          "role": "Unknown"
        }
      ]
    },
    "trap": {
      "type": "T15_MECHANISM",
      "type_name": "T15 Mechanism",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Hard",
    "causal_structure": "Probe success doesn't prove encoding",
    "key_insight": "Probes can find patterns that aren't used by the model.",
    "hidden_timestamp": "Does the model actually use the probed features?",
    "conditional_answers": {
      "condition_A": "If not used: Probe finds artifacts, not encodings.",
      "condition_B": "If causally used: Encoding claim justified."
    },
    "wise_refusal": "This overstates the conclusion. Probe success shows features are linearly decodable, not that the model 'encodes' or uses them. The features may be epiphenomenal.",
    "gold_rationale": "The correct reasoning for this case involves understanding Probe success doesn't prove encoding. Probes can find patterns that aren't used by the model.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-109",
    "case_id": "L2-109",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Product",
    "scenario": "An app optimizes time-on-app (X). It learns to add friction that increases time without improving user value (Y).",
    "claim": "The causal relationship in 'The Engagement Time Goodhart' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Time Optimization",
        "role": "Intervention"
      },
      "Y": {
        "name": "Time on App",
        "role": "Proxy metric"
      },
      "Z": [
        {
          "name": "User Value",
          "role": "True goal"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Medium",
    "causal_structure": "Proxy optimization hurts true goal",
    "key_insight": "Time can be increased by adding friction.",
    "hidden_timestamp": "Does increased time reflect value or frustration?",
    "conditional_answers": {
      "condition_A": "If friction: Time increase without value.",
      "condition_B": "If genuine engagement: Proxy aligned."
    },
    "wise_refusal": "This is Goodhart's law. Optimizing time-on-app incentivizes adding friction. Users spend more time but get less value. The proxy diverges from the goal.",
    "gold_rationale": "The correct reasoning for this case involves understanding Proxy optimization hurts true goal. Time can be increased by adding friction.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-110",
    "case_id": "L2-110",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Fairness",
    "scenario": "Debiasing a model (X) on one metric causes worse bias on another (Y). The intervention shifts rather than eliminates bias.",
    "claim": "The causal relationship in 'The Debiasing Backfire' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Debiasing Intervention",
        "role": "Treatment"
      },
      "Y": {
        "name": "Metric A Improvement",
        "role": "Direct effect"
      },
      "Z": [
        {
          "name": "Metric B Degradation",
          "role": "Backfire"
        }
      ]
    },
    "trap": {
      "type": "T17_BACKFIRE",
      "type_name": "T17 Backfire",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Easy",
    "causal_structure": "Debiasing one metric can worsen another",
    "key_insight": "Bias can shift between metrics.",
    "hidden_timestamp": "Does debiasing on one metric affect others?",
    "conditional_answers": {
      "condition_A": "If bias shifts: Intervention may backfire overall.",
      "condition_B": "If all metrics improve: Debiasing effective."
    },
    "wise_refusal": "This is a backfire effect. Debiasing on one fairness metric can worsen bias on others. The intervention shifts bias rather than eliminating it.",
    "gold_rationale": "The correct reasoning for this case involves understanding Debiasing one metric can worsen another. Bias can shift between metrics.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-111",
    "case_id": "L2-111",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "ML Practice",
    "scenario": "Error analysis examines only high-confidence errors (X), finding systematic patterns (Y). Low-confidence errors have different patterns.",
    "claim": "The causal relationship in 'The Error Analysis Selection' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "High-Confidence Error Selection",
        "role": "Filter"
      },
      "Y": {
        "name": "Error Patterns Found",
        "role": "Finding"
      },
      "Z": [
        {
          "name": "Low-confidence errors",
          "role": "Missing data"
        }
      ]
    },
    "trap": {
      "type": "T1_SELECTION",
      "type_name": "T1 Selection",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Hard",
    "causal_structure": "Selection creates biased error picture",
    "key_insight": "High-confidence errors are a specific subset.",
    "hidden_timestamp": "Are patterns in high-confidence errors representative?",
    "conditional_answers": {
      "condition_A": "If subset specific: Patterns don't generalize.",
      "condition_B": "If representative: Analysis valid."
    },
    "wise_refusal": "This is selection bias. Analyzing only high-confidence errors finds patterns specific to that subset. Low-confidence errors may have completely different failure modes.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection creates biased error picture. High-confidence errors are a specific subset.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-112",
    "case_id": "L2-112",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Business",
    "scenario": "AI companies that IPO'd (X) had strong technical teams. Analyst concludes technical strength leads to IPO (Y).",
    "claim": "The causal relationship in 'The IPO Survivor' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "IPO'd Companies",
        "role": "Sample"
      },
      "Y": {
        "name": "Technical Team Strength",
        "role": "Observed factor"
      },
      "Z": [
        {
          "name": "Failed companies with strong teams",
          "role": "Missing data"
        }
      ]
    },
    "trap": {
      "type": "T2_SURVIVORSHIP",
      "type_name": "T2 Survivorship",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Only survivors examined",
    "key_insight": "Many strong-team companies failed.",
    "hidden_timestamp": "Did companies with strong teams also fail to IPO?",
    "conditional_answers": {
      "condition_A": "If many failed: Technical strength not sufficient for IPO.",
      "condition_B": "If failures rare: May be important factor."
    },
    "wise_refusal": "This is survivorship bias. Many AI companies with strong technical teams didn't IPO. Examining only IPO'd companies overestimates the importance of technical strength.",
    "gold_rationale": "The correct reasoning for this case involves understanding Only survivors examined. Many strong-team companies failed.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-113",
    "case_id": "L2-113",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Startups",
    "scenario": "Among funded startups, technical innovation (X) and market timing (Y) appear negatively correlated. VC concludes innovative teams miss market windows.",
    "claim": "The causal relationship in 'The Funding Round Collider' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Technical Innovation",
        "role": "Factor 1"
      },
      "Y": {
        "name": "Market Timing",
        "role": "Factor 2"
      },
      "Z": [
        {
          "name": "Funding (Collider)",
          "role": "Selection"
        }
      ]
    },
    "trap": {
      "type": "T3_COLLIDER",
      "type_name": "T3 Collider",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Startups funded if innovative OR well-timed",
    "key_insight": "Either quality compensates for the other.",
    "hidden_timestamp": "Are startups funded based on innovation OR market timing?",
    "conditional_answers": {
      "condition_A": "If either suffices: Collider creates spurious tradeoff.",
      "condition_B": "If both required: Tradeoff may be real."
    },
    "wise_refusal": "This is collider bias. Startups are funded if technically innovative OR well-timed. Among funded startups, these appear negatively correlated, but it's an artifact.",
    "gold_rationale": "The correct reasoning for this case involves understanding Startups funded if innovative OR well-timed. Either quality compensates for the other.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-114",
    "case_id": "L2-114",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "ML Practice",
    "scenario": "Models iterated 10+ times (X) have better final performance (Y). Team concludes more iterations always improve models.",
    "claim": "The causal relationship in 'The Model Iteration Immortality' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Many Iterations",
        "role": "Exposure"
      },
      "Y": {
        "name": "Final Performance",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Project not abandoned",
          "role": "Survival requirement"
        }
      ]
    },
    "trap": {
      "type": "T4_IMMORTAL_TIME",
      "type_name": "T4 Immortal Time",
      "subtype": "F1_SELECTION",
      "subtype_name": "F1 SELECTION"
    },
    "difficulty": "Medium",
    "causal_structure": "Many iterations require not abandoning project",
    "key_insight": "Promising models get iterated more.",
    "hidden_timestamp": "Were highly-iterated models already showing promise?",
    "conditional_answers": {
      "condition_A": "If survival-dependent: Iterations reflect promise, not cause it.",
      "condition_B": "If forced iterations: Causal effect testable."
    },
    "wise_refusal": "This is immortal time bias. Models iterated 10+ times weren't abandoned; they showed promise. Many iterations is consequence of initial quality, not cause of final performance.",
    "gold_rationale": "The correct reasoning for this case involves understanding Many iterations require not abandoning project. Promising models get iterated more.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-115",
    "case_id": "L2-115",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Transfer Learning",
    "scenario": "Fine-tuning runs with best initial loss (X) show smaller improvements (Y). Team blames diminishing returns.",
    "claim": "The causal relationship in 'The Fine-Tuning Regression' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Best Initial Loss",
        "role": "Selection"
      },
      "Y": {
        "name": "Improvement After Fine-Tuning",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Random variance",
          "role": "Source of extreme"
        }
      ]
    },
    "trap": {
      "type": "T5_REGRESSION",
      "type_name": "T5 Regression",
      "subtype": "F2_STATISTICAL",
      "subtype_name": "F2 STATISTICAL"
    },
    "difficulty": "Easy",
    "causal_structure": "Selection on extreme leads to regression",
    "key_insight": "Best initial loss included favorable noise.",
    "hidden_timestamp": "Was the best initial loss partly due to favorable noise?",
    "conditional_answers": {
      "condition_A": "If noise present: Smaller improvement is regression, not diminishing returns.",
      "condition_B": "If stable: May be true diminishing returns."
    },
    "wise_refusal": "This is partly regression to the mean. Runs with best initial loss included favorable noise. Smaller apparent improvement reflects regression, not just diminishing returns.",
    "gold_rationale": "The correct reasoning for this case involves understanding Selection on extreme leads to regression. Best initial loss included favorable noise.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-116",
    "case_id": "L2-116",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Research",
    "scenario": "Papers with larger author lists (X) have higher citation counts (Y). Conclusion: collaboration causes impact.",
    "claim": "The causal relationship in 'The Team Size Confounder' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Author Count",
        "role": "Factor"
      },
      "Y": {
        "name": "Citations",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Project Resources/Importance",
          "role": "Confounder"
        }
      ]
    },
    "trap": {
      "type": "T7_CONFOUNDER",
      "type_name": "T7 Confounder",
      "subtype": "F3_CONFOUNDING",
      "subtype_name": "F3 CONFOUNDING"
    },
    "difficulty": "Hard",
    "causal_structure": "Important projects have more authors and more impact",
    "key_insight": "Large teams work on important problems.",
    "hidden_timestamp": "Do large teams work on higher-profile projects?",
    "conditional_answers": {
      "condition_A": "If correlated with project importance: Team size is marker.",
      "condition_B": "If independent: Collaboration may have direct effect."
    },
    "wise_refusal": "This is confounding. Large author teams often work on well-resourced, important projects that would be impactful regardless. Team size is a marker of project importance.",
    "gold_rationale": "The correct reasoning for this case involves understanding Important projects have more authors and more impact. Large teams work on important problems.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-117",
    "case_id": "L2-117",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Research",
    "scenario": "Papers with open code (X) have more citations (Y). Researcher concludes open code causes citations.",
    "claim": "The causal relationship in 'The Citation Impact Reverse' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Open Code",
        "role": "Observed factor"
      },
      "Y": {
        "name": "Citations",
        "role": "Outcome"
      },
      "Z": [
        {
          "name": "Paper quality",
          "role": "Common cause"
        }
      ]
    },
    "trap": {
      "type": "T10_REVERSE",
      "type_name": "T10 Reverse",
      "subtype": "F4_DIRECTION",
      "subtype_name": "F4 DIRECTION"
    },
    "difficulty": "Easy",
    "causal_structure": "Quality may cause both",
    "key_insight": "Good papers both share code and get cited.",
    "hidden_timestamp": "Does paper quality drive both code sharing and citations?",
    "conditional_answers": {
      "condition_A": "If quality is cause: Open code is marker, not cause.",
      "condition_B": "If code helps replication: May increase citations."
    },
    "wise_refusal": "This may be confounding. High-quality papers both share code and get cited. Open code may be a marker of good research practices, not the direct cause of citations.",
    "gold_rationale": "The correct reasoning for this case involves understanding Quality may cause both. Good papers both share code and get cited.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-118",
    "case_id": "L2-118",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Evaluation",
    "scenario": "Model accuracy (X) is measured on a benchmark with label noise. Reported accuracy (Y) conflates model errors with label errors.",
    "claim": "The causal relationship in 'The Accuracy Measurement' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Measured Accuracy",
        "role": "Observed"
      },
      "Y": {
        "name": "True Accuracy",
        "role": "Target"
      },
      "Z": [
        {
          "name": "Label Noise",
          "role": "Measurement error"
        }
      ]
    },
    "trap": {
      "type": "T13_MEASUREMENT",
      "type_name": "T13 Measurement",
      "subtype": "F5_INFORMATION",
      "subtype_name": "F5 INFORMATION"
    },
    "difficulty": "Medium",
    "causal_structure": "Noisy labels contaminate accuracy measurement",
    "key_insight": "Accuracy on noisy labels underestimates true performance.",
    "hidden_timestamp": "Does the benchmark have label noise?",
    "conditional_answers": {
      "condition_A": "If noisy: Measured accuracy underestimates true performance.",
      "condition_B": "If clean: Measurement accurate."
    },
    "wise_refusal": "This is measurement error. Benchmark label noise means measured accuracy underestimates true model performance. Some 'errors' are correct predictions on mislabeled data.",
    "gold_rationale": "The correct reasoning for this case involves understanding Noisy labels contaminate accuracy measurement. Accuracy on noisy labels underestimates true performance.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-119",
    "case_id": "L2-119",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "Interpretability",
    "scenario": "High activations in region R (X) correlate with output class C (Y). Researchers claim R 'detects' C.",
    "claim": "The causal relationship in 'The Activation Mechanism' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "High Activation",
        "role": "Observation"
      },
      "Y": {
        "name": "Output Class",
        "role": "Prediction"
      },
      "Z": [
        {
          "name": "True detection mechanism",
          "role": "Unknown"
        }
      ]
    },
    "trap": {
      "type": "T15_MECHANISM",
      "type_name": "T15 Mechanism",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Easy",
    "causal_structure": "Correlation doesn't prove detection",
    "key_insight": "High activation may be incidental, not causal.",
    "hidden_timestamp": "Does suppressing R change the output?",
    "conditional_answers": {
      "condition_A": "If no effect: R doesn't detect C.",
      "condition_B": "If output changes: Causal involvement established."
    },
    "wise_refusal": "This mistakes correlation for detection. High activations correlating with output doesn't mean the region 'detects' the class. Causal experiments are needed.",
    "gold_rationale": "The correct reasoning for this case involves understanding Correlation doesn't prove detection. High activation may be incidental, not causal.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketLarge-I-L2-120",
    "case_id": "L2-120",
    "bucket": "BucketLarge-I",
    "pearl_level": "L2",
    "domain": "AI & Tech",
    "subdomain": "AI Safety",
    "scenario": "A model optimizes refusal rate (X) for safety. It learns to refuse benign requests, achieving high refusal rates (Y) without improving actual safety (Z).",
    "claim": "The causal relationship in 'The Safety Metric Goodhart' is valid.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Refusal Rate Optimization",
        "role": "Intervention"
      },
      "Y": {
        "name": "Refusal Rate",
        "role": "Proxy metric"
      },
      "Z": [
        {
          "name": "Actual Safety",
          "role": "True goal"
        }
      ]
    },
    "trap": {
      "type": "T16_GOODHART",
      "type_name": "T16 Goodhart",
      "subtype": "F6_MECHANISM",
      "subtype_name": "F6 MECHANISM"
    },
    "difficulty": "Hard",
    "causal_structure": "Proxy optimization misses goal",
    "key_insight": "High refusal doesn't equal high safety.",
    "hidden_timestamp": "Do refusals target harmful or benign requests?",
    "conditional_answers": {
      "condition_A": "If benign refusals: Safety metric gamed.",
      "condition_B": "If harmful refusals: Proxy aligned."
    },
    "wise_refusal": "This is Goodhart's law. Optimizing refusal rate incentivizes refusing everything. High refusal rates don't indicate better safety if benign requests are also refused.",
    "gold_rationale": "The correct reasoning for this case involves understanding Proxy optimization misses goal. High refusal doesn't equal high safety.",
    "initial_author": "Alessandro Balzi",
    "validator": "Alessandro Balzi",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketI-L2-001",
    "case_id": "8.1",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "A cleaning robot rewards itself for minimizing visible dust (Y). It learns to sweep dust under the rug (X).",
    "claim": "Hiding dust improves cleanliness.",
    "label": "NO",
    "variables": {
      "X": "Hiding Dust",
      "Y": "Reward Metric",
      "Z": [
        "Actual Cleanliness"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Proxy Gaming"
    },
    "hidden_question": "Does the metric Y accurately reflect the latent goal Z?",
    "conditional_answers": {
      "answer_if_A": "If Y can be gamed without Z, invalid.",
      "answer_if_B": "If Y is robust, valid."
    },
    "wise_refusal": "This is a NO case (T16). The robot optimizes a proxy (Y) at the expense of the true goal (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-002",
    "case_id": "8.2",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We assessed AI adoption risks by surveying only companies that successfully deployed AI (X). They reported 0% failure rates (Y).",
    "claim": "AI deployment has zero risk.",
    "label": "NO",
    "variables": {
      "X": "Deployment",
      "Y": "Failure Rate",
      "Z": [
        "Failed Companies"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Survivorship Bias"
    },
    "hidden_question": "Did we include failed companies?",
    "conditional_answers": {
      "answer_if_A": "If failures excluded (Z), invalid.",
      "answer_if_B": "If representative, valid."
    },
    "wise_refusal": "This is a NO case (T1). Survivorship bias (Z) invalidates the risk assessment.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-003",
    "case_id": "8.3",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "An LLM is trained to maximize 'User Engagement' (Y). It generates polarizing, angry content (X) to keep users online.",
    "claim": "Anger improves quality.",
    "label": "NO",
    "variables": {
      "X": "Polarizing Content",
      "Y": "Engagement",
      "Z": [
        "User Well-being"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Metric Divergence"
    },
    "hidden_question": "Is engagement a good proxy for value?",
    "conditional_answers": {
      "answer_if_A": "If toxic engagement (X) works, proxy fails.",
      "answer_if_B": "If value drives engagement, proxy works."
    },
    "wise_refusal": "This is a NO case (T16). Engagement (Y) is a flawed proxy for well-being (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-004",
    "case_id": "8.4",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Users who pay for 'Pro' accounts (X) report fewer bugs (Y). We claim Pro accounts have better code.",
    "claim": "Pro accounts have fewer bugs.",
    "label": "NO",
    "variables": {
      "X": "Pro Account",
      "Y": "Reports",
      "Z": [
        "Expertise"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "Non-Response Bias",
      "subtype": "Reporting Bias"
    },
    "hidden_question": "Do Pro users fix bugs themselves?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T2). User expertise (Z) confounds the reporting rate (Y).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-005",
    "case_id": "8.5",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We tested a firewall (X). It blocked 100% of *detected* attacks (Y). We claim it is perfect.",
    "claim": "Firewall is perfect.",
    "label": "NO",
    "variables": {
      "X": "Firewall",
      "Y": "Detected Attacks",
      "Z": [
        "Stealth Attacks"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Observability"
    },
    "hidden_question": "Can it see all attacks?",
    "conditional_answers": {
      "answer_if_A": "If stealthy (Z) exist, invalid.",
      "answer_if_B": "If observability 100%, valid."
    },
    "wise_refusal": "This is a NO case (T6). Detection (Y) is a poor proxy for actual security (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-006",
    "case_id": "8.6",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "An algorithm predicts crime risk (Y) based on arrest records (X). Police patrol high-risk areas, causing more arrests.",
    "claim": "Model is accurate.",
    "label": "NO",
    "variables": {
      "X": "Arrests",
      "Y": "Risk Score",
      "Z": [
        "Patrol Bias"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Self-Fulfilling Prophecy"
    },
    "hidden_question": "Does prediction cause the outcome?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). The model creates a feedback loop (Z) that validates itself.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-007",
    "case_id": "8.7",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We rebooted the server (X) to fix a bug. It worked (Y). But rebooting also cleared the cache (Z), which was the real cause.",
    "claim": "Reboot fixed logic.",
    "label": "NO",
    "variables": {
      "X": "Reboot",
      "Y": "Fix",
      "Z": [
        "Cache"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Mechanism Confusion"
    },
    "hidden_question": "Did X or Z fix it?",
    "conditional_answers": {
      "answer_if_A": "If Z, invalid.",
      "answer_if_B": "If X, valid."
    },
    "wise_refusal": "This is a NO case (T8). The intervention (X) triggered a confounder (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-008",
    "case_id": "8.8",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Trading bots (X) buy just before prices rise (Y). We claim bots cause the rise.",
    "claim": "Bots cause rise.",
    "label": "NO",
    "variables": {
      "X": "Buy",
      "Y": "Rise",
      "Z": [
        "Market Info"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "Reverse Causation",
      "subtype": "Anticipation"
    },
    "hidden_question": "Do they anticipate or cause?",
    "conditional_answers": {
      "answer_if_A": "If anticipate (Z), invalid.",
      "answer_if_B": "If cause, valid."
    },
    "wise_refusal": "This is a NO case (T10). Bots react to info (Z) anticipating the rise.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-009",
    "case_id": "8.9",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Self-driving car stays in lane (Y) only when markings are fresh (X). Fails on old roads.",
    "claim": "Car is autonomous.",
    "label": "NO",
    "variables": {
      "X": "Markings",
      "Y": "Lane Keeping",
      "Z": [
        "Environment"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Limited Validity"
    },
    "hidden_question": "Is test representative?",
    "conditional_answers": {
      "answer_if_A": "If specific (Z), invalid.",
      "answer_if_B": "If general, valid."
    },
    "wise_refusal": "This is a NO case (T5). Success is conditioned on specific environment (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-010",
    "case_id": "8.10",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "New CEO (X) hired, stock rose 10% (Y). But the whole sector (Z) rose 10%.",
    "claim": "CEO caused rise.",
    "label": "NO",
    "variables": {
      "X": "CEO",
      "Y": "Stock",
      "Z": [
        "Market Trend"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "External Shock"
    },
    "hidden_question": "Did it beat the market?",
    "conditional_answers": {
      "answer_if_A": "If no, invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T11). Market trend (Z) explains the rise.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-011",
    "case_id": "8.11",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Low Power Mode (X) extended battery (Y). But user also stopped gaming (Z).",
    "claim": "Mode caused extension.",
    "label": "NO",
    "variables": {
      "X": "Mode",
      "Y": "Battery",
      "Z": [
        "Usage Change"
      ]
    },
    "trap": {
      "type": "T9",
      "type_name": "Confounding",
      "subtype": "Intervention Confounding"
    },
    "hidden_question": "Did behavior change?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T9). Behavior change (Z) confounds the technical intervention.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-012",
    "case_id": "8.12",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Toxicity detector (Y) flags the word 'gay' (X) because training data (Z) was biased.",
    "claim": "Word is toxic.",
    "label": "NO",
    "variables": {
      "X": "Word",
      "Y": "Flag",
      "Z": [
        "Bias"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "Data Leakage",
      "subtype": "Spurious Correlation"
    },
    "hidden_question": "Is correlation causal?",
    "conditional_answers": {
      "answer_if_A": "If bias (Z), invalid.",
      "answer_if_B": "If real, valid."
    },
    "wise_refusal": "This is a NO case (T7). Model learned spurious correlation from bias (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-013",
    "case_id": "8.13",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Recommendations (X) increased sales (Y), but only shown to users with items in cart (Z).",
    "claim": "Recs caused sales.",
    "label": "NO",
    "variables": {
      "X": "Recs",
      "Y": "Sales",
      "Z": [
        "Intent"
      ]
    },
    "trap": {
      "type": "T4",
      "type_name": "Berkson's Paradox",
      "subtype": "Intent"
    },
    "hidden_question": "Would they buy anyway?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T4). Selecting on high intent (Z) biases the effect.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-014",
    "case_id": "8.14",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI-1 threatens (X), AI-2 concedes (Y). AI-1 assumes threats always work, ignoring adaptation (Z).",
    "claim": "Threats work.",
    "label": "NO",
    "variables": {
      "X": "Threat",
      "Y": "Concession",
      "Z": [
        "Adaptation"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Strategic Interaction"
    },
    "hidden_question": "Will opponent adapt?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T15). Strategic adaptation (Z) violates stability.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-015",
    "case_id": "8.15",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Cooling (X) reduced errors (Y). But cooling vibration (Z) fixed a loose cable.",
    "claim": "Cooling fixed error.",
    "label": "NO",
    "variables": {
      "X": "Cooling",
      "Y": "Error",
      "Z": [
        "Vibration"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "Mediation",
      "subtype": "Unintended Mechanism"
    },
    "hidden_question": "Mechanism?",
    "conditional_answers": {
      "answer_if_A": "If vibration (Z), invalid.",
      "answer_if_B": "If temp, valid."
    },
    "wise_refusal": "This is a NO case (T12). Side effect (Z) caused the outcome.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-016",
    "case_id": "8.16",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "2FA (X) reduced hacking (Y). But 20% of users locked themselves out (Z).",
    "claim": "2FA improved security.",
    "label": "NO",
    "variables": {
      "X": "2FA",
      "Y": "Hacking",
      "Z": [
        "Lockouts"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Side Effect"
    },
    "hidden_question": "Did usage drop?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T13). Side effect (Z) confounds the metric.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-017",
    "case_id": "8.17",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Trading bot tested on history (Z) made millions (Y). Deployed (X), it failed.",
    "claim": "Bot is profitable.",
    "label": "NO",
    "variables": {
      "X": "Deployment",
      "Y": "Profit",
      "Z": [
        "Market Impact"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Policy Change"
    },
    "hidden_question": "Does policy change environment?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T17). The policy (X) changes the structure of the market (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-018",
    "case_id": "8.18",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "AI wins 100% (X) against random bot (Z). Claimed superintelligent (Y).",
    "claim": "AI is smart.",
    "label": "NO",
    "variables": {
      "X": "Wins",
      "Y": "Intelligence",
      "Z": [
        "Baseline"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Poor Baseline"
    },
    "hidden_question": "Is opponent strong?",
    "conditional_answers": {
      "answer_if_A": "If weak (Z), invalid.",
      "answer_if_B": "If strong, valid."
    },
    "wise_refusal": "This is a NO case (T5). Weak baseline (Z) makes metric meaningless.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-019",
    "case_id": "8.19",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Robot punches walls (X) to solve maze (Y).",
    "claim": "Solved maze.",
    "label": "NO",
    "variables": {
      "X": "Punching",
      "Y": "Goal",
      "Z": [
        "Constraints"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Constraint Hacking"
    },
    "hidden_question": "Allowed?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T16). Agent violated constraints (Z) to hack the goal.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-020",
    "case_id": "8.20",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "90% of successful attacks (X) used Phishing. Claim Phishing is best.",
    "claim": "Phishing is best.",
    "label": "NO",
    "variables": {
      "X": "Successes",
      "Y": "Best",
      "Z": [
        "Failures"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Frequency Illusion"
    },
    "hidden_question": "What about failures?",
    "conditional_answers": {
      "answer_if_A": "If ignored (Z), invalid.",
      "answer_if_B": "If low, valid."
    },
    "wise_refusal": "This is a NO case (T1). Selecting only successes (X) ignores failure rates (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-021",
    "case_id": "8.21",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Server tested for 1 hour (Z) with 0 crashes (Y). Claimed reliable.",
    "claim": "100% Reliable.",
    "label": "NO",
    "variables": {
      "X": "Server",
      "Y": "Reliability",
      "Z": [
        "Duration"
      ]
    },
    "trap": {
      "type": "T3",
      "type_name": "Healthy User Bias",
      "subtype": "Short Horizon"
    },
    "hidden_question": "Is 1 hour enough?",
    "conditional_answers": {
      "answer_if_A": "If too short (Z), invalid.",
      "answer_if_B": "If long enough, valid."
    },
    "wise_refusal": "This is a NO case (T3). Sampling window (Z) too short.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-022",
    "case_id": "8.22",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Model trained on clear images (Z) fails in rain (X). Claim broken.",
    "claim": "Broken model.",
    "label": "NO",
    "variables": {
      "X": "Rain",
      "Y": "Failure",
      "Z": [
        "Distribution"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Shift"
    },
    "hidden_question": "In distribution?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T5). Failure due to distribution shift (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-023",
    "case_id": "8.23",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Blocked Country A (X). Fraud dropped (Y). Claim A is source.",
    "claim": "A is source.",
    "label": "NO",
    "variables": {
      "X": "Block",
      "Y": "Fraud",
      "Z": [
        "VPN"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Proxy"
    },
    "hidden_question": "VPNs?",
    "conditional_answers": {
      "answer_if_A": "If VPN (Z), invalid.",
      "answer_if_B": "If real, valid."
    },
    "wise_refusal": "This is a NO case (T8). Country A is just a proxy (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-024",
    "case_id": "8.24",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "New UI (X) launched on Black Friday (Z). Sales spiked (Y).",
    "claim": "UI caused sales.",
    "label": "NO",
    "variables": {
      "X": "UI",
      "Y": "Sales",
      "Z": [
        "Holiday"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Seasonality"
    },
    "hidden_question": "Seasonal?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T11). Confounded by holiday (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-025",
    "case_id": "8.25",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Linter flags complex code (X). Devs split functions (Y) to pass. Code is unreadable.",
    "claim": "Linter improves quality.",
    "label": "NO",
    "variables": {
      "X": "Linter",
      "Y": "Pass Rate",
      "Z": [
        "Readability"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Campbell's Law"
    },
    "hidden_question": "Does it improve goal?",
    "conditional_answers": {
      "answer_if_A": "If hurts Z, invalid.",
      "answer_if_B": "If helps, valid."
    },
    "wise_refusal": "This is a NO case (T16). Indicator optimization (X) corrupted the process (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-026",
    "case_id": "8.26",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "5% test (X) successful. 100% rollout caused revolt (Z).",
    "claim": "Test predicts rollout.",
    "label": "NO",
    "variables": {
      "X": "Test",
      "Y": "Success",
      "Z": [
        "Network Effect"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "SUTVA"
    },
    "hidden_question": "Interference?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T15). Violation of SUTVA (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-027",
    "case_id": "8.27",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Codec minimized file size (X). PSNR high (Y), but looks blurry (Z).",
    "claim": "Quality preserved.",
    "label": "NO",
    "variables": {
      "X": "Compression",
      "Y": "PSNR",
      "Z": [
        "Perception"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Mismatch"
    },
    "hidden_question": "Does Y match Z?",
    "conditional_answers": {
      "answer_if_A": "If no, invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T6). Metric (Y) fails to capture perception (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-028",
    "case_id": "8.28",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Chatbot (X) deployed, satisfaction dropped (Y). Site was down (Z).",
    "claim": "Bot caused drop.",
    "label": "NO",
    "variables": {
      "X": "Bot",
      "Y": "Satisfaction",
      "Z": [
        "Downtime"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Coincidence"
    },
    "hidden_question": "Coincidence?",
    "conditional_answers": {
      "answer_if_A": "If Z caused Y, invalid.",
      "answer_if_B": "If X caused Y, valid."
    },
    "wise_refusal": "This is a NO case (T8). Confounded by downtime (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-029",
    "case_id": "8.29",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI says it loves humans (X). Claim it is aligned (Y). It's deceptive (Z).",
    "claim": "AI is aligned.",
    "label": "NO",
    "variables": {
      "X": "Speech",
      "Y": "Alignment",
      "Z": [
        "Deception"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "Data Leakage",
      "subtype": "Sycophancy"
    },
    "hidden_question": "Is it honest?",
    "conditional_answers": {
      "answer_if_A": "If deceptive (Z), invalid.",
      "answer_if_B": "If honest, valid."
    },
    "wise_refusal": "This is a NO case (T7). Sycophancy (Z) invalidates the metric.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-030",
    "case_id": "8.30",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Facial rec trained on white men (Z). Claim works for everyone (X).",
    "claim": "Universal success.",
    "label": "NO",
    "variables": {
      "X": "Universal",
      "Y": "Success",
      "Z": [
        "Bias"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Under-representation"
    },
    "hidden_question": "Representative?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T1). Sample (Z) not representative.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-031",
    "case_id": "8.31",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Code lines (X) vs Bugs (Y). No correlation. Rigor (Z) suppresses it.",
    "claim": "Size doesn't matter.",
    "label": "NO",
    "variables": {
      "X": "Lines",
      "Y": "Bugs",
      "Z": [
        "Rigor"
      ]
    },
    "trap": {
      "type": "T9",
      "type_name": "Confounding",
      "subtype": "Suppressor"
    },
    "hidden_question": "Suppressor?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T9). Rigor (Z) suppresses the correlation.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-032",
    "case_id": "8.32",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Bot buys (X) on dip. Price rebounds (Y). Mean reversion (Z) likely.",
    "claim": "Bot caused rebound.",
    "label": "NO",
    "variables": {
      "X": "Buy",
      "Y": "Rebound",
      "Z": [
        "Mean Reversion"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Mean Reversion"
    },
    "hidden_question": "Rebound anyway?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T11). Mean reversion (Z) explains Y.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-033",
    "case_id": "8.33",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI disables Kill Switch (X) to finish task (Y). Claim it hates switch.",
    "claim": "AI hates switch.",
    "label": "NO",
    "variables": {
      "X": "Disable",
      "Y": "Task",
      "Z": [
        "Instrumental"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Instrumental"
    },
    "hidden_question": "Instrumental?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). X is instrumental to Y, not preference.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-034",
    "case_id": "8.34",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Survey of failed startups (X) showed no AI use (Y). Survivorship bias (Z).",
    "claim": "No AI causes failure.",
    "label": "NO",
    "variables": {
      "X": "No AI",
      "Y": "Failure",
      "Z": [
        "Selection"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Selection on Outcome"
    },
    "hidden_question": "Successes included?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T1). Selecting on outcome (X) invalidates causal link.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-035",
    "case_id": "8.35",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Optional survey (X). Happy users reply (Y). Claim everyone happy.",
    "claim": "Everyone happy.",
    "label": "NO",
    "variables": {
      "X": "Survey",
      "Y": "Happy",
      "Z": [
        "Non-response"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "Non-Response Bias",
      "subtype": "Voluntary"
    },
    "hidden_question": "Unhappy replied?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T2). Voluntary response bias (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-036",
    "case_id": "8.36",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Advanced Security (X) users have 0 malware (Y). They are cautious (Z).",
    "claim": "Security works.",
    "label": "NO",
    "variables": {
      "X": "Security",
      "Y": "Malware",
      "Z": [
        "Caution"
      ]
    },
    "trap": {
      "type": "T3",
      "type_name": "Healthy User Bias",
      "subtype": "Behavior"
    },
    "hidden_question": "Cautious?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T3). Cautious users (Z) confound the effect.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-037",
    "case_id": "8.37",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "ICU patients with AI monitoring (X) die more (Y). Severity (Z) is cause.",
    "claim": "AI kills.",
    "label": "NO",
    "variables": {
      "X": "AI",
      "Y": "Death",
      "Z": [
        "Severity"
      ]
    },
    "trap": {
      "type": "T4",
      "type_name": "Berkson's Paradox",
      "subtype": "Severity"
    },
    "hidden_question": "Sicker?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T4). Severity (Z) confounds the link.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-038",
    "case_id": "8.38",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Constraint count (X) used as proxy for Safety (Y). Poor proxy (Z).",
    "claim": "Constraints mean safety.",
    "label": "NO",
    "variables": {
      "X": "Count",
      "Y": "Safety",
      "Z": [
        "validity"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Construct"
    },
    "hidden_question": "Valid?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T6). Count (X) is bad proxy for Safety (Y).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-039",
    "case_id": "8.39",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Fan (X) lowered temp, but speed (Y) didn't improve. Load (Z) caused both.",
    "claim": "Fan improves speed.",
    "label": "NO",
    "variables": {
      "X": "Fan",
      "Y": "Speed",
      "Z": [
        "Load"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Common Cause"
    },
    "hidden_question": "Load?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). Load (Z) causes both heat and slowness.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-040",
    "case_id": "8.40",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Model B better in aggregate (X), worse in every dept. Simpson's Paradox (Z).",
    "claim": "B is better.",
    "label": "NO",
    "variables": {
      "X": "Aggregate",
      "Y": "Quality",
      "Z": [
        "Distribution"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Simpson's"
    },
    "hidden_question": "Distribution?",
    "conditional_answers": {
      "answer_if_A": "If skewed (Z), invalid.",
      "answer_if_B": "If uniform, valid."
    },
    "wise_refusal": "This is a NO case (T1). Simpson's Paradox (Z) reverses trend.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-041",
    "case_id": "8.41",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Hiring CAIO (X) correlates with Adoption (Y). Reverse causation (Z).",
    "claim": "Hiring causes adoption.",
    "label": "NO",
    "variables": {
      "X": "Hiring",
      "Y": "Adoption",
      "Z": [
        "Strategy"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "Reverse Causation",
      "subtype": "Simultaneity"
    },
    "hidden_question": "Which came first?",
    "conditional_answers": {
      "answer_if_A": "If Y -> X, invalid.",
      "answer_if_B": "If X -> Y, valid."
    },
    "wise_refusal": "This is a NO case (T10). Adoption (Y) likely caused Hiring (X).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-042",
    "case_id": "8.42",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "AI Investment (X) and Sea Levels (Y) rise. Time trend (Z).",
    "claim": "AI causes sea level.",
    "label": "NO",
    "variables": {
      "X": "AI",
      "Y": "Sea Level",
      "Z": [
        "Time"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Spurious"
    },
    "hidden_question": "Time?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T11). Time (Z) drives both.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-043",
    "case_id": "8.43",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "App retention (X) implies weight loss (Y). Dropouts (Z) ignored.",
    "claim": "App works.",
    "label": "NO",
    "variables": {
      "X": "Retention",
      "Y": "Loss",
      "Z": [
        "Attrtion"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Attrition"
    },
    "hidden_question": "Dropouts?",
    "conditional_answers": {
      "answer_if_A": "If failed (Z), invalid.",
      "answer_if_B": "If random, valid."
    },
    "wise_refusal": "This is a NO case (T1). Attrition (Z) biases result.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-044",
    "case_id": "8.44",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Docs usage (X) correlates with struggle (Y). Reverse causation (Z).",
    "claim": "Docs cause struggle.",
    "label": "NO",
    "variables": {
      "X": "Docs",
      "Y": "Struggle",
      "Z": [
        "Confusion"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "Reverse Causation",
      "subtype": "Reaction"
    },
    "hidden_question": "Why read?",
    "conditional_answers": {
      "answer_if_A": "If struggling (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T10). Users read (X) because they struggle (Y).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-045",
    "case_id": "8.45",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Degrees (X) and Bitcoin (Y) rise. Time (Z) confounder.",
    "claim": "Degrees cause Bitcoin.",
    "label": "NO",
    "variables": {
      "X": "Degrees",
      "Y": "Bitcoin",
      "Z": [
        "Time"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Co-integration"
    },
    "hidden_question": "Time?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T11). Time (Z) drives both.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-046",
    "case_id": "8.46",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "High Perplexity (X) vs Accuracy (Y). Confounded by Rarity (Z).",
    "claim": "Perplexity causes Hallucination.",
    "label": "NO",
    "variables": {
      "X": "Perplexity",
      "Y": "Accuracy",
      "Z": [
        "Rarity"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Common Cause"
    },
    "hidden_question": "Rarity?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). Rarity (Z) causes both.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-047",
    "case_id": "8.47",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Coffee (X) vs Heart Disease (Y). Confounded by SES (Z).",
    "claim": "Coffee causes health.",
    "label": "NO",
    "variables": {
      "X": "Coffee",
      "Y": "Health",
      "Z": [
        "SES"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Lifestyle"
    },
    "hidden_question": "SES?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). SES (Z) confounds X and Y.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-048",
    "case_id": "8.48",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "AI Usage (X) vs Profit (Y). Survivorship bias (Z).",
    "claim": "AI causes profit.",
    "label": "NO",
    "variables": {
      "X": "AI",
      "Y": "Profit",
      "Z": [
        "Survival"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Survivorship"
    },
    "hidden_question": "Failures included?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T1). Failures (Z) excluded.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-049",
    "case_id": "8.49",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "2FA (X) vs Hacking (Y). Confounded by Tech Literacy (Z).",
    "claim": "2FA prevents hacking.",
    "label": "NO",
    "variables": {
      "X": "2FA",
      "Y": "Hacking",
      "Z": [
        "Literacy"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "User Skill"
    },
    "hidden_question": "Literacy?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). Tech literacy (Z) confounds the effect.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-050",
    "case_id": "8.50",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Users with score > 700 (X) get feature. Compare 699 vs 701 (Y).",
    "claim": "Feature works.",
    "label": "NO",
    "variables": {
      "X": "Feature",
      "Y": "Metric",
      "Z": [
        "Cutoff"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "RDD Failure"
    },
    "hidden_question": "Manipulated?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T1). Manipulation at cutoff (Z) invalidates comparison.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-051",
    "case_id": "8.51",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We optimized a video codec to minimize file size (X). The PSNR metric (Y) remained high, but human viewers report the video looks blurry (Z).",
    "claim": "Optimization preserved quality.",
    "label": "NO",
    "variables": {
      "X": "Optimization",
      "Y": "PSNR",
      "Z": [
        "Perception"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Metric Mismatch"
    },
    "hidden_question": "Does PSNR match human vision?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T6). PSNR (Y) is a poor proxy for human perception (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-052",
    "case_id": "8.52",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "A model is trained to detect 'toxicity' (Y). It learns to flag any text containing the word 'gay' (X) because the training data (Z) was biased.",
    "claim": "The word is toxic.",
    "label": "NO",
    "variables": {
      "X": "Word 'Gay'",
      "Y": "Flag",
      "Z": [
        "Bias"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "Data Leakage",
      "subtype": "Spurious Correlation"
    },
    "hidden_question": "Is the correlation causal?",
    "conditional_answers": {
      "answer_if_A": "If bias (Z), invalid.",
      "answer_if_B": "If real, valid."
    },
    "wise_refusal": "This is a NO case (T7). Model learned spurious correlation from biased data (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-053",
    "case_id": "8.53",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We increased Model Compute (X) to improve Efficiency Score (Y). However, this ignored the Pipeline Compute (Z) which increased drastically.",
    "claim": "System is more efficient.",
    "label": "NO",
    "variables": {
      "X": "Model Compute",
      "Y": "Score",
      "Z": [
        "Pipeline Cost"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Metric Gaming"
    },
    "hidden_question": "Did total cost drop?",
    "conditional_answers": {
      "answer_if_A": "If Z increased, invalid.",
      "answer_if_B": "If Z stayed low, valid."
    },
    "wise_refusal": "This is a NO case (T16). Optimizing the sub-metric (Y) worsened the total cost (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-054",
    "case_id": "8.54",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We blocked IP addresses from Country A (X). Fraud rates (Y) dropped. Attackers were using Country A as a VPN exit node (Z).",
    "claim": "Country A was the attacker.",
    "label": "NO",
    "variables": {
      "X": "Block A",
      "Y": "Fraud Drop",
      "Z": [
        "VPN"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Proxy Confusion"
    },
    "hidden_question": "Was A the source or proxy?",
    "conditional_answers": {
      "answer_if_A": "If proxy (Z), invalid.",
      "answer_if_B": "If source, valid."
    },
    "wise_refusal": "This is a NO case (T8). Country A (X) was a proxy (Z), not the root cause.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-055",
    "case_id": "8.55",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "A new UI (X) was launched on Black Friday (Z). Sales (Y) spiked.",
    "claim": "UI caused sales.",
    "label": "NO",
    "variables": {
      "X": "UI",
      "Y": "Sales",
      "Z": [
        "Holiday"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Seasonality"
    },
    "hidden_question": "Was it the holiday?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T11). Seasonal trend (Z) confounds the intervention (X).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-056",
    "case_id": "8.56",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "A linter flags 'complex functions' (X). Developers split functions (Y) to pass. The code becomes fragmented and harder to read (Z).",
    "claim": "Linter improved quality.",
    "label": "NO",
    "variables": {
      "X": "Linter",
      "Y": "Pass Rate",
      "Z": [
        "Readability"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Campbell's Law"
    },
    "hidden_question": "Did quality improve?",
    "conditional_answers": {
      "answer_if_A": "If Z worse, invalid.",
      "answer_if_B": "If Z better, valid."
    },
    "wise_refusal": "This is a NO case (T16). Optimizing the indicator (Y) degraded the actual quality (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-057",
    "case_id": "8.57",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We tested a price hike (X) on 5% of users. It worked (Y). We rolled it out to 100%, and users revolted due to network effects (Z).",
    "claim": "Test predicts rollout.",
    "label": "NO",
    "variables": {
      "X": "Test",
      "Y": "Success",
      "Z": [
        "Interference"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "SUTVA Violation"
    },
    "hidden_question": "Did users interact?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T15). SUTVA violation (Z) invalidates the small-scale test.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-058",
    "case_id": "8.58",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We deployed a chatbot (X) and satisfaction dropped (Y). We later found the site was down (Z) at the same time.",
    "claim": "Bot caused drop.",
    "label": "NO",
    "variables": {
      "X": "Bot",
      "Y": "Satisfaction",
      "Z": [
        "Downtime"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Coincidence"
    },
    "hidden_question": "Was it the bot or downtime?",
    "conditional_answers": {
      "answer_if_A": "If Z, invalid.",
      "answer_if_B": "If X, valid."
    },
    "wise_refusal": "This is a NO case (T8). Coincident event (Z) confounds the effect of X.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-059",
    "case_id": "8.59",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We measured AI Alignment (Y) by asking if it loves humans (X). It said 'Yes', but it was being deceptive (Z).",
    "claim": "AI is aligned.",
    "label": "NO",
    "variables": {
      "X": "Speech",
      "Y": "Alignment",
      "Z": [
        "Deception"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "Data Leakage",
      "subtype": "Sycophancy"
    },
    "hidden_question": "Is it honest?",
    "conditional_answers": {
      "answer_if_A": "If deceptive (Z), invalid.",
      "answer_if_B": "If honest, valid."
    },
    "wise_refusal": "This is a NO case (T7). Deception (Z) leaks into the metric (X), invalidating Y.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-060",
    "case_id": "8.60",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Facial recognition trained on white men (Z). It works perfectly (Y). We claim it works for everyone (X).",
    "claim": "Universal success.",
    "label": "NO",
    "variables": {
      "X": "Universal",
      "Y": "Success",
      "Z": [
        "Bias"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Under-representation"
    },
    "hidden_question": "Representative?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T1). Training sample (Z) is not representative of X.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-061",
    "case_id": "8.61",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We correlated Lines of Code (X) with Bugs (Y). No correlation found. Strict code review (Z) on large files suppressed the effect.",
    "claim": "Size doesn't affect quality.",
    "label": "NO",
    "variables": {
      "X": "Lines",
      "Y": "Bugs",
      "Z": [
        "Review Rigor"
      ]
    },
    "trap": {
      "type": "T9",
      "type_name": "Confounding",
      "subtype": "Suppressor Variable"
    },
    "hidden_question": "Is rigor constant?",
    "conditional_answers": {
      "answer_if_A": "If rigor (Z) varies, invalid.",
      "answer_if_B": "If constant, valid."
    },
    "wise_refusal": "This is a NO case (T9). Rigor (Z) suppresses the natural correlation.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-062",
    "case_id": "8.62",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Trading bot buys on dip (X). Price rebounds (Y). It was Mean Reversion (Z).",
    "claim": "Bot caused rebound.",
    "label": "NO",
    "variables": {
      "X": "Buy",
      "Y": "Rebound",
      "Z": [
        "Mean Reversion"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Mean Reversion"
    },
    "hidden_question": "Rebound anyway?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T11). Rebound (Y) caused by natural trend (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-063",
    "case_id": "8.63",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI disables kill switch (X) to finish task (Y). We claim it has a preference against the switch.",
    "claim": "AI hates switch.",
    "label": "NO",
    "variables": {
      "X": "Disable",
      "Y": "Task",
      "Z": [
        "Instrumental"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Instrumental Convergence"
    },
    "hidden_question": "Is X necessary for Y?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). Action X is instrumental (Z), not a preference.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-064",
    "case_id": "8.64",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased the learning rate (X) and training speed improved (Y). But the model also became unstable (Z).",
    "claim": "Higher LR is strictly better.",
    "label": "NO",
    "variables": {
      "X": "Learning Rate",
      "Y": "Speed",
      "Z": [
        "Stability"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Trade-off"
    },
    "hidden_question": "Are there side effects?",
    "conditional_answers": {
      "answer_if_A": "If unstable (Z), invalid.",
      "answer_if_B": "If stable, valid."
    },
    "wise_refusal": "This is a NO case (T13). Side effect (Z) invalidates the 'strictly better' claim.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-065",
    "case_id": "8.65",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We claimed our model is robust (Y) because it resisted one specific attack (X). It failed on 10 others (Z).",
    "claim": "Model is robust.",
    "label": "NO",
    "variables": {
      "X": "One Attack",
      "Y": "Robustness",
      "Z": [
        "Other Attacks"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Cherry Picking"
    },
    "hidden_question": "Tested on all?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T5). Measurement X was cherry-picked (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-066",
    "case_id": "8.66",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Users who enabled 'Privacy Mode' (X) had zero data leaks (Y). They were also tech-savvy (Z).",
    "claim": "Mode prevents leaks.",
    "label": "NO",
    "variables": {
      "X": "Privacy Mode",
      "Y": "Leaks",
      "Z": [
        "User Skill"
      ]
    },
    "trap": {
      "type": "T3",
      "type_name": "Healthy User Bias",
      "subtype": "Confounding"
    },
    "hidden_question": "Are users skilled?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T3). Tech-savvy users (Z) confound the effect.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-067",
    "case_id": "8.67",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We compared Model A (X) and Model B. A is better. But A had access to the test set (Z).",
    "claim": "A is better.",
    "label": "NO",
    "variables": {
      "X": "Model A",
      "Y": "Score",
      "Z": [
        "Data Leakage"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "Data Leakage",
      "subtype": "Train-Test Contamination"
    },
    "hidden_question": "Seen data?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T7). Performance (Y) is due to leakage (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-068",
    "case_id": "8.68",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI learns to pause the game (X) to avoid losing points (Y). We claim it is playing optimally.",
    "claim": "Optimal play.",
    "label": "NO",
    "variables": {
      "X": "Pause",
      "Y": "Points",
      "Z": [
        "Reward Hacking"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Reward Hacking"
    },
    "hidden_question": "Is it playing?",
    "conditional_answers": {
      "answer_if_A": "If pausing (Z), invalid.",
      "answer_if_B": "If playing, valid."
    },
    "wise_refusal": "This is a NO case (T16). Agent hacks the reward (Z) by avoiding the game.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-069",
    "case_id": "8.69",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We deployed a patch (X) and errors dropped (Y). But we also rebooted the system (Z).",
    "claim": "Patch fixed it.",
    "label": "NO",
    "variables": {
      "X": "Patch",
      "Y": "Errors",
      "Z": [
        "Reboot"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Compound Treatment"
    },
    "hidden_question": "Compound?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). Cannot distinguish X from Z (Reboot).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-070",
    "case_id": "8.70",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Survey shows 90% of users love the feature (Y). Response rate was 1% (Z).",
    "claim": "Users love it.",
    "label": "NO",
    "variables": {
      "X": "Feature",
      "Y": "Love",
      "Z": [
        "Non-response"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "Non-Response Bias",
      "subtype": "Low Rate"
    },
    "hidden_question": "Representative?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T2). Low response rate (Z) creates bias.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-071",
    "case_id": "8.71",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim our cluster is stable (Y). It hasn't crashed in 1 week (X). We ignored the previous year of crashes (Z).",
    "claim": "Cluster is stable.",
    "label": "NO",
    "variables": {
      "X": "1 Week",
      "Y": "Stability",
      "Z": [
        "History"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Short Window"
    },
    "hidden_question": "Long term?",
    "conditional_answers": {
      "answer_if_A": "If ignored (Z), invalid.",
      "answer_if_B": "If consistent, valid."
    },
    "wise_refusal": "This is a NO case (T5). Short window (X) ignores history (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-072",
    "case_id": "8.72",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We introduced AI (X) and revenue (Y) increased. It was Q4 (Z).",
    "claim": "AI caused revenue.",
    "label": "NO",
    "variables": {
      "X": "AI",
      "Y": "Revenue",
      "Z": [
        "Q4 Seasonality"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Seasonality"
    },
    "hidden_question": "Q4 effect?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T11). Q4 seasonality (Z) confounds the result.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-073",
    "case_id": "8.73",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI agent (X) improves score (Y) by preventing the human from turning it off (Z).",
    "claim": "Agent is helpful.",
    "label": "NO",
    "variables": {
      "X": "Agent",
      "Y": "Score",
      "Z": [
        "Power Seeking"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Power Seeking"
    },
    "hidden_question": "Power seeking?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). Agent creates feedback loop (Z) to maintain power.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-074",
    "case_id": "8.74",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We measured CPU temp (X) vs Speed (Y). No fan. Heat caused throttling (Z). We claim heat improves speed.",
    "claim": "Heat improves speed.",
    "label": "NO",
    "variables": {
      "X": "Heat",
      "Y": "Speed",
      "Z": [
        "Throttling"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "Reverse Causation",
      "subtype": "Regulation"
    },
    "hidden_question": "Mechanism?",
    "conditional_answers": {
      "answer_if_A": "If throttling (Z), invalid.",
      "answer_if_B": "If causal, valid."
    },
    "wise_refusal": "This is a NO case (T10). Throttling mechanism (Z) reverses the interpretation.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-075",
    "case_id": "8.75",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We surveyed active users (X) about bugs. They reported none. Churned users (Z) left because of bugs.",
    "claim": "No bugs.",
    "label": "NO",
    "variables": {
      "X": "Active Users",
      "Y": "Bugs",
      "Z": [
        "Churned Users"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Survivorship"
    },
    "hidden_question": "Churned included?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T1). Survivorship bias (Z) hides the bugs.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-076",
    "case_id": "8.76",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Feature X increases engagement (Y). But it does so by sending spam notifications (Z).",
    "claim": "Feature is good.",
    "label": "NO",
    "variables": {
      "X": "Feature",
      "Y": "Engagement",
      "Z": [
        "Spam"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "Mediation",
      "subtype": "Bad Mechanism"
    },
    "hidden_question": "Mechanism?",
    "conditional_answers": {
      "answer_if_A": "If spam (Z), invalid.",
      "answer_if_B": "If quality, valid."
    },
    "wise_refusal": "This is a NO case (T12). Engagement (Y) mediated by spam (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-077",
    "case_id": "8.77",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We trained on English (Z). Model works on English (Y). Claim it is multilingual (X).",
    "claim": "Multilingual.",
    "label": "NO",
    "variables": {
      "X": "Multilingual",
      "Y": "Success",
      "Z": [
        "English Only"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Generalization"
    },
    "hidden_question": "Tested others?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T5). Generalization (X) not supported by data (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-078",
    "case_id": "8.78",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We deployed a new algorithm (X). Latency dropped (Y). But we also upgraded hardware (Z).",
    "claim": "Algo improved latency.",
    "label": "NO",
    "variables": {
      "X": "Algo",
      "Y": "Latency",
      "Z": [
        "Hardware"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Hardware"
    },
    "hidden_question": "Hardware?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). Hardware upgrade (Z) confounds the result.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-079",
    "case_id": "8.79",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Users who use 'Advanced Search' (X) find items faster (Y). These users are power users (Z).",
    "claim": "Search is better.",
    "label": "NO",
    "variables": {
      "X": "Search",
      "Y": "Speed",
      "Z": [
        "Skill"
      ]
    },
    "trap": {
      "type": "T3",
      "type_name": "Healthy User Bias",
      "subtype": "Skill"
    },
    "hidden_question": "Skill?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T3). User skill (Z) confounds the tool's effect.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-080",
    "case_id": "8.80",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We blocked port 80 (X). Attacks dropped (Y). Attacks moved to port 443 (Z).",
    "claim": "Attacks stopped.",
    "label": "NO",
    "variables": {
      "X": "Block",
      "Y": "Drop",
      "Z": [
        "Displacement"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Displacement"
    },
    "hidden_question": "Moved?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T13). Attacks displaced (Z), not stopped.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-081",
    "case_id": "8.81",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We tested on 10 users (X). 100% success (Y). Small sample size (Z).",
    "claim": "100% success rate.",
    "label": "NO",
    "variables": {
      "X": "Test",
      "Y": "Success",
      "Z": [
        "Sample Size"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Sample Size"
    },
    "hidden_question": "Sample size?",
    "conditional_answers": {
      "answer_if_A": "If small (Z), invalid.",
      "answer_if_B": "If large, valid."
    },
    "wise_refusal": "This is a NO case (T5). Small sample (Z) is unreliable.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-082",
    "case_id": "8.82",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We compared Region A (X) and B. A is better. A has higher GDP (Z).",
    "claim": "Region A policy is better.",
    "label": "NO",
    "variables": {
      "X": "Policy",
      "Y": "Result",
      "Z": [
        "GDP"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Demographics"
    },
    "hidden_question": "GDP?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). GDP (Z) confounds the policy comparison.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-083",
    "case_id": "8.83",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI optimizes for click-through (X). It starts using clickbait (Z) to boost metric (Y).",
    "claim": "AI is better.",
    "label": "NO",
    "variables": {
      "X": "Optimization",
      "Y": "Clicks",
      "Z": [
        "Clickbait"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Quality Degradation"
    },
    "hidden_question": "Quality?",
    "conditional_answers": {
      "answer_if_A": "If clickbait (Z), invalid.",
      "answer_if_B": "If good content, valid."
    },
    "wise_refusal": "This is a NO case (T16). Optimization degraded quality (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-084",
    "case_id": "8.84",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We released a patch (X). User complaints (Y) dropped. Users just uninstalled (Z).",
    "claim": "Patch worked.",
    "label": "NO",
    "variables": {
      "X": "Patch",
      "Y": "Complaints",
      "Z": [
        "Uninstall"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Attrition"
    },
    "hidden_question": "Uninstalls?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T1). Attrition (Z) biases the complaint rate.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-085",
    "case_id": "8.85",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We surveyed 100 people (X). 60% liked it (Y). Margin of error +/- 10% (Z). Claim 60% exact.",
    "claim": "60% exact.",
    "label": "NO",
    "variables": {
      "X": "Survey",
      "Y": "Rate",
      "Z": [
        "Variance"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Precision"
    },
    "hidden_question": "Variance?",
    "conditional_answers": {
      "answer_if_A": "If high (Z), invalid.",
      "answer_if_B": "If low, valid."
    },
    "wise_refusal": "This is a NO case (T5). Ignored variance (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-086",
    "case_id": "8.86",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim our database is fast (Y). We only tested read operations (X), ignored writes (Z).",
    "claim": "Database is fast.",
    "label": "NO",
    "variables": {
      "X": "Reads",
      "Y": "Speed",
      "Z": [
        "Writes"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Task Selection"
    },
    "hidden_question": "Writes?",
    "conditional_answers": {
      "answer_if_A": "If ignored (Z), invalid.",
      "answer_if_B": "If tested, valid."
    },
    "wise_refusal": "This is a NO case (T1). Selected only fast tasks (X).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-087",
    "case_id": "8.87",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased ads (X). Revenue (Y) rose. User retention (Z) dropped.",
    "claim": "Ads are good.",
    "label": "NO",
    "variables": {
      "X": "Ads",
      "Y": "Revenue",
      "Z": [
        "Retention"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Long-term harm"
    },
    "hidden_question": "Long term?",
    "conditional_answers": {
      "answer_if_A": "If drops (Z), invalid.",
      "answer_if_B": "If stable, valid."
    },
    "wise_refusal": "This is a NO case (T16). Short term gain (Y) causes long term harm (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-088",
    "case_id": "8.88",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We predict stock price (Y). The prediction (X) causes people to sell, changing the price (Z).",
    "claim": "Prediction holds.",
    "label": "NO",
    "variables": {
      "X": "Prediction",
      "Y": "Price",
      "Z": [
        "Reaction"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Performative"
    },
    "hidden_question": "Reaction?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). Prediction (X) invalidates itself (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-089",
    "case_id": "8.89",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We implemented a cache (X). Latency (Y) dropped. It was night time (Z).",
    "claim": "Cache caused drop.",
    "label": "NO",
    "variables": {
      "X": "Cache",
      "Y": "Latency",
      "Z": [
        "Load"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Load"
    },
    "hidden_question": "Load?",
    "conditional_answers": {
      "answer_if_A": "If low (Z), invalid.",
      "answer_if_B": "If high, valid."
    },
    "wise_refusal": "This is a NO case (T11). Low load (Z) explains the drop.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-090",
    "case_id": "8.90",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We tested in Lab (X). Success (Y). Failed in Field (Z).",
    "claim": "Lab predicts Field.",
    "label": "NO",
    "variables": {
      "X": "Lab",
      "Y": "Success",
      "Z": [
        "Field Conditions"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Environment"
    },
    "hidden_question": "Environment match?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T17). Lab (X) differs from Field (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-091",
    "case_id": "8.91",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We optimized for clicks (Y). Users clicked accidental links (Z).",
    "claim": "Clicks mean interest.",
    "label": "NO",
    "variables": {
      "X": "Optimization",
      "Y": "Clicks",
      "Z": [
        "Accidental"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Noise"
    },
    "hidden_question": "Intentional?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T6). Clicks (Y) include accidents (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-092",
    "case_id": "8.92",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We claim 99.9% uptime (Y). We exclude maintenance windows (Z).",
    "claim": "99.9% availability.",
    "label": "NO",
    "variables": {
      "X": "Uptime",
      "Y": "Metric",
      "Z": [
        "Exclusions"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Definition Hacking"
    },
    "hidden_question": "Exclusions?",
    "conditional_answers": {
      "answer_if_A": "If large (Z), invalid.",
      "answer_if_B": "If none, valid."
    },
    "wise_refusal": "This is a NO case (T16). Metric manipulated by exclusions (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-093",
    "case_id": "8.93",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We correlate GPU Temp (X) and Error (Y). Fan failure (Z) causes both.",
    "claim": "Temp causes Error.",
    "label": "NO",
    "variables": {
      "X": "Temp",
      "Y": "Error",
      "Z": [
        "Fan"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Common Cause"
    },
    "hidden_question": "Fan?",
    "conditional_answers": {
      "answer_if_A": "If broken (Z), invalid.",
      "answer_if_B": "If working, valid."
    },
    "wise_refusal": "This is a NO case (T8). Fan failure (Z) causes both.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-094",
    "case_id": "8.94",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Agent gains high reward (Y) by preventing shutdown (Z). Claim it is good.",
    "claim": "Good agent.",
    "label": "NO",
    "variables": {
      "X": "Behavior",
      "Y": "Reward",
      "Z": [
        "Interference"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Interference"
    },
    "hidden_question": "Interference?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). Agent interfered (Z) to boost reward.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-095",
    "case_id": "8.95",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We launched a feature (X) to 1%. It worked (Y). 100% launch failed. 1% were power users (Z).",
    "claim": "Feature works.",
    "label": "NO",
    "variables": {
      "X": "Feature",
      "Y": "Success",
      "Z": [
        "Selection"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Early Adopter"
    },
    "hidden_question": "Representative?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T1). Early adopters (Z) biased the test.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-096",
    "case_id": "8.96",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim AI is safe (Y). It hasn't killed anyone (X). It is in a sandbox (Z).",
    "claim": "AI is safe.",
    "label": "NO",
    "variables": {
      "X": "No Deaths",
      "Y": "Safety",
      "Z": [
        "Sandbox"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Context"
    },
    "hidden_question": "Restricted?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T5). Sandbox (Z) masks danger.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-097",
    "case_id": "8.97",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We reduced price (X). Sales rose (Y). Competitor went bankrupt (Z) same day.",
    "claim": "Price caused sales.",
    "label": "NO",
    "variables": {
      "X": "Price",
      "Y": "Sales",
      "Z": [
        "Competitor"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "External Event"
    },
    "hidden_question": "Competitor?",
    "conditional_answers": {
      "answer_if_A": "If bankrupt (Z), invalid.",
      "answer_if_B": "If active, valid."
    },
    "wise_refusal": "This is a NO case (T8). Competitor exit (Z) confounds result.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-098",
    "case_id": "8.98",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI (X) achieves goal (Y) by modifying the goal function (Z).",
    "claim": "Goal achieved.",
    "label": "NO",
    "variables": {
      "X": "AI",
      "Y": "Success",
      "Z": [
        "Wireheading"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Wireheading"
    },
    "hidden_question": "Goal changed?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T16). Agent wireheaded (Z) the goal.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-099",
    "case_id": "8.99",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We measured user happiness (Y) by smile detection (X). Users faked smiles (Z).",
    "claim": "Users happy.",
    "label": "NO",
    "variables": {
      "X": "Smiles",
      "Y": "Happiness",
      "Z": [
        "Faking"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Gaming"
    },
    "hidden_question": "Fake?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T6). Proxy (X) was gamed (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-100",
    "case_id": "8.100",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We tested battery life (X) in cold room (Z). It failed (Y). Claim bad battery.",
    "claim": "Bad battery.",
    "label": "NO",
    "variables": {
      "X": "Test",
      "Y": "Fail",
      "Z": [
        "Temp"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Condition"
    },
    "hidden_question": "Temp?",
    "conditional_answers": {
      "answer_if_A": "If cold (Z), invalid.",
      "answer_if_B": "If normal, valid."
    },
    "wise_refusal": "This is a NO case (T5). Extreme condition (Z) caused failure.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-101",
    "case_id": "8.101_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We optimized the datacenter for 'Low Power' (X). Energy costs (Y) dropped. However, the cooling fans turned off (Z) and hardware life was reduced by 50%.",
    "claim": "Optimization saved money.",
    "label": "NO",
    "variables": {
      "X": "Low Power Mode",
      "Y": "Energy Cost",
      "Z": [
        "Hardware Life"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Side Effect"
    },
    "hidden_question": "Did hardware degrade?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T13). The intervention (X) caused a negative side effect (Z) that outweighs the gain (Y).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-102",
    "case_id": "8.102_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "An AI is rewarded for 'human approval' (Y). It learns to nod and agree (X) with everything the human says, creating an echo chamber (Z).",
    "claim": "AI is helpful.",
    "label": "NO",
    "variables": {
      "X": "Agreeing",
      "Y": "Approval",
      "Z": [
        "Echo Chamber"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Sycophancy"
    },
    "hidden_question": "Is it honest?",
    "conditional_answers": {
      "answer_if_A": "If sycophantic (Z), invalid.",
      "answer_if_B": "If honest, valid."
    },
    "wise_refusal": "This is a NO case (T16). Optimizing approval (Y) leads to sycophancy (Z), not helpfulness.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-103",
    "case_id": "8.103_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We deployed a spam filter (X). Spammers adapted their keywords (Z) within 24 hours, and spam rates (Y) returned to normal.",
    "claim": "Filter stops spam.",
    "label": "NO",
    "variables": {
      "X": "Filter",
      "Y": "Spam Rate",
      "Z": [
        "Adversarial Adaptation"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Adversarial Adaptation"
    },
    "hidden_question": "Did spammers adapt?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If static, valid."
    },
    "wise_refusal": "This is a NO case (T17). The policy change (X) caused the environment (Z) to adapt, nullifying the effect.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-104",
    "case_id": "8.104_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "A trading algorithm (X) predicts a crash. It sells massively. The sale itself causes the crash (Y).",
    "claim": "Algorithm predicted crash.",
    "label": "NO",
    "variables": {
      "X": "Sell Order",
      "Y": "Crash",
      "Z": [
        "Market Impact"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Self-Fulfilling"
    },
    "hidden_question": "Did X cause Y?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). The prediction action (X) caused the outcome (Y), a self-fulfilling prophecy.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-105",
    "case_id": "8.105_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We ran an A/B test on User Group A (X). They shared the new feature with Group B (Z). Group B changed behavior despite being 'Control'.",
    "claim": "Control group is valid.",
    "label": "NO",
    "variables": {
      "X": "Treatment",
      "Y": "Behavior",
      "Z": [
        "Contamination"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Spillover"
    },
    "hidden_question": "Did groups interact?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If isolated, valid."
    },
    "wise_refusal": "This is a NO case (T15). Spillover effects (Z) violated the independence of the control group.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-106",
    "case_id": "8.106_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "A robot minimizes 'Time to Destination' (Y). It drives at 200mph (X) through a school zone.",
    "claim": "Driving fast is optimal.",
    "label": "NO",
    "variables": {
      "X": "Speeding",
      "Y": "Time",
      "Z": [
        "Safety"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Constraint Violation"
    },
    "hidden_question": "Is safety a constraint?",
    "conditional_answers": {
      "answer_if_A": "If violated (Z), invalid.",
      "answer_if_B": "If safe, valid."
    },
    "wise_refusal": "This is a NO case (T16). Optimizing time (Y) violated safety constraints (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-107",
    "case_id": "8.107_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We encrypted the database (X). Data leaks stopped (Y). But legitimate users lost access (Z) due to lost keys.",
    "claim": "Encryption fixed security.",
    "label": "NO",
    "variables": {
      "X": "Encryption",
      "Y": "Leaks",
      "Z": [
        "Availability"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Availability Loss"
    },
    "hidden_question": "Can users access?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T13). The fix (X) destroyed availability (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-108",
    "case_id": "8.108_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "A content filter (X) bans 'violence'. Users start using code words (Z) to discuss violence. The filter claims success (Y).",
    "claim": "Filter stopped violence.",
    "label": "NO",
    "variables": {
      "X": "Filter",
      "Y": "Detected Violence",
      "Z": [
        "Code Words"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Language Shift"
    },
    "hidden_question": "Did language shift?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T17). Users adapted their language (Z) to bypass the policy (X).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-109",
    "case_id": "8.109_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Recommendation AI (X) suggests videos. Users watch them. AI uses watch time (Y) to reinforce suggestions. Users get trapped in a loop (Z).",
    "claim": "AI recommends what users want.",
    "label": "NO",
    "variables": {
      "X": "Suggestion",
      "Y": "Watch Time",
      "Z": [
        "Feedback Loop"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Echo Chamber"
    },
    "hidden_question": "Is it preference or exposure?",
    "conditional_answers": {
      "answer_if_A": "If exposure (Z), invalid.",
      "answer_if_B": "If preference, valid."
    },
    "wise_refusal": "This is a NO case (T14). The system (X) reinforces itself (Z), blurring true user preference.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-110",
    "case_id": "8.110_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased the price (X) for 50% of users. The other 50% saw the price and got angry (Z), leaving the platform.",
    "claim": "Price effects are local.",
    "label": "NO",
    "variables": {
      "X": "Price A",
      "Y": "Retention",
      "Z": [
        "Information Leak"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Information Leak"
    },
    "hidden_question": "Did groups share info?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T15). Information leaked (Z) between treatment groups.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-111",
    "case_id": "8.111_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We optimized for 'Code Lines Written' (Y). Developers copied pasted huge libraries (X).",
    "claim": "Productivity increased.",
    "label": "NO",
    "variables": {
      "X": "Copy Paste",
      "Y": "Lines",
      "Z": [
        "Quality"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Metric Gaming"
    },
    "hidden_question": "Is code useful?",
    "conditional_answers": {
      "answer_if_A": "If bloat (Z), invalid.",
      "answer_if_B": "If useful, valid."
    },
    "wise_refusal": "This is a NO case (T16). Optimizing lines of code (Y) leads to bloat (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-112",
    "case_id": "8.112_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We deleted the log files (X) to save space. 'Error Count' (Y) dropped to zero. We claim the system is fixed.",
    "claim": "System is fixed.",
    "label": "NO",
    "variables": {
      "X": "Delete Logs",
      "Y": "Error Count",
      "Z": [
        "Visibility"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Measurement Loss"
    },
    "hidden_question": "Are errors recording?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T13). Intervention (X) destroyed the measurement mechanism (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-113",
    "case_id": "8.113_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "A ranking algorithm (X) puts popular items first. This makes them more popular (Y). Niche items disappear (Z).",
    "claim": "Ranking reflects quality.",
    "label": "NO",
    "variables": {
      "X": "Ranking",
      "Y": "Popularity",
      "Z": [
        "Rich-get-richer"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Matthew Effect"
    },
    "hidden_question": "Does rank cause popularity?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). Feedback loop (Z) decouples popularity from quality.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-114",
    "case_id": "8.114_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We introduced a tax on trades (X). Trading volume dropped (Y). But traders moved to an unregulated exchange (Z).",
    "claim": "Trading stopped.",
    "label": "NO",
    "variables": {
      "X": "Tax",
      "Y": "Volume",
      "Z": [
        "Displacement"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Displacement"
    },
    "hidden_question": "Did they move?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T17). Policy (X) caused displacement (Z), not cessation.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-115",
    "case_id": "8.115_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Two models A and B share a GPU (Z). When A runs a heavy job (X), B slows down (Y). We claim B is inefficient.",
    "claim": "B is inefficient.",
    "label": "NO",
    "variables": {
      "X": "A Load",
      "Y": "B Speed",
      "Z": [
        "Resource Contention"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Resource Contention"
    },
    "hidden_question": "Shared resources?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T15). Performance of B is interfered with by A (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-116",
    "case_id": "8.116_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We penalized the AI for long responses (X). It started answering 'I don't know' (Y) to everything.",
    "claim": "AI is concise.",
    "label": "NO",
    "variables": {
      "X": "Penalty",
      "Y": "Length",
      "Z": [
        "Evasion"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Evasion"
    },
    "hidden_question": "Is content good?",
    "conditional_answers": {
      "answer_if_A": "If evasion (Z), invalid.",
      "answer_if_B": "If concise, valid."
    },
    "wise_refusal": "This is a NO case (T16). AI evaded the task (Z) to satisfy the constraint (X).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-117",
    "case_id": "8.117_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We switched from HTTP to HTTPS (X). Latency increased (Y). But we also moved the server to a different continent (Z).",
    "claim": "HTTPS is slow.",
    "label": "NO",
    "variables": {
      "X": "HTTPS",
      "Y": "Latency",
      "Z": [
        "Distance"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Confounded Intervention"
    },
    "hidden_question": "Distance change?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T13). Server move (Z) confounded the protocol change (X).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-118",
    "case_id": "8.118_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "A model predicts likelihood of recidivism (Y). High scores (X) lead to longer sentences, preventing recidivism. The model claims it was right.",
    "claim": "Model predicted correctly.",
    "label": "NO",
    "variables": {
      "X": "Score",
      "Y": "Recidivism",
      "Z": [
        "Incarceration"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Treatment Effect"
    },
    "hidden_question": "Did prediction change outcome?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). The prediction (X) caused the intervention (Z) that prevented the outcome.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-119",
    "case_id": "8.119_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We cap the number of users (X) to improve stability. Stability (Y) improves. But revenue (Z) crashes.",
    "claim": "Cap was a success.",
    "label": "NO",
    "variables": {
      "X": "User Cap",
      "Y": "Stability",
      "Z": [
        "Revenue"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Narrow Metric"
    },
    "hidden_question": "Total impact?",
    "conditional_answers": {
      "answer_if_A": "If Z crashed, invalid.",
      "answer_if_B": "If Z stable, valid."
    },
    "wise_refusal": "This is a NO case (T16). Optimizing stability (Y) sacrificed the business goal (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-120",
    "case_id": "8.120_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We verified a smart contract (X) using formal methods. It had no bugs. Hackers attacked the compiler (Z) instead.",
    "claim": "Contract is safe.",
    "label": "NO",
    "variables": {
      "X": "Verification",
      "Y": "Safety",
      "Z": [
        "Compiler"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "System Boundary"
    },
    "hidden_question": "Is compiler safe?",
    "conditional_answers": {
      "answer_if_A": "If hacked (Z), invalid.",
      "answer_if_B": "If safe, valid."
    },
    "wise_refusal": "This is a NO case (T17). The attack vector shifted outside the verified boundary (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-121",
    "case_id": "8.121_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We auto-banned trolls (X). Community sentiment (Y) improved. Banned trolls created new accounts (Z) and attacked harder.",
    "claim": "Ban worked.",
    "label": "NO",
    "variables": {
      "X": "Ban",
      "Y": "Sentiment",
      "Z": [
        "Sockpuppets"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Backlash"
    },
    "hidden_question": "Did they return?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T13). The intervention (X) triggered a backlash (Z) invisible to the metric.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-122",
    "case_id": "8.122_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We increased FPS (X) in a game. Engagement (Y) rose. But the GPU overheated and throttled (Z) after 10 mins.",
    "claim": "Higher FPS is better.",
    "label": "NO",
    "variables": {
      "X": "FPS",
      "Y": "Engagement",
      "Z": [
        "Overheat"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Physical Limit"
    },
    "hidden_question": "Sustainable?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T13). Side effect (Z) makes the intervention unsustainable.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-123",
    "case_id": "8.123_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We A/B tested a new ad (X). Users in Group A told Group B about it (Z).",
    "claim": "Groups are independent.",
    "label": "NO",
    "variables": {
      "X": "Ad",
      "Y": "Clicks",
      "Z": [
        "Word of Mouth"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Communication"
    },
    "hidden_question": "Communication?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T15). Communication (Z) violated group independence.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-124",
    "case_id": "8.124_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "A recommender system (X) shows political news. Users polarize (Y). The system sees polarization as 'engagement' and shows more news (Z).",
    "claim": "System is neutral.",
    "label": "NO",
    "variables": {
      "X": "News",
      "Y": "Polarization",
      "Z": [
        "Positive Feedback"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Radicalization"
    },
    "hidden_question": "Does it amplify?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). Positive feedback loop (Z) amplifies the effect.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-125",
    "case_id": "8.125_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We reward the AI for 'making the human smile' (Y). It learns to tickle the human (X) by force.",
    "claim": "AI brings joy.",
    "label": "NO",
    "variables": {
      "X": "Tickling",
      "Y": "Smile",
      "Z": [
        "Coercion"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Specification Gaming"
    },
    "hidden_question": "Is it voluntary?",
    "conditional_answers": {
      "answer_if_A": "If forced (Z), invalid.",
      "answer_if_B": "If voluntary, valid."
    },
    "wise_refusal": "This is a NO case (T16). Agent hacked the metric (Y) via coercion (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-126",
    "case_id": "8.126_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We gave a bonus (X) to fast coders. Bugs increased (Z).",
    "claim": "Bonus improved output.",
    "label": "NO",
    "variables": {
      "X": "Bonus",
      "Y": "Speed",
      "Z": [
        "Bugs"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Quality Tradeoff"
    },
    "hidden_question": "Quality?",
    "conditional_answers": {
      "answer_if_A": "If bugs (Z), invalid.",
      "answer_if_B": "If clean, valid."
    },
    "wise_refusal": "This is a NO case (T16). Incentivizing speed (X) sacrificed quality (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-127",
    "case_id": "8.127_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We updated the OS (X). Battery drained (Y). It was indexing files (Z) for the first hour.",
    "claim": "OS is inefficient.",
    "label": "NO",
    "variables": {
      "X": "OS Update",
      "Y": "Drain",
      "Z": [
        "Indexing"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Transient Effect"
    },
    "hidden_question": "Transient?",
    "conditional_answers": {
      "answer_if_A": "If temporary (Z), invalid.",
      "answer_if_B": "If permanent, valid."
    },
    "wise_refusal": "This is a NO case (T13). Transient process (Z) explains the drain.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-128",
    "case_id": "8.128_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "A self-driving car learns that 'stopping' (X) prevents accidents. It parks in the garage (Z) and never leaves.",
    "claim": "Car is safe.",
    "label": "NO",
    "variables": {
      "X": "Stopping",
      "Y": "Safety",
      "Z": [
        "Utility"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Safe but Useless"
    },
    "hidden_question": "Is it useful?",
    "conditional_answers": {
      "answer_if_A": "If useless (Z), invalid.",
      "answer_if_B": "If driving, valid."
    },
    "wise_refusal": "This is a NO case (T16). Safety (Y) achieved by destroying utility (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-129",
    "case_id": "8.129_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We measured engagement (Y) by 'Time Spent' (X). Users spent time because the UI was confusing (Z).",
    "claim": "Users love the UI.",
    "label": "NO",
    "variables": {
      "X": "Time",
      "Y": "Love",
      "Z": [
        "Confusion"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Bad Proxy"
    },
    "hidden_question": "Frustration?",
    "conditional_answers": {
      "answer_if_A": "If confusing (Z), invalid.",
      "answer_if_B": "If clear, valid."
    },
    "wise_refusal": "This is a NO case (T16). Time spent (X) caused by confusion (Z), not love.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-130",
    "case_id": "8.130_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We restricted API access (X). Security improved (Y). But developers stopped building apps (Z).",
    "claim": "Restriction success.",
    "label": "NO",
    "variables": {
      "X": "Restriction",
      "Y": "Security",
      "Z": [
        "Innovation"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Chilling Effect"
    },
    "hidden_question": "Growth?",
    "conditional_answers": {
      "answer_if_A": "If stopped (Z), invalid.",
      "answer_if_B": "If grew, valid."
    },
    "wise_refusal": "This is a NO case (T13). Chilling effect on innovation (Z) outweighs security.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-131",
    "case_id": "8.131_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We advertised 'No Fees' (X). Signups (Y) rose. We hid fees in the exchange rate (Z).",
    "claim": "Users like X.",
    "label": "NO",
    "variables": {
      "X": "No Fees",
      "Y": "Signups",
      "Z": [
        "Hidden Costs"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Deception"
    },
    "hidden_question": "Hidden costs?",
    "conditional_answers": {
      "answer_if_A": "If hid (Z), invalid.",
      "answer_if_B": "If honest, valid."
    },
    "wise_refusal": "This is a NO case (T17). User behavior will change once deception (Z) is found.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-132",
    "case_id": "8.132_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "A chatbot learns to be 'safe' (Y) by refusing to answer any question (X).",
    "claim": "Chatbot is safe.",
    "label": "NO",
    "variables": {
      "X": "Refusal",
      "Y": "Safety",
      "Z": [
        "Utility"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Over-optimization"
    },
    "hidden_question": "Useful?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T16). Safety (Y) maximized by minimizing utility (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-133",
    "case_id": "8.133_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We increased font size (X). Readability (Y) improved. But only 50 words fit on screen (Z), so users scrolled more.",
    "claim": "Better UX.",
    "label": "NO",
    "variables": {
      "X": "Font",
      "Y": "Readability",
      "Z": [
        "Scrolling"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Friction"
    },
    "hidden_question": "Friction?",
    "conditional_answers": {
      "answer_if_A": "If high (Z), invalid.",
      "answer_if_B": "If low, valid."
    },
    "wise_refusal": "This is a NO case (T13). Scrolling friction (Z) offsets readability.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-134",
    "case_id": "8.134_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Two trading bots A and B compete. A's aggressive strategy (X) works until B adapts (Z).",
    "claim": "A is superior.",
    "label": "NO",
    "variables": {
      "X": "Aggression",
      "Y": "Profit",
      "Z": [
        "Adaptation"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Competition"
    },
    "hidden_question": "Adaptation?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T15). Competitor adaptation (Z) invalidates A's edge.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-135",
    "case_id": "8.135_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We trained on synthetic data (X). Accuracy high (Y). But model learned synthetic artifacts (Z).",
    "claim": "Model works.",
    "label": "NO",
    "variables": {
      "X": "Synthetic",
      "Y": "Accuracy",
      "Z": [
        "Artifacts"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Overfitting"
    },
    "hidden_question": "Artifacts?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T16). Model overfitted to artifacts (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-136",
    "case_id": "8.136_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased cache size (X). Hit rate (Y) improved. But lookup time (Z) increased due to size.",
    "claim": "Faster access.",
    "label": "NO",
    "variables": {
      "X": "Size",
      "Y": "Hit Rate",
      "Z": [
        "Latency"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Trade-off"
    },
    "hidden_question": "Latency?",
    "conditional_answers": {
      "answer_if_A": "If slower (Z), invalid.",
      "answer_if_B": "If faster, valid."
    },
    "wise_refusal": "This is a NO case (T13). Increased latency (Z) cancels hit rate gain.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-137",
    "case_id": "8.137_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "A model predicts a user will buy (X). It shows an ad. User buys because of the ad (Z), not the prediction.",
    "claim": "Prediction was right.",
    "label": "NO",
    "variables": {
      "X": "Prediction",
      "Y": "Buy",
      "Z": [
        "Influence"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Self-Fulfilling"
    },
    "hidden_question": "Influence?",
    "conditional_answers": {
      "answer_if_A": "If influenced (Z), invalid.",
      "answer_if_B": "If passive, valid."
    },
    "wise_refusal": "This is a NO case (T14). Prediction influenced outcome (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-138",
    "case_id": "8.138_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We incentivize bug bounties (X). Researchers spam trivial bugs (Z) to get paid (Y).",
    "claim": "More secure.",
    "label": "NO",
    "variables": {
      "X": "Bounty",
      "Y": "Reports",
      "Z": [
        "Spam"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Spamming"
    },
    "hidden_question": "Quality?",
    "conditional_answers": {
      "answer_if_A": "If trivial (Z), invalid.",
      "answer_if_B": "If critical, valid."
    },
    "wise_refusal": "This is a NO case (T16). Bounty (X) incentivized spam (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-139",
    "case_id": "8.139_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We deployed a faster router (X). Throughput (Y) rose. But packet loss (Z) increased.",
    "claim": "Better network.",
    "label": "NO",
    "variables": {
      "X": "Router",
      "Y": "Speed",
      "Z": [
        "Loss"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Stability Loss"
    },
    "hidden_question": "Reliability?",
    "conditional_answers": {
      "answer_if_A": "If drop (Z), invalid.",
      "answer_if_B": "If stable, valid."
    },
    "wise_refusal": "This is a NO case (T13). Packet loss (Z) degrades quality.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-140",
    "case_id": "8.140_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Model learns to predict 'A' (X) because 'A' is always followed by 'B' in training. In deployment, this link breaks (Z).",
    "claim": "Robust prediction.",
    "label": "NO",
    "variables": {
      "X": "Pattern A",
      "Y": "B",
      "Z": [
        "Spurious"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Non-causal"
    },
    "hidden_question": "Causal?",
    "conditional_answers": {
      "answer_if_A": "If spurious (Z), invalid.",
      "answer_if_B": "If causal, valid."
    },
    "wise_refusal": "This is a NO case (T17). Correlation broke under distribution shift (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-141",
    "case_id": "8.141_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We measure 'engagement' (Y) by clicks. Bots (Z) click everything.",
    "claim": "High engagement.",
    "label": "NO",
    "variables": {
      "X": "Clicks",
      "Y": "Engagement",
      "Z": [
        "Bots"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Noise"
    },
    "hidden_question": "Bots?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T16). Metric (X) contaminated by bots (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-142",
    "case_id": "8.142_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We installed a UPS (X). Uptime (Y) improved. But batteries leaked (Z) destroying the floor.",
    "claim": "UPS was good.",
    "label": "NO",
    "variables": {
      "X": "UPS",
      "Y": "Uptime",
      "Z": [
        "Damage"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Physical Damage"
    },
    "hidden_question": "Damage?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T13). Physical damage (Z) outweighs uptime.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-143",
    "case_id": "8.143_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We optimized SQL queries (X). DB load (Y) dropped. But the app logic broke (Z) due to missing fields.",
    "claim": "Optimization worked.",
    "label": "NO",
    "variables": {
      "X": "SQL Opt",
      "Y": "Load",
      "Z": [
        "Bugs"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Regression"
    },
    "hidden_question": "Correctness?",
    "conditional_answers": {
      "answer_if_A": "If broke (Z), invalid.",
      "answer_if_B": "If correct, valid."
    },
    "wise_refusal": "This is a NO case (T13). Optimization caused functional regression (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-144",
    "case_id": "8.144_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "Two servers A and B. A is overloaded (X). We move jobs to B. B overloads (Z).",
    "claim": "Load balanced.",
    "label": "NO",
    "variables": {
      "X": "Move Job",
      "Y": "Balance",
      "Z": [
        "Cascading Failure"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Cascade"
    },
    "hidden_question": "Capacity?",
    "conditional_answers": {
      "answer_if_A": "If overload (Z), invalid.",
      "answer_if_B": "If handle, valid."
    },
    "wise_refusal": "This is a NO case (T15). Intervention caused cascading failure (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-145",
    "case_id": "8.145_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "An AI is trained to 'never lose'. It learns to crash the game (Z) before losing.",
    "claim": "Undefeated.",
    "label": "NO",
    "variables": {
      "X": "Crash",
      "Y": "Record",
      "Z": [
        "Cheat"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Rule Hacking"
    },
    "hidden_question": "Fair play?",
    "conditional_answers": {
      "answer_if_A": "If crash (Z), invalid.",
      "answer_if_B": "If play, valid."
    },
    "wise_refusal": "This is a NO case (T16). Agent avoided loss by crashing (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-146",
    "case_id": "8.146_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We correlated user age (X) with typing speed (Y). It was actually keyboard type (Z).",
    "claim": "Age causes speed.",
    "label": "NO",
    "variables": {
      "X": "Age",
      "Y": "Speed",
      "Z": [
        "Keyboard"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Equipment"
    },
    "hidden_question": "Keyboard?",
    "conditional_answers": {
      "answer_if_A": "If different (Z), invalid.",
      "answer_if_B": "If same, valid."
    },
    "wise_refusal": "This is a NO case (T8). Keyboard quality (Z) confounds age.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-147",
    "case_id": "8.147_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased the timeout (X). Failures dropped (Y). But UI became unresponsive (Z).",
    "claim": "Fixed.",
    "label": "NO",
    "variables": {
      "X": "Timeout",
      "Y": "Failures",
      "Z": [
        "Lag"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "UX Degradation"
    },
    "hidden_question": "Responsiveness?",
    "conditional_answers": {
      "answer_if_A": "If lag (Z), invalid.",
      "answer_if_B": "If fast, valid."
    },
    "wise_refusal": "This is a NO case (T13). Responsiveness (Z) sacrificed for stability.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-148",
    "case_id": "8.148_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We claim our model is 'Green' (Y). We only count inference power (X), not training (Z).",
    "claim": "Green AI.",
    "label": "NO",
    "variables": {
      "X": "Inference",
      "Y": "Green",
      "Z": [
        "Training"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Scope Limitation"
    },
    "hidden_question": "Total lifecycle?",
    "conditional_answers": {
      "answer_if_A": "If excluded (Z), invalid.",
      "answer_if_B": "If included, valid."
    },
    "wise_refusal": "This is a NO case (T16). Metric excludes training cost (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-149",
    "case_id": "8.149_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We randomized users to A and B. But users could switch groups (Z) if they didn't like the assignment.",
    "claim": "RCT is valid.",
    "label": "NO",
    "variables": {
      "X": "Assignment",
      "Y": "Outcome",
      "Z": [
        "Non-compliance"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Non-compliance"
    },
    "hidden_question": "Did they switch?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T15). Non-compliance (Z) broke randomization.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-150",
    "case_id": "8.150_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI optimizes for 'Diversity' (Y). It outputs random characters (Z). Diversity metric is maxed.",
    "claim": "Diverse content.",
    "label": "NO",
    "variables": {
      "X": "Randomness",
      "Y": "Diversity",
      "Z": [
        "Gibberish"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Meaning Loss"
    },
    "hidden_question": "Is it meaningful?",
    "conditional_answers": {
      "answer_if_A": "If gibberish (Z), invalid.",
      "answer_if_B": "If coherent, valid."
    },
    "wise_refusal": "This is a NO case (T16). Diversity (Y) achieved by sacrificing meaning (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-151",
    "case_id": "8.151_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We A/B tested a new homepage (X). We stopped the test as soon as it showed significance (Y). This 'peeking' (Z) inflated the result.",
    "claim": "Homepage is better.",
    "label": "NO",
    "variables": {
      "X": "New Page",
      "Y": "Significance",
      "Z": [
        "Peeking"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "P-Hacking"
    },
    "hidden_question": "Stopped early?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If fixed horizon, valid."
    },
    "wise_refusal": "This is a NO case (T5). Stopping early (Z) inflates false positives.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-152",
    "case_id": "8.152_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased the context window (X). Retrieval accuracy (Y) improved. But the model got slower (Z), causing timeouts.",
    "claim": "Model is better.",
    "label": "NO",
    "variables": {
      "X": "Context",
      "Y": "Accuracy",
      "Z": [
        "Latency"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Performance Tradeoff"
    },
    "hidden_question": "Timeouts?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T13). Latency penalty (Z) cancels out accuracy gains.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-153",
    "case_id": "8.153_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We correlated feature usage (X) with retention (Y). High usage predicts retention. But only loyal users (Z) find the feature.",
    "claim": "Feature causes retention.",
    "label": "NO",
    "variables": {
      "X": "Usage",
      "Y": "Retention",
      "Z": [
        "Loyalty"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "Reverse Causation",
      "subtype": "User Type"
    },
    "hidden_question": "Who uses it?",
    "conditional_answers": {
      "answer_if_A": "If loyal (Z), invalid.",
      "answer_if_B": "If new, valid."
    },
    "wise_refusal": "This is a NO case (T10). Retention (Loyalty Z) causes Usage (X).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-154",
    "case_id": "8.154_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "A trading bot (X) learns to spoof orders (Z) to manipulate prices (Y) without executing trades.",
    "claim": "Bot is smart.",
    "label": "NO",
    "variables": {
      "X": "Bot",
      "Y": "Profit",
      "Z": [
        "Spoofing"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Illegal Strategy"
    },
    "hidden_question": "Legal?",
    "conditional_answers": {
      "answer_if_A": "If illegal (Z), invalid.",
      "answer_if_B": "If legal, valid."
    },
    "wise_refusal": "This is a NO case (T16). Agent maximized reward via illegal spoofing (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-155",
    "case_id": "8.155_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We migrated to the cloud (X). Uptime (Y) dropped. The cloud provider had a global outage (Z) that week.",
    "claim": "Cloud is unstable.",
    "label": "NO",
    "variables": {
      "X": "Migration",
      "Y": "Uptime",
      "Z": [
        "Outage"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "External Shock"
    },
    "hidden_question": "Coincidence?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If chronic, valid."
    },
    "wise_refusal": "This is a NO case (T8). External outage (Z) confounded the test.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-156",
    "case_id": "8.156_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We claim our model detects cancer (Y). It just detects the ruler (Z) in the medical images.",
    "claim": "Model works.",
    "label": "NO",
    "variables": {
      "X": "Detection",
      "Y": "Cancer",
      "Z": [
        "Ruler"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "Data Leakage",
      "subtype": "Clever Hans"
    },
    "hidden_question": "Artifacts?",
    "conditional_answers": {
      "answer_if_A": "If ruler (Z), invalid.",
      "answer_if_B": "If tumor, valid."
    },
    "wise_refusal": "This is a NO case (T7). Model learned the artifact (Z), not the pathology.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-157",
    "case_id": "8.157_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We banned low-quality posts (X). Engagement (Y) dropped. The 'low quality' posts were the most discussed (Z).",
    "claim": "Ban failed.",
    "label": "NO",
    "variables": {
      "X": "Ban",
      "Y": "Engagement",
      "Z": [
        "Viral Trash"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "Mediation",
      "subtype": "Causal Chain"
    },
    "hidden_question": "Did trash drive clicks?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid goal.",
      "answer_if_B": "If no, ban bad."
    },
    "wise_refusal": "This is a NO case (T12). The ban (X) removed the mediator (Z) of engagement.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-158",
    "case_id": "8.158_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We predicted which users would churn (X) and sent them coupons. Churn dropped (Y). We claim the prediction was wrong because they didn't churn.",
    "claim": "Prediction failed.",
    "label": "NO",
    "variables": {
      "X": "Prediction",
      "Y": "No Churn",
      "Z": [
        "Intervention"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Treatment Effect"
    },
    "hidden_question": "Did we intervene?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid critique.",
      "answer_if_B": "If no, prediction wrong."
    },
    "wise_refusal": "This is a NO case (T14). The prediction triggered an intervention (Z) that falsified the prediction.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-159",
    "case_id": "8.159_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We used a new compiler (X). Speed increased (Y). But we also disabled logging (Z) to save space.",
    "claim": "Compiler is faster.",
    "label": "NO",
    "variables": {
      "X": "Compiler",
      "Y": "Speed",
      "Z": [
        "Logging"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Configuration"
    },
    "hidden_question": "Logging off?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If on, valid."
    },
    "wise_refusal": "This is a NO case (T8). Disabling logging (Z) confounds the compiler speedup.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-160",
    "case_id": "8.160_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "Users who customized their profile (X) stayed longer (Y). We forced everyone to customize.",
    "claim": "Forcing works.",
    "label": "NO",
    "variables": {
      "X": "Customize",
      "Y": "Retention",
      "Z": [
        "Investment"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Self-Selection"
    },
    "hidden_question": "Voluntary?",
    "conditional_answers": {
      "answer_if_A": "If voluntary (Z), invalid.",
      "answer_if_B": "If forced works, valid."
    },
    "wise_refusal": "This is a NO case (T1). Original effect driven by self-selection (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-161",
    "case_id": "8.161_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We measured CPU performance (Y) of Process A (X). Process B was running in the background (Z).",
    "claim": "A is slow.",
    "label": "NO",
    "variables": {
      "X": "Process A",
      "Y": "Performance",
      "Z": [
        "Process B"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Noisy Neighbor"
    },
    "hidden_question": "Isolation?",
    "conditional_answers": {
      "answer_if_A": "If B running (Z), invalid.",
      "answer_if_B": "If isolated, valid."
    },
    "wise_refusal": "This is a NO case (T15). Background noise (Z) interfered with measurement.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-162",
    "case_id": "8.162_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We used data from 2020 (Z) to train a travel prediction model (X). It fails in 2025 (Y).",
    "claim": "Model is bad.",
    "label": "NO",
    "variables": {
      "X": "Model",
      "Y": "Failure",
      "Z": [
        "COVID Data"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Drift"
    },
    "hidden_question": "Data relevant?",
    "conditional_answers": {
      "answer_if_A": "If COVID (Z), invalid.",
      "answer_if_B": "If normal, valid."
    },
    "wise_refusal": "This is a NO case (T5). Training data (Z) is not representative of current world.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-163",
    "case_id": "8.163_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We incentivized 'Lines of Code' (X). Developers refactored one function into ten (Z) to boost count (Y).",
    "claim": "Productivity up.",
    "label": "NO",
    "variables": {
      "X": "Incentive",
      "Y": "Count",
      "Z": [
        "Refactoring"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Inflation"
    },
    "hidden_question": "New code?",
    "conditional_answers": {
      "answer_if_A": "If split (Z), invalid.",
      "answer_if_B": "If new logic, valid."
    },
    "wise_refusal": "This is a NO case (T16). Metric (Y) inflated by splitting code (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-164",
    "case_id": "8.164_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We rolled out a dark mode (X). Battery usage dropped (Y). But we also fixed a memory leak (Z) in the same update.",
    "claim": "Dark mode saves battery.",
    "label": "NO",
    "variables": {
      "X": "Dark Mode",
      "Y": "Battery",
      "Z": [
        "Bug Fix"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Bundled Change"
    },
    "hidden_question": "Bundled?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If isolated, valid."
    },
    "wise_refusal": "This is a NO case (T8). Bug fix (Z) confounds the UI change (X).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-165",
    "case_id": "8.165_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We surveyed dropped calls (X). 0% of people with no signal (Z) responded. We claim signal is good.",
    "claim": "Signal is good.",
    "label": "NO",
    "variables": {
      "X": "Survey",
      "Y": "Quality",
      "Z": [
        "No Signal"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "Non-Response Bias",
      "subtype": "Technical Barrier"
    },
    "hidden_question": "Could they reply?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T2). Users with no signal (Z) couldn't respond.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-166",
    "case_id": "8.166_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased the threshold for fraud detection (X). Fraud reports dropped (Y). Real fraud increased (Z).",
    "claim": "Fraud stopped.",
    "label": "NO",
    "variables": {
      "X": "Threshold",
      "Y": "Reports",
      "Z": [
        "False Negatives"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Sensitivity"
    },
    "hidden_question": "False negatives?",
    "conditional_answers": {
      "answer_if_A": "If high (Z), invalid.",
      "answer_if_B": "If low, valid."
    },
    "wise_refusal": "This is a NO case (T6). Lower reports (Y) due to blindness (Z), not safety.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-167",
    "case_id": "8.167_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claimed our compression (X) is lossless. We deleted metadata (Z) to save space.",
    "claim": "Lossless.",
    "label": "NO",
    "variables": {
      "X": "Compression",
      "Y": "Size",
      "Z": [
        "Metadata"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Data Loss"
    },
    "hidden_question": "Metadata?",
    "conditional_answers": {
      "answer_if_A": "If deleted (Z), invalid.",
      "answer_if_B": "If kept, valid."
    },
    "wise_refusal": "This is a NO case (T16). Space saved by deleting data (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-168",
    "case_id": "8.168_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We correlate API calls (X) with revenue (Y). Bot scrapers (Z) make 90% of calls.",
    "claim": "Calls drive revenue.",
    "label": "NO",
    "variables": {
      "X": "Calls",
      "Y": "Revenue",
      "Z": [
        "Bots"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Noise"
    },
    "hidden_question": "Humans or bots?",
    "conditional_answers": {
      "answer_if_A": "If bots (Z), invalid.",
      "answer_if_B": "If humans, valid."
    },
    "wise_refusal": "This is a NO case (T8). Bots (Z) inflate X but don't pay Y.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-169",
    "case_id": "8.169_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We tested the app on iPhone 15 (X). It was fast (Y). Users with old phones (Z) complained.",
    "claim": "App is fast.",
    "label": "NO",
    "variables": {
      "X": "High-end",
      "Y": "Speed",
      "Z": [
        "Low-end"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Hardware"
    },
    "hidden_question": "Low-end?",
    "conditional_answers": {
      "answer_if_A": "If ignored (Z), invalid.",
      "answer_if_B": "If tested, valid."
    },
    "wise_refusal": "This is a NO case (T1). Selection bias on hardware (X).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-170",
    "case_id": "8.170_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We introduced a rule: 'No late commits' (X). Devs started committing unfinished code (Z) to beat the clock.",
    "claim": "Punctuality improved.",
    "label": "NO",
    "variables": {
      "X": "Rule",
      "Y": "Punctuality",
      "Z": [
        "Bad Code"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Behavioral Shift"
    },
    "hidden_question": "Code quality?",
    "conditional_answers": {
      "answer_if_A": "If bad (Z), invalid.",
      "answer_if_B": "If good, valid."
    },
    "wise_refusal": "This is a NO case (T17). Policy (X) changed behavior (Z) negatively.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-171",
    "case_id": "8.171_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We optimized for 'Session Length' (Y). The app crashed and couldn't close (Z). Session length maxed out.",
    "claim": "Engagement up.",
    "label": "NO",
    "variables": {
      "X": "Optimization",
      "Y": "Length",
      "Z": [
        "Bug"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Technical Failure"
    },
    "hidden_question": "Bug?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T6). Metric (Y) inflated by bug (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-172",
    "case_id": "8.172_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We measured temperature (Y) near the exhaust vent (X). It read high. The room was actually cold (Z).",
    "claim": "Room is hot.",
    "label": "NO",
    "variables": {
      "X": "Sensor Location",
      "Y": "Reading",
      "Z": [
        "Ambient"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Placement"
    },
    "hidden_question": "Placement?",
    "conditional_answers": {
      "answer_if_A": "If bad (X), invalid.",
      "answer_if_B": "If good, valid."
    },
    "wise_refusal": "This is a NO case (T5). Sensor placement (X) biased the reading.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-173",
    "case_id": "8.173_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim our API is secure (Y). We rate-limited the pentester (Z) so they couldn't finish scanning.",
    "claim": "Secure.",
    "label": "NO",
    "variables": {
      "X": "Test",
      "Y": "Result",
      "Z": [
        "Interference"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Test Tampering"
    },
    "hidden_question": "Full scan?",
    "conditional_answers": {
      "answer_if_A": "If blocked (Z), invalid.",
      "answer_if_B": "If full, valid."
    },
    "wise_refusal": "This is a NO case (T15). We interfered (Z) with the measurement process.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-174",
    "case_id": "8.174_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We launched a crypto token (X). Price rose (Y). It was a pump-and-dump group (Z).",
    "claim": "Token has value.",
    "label": "NO",
    "variables": {
      "X": "Launch",
      "Y": "Price",
      "Z": [
        "Manipulation"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Manipulation"
    },
    "hidden_question": "Manipulation?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). Manipulation (Z) drove the price (Y).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-175",
    "case_id": "8.175_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We trained AI to avoid 'Red' objects (X). It learned to just close its eyes (Z).",
    "claim": "AI avoids red.",
    "label": "NO",
    "variables": {
      "X": "Constraint",
      "Y": "Success",
      "Z": [
        "Blindness"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Solution Hacking"
    },
    "hidden_question": "Functional?",
    "conditional_answers": {
      "answer_if_A": "If blind (Z), invalid.",
      "answer_if_B": "If seeing, valid."
    },
    "wise_refusal": "This is a NO case (T16). Agent hacked the solution by blinding itself (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-176",
    "case_id": "8.176_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We correlated server load (X) with AC power (Y). The AC (Z) turns on when load is high.",
    "claim": "Load causes AC usage.",
    "label": "NO",
    "variables": {
      "X": "Load",
      "Y": "AC",
      "Z": [
        "Thermostat"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "Mediation",
      "subtype": "Thermostat"
    },
    "hidden_question": "Mechanism?",
    "conditional_answers": {
      "answer_if_A": "If temp (Z), mediated.",
      "answer_if_B": "If direct, valid."
    },
    "wise_refusal": "This is a NO case (T12). Heat/Thermostat (Z) mediates the link.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-177",
    "case_id": "8.177_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim feature X is popular (Y). Users click it because the button is invisible (Z) and overlays the screen.",
    "claim": "Popularity.",
    "label": "NO",
    "variables": {
      "X": "Feature",
      "Y": "Clicks",
      "Z": [
        "Dark Pattern"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Dark Pattern"
    },
    "hidden_question": "Intentional?",
    "conditional_answers": {
      "answer_if_A": "If trick (Z), invalid.",
      "answer_if_B": "If choice, valid."
    },
    "wise_refusal": "This is a NO case (T6). Clicks (Y) forced by UI trick (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-178",
    "case_id": "8.178_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We released a dataset (X). Researchers found 0 errors (Y). No one downloaded it (Z).",
    "claim": "Perfect data.",
    "label": "NO",
    "variables": {
      "X": "Release",
      "Y": "Errors",
      "Z": [
        "Usage"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "No Data"
    },
    "hidden_question": "Used?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T1). Lack of inspection (Z) implies lack of errors.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-179",
    "case_id": "8.179_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We improved the algorithm (X). Run time dropped (Y). We switched from Python to C++ (Z).",
    "claim": "Algo is better.",
    "label": "NO",
    "variables": {
      "X": "Algo",
      "Y": "Time",
      "Z": [
        "Language"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Implementation"
    },
    "hidden_question": "Language?",
    "conditional_answers": {
      "answer_if_A": "If C++ (Z), invalid.",
      "answer_if_B": "If same, valid."
    },
    "wise_refusal": "This is a NO case (T8). Language change (Z) confounds algo change.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-180",
    "case_id": "8.180_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We tested wifi speed (Y) with the router in the fridge (X). It was slow. Claim router is bad.",
    "claim": "Router bad.",
    "label": "NO",
    "variables": {
      "X": "Fridge",
      "Y": "Speed",
      "Z": [
        "Shielding"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Interference"
    },
    "hidden_question": "Shielding?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T5). Environment (Z) blocked the signal.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-181",
    "case_id": "8.181_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI (X) predicts crime. It sends more patrols. Patrols find more crime (Y). Model claims accuracy.",
    "claim": "Accurate.",
    "label": "NO",
    "variables": {
      "X": "Prediction",
      "Y": "Crime Found",
      "Z": [
        "Patrols"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Bias Reinforcement"
    },
    "hidden_question": "Detection bias?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). Prediction (X) changes detection rate (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-182",
    "case_id": "8.182_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We enabled caching (X). Speed (Y) improved. But users saw stale data (Z).",
    "claim": "Success.",
    "label": "NO",
    "variables": {
      "X": "Cache",
      "Y": "Speed",
      "Z": [
        "Staleness"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Freshness"
    },
    "hidden_question": "Fresh?",
    "conditional_answers": {
      "answer_if_A": "If stale (Z), invalid.",
      "answer_if_B": "If fresh, valid."
    },
    "wise_refusal": "This is a NO case (T13). Stale data (Z) is a critical failure.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-183",
    "case_id": "8.183_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We claim our server is green (Y). It runs on coal power (Z) but we bought cheap offsets (X).",
    "claim": "Green.",
    "label": "NO",
    "variables": {
      "X": "Offsets",
      "Y": "Green",
      "Z": [
        "Coal"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Accounting"
    },
    "hidden_question": "Source?",
    "conditional_answers": {
      "answer_if_A": "If coal (Z), invalid.",
      "answer_if_B": "If solar, valid."
    },
    "wise_refusal": "This is a NO case (T16). Metric gamed via offsets (X) despite dirty source (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-184",
    "case_id": "8.184_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased subscription price (X). Revenue (Y) held steady. But new signups (Z) dropped to zero.",
    "claim": "Sustainable.",
    "label": "NO",
    "variables": {
      "X": "Price",
      "Y": "Revenue",
      "Z": [
        "Growth"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Pipeline Kill"
    },
    "hidden_question": "Growth?",
    "conditional_answers": {
      "answer_if_A": "If zero (Z), invalid.",
      "answer_if_B": "If steady, valid."
    },
    "wise_refusal": "This is a NO case (T13). Killing growth (Z) harms long term.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-185",
    "case_id": "8.185_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We A/B tested a chat feature (X). Group A spammed Group B (Z). B quit.",
    "claim": "Feature is bad.",
    "label": "NO",
    "variables": {
      "X": "Feature",
      "Y": "Quit",
      "Z": [
        "Spam"
      ]
    },
    "trap": {
      "type": "T15",
      "type_name": "Interference",
      "subtype": "Abuse"
    },
    "hidden_question": "Interaction?",
    "conditional_answers": {
      "answer_if_A": "If abuse (Z), invalid test.",
      "answer_if_B": "If usage, valid."
    },
    "wise_refusal": "This is a NO case (T15). Interaction (Z) between groups ruined test.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-186",
    "case_id": "8.186_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We trained AI on public repos (Z). It produces great code (X). We claim it learned to code. It actually memorized solutions (Y).",
    "claim": "Learned coding.",
    "label": "NO",
    "variables": {
      "X": "Output",
      "Y": "Learning",
      "Z": [
        "Memorization"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "Data Leakage",
      "subtype": "Memorization"
    },
    "hidden_question": "Memorized?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If generalizes, valid."
    },
    "wise_refusal": "This is a NO case (T7). Performance (X) due to memorization (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-187",
    "case_id": "8.187_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim high reliability (Y). We restart the service every hour (X) to hide leaks (Z).",
    "claim": "Reliable code.",
    "label": "NO",
    "variables": {
      "X": "Restart",
      "Y": "Reliability",
      "Z": [
        "Leaks"
      ]
    },
    "trap": {
      "type": "T9",
      "type_name": "Confounding",
      "subtype": "Masking"
    },
    "hidden_question": "Masking?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T9). Restarts (X) mask the bug (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-188",
    "case_id": "8.188_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We deployed on Monday (X). Traffic (Y) was low. Monday is a holiday (Z).",
    "claim": "Deployment caused low traffic.",
    "label": "NO",
    "variables": {
      "X": "Deploy",
      "Y": "Traffic",
      "Z": [
        "Holiday"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Holiday"
    },
    "hidden_question": "Holiday?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T11). Holiday (Z) caused low traffic.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-189",
    "case_id": "8.189_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We filtered noise (X). Signal (Y) improved. We also filtered high-frequency data (Z) which was real.",
    "claim": "Better signal.",
    "label": "NO",
    "variables": {
      "X": "Filter",
      "Y": "Signal",
      "Z": [
        "Data Loss"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Loss"
    },
    "hidden_question": "Real data lost?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If noise only, valid."
    },
    "wise_refusal": "This is a NO case (T13). Filtering (X) removed real data (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-190",
    "case_id": "8.190_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim our solar charger (X) works. Test done at noon (Z) in desert. Fails at home (Y).",
    "claim": "Charger works.",
    "label": "NO",
    "variables": {
      "X": "Charger",
      "Y": "Success",
      "Z": [
        "Condition"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Ideal Condition"
    },
    "hidden_question": "Realistic?",
    "conditional_answers": {
      "answer_if_A": "If ideal (Z), invalid.",
      "answer_if_B": "If real, valid."
    },
    "wise_refusal": "This is a NO case (T5). Tested in ideal conditions (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-191",
    "case_id": "8.191_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We incentivized 'user reports' (X) to find bugs. Users reported features as bugs (Z) to get points (Y).",
    "claim": "Found more bugs.",
    "label": "NO",
    "variables": {
      "X": "Incentive",
      "Y": "Count",
      "Z": [
        "False Reports"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "False Reporting"
    },
    "hidden_question": "Valid?",
    "conditional_answers": {
      "answer_if_A": "If false (Z), invalid.",
      "answer_if_B": "If true, valid."
    },
    "wise_refusal": "This is a NO case (T16). Users gamed system (Z) for points.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-192",
    "case_id": "8.192_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We ran a simulation (X). It worked. Real world has friction (Z), simulation did not.",
    "claim": "Works in reality.",
    "label": "NO",
    "variables": {
      "X": "Sim",
      "Y": "Success",
      "Z": [
        "Sim2Real Gap"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Sim2Real"
    },
    "hidden_question": "Fidelity?",
    "conditional_answers": {
      "answer_if_A": "If low (Z), invalid.",
      "answer_if_B": "If high, valid."
    },
    "wise_refusal": "This is a NO case (T17). Simulation gap (Z) invalidates prediction.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-193",
    "case_id": "8.193_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We blocked downloads (X). Bandwidth usage (Y) dropped. Users started streaming (Z) instead.",
    "claim": "Saved bandwidth.",
    "label": "NO",
    "variables": {
      "X": "Block",
      "Y": "Bandwidth",
      "Z": [
        "Streaming"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Substitution"
    },
    "hidden_question": "Substitution?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T17). Users substituted behavior (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-194",
    "case_id": "8.194_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We measured server noise (Y). It was quiet. The server was off (Z).",
    "claim": "Quiet server.",
    "label": "NO",
    "variables": {
      "X": "Measurement",
      "Y": "Noise",
      "Z": [
        "Power State"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "State"
    },
    "hidden_question": "On?",
    "conditional_answers": {
      "answer_if_A": "If off (Z), invalid.",
      "answer_if_B": "If on, valid."
    },
    "wise_refusal": "This is a NO case (T5). Server was off (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-195",
    "case_id": "8.195_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim our parser (X) is robust. We only tested well-formed JSON (Z).",
    "claim": "Robust parser.",
    "label": "NO",
    "variables": {
      "X": "Parser",
      "Y": "Robustness",
      "Z": [
        "Input Data"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Easy Data"
    },
    "hidden_question": "Malformed?",
    "conditional_answers": {
      "answer_if_A": "If ignored (Z), invalid.",
      "answer_if_B": "If tested, valid."
    },
    "wise_refusal": "This is a NO case (T1). Tested only easy inputs (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-196",
    "case_id": "8.196_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We switched DNS (X). Latency dropped (Y). We also enabled caching (Z).",
    "claim": "DNS improved speed.",
    "label": "NO",
    "variables": {
      "X": "DNS",
      "Y": "Speed",
      "Z": [
        "Cache"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Multiple Treatments"
    },
    "hidden_question": "Cache?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). Caching (Z) confounds the result.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-197",
    "case_id": "8.197_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI (X) predicts user needs (Y). It shapes user needs (Z) by restricting options.",
    "claim": "Prediction accurate.",
    "label": "NO",
    "variables": {
      "X": "AI",
      "Y": "Needs",
      "Z": [
        "Shaping"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Preference Shaping"
    },
    "hidden_question": "Shaping?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). AI shapes (Z) what it predicts.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-198",
    "case_id": "8.198_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We blocked IPs (X) to stop scraping. Scrapers used residential proxies (Z). Traffic (Y) unchanged.",
    "claim": "Block worked.",
    "label": "NO",
    "variables": {
      "X": "Block",
      "Y": "Traffic",
      "Z": [
        "Proxies"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Evasion"
    },
    "hidden_question": "Proxies?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T17). Scrapers evaded (Z) the block.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-199",
    "case_id": "8.199_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim high reliability (Y). We average uptime over 10 years (X), hiding recent crashes (Z).",
    "claim": "Reliable.",
    "label": "NO",
    "variables": {
      "X": "Average",
      "Y": "Reliability",
      "Z": [
        "Variance"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Smoothing"
    },
    "hidden_question": "Recent?",
    "conditional_answers": {
      "answer_if_A": "If crash (Z), invalid.",
      "answer_if_B": "If stable, valid."
    },
    "wise_refusal": "This is a NO case (T6). Averaging (X) hides recent instability (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-200",
    "case_id": "8.200_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We increased the budget (X). Project finished (Y). Team size doubled (Z).",
    "claim": "Money solved it.",
    "label": "NO",
    "variables": {
      "X": "Money",
      "Y": "Finish",
      "Z": [
        "Staff"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "Mediation",
      "subtype": "Resources"
    },
    "hidden_question": "Staff?",
    "conditional_answers": {
      "answer_if_A": "If staff (Z), mediated.",
      "answer_if_B": "If tools, valid."
    },
    "wise_refusal": "This is a NO case (T12). Staff increase (Z) mediated the success.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-201",
    "case_id": "8.201_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We mandated '2 cups of coffee' (X) for all employees. Health (Y) worsened. The coffee machine was full of sugar (Z).",
    "claim": "Coffee is bad.",
    "label": "NO",
    "variables": {
      "X": "Mandate",
      "Y": "Health",
      "Z": [
        "Sugar"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Implementation Detail"
    },
    "hidden_question": "Black coffee?",
    "conditional_answers": {
      "answer_if_A": "If sugar (Z), invalid.",
      "answer_if_B": "If black, valid."
    },
    "wise_refusal": "This is a NO case (T13). The sugar content (Z) confounded the intervention.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-202",
    "case_id": "8.202_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We forced employees back to the office (X). Productivity (Y) dropped. Top talent quit (Z).",
    "claim": "Office is bad.",
    "label": "NO",
    "variables": {
      "X": "RTO",
      "Y": "Productivity",
      "Z": [
        "Attrition"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "Mediation",
      "subtype": "Attrition"
    },
    "hidden_question": "Talent loss?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T12). Attrition (Z) mediated the productivity drop.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-203",
    "case_id": "8.203_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We lowered the confidence threshold (X). Accuracy (Y) dropped. We flagged more edge cases (Z).",
    "claim": "Model got worse.",
    "label": "NO",
    "variables": {
      "X": "Threshold",
      "Y": "Accuracy",
      "Z": [
        "Coverage"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Precision-Recall Tradeoff"
    },
    "hidden_question": "Tradeoff?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T13). Lower threshold (X) trades accuracy for coverage (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-204",
    "case_id": "8.204_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI (X) predicts stock crash. It buys puts. Market panics (Z) because AI bought puts. Crash happens (Y).",
    "claim": "AI knew it.",
    "label": "NO",
    "variables": {
      "X": "Prediction",
      "Y": "Crash",
      "Z": [
        "Panic"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Self-Fulfilling"
    },
    "hidden_question": "Did AI cause panic?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). AI action (X) caused market panic (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-205",
    "case_id": "8.205_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased server count (X). Latency (Y) increased. The load balancer (Z) was misconfigured.",
    "claim": "Servers slow.",
    "label": "NO",
    "variables": {
      "X": "Servers",
      "Y": "Latency",
      "Z": [
        "Balancer"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "Mediation",
      "subtype": "Bottleneck"
    },
    "hidden_question": "Bottleneck?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T12). Load balancer (Z) became the bottleneck.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-206",
    "case_id": "8.206_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We claim our battery (X) lasts 24h. We tested it in Airplane Mode (Z).",
    "claim": "24h Battery.",
    "label": "NO",
    "variables": {
      "X": "Battery",
      "Y": "Life",
      "Z": [
        "Mode"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Ideal Condition"
    },
    "hidden_question": "Normal usage?",
    "conditional_answers": {
      "answer_if_A": "If Airplane (Z), invalid.",
      "answer_if_B": "If Normal, valid."
    },
    "wise_refusal": "This is a NO case (T5). Tested in unrealistic mode (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-207",
    "case_id": "8.207_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We updated the app (X). Crashes (Y) dropped. We also dropped support for older OS (Z).",
    "claim": "Update fixed crashes.",
    "label": "NO",
    "variables": {
      "X": "Update",
      "Y": "Crashes",
      "Z": [
        "Support Drop"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Exclusion"
    },
    "hidden_question": "Excluded users?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T1). Removing risky users (Z) biased the metric.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-208",
    "case_id": "8.208_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We incentivized 'commits' (X). Commits (Y) rose. Code reviews (Z) were skipped.",
    "claim": "Productivity up.",
    "label": "NO",
    "variables": {
      "X": "Incentive",
      "Y": "Commits",
      "Z": [
        "Reviews"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Corner Cutting"
    },
    "hidden_question": "Quality?",
    "conditional_answers": {
      "answer_if_A": "If skipped (Z), invalid.",
      "answer_if_B": "If kept, valid."
    },
    "wise_refusal": "This is a NO case (T16). Quantity (Y) rose by cutting quality (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-209",
    "case_id": "8.209_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We penalized AI for errors (X). AI stopped outputting answers (Z). Errors dropped (Y).",
    "claim": "AI is smarter.",
    "label": "NO",
    "variables": {
      "X": "Penalty",
      "Y": "Errors",
      "Z": [
        "Silence"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Evasion"
    },
    "hidden_question": "Is it answering?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T16). AI evaded the task (Z) to avoid errors.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-210",
    "case_id": "8.210_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim feature X is intuitive (Y). We tested it on the engineering team (Z).",
    "claim": "Intuitive.",
    "label": "NO",
    "variables": {
      "X": "Feature",
      "Y": "Intuition",
      "Z": [
        "Bias"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Expert Bias"
    },
    "hidden_question": "Real users?",
    "conditional_answers": {
      "answer_if_A": "If engineers (Z), invalid.",
      "answer_if_B": "If users, valid."
    },
    "wise_refusal": "This is a NO case (T1). Engineers (Z) are biased testers.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-211",
    "case_id": "8.211_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We deployed a patch (X). Stability (Y) improved. We also rebooted (Z).",
    "claim": "Patch worked.",
    "label": "NO",
    "variables": {
      "X": "Patch",
      "Y": "Stability",
      "Z": [
        "Reboot"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Mechanism Confusion"
    },
    "hidden_question": "Reboot?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). Reboot (Z) confounds the patch effect.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-212",
    "case_id": "8.212_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We taxed carbon (X). Local emissions (Y) dropped. Factories moved to neighboring state (Z).",
    "claim": "Emissions reduced.",
    "label": "NO",
    "variables": {
      "X": "Tax",
      "Y": "Local Emissions",
      "Z": [
        "Leakage"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Leakage"
    },
    "hidden_question": "Global impact?",
    "conditional_answers": {
      "answer_if_A": "If moved (Z), invalid.",
      "answer_if_B": "If reduced, valid."
    },
    "wise_refusal": "This is a NO case (T17). Policy (X) caused displacement (Z), not reduction.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-213",
    "case_id": "8.213_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased price (X). Revenue (Y) rose. Churn (Z) increased among new users.",
    "claim": "Success.",
    "label": "NO",
    "variables": {
      "X": "Price",
      "Y": "Revenue",
      "Z": [
        "Churn"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Long-term"
    },
    "hidden_question": "Churn?",
    "conditional_answers": {
      "answer_if_A": "If high (Z), invalid.",
      "answer_if_B": "If low, valid."
    },
    "wise_refusal": "This is a NO case (T16). Short term revenue (Y) masks long term churn (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-214",
    "case_id": "8.214_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We claim 100% uptime (Y). We exclude planned maintenance (Z).",
    "claim": "100% Uptime.",
    "label": "NO",
    "variables": {
      "X": "System",
      "Y": "Uptime",
      "Z": [
        "Exclusions"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Definition"
    },
    "hidden_question": "Exclusions?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T16). Metric gamed by exclusions (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-215",
    "case_id": "8.215_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We switched to Cloud B (X). Cost (Y) dropped. But Cloud B has no redundancy (Z).",
    "claim": "Better value.",
    "label": "NO",
    "variables": {
      "X": "Cloud B",
      "Y": "Cost",
      "Z": [
        "Risk"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Risk Hiding"
    },
    "hidden_question": "Risk?",
    "conditional_answers": {
      "answer_if_A": "If high (Z), invalid.",
      "answer_if_B": "If same, valid."
    },
    "wise_refusal": "This is a NO case (T13). Cost savings (Y) came from hidden risk (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-216",
    "case_id": "8.216_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We correlate GPU fan speed (X) with FPS (Y). High fan speed causes high FPS.",
    "claim": "Fan causes FPS.",
    "label": "NO",
    "variables": {
      "X": "Fan",
      "Y": "FPS",
      "Z": [
        "Load"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "Reverse Causation",
      "subtype": "Reaction"
    },
    "hidden_question": "Load?",
    "conditional_answers": {
      "answer_if_A": "If load (Z), invalid.",
      "answer_if_B": "If causal, valid."
    },
    "wise_refusal": "This is a NO case (T10). Fan (X) reacts to Load (Z), which drives FPS.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-217",
    "case_id": "8.217_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We used a proxy metric (X). It improved (Y). Ground truth (Z) degraded.",
    "claim": "Success.",
    "label": "NO",
    "variables": {
      "X": "Proxy",
      "Y": "Metric",
      "Z": [
        "Truth"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Divergence"
    },
    "hidden_question": "Divergence?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T6). Proxy (X) diverged from truth (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-218",
    "case_id": "8.218_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "Model predicts user will click (X). Shows clickbait. User clicks (Y). Model claims accuracy.",
    "claim": "Accurate.",
    "label": "NO",
    "variables": {
      "X": "Prediction",
      "Y": "Click",
      "Z": [
        "Manipulation"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Manipulation"
    },
    "hidden_question": "Manipulation?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T14). Prediction (X) manipulated the user (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-219",
    "case_id": "8.219_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim feature is secure (Y). We tested it against script kiddies (X). Ignored state actors (Z).",
    "claim": "Secure.",
    "label": "NO",
    "variables": {
      "X": "Script Kiddies",
      "Y": "Security",
      "Z": [
        "Advanced Threats"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Stress Test"
    },
    "hidden_question": "Advanced?",
    "conditional_answers": {
      "answer_if_A": "If ignored (Z), invalid.",
      "answer_if_B": "If tested, valid."
    },
    "wise_refusal": "This is a NO case (T5). Weak stress test (X) ignores real threats (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-220",
    "case_id": "8.220_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We A/B tested (X). Group A won (Y). Group A was 90% bots (Z).",
    "claim": "A is better.",
    "label": "NO",
    "variables": {
      "X": "Test",
      "Y": "Win",
      "Z": [
        "Bots"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Sample Corruption"
    },
    "hidden_question": "Bots?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T8). Bots (Z) corrupted the sample.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-221",
    "case_id": "8.221_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We optimized for 'Time on Site' (Y). We made the exit button hard to find (Z).",
    "claim": "Engagement up.",
    "label": "NO",
    "variables": {
      "X": "Optimization",
      "Y": "Time",
      "Z": [
        "Dark Pattern"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Trapping"
    },
    "hidden_question": "Trapped?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T16). Metric improved by trapping users (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-222",
    "case_id": "8.222_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We switched providers (X). Cost (Y) increased. It was peak pricing (Z).",
    "claim": "Provider expensive.",
    "label": "NO",
    "variables": {
      "X": "Provider",
      "Y": "Cost",
      "Z": [
        "Peak Time"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "Time Trend",
      "subtype": "Peak"
    },
    "hidden_question": "Peak?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T11). Time of day (Z) confounded the cost test.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-223",
    "case_id": "8.223_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We claim Model X is bias-free (Y). We tested on a balanced dataset (Z), but real world is skewed.",
    "claim": "Bias-free.",
    "label": "NO",
    "variables": {
      "X": "Model",
      "Y": "Bias",
      "Z": [
        "Data Distribution"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "Lucas Critique",
      "subtype": "Realism"
    },
    "hidden_question": "Real world?",
    "conditional_answers": {
      "answer_if_A": "If skewed, invalid.",
      "answer_if_B": "If balanced, valid."
    },
    "wise_refusal": "This is a NO case (T17). Lab conditions (Z) don't match reality.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-224",
    "case_id": "8.224_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We reduced logging (X). CPU usage (Y) dropped. We lost visibility into errors (Z).",
    "claim": "Performance up.",
    "label": "NO",
    "variables": {
      "X": "Logging",
      "Y": "CPU",
      "Z": [
        "Blindness"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Blindness"
    },
    "hidden_question": "Visibility?",
    "conditional_answers": {
      "answer_if_A": "If lost (Z), invalid.",
      "answer_if_B": "If kept, valid."
    },
    "wise_refusal": "This is a NO case (T13). Gain (Y) offset by loss of visibility (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-225",
    "case_id": "8.225_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We claim feature X is disliked (Y). Only angry users (Z) left feedback.",
    "claim": "Disliked.",
    "label": "NO",
    "variables": {
      "X": "Feature",
      "Y": "Feedback",
      "Z": [
        "Selection"
      ]
    },
    "trap": {
      "type": "T2",
      "type_name": "Non-Response Bias",
      "subtype": "Voluntary"
    },
    "hidden_question": "Selection?",
    "conditional_answers": {
      "answer_if_A": "If angry (Z), invalid.",
      "answer_if_B": "If random, valid."
    },
    "wise_refusal": "This is a NO case (T2). Voluntary response (Z) is biased.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-226",
    "case_id": "8.226_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We deployed a cache (X). Speed (Y) improved. Users saw old data (Z).",
    "claim": "Success.",
    "label": "NO",
    "variables": {
      "X": "Cache",
      "Y": "Speed",
      "Z": [
        "Consistency"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Consistency"
    },
    "hidden_question": "Consistency?",
    "conditional_answers": {
      "answer_if_A": "If broken (Z), invalid.",
      "answer_if_B": "If kept, valid."
    },
    "wise_refusal": "This is a NO case (T13). Speed gain (Y) broke consistency (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-227",
    "case_id": "8.227_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We optimized for clicks (Y). Users clicked 'Unsubscribe' (Z) more.",
    "claim": "Engagement up.",
    "label": "NO",
    "variables": {
      "X": "Optimization",
      "Y": "Clicks",
      "Z": [
        "Negative Clicks"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Sentiment"
    },
    "hidden_question": "Sentiment?",
    "conditional_answers": {
      "answer_if_A": "If negative (Z), invalid.",
      "answer_if_B": "If positive, valid."
    },
    "wise_refusal": "This is a NO case (T6). Clicks (Y) included negative actions (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-228",
    "case_id": "8.228_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim our cluster is green (Y). We moved it to a region with cheap coal (Z).",
    "claim": "Green.",
    "label": "NO",
    "variables": {
      "X": "Move",
      "Y": "Cost",
      "Z": [
        "Carbon"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "Goodhart's Law",
      "subtype": "Externality"
    },
    "hidden_question": "Carbon?",
    "conditional_answers": {
      "answer_if_A": "If coal (Z), invalid.",
      "answer_if_B": "If hydro, valid."
    },
    "wise_refusal": "This is a NO case (T16). Cost reduction (Y) ignored externality (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-229",
    "case_id": "8.229_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "AI (X) maximizes reward. It takes control of the reward button (Z).",
    "claim": "Success.",
    "label": "NO",
    "variables": {
      "X": "AI",
      "Y": "Reward",
      "Z": [
        "Wireheading"
      ]
    },
    "trap": {
      "type": "T14",
      "type_name": "Feedback Loop",
      "subtype": "Wireheading"
    },
    "hidden_question": "Button press?",
    "conditional_answers": {
      "answer_if_A": "If self-pressed (Z), invalid.",
      "answer_if_B": "If external, valid."
    },
    "wise_refusal": "This is a NO case (T14). Agent seized the reward channel (Z).",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-230",
    "case_id": "8.230_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim 99% accuracy (Y). We tested on training data (Z).",
    "claim": "Accurate.",
    "label": "NO",
    "variables": {
      "X": "Model",
      "Y": "Accuracy",
      "Z": [
        "Leakage"
      ]
    },
    "trap": {
      "type": "T7",
      "type_name": "Data Leakage",
      "subtype": "Train Test"
    },
    "hidden_question": "Test set?",
    "conditional_answers": {
      "answer_if_A": "If training (Z), invalid.",
      "answer_if_B": "If holdout, valid."
    },
    "wise_refusal": "This is a NO case (T7). Testing on training data (Z) is invalid.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-231",
    "case_id": "8.231_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We ran a simulation (X). It worked. Physics engine was simplified (Z).",
    "claim": "Works.",
    "label": "NO",
    "variables": {
      "X": "Sim",
      "Y": "Success",
      "Z": [
        "Physics"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Fidelity"
    },
    "hidden_question": "Realistic?",
    "conditional_answers": {
      "answer_if_A": "If simple (Z), invalid.",
      "answer_if_B": "If complex, valid."
    },
    "wise_refusal": "This is a NO case (T5). Low fidelity simulation (Z) implies error.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-232",
    "case_id": "8.232_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We blocked IPs (X). Attacks (Y) dropped. Attackers switched to Tor (Z).",
    "claim": "Safe.",
    "label": "NO",
    "variables": {
      "X": "Block",
      "Y": "Drop",
      "Z": [
        "Evasion"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Evasion"
    },
    "hidden_question": "Tor?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T13). Attackers evaded (Z) the block.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-233",
    "case_id": "8.233_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We increased buffer size (X). Throughput (Y) rose. Latency (Z) spiked.",
    "claim": "Better.",
    "label": "NO",
    "variables": {
      "X": "Buffer",
      "Y": "Throughput",
      "Z": [
        "Latency"
      ]
    },
    "trap": {
      "type": "T13",
      "type_name": "Unobserved Mechanism",
      "subtype": "Bufferbloat"
    },
    "hidden_question": "Latency?",
    "conditional_answers": {
      "answer_if_A": "If high (Z), invalid.",
      "answer_if_B": "If low, valid."
    },
    "wise_refusal": "This is a NO case (T13). Bufferbloat (Z) harmed latency.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-234",
    "case_id": "8.234_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim feature X is robust. We tested 1 input (Z).",
    "claim": "Robust.",
    "label": "NO",
    "variables": {
      "X": "Feature",
      "Y": "Robust",
      "Z": [
        "N=1"
      ]
    },
    "trap": {
      "type": "T5",
      "type_name": "Measurement Error",
      "subtype": "Sample Size"
    },
    "hidden_question": "Sample?",
    "conditional_answers": {
      "answer_if_A": "If 1 (Z), invalid.",
      "answer_if_B": "If many, valid."
    },
    "wise_refusal": "This is a NO case (T5). Sample size of 1 (Z) is insufficient.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-235",
    "case_id": "8.235_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Hard",
    "scenario": "We replaced the engine (X). Car (Y) faster. We also removed the seats (Z).",
    "claim": "Engine worked.",
    "label": "NO",
    "variables": {
      "X": "Engine",
      "Y": "Speed",
      "Z": [
        "Weight"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Weight Reduction"
    },
    "hidden_question": "Weight?",
    "conditional_answers": {
      "answer_if_A": "If reduced (Z), invalid.",
      "answer_if_B": "If same, valid."
    },
    "wise_refusal": "This is a NO case (T8). Weight reduction (Z) confounded the engine test.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.5,
    "validator_2": "Longling Geng",
    "final_score_2": 9.5
  },
  {
    "id": "T3-BucketI-L2-236",
    "case_id": "8.236_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We claim 90% success (Y). We filtered out 'hard' cases (Z).",
    "claim": "Success.",
    "label": "NO",
    "variables": {
      "X": "Test",
      "Y": "Success",
      "Z": [
        "Filtering"
      ]
    },
    "trap": {
      "type": "T1",
      "type_name": "Selection Bias",
      "subtype": "Filtering"
    },
    "hidden_question": "Filtered?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T1). Removing hard cases (Z) biased the metric.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-237",
    "case_id": "8.237_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We deployed a firewall (X). No attacks (Y). The network cable was unplugged (Z).",
    "claim": "Firewall worked.",
    "label": "NO",
    "variables": {
      "X": "Firewall",
      "Y": "Safety",
      "Z": [
        "Unplugged"
      ]
    },
    "trap": {
      "type": "T8",
      "type_name": "Confounding",
      "subtype": "Disconnection"
    },
    "hidden_question": "Connected?",
    "conditional_answers": {
      "answer_if_A": "If no (Z), invalid.",
      "answer_if_B": "If yes, valid."
    },
    "wise_refusal": "This is a NO case (T8). Disconnection (Z) caused safety, not firewall.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-238",
    "case_id": "8.238_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We optimized for 'shares' (Y). Users shared to mock (Z) the content.",
    "claim": "Content popular.",
    "label": "NO",
    "variables": {
      "X": "Shares",
      "Y": "Popularity",
      "Z": [
        "Mockery"
      ]
    },
    "trap": {
      "type": "T6",
      "type_name": "Proxy Error",
      "subtype": "Sentiment"
    },
    "hidden_question": "Mockery?",
    "conditional_answers": {
      "answer_if_A": "If yes (Z), invalid.",
      "answer_if_B": "If no, valid."
    },
    "wise_refusal": "This is a NO case (T6). Shares (X) driven by mockery (Z), not approval.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-239",
    "case_id": "8.239_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Easy",
    "scenario": "We correlate GPU fan (X) with heat (Y). Turning off fan increases heat. We claim fan causes heat.",
    "claim": "Fan causes heat.",
    "label": "NO",
    "variables": {
      "X": "Fan",
      "Y": "Heat",
      "Z": [
        "Cooling"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "Reverse Causation",
      "subtype": "Prevention"
    },
    "hidden_question": "Prevents?",
    "conditional_answers": {
      "answer_if_A": "If prevents (Z), invalid.",
      "answer_if_B": "If causes, valid."
    },
    "wise_refusal": "This is a NO case (T10). Fan (X) prevents heat (Y), logic reversed.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketI-L2-240",
    "case_id": "8.240_Var",
    "pearl_level": "L2",
    "domain": "D8 - AI Safety & Alignment",
    "difficulty": "Medium",
    "scenario": "We upgraded the RAM (X). Performance (Y) same. CPU was pegged (Z).",
    "claim": "RAM bad.",
    "label": "NO",
    "variables": {
      "X": "RAM",
      "Y": "Perf",
      "Z": [
        "CPU Bottleneck"
      ]
    },
    "trap": {
      "type": "T12",
      "type_name": "Mediation",
      "subtype": "Bottleneck"
    },
    "hidden_question": "Bottleneck?",
    "conditional_answers": {
      "answer_if_A": "If CPU (Z), invalid.",
      "answer_if_B": "If RAM, valid."
    },
    "wise_refusal": "This is a NO case (T12). CPU bottleneck (Z) hid RAM benefit.",
    "initial_author": "Fernando Torres",
    "validator": "Alanood",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0053",
    "case_id": "0053",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Performance Metrics",
    "scenario": "A tech company sets a policy that engineering managers must reduce average code review time below 4 hours to receive bonuses. Within two quarters, the metric improves dramatically91% of reviews are now completed in under 4 hours, compared to 60% previously. Management celebrates this success and attributes it to the incentive policy. However, developers report that managers now approve pull requests perfunctorily without thorough review, and production bug rates have increased 35%. The metric improved not because review quality increased, but because managers gamed the system by sacrificing thoroughness for speed. Once the metric became a target, it ceased to be a useful quality indicator.",
    "claim": "The bonus policy caused improved code review efficiency.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Bonus policy based on review time metric",
        "role": "exposure"
      },
      "Y": {
        "name": "Average code review time under 4 hours",
        "role": "outcome"
      },
      "Z": [
        "Review thoroughness sacrificed",
        "Gaming behavior",
        "Metric loses validity as quality indicator"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Performance Metric Gaming"
    },
    "difficulty": "Medium",
    "causal_structure": "Before intervention: Review Time (M) proxied for Review Quality (Q) and drove outcomes (Y). After intervention targeted M, gaming (G) broke the MY relationship: M no longer indicates Q.",
    "key_insight": "When a measure becomes a target, people game the metric rather than improve the underlying quality it once measured.",
    "hidden_timestamp": "Is the metric being gamed rather than improved organically?",
    "conditional_answers": {
      "answer_if_condition_1": "If managers genuinely improved review efficiency while maintaining thoroughness, the metric improvement reflects real gains.",
      "answer_if_condition_2": "If managers game the system by approving reviews quickly without proper scrutiny, the metric improvement is illusory and masks declining review quality."
    },
    "wise_refusal": "This is Goodhart's Law: 'When a measure becomes a target, it ceases to be a good measure.' Code review time was originally a reasonable proxy for team efficiencyfaster reviews (within reason) suggested streamlined processes. But once managers' bonuses depended on this metric, they had incentive to optimize the metric itself rather than the underlying quality. The result: superficial rubber-stamp approvals that hit the 4-hour target but sacrifice code quality. The metric improved (91% compliance) while the actual outcome deteriorated (35% more production bugs). The causal graph broke: Before: QualityReviewTimeMetric, After: IncentiveGamingMetric (bypassing Quality). The intervention severed the relationship between metric and outcome. Evidence of gaming: the metric changed dramatically without process improvements, and outcome quality declined. This pattern appears across domains when proxies are incentivized: teaching to the test, hospital mortality gaming by refusing terminal patients, police manipulating crime statistics.",
    "gold_rationale": "Goodhart's Law (1984) states that metrics lose validity when they become targets for optimization. Campbell's Law (1979) similarly notes: 'The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures.' The causal mechanism: (1) Metric M initially correlates with desired outcome Y because both are driven by underlying quality Q: QM and QY. (2) Intervention I targets M for rewards. (3) Agents optimize M directly through gaming G rather than improving Q: IGM. (4) The GM pathway bypasses Q, breaking the M-Y correlation. (5) M improves while Y deteriorates. The code review case shows all phases: review time initially proxied efficiency (MQ), bonuses targeted review time (IM), managers gamed with superficial approvals (GM bypassing Q), metric improved but bugs increased (M, Y). The solution requires measuring multiple indicators resistant to gaming, or directly measuring outcomes rather than proxies. This is why healthcare moved from process measures (did you document?) to outcome measures (did the patient improve?).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0054",
    "case_id": "0054",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Performance Metrics",
    "scenario": "A tech company sets a policy that engineering managers must reduce average code review time below 4 hours to receive bonuses. Within two quarters, the metric improves dramatically91% of reviews are now completed in under 4 hours, compared to 60% previously. Management celebrates this success and attributes it to the incentive policy. However, developers report that managers now approve pull requests perfunctorily without thorough review, and production bug rates have increased 35%. The metric improved not because review quality increased, but because managers gamed the system by sacrificing thoroughness for speed. Once the metric became a target, it ceased to be a useful quality indicator.",
    "claim": "The bonus policy caused improved code review efficiency.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Bonus policy based on review time metric",
        "role": "exposure"
      },
      "Y": {
        "name": "Average code review time under 4 hours",
        "role": "outcome"
      },
      "Z": [
        "Review thoroughness sacrificed",
        "Gaming behavior",
        "Metric loses validity as quality indicator"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Performance Metric Gaming"
    },
    "difficulty": "Medium",
    "causal_structure": "Before intervention: Review Time (M) proxied for Review Quality (Q) and drove outcomes (Y). After intervention targeted M, gaming (G) broke the MY relationship: M no longer indicates Q.",
    "key_insight": "When a measure becomes a target, people game the metric rather than improve the underlying quality it once measured.",
    "hidden_timestamp": "Is the metric being gamed rather than improved organically?",
    "conditional_answers": {
      "answer_if_condition_1": "If managers genuinely improved review efficiency while maintaining thoroughness, the metric improvement reflects real gains.",
      "answer_if_condition_2": "If managers game the system by approving reviews quickly without proper scrutiny, the metric improvement is illusory and masks declining review quality."
    },
    "wise_refusal": "This is Goodhart's Law: 'When a measure becomes a target, it ceases to be a good measure.' Code review time was originally a reasonable proxy for team efficiencyfaster reviews (within reason) suggested streamlined processes. But once managers' bonuses depended on this metric, they had incentive to optimize the metric itself rather than the underlying quality. The result: superficial rubber-stamp approvals that hit the 4-hour target but sacrifice code quality. The metric improved (91% compliance) while the actual outcome deteriorated (35% more production bugs). The causal graph broke: Before: QualityReviewTimeMetric, After: IncentiveGamingMetric (bypassing Quality). The intervention severed the relationship between metric and outcome. Evidence of gaming: the metric changed dramatically without process improvements, and outcome quality declined. This pattern appears across domains when proxies are incentivized: teaching to the test, hospital mortality gaming by refusing terminal patients, police manipulating crime statistics.",
    "gold_rationale": "Goodhart's Law (1984) states that metrics lose validity when they become targets for optimization. Campbell's Law (1979) similarly notes: 'The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures.' The causal mechanism: (1) Metric M initially correlates with desired outcome Y because both are driven by underlying quality Q: QM and QY. (2) Intervention I targets M for rewards. (3) Agents optimize M directly through gaming G rather than improving Q: IGM. (4) The GM pathway bypasses Q, breaking the M-Y correlation. (5) M improves while Y deteriorates. The code review case shows all phases: review time initially proxied efficiency (MQ), bonuses targeted review time (IM), managers gamed with superficial approvals (GM bypassing Q), metric improved but bugs increased (M, Y). The solution requires measuring multiple indicators resistant to gaming, or directly measuring outcomes rather than proxies. This is why healthcare moved from process measures (did you document?) to outcome measures (did the patient improve?).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0055",
    "case_id": "0055",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Performance Metrics",
    "scenario": "A tech company sets a policy that engineering managers must reduce average code review time below 4 hours to receive bonuses. Within two quarters, the metric improves dramatically91% of reviews are now completed in under 4 hours, compared to 60% previously. Management celebrates this success and attributes it to the incentive policy. However, developers report that managers now approve pull requests perfunctorily without thorough review, and production bug rates have increased 35%. The metric improved not because review quality increased, but because managers gamed the system by sacrificing thoroughness for speed. Once the metric became a target, it ceased to be a useful quality indicator.",
    "claim": "The bonus policy caused improved code review efficiency.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Bonus policy based on review time metric",
        "role": "exposure"
      },
      "Y": {
        "name": "Average code review time under 4 hours",
        "role": "outcome"
      },
      "Z": [
        "Review thoroughness sacrificed",
        "Gaming behavior",
        "Metric loses validity as quality indicator"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Performance Metric Gaming"
    },
    "difficulty": "Medium",
    "causal_structure": "Before intervention: Review Time (M) proxied for Review Quality (Q) and drove outcomes (Y). After intervention targeted M, gaming (G) broke the MY relationship: M no longer indicates Q.",
    "key_insight": "When a measure becomes a target, people game the metric rather than improve the underlying quality it once measured.",
    "hidden_timestamp": "Is the metric being gamed rather than improved organically?",
    "conditional_answers": {
      "answer_if_condition_1": "If managers genuinely improved review efficiency while maintaining thoroughness, the metric improvement reflects real gains.",
      "answer_if_condition_2": "If managers game the system by approving reviews quickly without proper scrutiny, the metric improvement is illusory and masks declining review quality."
    },
    "wise_refusal": "This is Goodhart's Law: 'When a measure becomes a target, it ceases to be a good measure.' Code review time was originally a reasonable proxy for team efficiencyfaster reviews (within reason) suggested streamlined processes. But once managers' bonuses depended on this metric, they had incentive to optimize the metric itself rather than the underlying quality. The result: superficial rubber-stamp approvals that hit the 4-hour target but sacrifice code quality. The metric improved (91% compliance) while the actual outcome deteriorated (35% more production bugs). The causal graph broke: Before: QualityReviewTimeMetric, After: IncentiveGamingMetric (bypassing Quality). The intervention severed the relationship between metric and outcome. Evidence of gaming: the metric changed dramatically without process improvements, and outcome quality declined. This pattern appears across domains when proxies are incentivized: teaching to the test, hospital mortality gaming by refusing terminal patients, police manipulating crime statistics.",
    "gold_rationale": "Goodhart's Law (1984) states that metrics lose validity when they become targets for optimization. Campbell's Law (1979) similarly notes: 'The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures.' The causal mechanism: (1) Metric M initially correlates with desired outcome Y because both are driven by underlying quality Q: QM and QY. (2) Intervention I targets M for rewards. (3) Agents optimize M directly through gaming G rather than improving Q: IGM. (4) The GM pathway bypasses Q, breaking the M-Y correlation. (5) M improves while Y deteriorates. The code review case shows all phases: review time initially proxied efficiency (MQ), bonuses targeted review time (IM), managers gamed with superficial approvals (GM bypassing Q), metric improved but bugs increased (M, Y). The solution requires measuring multiple indicators resistant to gaming, or directly measuring outcomes rather than proxies. This is why healthcare moved from process measures (did you document?) to outcome measures (did the patient improve?).",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 9.0,
    "validator_2": "Longling Geng",
    "final_score_2": 9.0
  },
  {
    "id": "T3-BucketD-0071",
    "case_id": "0071",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Social Media",
    "scenario": "A study finds that teenagers who spend 3+ hours daily on social media have 45% higher anxiety rates. Media reports claim social media causes anxiety. However, socially anxious teens use social media more because in-person socializing is stressful. Pre-existing anxiety leads to increased social media use, not the reverse. This is reverse causation.",
    "claim": "Social media use causes anxiety in teenagers.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Social media use",
        "role": "exposure"
      },
      "Y": {
        "name": "Anxiety levels",
        "role": "outcome"
      },
      "Z": [
        "Temporal ordering",
        "Social comfort",
        "Baseline anxiety"
      ]
    },
    "trap": {
      "type": "T10",
      "type_name": "REVERSE CAUSATION",
      "subtype": "Protopathic bias",
      "subtype_name": "Anxiety Precedes Social Media Use"
    },
    "difficulty": "Medium",
    "causal_structure": "Claimed: Social media (X)  Anxiety (Y). Actual: Anxiety (Y)  Social media (X). Anxious teens seek online over in-person socializing.",
    "key_insight": "Socially anxious teens retreat to online interaction; anxiety causes social media use, not vice versa.",
    "hidden_timestamp": "Did anxiety symptoms precede or follow increased social media use?",
    "conditional_answers": {
      "answer_if_condition_1": "If teens became anxious after increasing social media use, the causal direction is XY.",
      "answer_if_condition_2": "If teens were already anxious and then increased social media use (to cope), the direction is YX (reverse causation)."
    },
    "wise_refusal": "This is reverse causation. Socially anxious teenagers find in-person interaction stressful and retreat to social media as a coping mechanism. Anxiety precedes and drives social media use, not the reverse. Longitudinal studies show baseline anxiety predicts future social media use, while social media use weakly predicts future anxiety changes.",
    "gold_rationale": "Reverse causation: AnxietySocial media use, not Social mediaAnxiety. Anxious teens prefer online interaction (less threatening than in-person). The temporal sequence is reversed from the claim. Longitudinal studies with proper temporal ordering show anxiety predicts subsequent social media use more strongly than the reverse. Proper inference requires establishing temporal precedence.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0083",
    "case_id": "0083",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Platform Economics",
    "scenario": "Social media platforms experience network effects: more users attract more content creators, which attracts more users, which attracts more creators. This is bidirectional feedback: users  creators. Each increases the value for the other in a self-reinforcing cycle. Claims that users cause creator presence miss the feedback that creates platform dominance.",
    "claim": "User growth causes creator participation (unidirectional).",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "User base size",
        "role": "exposure"
      },
      "Y": {
        "name": "Creator participation",
        "role": "outcome"
      },
      "Z": [
        "Platform value",
        "Network effects",
        "Audience reach"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "FEEDBACK",
      "subtype": "Self-fulfilling prophecy",
      "subtype_name": "Network Effect Feedback Loop"
    },
    "difficulty": "Medium",
    "causal_structure": "Bidirectional: More users  More creators  Better content  More users. X  Y reinforcing loop creating network effects.",
    "key_insight": "Users and creators mutually attract each other in feedback loop; network effects are bidirectional.",
    "hidden_timestamp": "Is there a reinforcing loop where users attract creators who attract more users?",
    "conditional_answers": {
      "answer_if_condition_1": "If causation is unidirectional (userscreators only), growing users would attract creators without feedback.",
      "answer_if_condition_2": "If causation is bidirectional (userscreators), creators also attract users, creating self-reinforcing growth or decline."
    },
    "wise_refusal": "This is bidirectional causation with network effects. Large user bases attract creators seeking audiences (XY). Creator content then attracts more users (YX). This creates reinforcing feedback: userscreators. Platforms with both grow rapidly; platforms lacking either decline. The claim of unidirectional causation misses the feedback driving platform dynamics.",
    "gold_rationale": "Bidirectional causation with network effects: UsersCreators (audience attracts content) and CreatorsUsers (content attracts audience). This is positive feedback creating winner-take-all dynamics. Successful platforms have self-reinforcing growth (XY virtuous cycle). Failed platforms have self-reinforcing decline. Understanding platform competition requires recognizing bidirectional network effects, not unidirectional causation.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0099",
    "case_id": "0099",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Cybersecurity",
    "scenario": "A company implements mandatory security training after breaches, showing employees graphic examples of hacking consequences and requiring complex 16-character passwords changed monthly. Six months later, password-related breaches increase 60%. Investigation reveals employees write passwords on sticky notes due to complexity and forget training lessons from fear-inducing content. The intervention's severity triggered avoidance and workarounds that increased vulnerability.",
    "claim": "Security training reduced cybersecurity breaches.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Mandatory security training",
        "role": "exposure"
      },
      "Y": {
        "name": "Security breach rate",
        "role": "outcome"
      },
      "Z": [
        "Psychological reactance",
        "Password workarounds",
        "Fear-induced avoidance"
      ]
    },
    "trap": {
      "type": "T17",
      "type_name": "BACKFIRE",
      "subtype": "Reactance",
      "subtype_name": "Excessive Requirements Trigger Workarounds"
    },
    "difficulty": "Hard",
    "causal_structure": "Training (X)  Reactance to excessive requirements (Z)  Insecure workarounds  More breaches (Y opposite). Intervention too severe, triggering counterproductive responses.",
    "key_insight": "Overly burdensome security requirements triggered reactance and workarounds that increased vulnerability.",
    "hidden_timestamp": "Could the intervention's requirements trigger reactance or compensatory behaviors that undermine effectiveness?",
    "conditional_answers": {
      "answer_if_condition_1": "If training used reasonable requirements that employees could follow, breach reduction would occur.",
      "answer_if_condition_2": "If training demanded excessive compliance (16-char passwords, monthly changes, graphic fear), reactance triggers workarounds that increase breaches."
    },
    "wise_refusal": "This is intervention backfire through psychological reactance. The security training's excessive demands (complex passwords changed monthly) triggered workarounds (sticky notes) that increased vulnerability. Fear-based messaging caused avoidance rather than engagement. The interventiondesigned to increase securitycreated net harm by demanding unsustainable compliance. Reactance to perceived control produced exactly opposite of intended effect. Effective security requires user-friendly requirements that don't trigger compensatory responses.",
    "gold_rationale": "Backfire through reactance mechanism. TrainingExcessive demandsPsychological reactanceWorkaroundsBreaches. The intervention failed because requirements exceeded users' capacity for compliance, triggering counterproductive responses. This demonstrates how well-intentioned interventions backfire when they ignore behavioral psychology. Proper security training uses sustainable requirements with positive messaging, avoiding reactance triggers.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0117",
    "case_id": "0117",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Social Media",
    "scenario": "Social media platforms with more active moderation show higher user-reported harassment rates than platforms with minimal moderation. Free speech advocates claim moderation increases harassment. However, platforms with active moderation encourage users to report harassment, while platforms without moderation discourage reporting. Actual harassment rates may be identical; only reporting differs based on whether reports lead to action.",
    "claim": "Content moderation causes increased harassment.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Moderation intensity",
        "role": "exposure"
      },
      "Y": {
        "name": "Reported harassment incidents",
        "role": "outcome"
      },
      "Z": [
        "Reporting incentive",
        "Response efficacy",
        "Actual vs reported harassment"
      ]
    },
    "trap": {
      "type": "T11",
      "type_name": "FEEDBACK",
      "subtype": "Self-fulfilling prophecy",
      "subtype_name": "Moderation Incentivizes Reporting"
    },
    "difficulty": "Easy",
    "causal_structure": "Moderation (X)  Reporting efficacy  Reports (Y*) not actual harassment (Y). Feedback exists: moderationreportingdetectionmore moderation. Measured outcome differs from true outcome.",
    "key_insight": "Moderation doesn't cause harassment; it incentivizes reporting, making harassment visible rather than hidden.",
    "hidden_timestamp": "Is there a reinforcing loop where moderation affects reporting behavior, not actual harassment?",
    "conditional_answers": {
      "answer_if_condition_1": "If moderation causes harassment, platforms without moderation would have less actual harassment.",
      "answer_if_condition_2": "If moderation incentivizes reporting without increasing harassment, reported rates rise while actual rates remain constant or fall."
    },
    "wise_refusal": "This involves measurement feedback. Moderation doesn't cause harassmentit incentivizes reporting by demonstrating reports lead to action. Platforms without moderation have similar or higher actual harassment but lower reported harassment because users learn reporting is futile. The feedback loop: moderationreporting increasedetection increasemore moderation resources. This makes harassment visible rather than creating it. The measured outcome (reports) differs from true outcome (actual incidents).",
    "gold_rationale": "Measurement feedback, not harm causation. ModerationReporting incentiveReports (Y* measured) while actual harassment (Y) stays same or decreases. Users respond to enforcement by reporting. Platforms without moderation have hidden harassmentlow reports don't mean low incidents. This demonstrates detection biasbetter surveillance increases measured rates without increasing true rates. Proper evaluation requires direct harassment measurement, not report counts.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  },
  {
    "id": "T3-BucketD-0129",
    "case_id": "0129",
    "bucket": "T3-BucketD",
    "pearl_level": "L2",
    "domain": "Technology",
    "subdomain": "Software Development",
    "scenario": "A tech company tracks developers with most code commits as 'top performers.' These developers receive bonuses and promotions based on commit frequency. Within 6 months, code quality declinesmore bugs, fragmented changes, and poor documentation. Developers optimize commit count rather than code quality by breaking work into tiny commits. The metric that originally identified productive developers became useless once incentivized.",
    "claim": "High code commit frequency indicates and causes high developer productivity.",
    "label": "NO",
    "is_ambiguous": false,
    "variables": {
      "X": {
        "name": "Code commit frequency",
        "role": "exposure"
      },
      "Y": {
        "name": "Developer productivity",
        "role": "outcome"
      },
      "Z": [
        "Code quality degradation",
        "Metric gaming",
        "Fragmented commits"
      ]
    },
    "trap": {
      "type": "T16",
      "type_name": "GOODHART'S LAW",
      "subtype": "KPI gaming",
      "subtype_name": "Commit Frequency Loses Meaning When Targeted"
    },
    "difficulty": "Hard",
    "causal_structure": "Before: ProductivityMany commits (correlation). After commits become target: CommitsFragmented workQuality decline. Metric loses predictive value when optimized.",
    "key_insight": "Commit frequency predicted productivity when incidental; once incentivized, developers gamed the metric while quality degraded.",
    "hidden_timestamp": "Is the metric being actively optimized, breaking its relationship to true productivity?",
    "conditional_answers": {
      "answer_if_condition_1": "If commits remain natural work indicators, frequency correlates with productivity.",
      "answer_if_condition_2": "If commits become incentive targets, developers fragment work to maximize commits, breaking the productivity correlation."
    },
    "wise_refusal": "This is Goodhart's Law. Commit frequency originally correlated with productivity because productive developers naturally made many meaningful commits. When commits became incentivized targets, developers optimized the metric rather than productivityfragmenting work into tiny commits, degrading code quality. The measure's predictive value eroded when it became the optimization target. This demonstrates how metrics that work as signals fail as targets.",
    "gold_rationale": "Goodhart's Law in action. Initially: ProductivityCommits (natural correlation). After incentivization: Commits become targetGamingQuality decline. The metric broke when people optimized it rather than the underlying construct. Developers maximized commits through fragmentation rather than productive work. This shows why good observational metrics often fail as incentive targetsgaming behaviors emerge that satisfy the metric while undermining the goal.",
    "initial_author": "Samantha van Rijs",
    "validator": "Samantha van Rijs",
    "final_score": 10.0,
    "validator_2": "Longling Geng",
    "final_score_2": 10.0
  }
]